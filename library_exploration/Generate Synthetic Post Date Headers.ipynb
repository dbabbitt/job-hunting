{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c6d02f-463e-4436-bafd-086f5e6db870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/5.24.2 ========\n",
      "Utility libraries created in 8 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "executable_path = sys.executable; scripts_folder = osp.join(osp.dirname(executable_path), 'Scripts')\n",
    "py_folder = osp.abspath('../py'); ffmpeg_folder = r'C:\\ffmpeg\\bin'\n",
    "if (scripts_folder not in sys.path): sys.path.insert(1, scripts_folder)\n",
    "if (py_folder not in sys.path): sys.path.insert(1, py_folder)\n",
    "if (ffmpeg_folder not in sys.path): sys.path.insert(1, ffmpeg_folder)\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import pyperclip\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f266820-b065-4884-859d-bfc5973d9c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 48,199 labeled parts of speech in here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train the POS Classifiers: 100%|███████████████| 25/25 [00:00<00:00, 354.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is available\n",
      "Parts-of-speech logistic regression model built in 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression model\n",
    "# Parts-of-speech logistic regression model is normally built in 1 hour, 10 minutes and 4 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'): print('predict_single is available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech logistic regression model built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3915da-a1d0-4a8d-9441-844036f8bb27",
   "metadata": {},
   "source": [
    "# Speed/Accuracy Tradeoffs and Synthetic Dataset Generation\n",
    "\n",
    "## Speed vs. Accuracy Tradeoffs\n",
    "- To run the job-hunting pipeline efficiently on a laptop, I had to make **speed vs. accuracy tradeoffs**.\n",
    "- For predicting the category of each `navigable_parent` (HTML navigable text wrapped in its parent tag), I chose **Logistic Regression**:\n",
    "  - Logistic Regression is relatively fast and interpretable.\n",
    "  - It sacrifices some accuracy compared to more complex machine learning models like neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918ad1f-e0f9-4d26-b339-9164c40d88bc",
   "metadata": {},
   "source": [
    "\n",
    "## Training Data Imbalance Challenge\n",
    "- The training data is highly **imbalanced**. For example, when training on **Post Date Headers (H-PD)**:\n",
    "  - I have only **5 examples** of the target class.\n",
    "  - There are **48,123 labeled parts of speech of non-examples**.\n",
    "- This imbalance makes it difficult for the model to learn meaningful patterns for the specific class (H-PD).\n",
    "- As a result, the model may perform poorly when classifying H-PD examples.\n",
    "\n",
    "## Synthetic Dataset Generation with LLMs\n",
    "- To address the training data imbalance, I am generating a **synthetic dataset** using **Large Language Models (LLMs)**:\n",
    "  - I provide the few available examples as input to the LLM.\n",
    "  - I refine the generation process using:\n",
    "    - **Prompt engineering** before generation.\n",
    "    - **Regular expressions** to clean and validate the generated examples post-generation.\n",
    "    - Letting the **Logistic Regression** model pick out the best of the generated examples.\n",
    "- The LLM generates additional synthetic data that resembles the target class (H-PD) closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f67713-fc4c-40e8-92ee-ddc47fc93593",
   "metadata": {},
   "source": [
    "\n",
    "## Speed and LLM Implementation Issues\n",
    "- The synthetic dataset generation process is implemented using **Cohere's API**:\n",
    "  - I haven't exceeded my current quota.\n",
    "  - The offline open source models I have on my laptop are too slow, preventing fast turnaround.\n",
    "- Manually fixing some labels in the training dataset forces me to retrain the POS Classifiers, which takes about 2 hours.\n",
    "\n",
    "## Goals and Future Testing\n",
    "- By combining **Logistic Regression** with **synthetic data augmentation**, I aim to:\n",
    "  - Strike a balance between **speed**, **accuracy**, and **practicality**.\n",
    "  - Improve the overall performance of the machine learning pipeline.\n",
    "- I am assuming adding labeled synthetic `navigable_parent`s significantly enhances model performance without compromising efficiency. I will test when I can find some more examples in the wild."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62c790-ae6a-4fd6-b165-f3339b5ab7c0",
   "metadata": {},
   "source": [
    "\n",
    "## Get some example job posting HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a186cd-2d9b-462e-b04f-a901b594cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>np_count</th>\n",
       "      <th>tagged_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>c0cbfde3d10e39b6_Experimentation_Data_Scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>ce2c3bfeb11aebb9_QA_Engineer_Morris_Plains_NJ_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>f8e9caebfcdaec5c_React_Full_Stack_Developer_Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1008058068135_Systems_Analyst_III.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1681373_Sr_Fullstack_Developer_Bertoni_Solutio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      np_count  tagged_count  edge_count  \\\n",
       "1178        16            16          16   \n",
       "2493         7             7           7   \n",
       "2265         8             8           8   \n",
       "3754         3             3           3   \n",
       "2874         5             5           5   \n",
       "\n",
       "                                              file_name  \n",
       "1178  c0cbfde3d10e39b6_Experimentation_Data_Scientis...  \n",
       "2493  ce2c3bfeb11aebb9_QA_Engineer_Morris_Plains_NJ_...  \n",
       "2265  f8e9caebfcdaec5c_React_Full_Stack_Developer_Re...  \n",
       "3754             1008058068135_Systems_Analyst_III.html  \n",
       "2874  1681373_Sr_Fullstack_Developer_Bertoni_Solutio...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get all at-least-partially tagged file names\n",
    "cypher_str = f'''\n",
    "    // Get the tagged node counts for each file\n",
    "    MATCH (pos:PartsOfSpeech)-[r1:SUMMARIZES]->(np1:NavigableParents)-[r2:NEXT]->(np2:NavigableParents)\n",
    "    WITH\n",
    "        r2.file_name AS file_name,\n",
    "        COUNT(r1) AS tagged_count,\n",
    "        COUNT(r2) AS edge_count,\n",
    "        COUNT(np1) AS np_count\n",
    "    RETURN np_count, tagged_count, edge_count, file_name\n",
    "    ORDER BY edge_count DESC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    tagged_node_counts_df = DataFrame(row_objs_list)\n",
    "    if tagged_node_counts_df.shape[0]:\n",
    "        display(tagged_node_counts_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3718e92e-cb1f-48c2-b5c8-d87bd18e6b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43278</th>\n",
       "      <td>&lt;div class=\"css-tvvxwd ecydgvn1\"&gt;Paid time off...</td>\n",
       "      <td>O-SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47051</th>\n",
       "      <td>&lt;li&gt;Health insurance&lt;/li&gt;</td>\n",
       "      <td>O-SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37219</th>\n",
       "      <td>&lt;li&gt;Day shift&lt;/li&gt;</td>\n",
       "      <td>O-JD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16418</th>\n",
       "      <td>&lt;li&gt;Experience with any or all of the followin...</td>\n",
       "      <td>O-RQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34570</th>\n",
       "      <td>&lt;p&gt;Work Location: Remote&lt;/p&gt;</td>\n",
       "      <td>O-OL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text pos_symbol\n",
       "43278  <div class=\"css-tvvxwd ecydgvn1\">Paid time off...       O-SP\n",
       "47051                          <li>Health insurance</li>       O-SP\n",
       "37219                                 <li>Day shift</li>       O-JD\n",
       "16418  <li>Experience with any or all of the followin...       O-RQ\n",
       "34570                       <p>Work Location: Remote</p>       O-OL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get all POS symbols for the at-least-partially tagged files\n",
    "filenames_list = tagged_node_counts_df.file_name.tolist()\n",
    "filenames_str = '\", \"'.join(filenames_list)\n",
    "cypher_str = f'''\n",
    "    // Get child string and POS for each at-least-partially tagged file\n",
    "    MATCH (pos:PartsOfSpeech)-[r1:SUMMARIZES]->(np1:NavigableParents)-[r2:NEXT]->(np2:NavigableParents)\n",
    "    WHERE\n",
    "        r2.file_name IN [\"{filenames_str}\"]\n",
    "    RETURN\n",
    "        np1.navigable_parent AS text,\n",
    "        pos.pos_symbol AS pos_symbol;'''\n",
    "# print(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    file_tags_df = DataFrame(row_objs_list)\n",
    "    if file_tags_df.shape[0]:\n",
    "        display(file_tags_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c0b5bf-8de6-4215-afd6-f98385a3160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data is highly imbalanced. For example, when training on Interview Procedures Header (H-IP):\n",
      "    I have only 140 examples of the target class.\n",
      "    There are 57,618 labeled parts of speech of non-examples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;b&gt;Application Process&lt;/b&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;b&gt;GS-12&lt;/b&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;HOW TO APPLY&lt;/p&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to join our VIRTUAL team, where we accommodate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;b&gt;(Additional relevant work experience and/or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                         <b>Application Process</b>\n",
       "1                                       <b>GS-12</b>\n",
       "2                                <p>HOW TO APPLY</p>\n",
       "3  to join our VIRTUAL team, where we accommodate...\n",
       "4  <b>(Additional relevant work experience and/or..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get the most unbalance POS symbol\n",
    "min_support_pos_symbol = file_tags_df.groupby('pos_symbol').count().reset_index().rename(columns={'text': 'labeled_count'}).sort_values('labeled_count').iloc[0].pos_symbol\n",
    "min_recall_pos_symbol = nu.load_object('min_recall_pos_symbol')\n",
    "print(f'The training data is highly imbalanced. For example, when training on {hc.POS_EXPLANATION_DICT[min_recall_pos_symbol]} ({min_recall_pos_symbol}):')\n",
    "\n",
    "# Get all summarized child strings\n",
    "cypher_str = f'''\n",
    "    // Get all summarized child strings\n",
    "    MATCH (pos:PartsOfSpeech)-[r1:SUMMARIZES]->(np1:NavigableParents)\n",
    "    WHERE pos.pos_symbol IN [\"{min_recall_pos_symbol}\"]\n",
    "    RETURN DISTINCT np1.navigable_parent AS text;'''\n",
    "# print(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    base_headers = df.text.to_list()\n",
    "    if df.shape[0]:\n",
    "        print(f'    I have only {df.shape[0]:,} examples of the target class.')\n",
    "        print(f'    There are {file_tags_df.shape[0]:,} labeled parts of speech of non-examples.')\n",
    "        display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edda5c-03af-4db6-bfc7-7c3a57727157",
   "metadata": {},
   "source": [
    "\n",
    "## Generate synthetic job posting HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7787022e-1939-4c62-a3e3-80e104903a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output a python list (not a function that generates a list) of job posting HTML examples similar to these Interview Procedures Headers (H-IP):\n",
      "['<b>Application Process</b>', '<b>GS-12</b>', '<p>HOW TO APPLY</p>', 'to join our VIRTUAL team, where we accommodate all US timezones for collaborative mid-day sessions and activities. The person we are looking for will help us develop and commercialize progressive software solutions to BigData challenges. The successful candidate will:', '<b>(Additional relevant work experience and/or education from an accredited college, university or technical school may be substituted.)</b>', \"<p>A qualified candidate's online application and resume must demonstrate at least one year of specialized experience equivalent to the next lower grade level in the Federal service. Specialized experience for these positions are defined as:</p>\", 'For immediate consideration, please send your resume to jbeauliere@matlensilver.com', '<div>The physical demands described below are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to do the following:</div>', '<b>submission notes which job(s) candidate has successfully worked remotely.</b>', '<b>Education cannot be substituted for experience at this grade level.</b>', '<b>Background Check</b>', '<b>How to Apply:</b>', '<b>Mandatory –</b>', '<b>GS-12:</b>', '<b>To Know More:</b>', 'nd share DL with below details.', '<p>*Qualifications may warrant placement in a different job level*</p>', '<p>Learn all about U.S. Bank employee benefits, including tuition reimbursement, retirement plans and more, by visiting careers.usbank.com .</p>', 'Candidates who apply under All U.S. Citizens announcements will be rated and ranked using Category Rating procedures. Qualified candidates will be assigned to a quality category. The categories are defined as follows:', 'HIRING SPECIFICS', '<b>Please submit the following documents:</b>', '<b>GS-14</b>', '<b>Important Notes:</b>', '<b>How to Apply</b>', '<p>You will be evaluated for this job based on how well you meet the qualifications above.</p>', '<b>Pre-requisite checklist/expectations from the candidate before sharing the relevant profile:</b>', 'Visa Sponsorship Information:', '<b>Survey Statistician, GS-1530-13, FPL 13</b>', '<b>CRITICAL NOTES:</b>', '<b>Detailed Job Description:</b>', '<b>Job Disclaimer:</b>', '<p>This job description will be reviewed periodically and is subject to change by management.</p>', '<b>If selected, official transcripts may be requested.</b>', '<b>This position has a positive education requirement.</b>', '<b>About this opportunity:</b>', 'Note:', '<em>We do not work with 3rd party employers. Visa Sponsorship NOT available</em>', '<div>Applicant Notes:</div>', '<span class=\"css-kyg8or eu4oa1w0\">Posted 1 day ago</span>', '<p>KPMG is currently seeking a Manager to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics.</p>', '<b>You must submit a</b>', '<b>Job Details:</b>', '<b>Referral</b>', '<b>Senior-level:</b>', 'Must have experience developing test plans and test procedures.', \"<strong>What's Next:</strong>\", '<b>IN DESCRIBING YOUR EXPERIENCE, PLEASE BE CLEAR AND SPECIFIC</b>', '<b>Delmock Technologies Inc’s</b>', 'For more relevant job opportunities please visit our website:', '<b>Disclaimer</b>', '<b>What to expect in the hiring process:</b>', 'CRITICAL NOTES:', '<p>Learn more at www.verndale.com</p>', '<b>resume</b>', '<b>The Right Fit for You:</b>', '<b>Entry-level:</b>', '<b>Persons with Disabilities:</b>', '<p>While an advanced degree is not required, we seek passionate technologists who possess both technical and soft skills to excel on our team. Our selection process is designed to assess the whole candidate and foster a mutual match for you and us. The process includes:</p>', '<b>Want more info?</b>', '<b>American Community Survey Office</b>', '<b>supporting your specialized experience and responses to the online questionnaire.</b>', '<b>Applicants must meet all qualification requirements by the closing date of this announcement.</b>', '<b>Required Documents:</b>', 'The scored occupational questionnaire will evaluate you on the following competencies; please do not provide a separate written response:', '<div>Required application materials (preferably in PDF Format):</div>', '<b>Note:</b>', \"<p>We are focused on building a diverse and inclusive workforce. If you're excited about this role, but do not meet 100% of the qualifications listed above, we encourage you to apply.</p>\", 'Please apply here or email me directly with you resume and any of the qualifications you DO NOT have - at', '<b>Veterans:</b>', '<b>: (Be specific in describing your experience in your application. Ensure the descriptions provided illustrate your competencies, specifically addressing the required and preferred qualifications.):</b>', 'You must have one year of experience at a level of difficulty and responsibility equivalent to the', '<b>Onboarding duration –</b>', \"<b>Want to learn more about Berkeley Lab's Culture, Benefits and answers to FAQs? Please visit:</b>\", '<b>Your application to this posting may potentially be considered for multiple positions within this group.</b>', \"The following job is now available and potentially matches your skills. I'd like to work with you in finding your next dream assignment, whether it is this position or another one of our thousands of\", 'AND', '<b>GS-13:</b>', '<b>Colorado, Connecticut, Nevada, or New York City Residents Only:</b>', '<b>Mid-level:</b>', '<b>Key words to search for the candidate</b>', 'Some things we think you should know', 'that you find value in our e-mail notifications as you continue to consider options for your professional career.', '<b>CTAP/ICTAP candidates:</b>', '<span style=\"font-size:11.0pt\">If you’re interested, please provide below details:</span>', 'To be considered \"well qualified\" you must meet all of the requirements as described in this section.', 'experience OR demonstrated ability to meet the job requirements through a', '<p>The following links provide information on various hiring authorities that may enable you to apply through merit assignment procedures, or be eligible for a non-competitive appointment.</p>', '<b>Conditions of Employment:</b>', '<span lang=\"EN\">Want to learn more? Apply today!</span>', '<b>GS-11</b>', 'For further consideration, please apply on at', '<b>The fine print:</b>', '<b>GS-15:</b>', \"This is the first question they'll confirm during the first call and quickly reject if not.\", '<p>COVID-19 Precaution(s):</p>', '<b>We recommend that you preview the online questions for this announcement before you start the application process.</b>', '<b>Learn more by visiting:</b>', 'COVID-19 Considerations:', '<b>GS-13</b>', '<strong>Note</strong>', '<b>Please be prepared to answer the following questions before the interview:</b>', '<b>You must meet the Basic Requirement listed in the Education Requirements section below and/or \"Specialized Experience\" to qualify for this series as described below.</b>', '<b>Interview Process:</b>', '<b>Notes:</b>', '<b>Screening of Applications Begins:</b>', '<strong>Want to learn more?</strong>', '<p>Application Question(s):</p>', '<p>The specialized experience listed are the minimum requirements for the series, each particular vacancy may have additional experience necessary to meet the applicable grade level.</p>', '<h2 class=\"iCIMS_SubHeader iCIMS_SubHeader_Job\">Options</h2>', '<p>What to Expect Next</p>', '<b>Grade 13</b>', '<p>For more information about TTEC, visit ttecjobs.com or search #ExperienceTTEC throughout social media to engage in the global conversation</p>', '<b>Become a part of the ADI community:</b>', ', Senior Recruiter Stan Blackwell (sblackwell@delmock.com / 410-218-0900) would love to speak with you regarding the following position:', '<b>What happens after you apply?</b>', 'Required', '<b>If specific educational requirements are indicated for this vacancy:</b>', '<b>GS-14:</b>', '<b>What Else You Need to Know</b>', 'experience.', 'Education must be obtained from an accredited institution recognized by the U.S. Department of Education.', \"This vacancy is advertised under 2 different announcements. Please read the 'Who May Apply' section carefully to determine your eligibility. If you are not eligible under this announcement, please see\", '<li>Experience - multiple levels can be accommodated:</li>', '<b>ALL APPLICANTS:</b>', '<b>OPM Qualification Standards for the GS-1530 series can be found at the following website:</b>', 'Therefore, you', '<p>Candidates will be selected based on their qualifications and matched to a specific project based on their skills and interests.</p>', '<b>LINKS</b>', '<p>If there s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants .</p>', ', or by email at TAhelp@indeed.com at least one week in advance of your interview.', '<b>Hello,</b>', 'You will be rated on the following Competencies as part of the assessment questionnaire for this position:', 'positions within the Census Bureau in the same geographical location with the same qualifications and specialized experience.', '<b>Grade 12</b>', '2-step (phone and in-person panel)', '<p>Please include a cover letter. We encourage candidates to visit our website at www.ohmconnect.com to learn more about us.</p>', 'Application Notes:', '<b>ARE YOU READY TO CONTRIBUTE TO THE FUTURE OF VIDEO, DIGITAL MEDIA AND ECOMMERCE?</b>', '<b>Questions that need answered</b>', \"<i>These are the desired skills for our team (it's okay if you don't have them all; apply anyways!)</i>\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cohere\n",
    "\n",
    "# Initialize the Cohere client\n",
    "co_key = wsu.secrets_json['Cohere_API_Key']\n",
    "co = cohere.Client(co_key)\n",
    "\n",
    "# Define the base headers for Post Date Headers\n",
    "prompt = f\"Output a python list (not a function that generates a list) of job posting HTML examples similar to these {hc.POS_EXPLANATION_DICT[min_recall_pos_symbol]}s ({min_recall_pos_symbol}):\\n\" + str(base_headers)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9105c78-5d63-4c59-bce2-45daa98b6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "element_strs_set = set([\n",
    "    ''\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04f18018-7cb2-418f-9c25-f5f24d91d144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter model is not a valid field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Python list of job posting HTML examples similar to the provided Post Date Headers (H-PD):\n",
      "\n",
      "```python\n",
      "job_posting_html_examples = [\n",
      "    '<h3>Posted on:</h3>',\n",
      "    '<strong>Date Posted:</strong>',\n",
      "    '<p>Job Posted: </p>',\n",
      "    '<div class=\"post-date\">Date: </div>',\n",
      "    '<span>Posted: </span>',\n",
      "    '<label>Post Date:</label>',\n",
      "    '<b>Job Ad Date:</b>',\n",
      "    '<i>Posted</i>',\n",
      "    '<div>Application Deadline: </div>',\n",
      "    '<p>Application Due: </p>'\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate synthetic headers\n",
    "response = co.generate(\n",
    "    prompt=prompt,\n",
    "    model='command-xlarge-nightly',\n",
    "    num_generations=5,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    ")\n",
    "generation_texts_list = [cohere_generation_obj.text for cohere_generation_obj in response.generations]\n",
    "print(max(generation_texts_list, key=lambda x: len(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b76b3a6-32a5-488c-9cb4-de55308bc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for generation_text in generation_texts_list:\n",
    "    # display(generation_text)\n",
    "    element_strs_list = re.findall(r\"\"\"['`]([^\\\\'`\\]\\[]+)['`],?\"\"\", generation_text)\n",
    "    for element_str in element_strs_list:\n",
    "        html_str = element_str.strip('\\'`').strip()\n",
    "        if html_str.startswith('<') or html_str.endswith('>'):\n",
    "            html_str = hau.get_navigable_children(hau.get_body_soup(html_str), [])[0].strip()\n",
    "\n",
    "            # Disqualify text surrounded by inline elements\n",
    "            if not any(map(lambda pe: html_str.endswith(f'</{pe}>'), cu.inline_elements_set)):\n",
    "                element_strs_set.add(html_str)\n",
    "        else:\n",
    "            element_strs_set.add(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e45ade7-65c8-4b94-9a09-fbeaf2e5b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-PD: <b>Announcement Date:</b>\n",
      "H-PD: <b>Commencement Date:</b>\n",
      "H-PD: <b>Job Posting Date:</b>\n",
      "H-PD: <b>Launch Date:</b>\n",
      "H-PD: <b>Post Date:</b>\n",
      "H-PD: <b>Update Date:</b>\n",
      "H-PD: <div>Date Published</div>\n",
      "H-PD: <div>Job Posting Details</div>\n",
      "H-PD: <h3>Job Posting Date:</h3>\n",
      "H-PD: <h4>Job Posting</h4>\n",
      "H-PD: <label>Job Posting</label>\n",
      "H-PD: <p>Job Posting Date:</p>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the HTML that the classifier thinks looks good\n",
    "db_pos_list = []\n",
    "child_strs_list = sorted(element_strs_set)\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list, verbose=False)\n",
    "for navigable_parent, db_pos_symbol in zip(child_strs_list, db_pos_list):\n",
    "    if db_pos_symbol and ('-' in db_pos_symbol):\n",
    "        # print(f'*{db_pos_symbol}: {navigable_parent}')\n",
    "        continue\n",
    "    else:\n",
    "        assert hasattr(slrcu, 'pos_predict_percent_fit_dict'), 'slrcu.predict_single needs to be available'\n",
    "        pr_pos_symbol = slrcu.predict_single(navigable_parent)\n",
    "        if pr_pos_symbol == min_recall_pos_symbol:\n",
    "            print(f'{pr_pos_symbol}: {navigable_parent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c792255-232c-46ee-9196-3d88183a994b",
   "metadata": {},
   "source": [
    "\n",
    "## Add (pos:PartsOfSpeech)-[r:SUMMARIZES]->(np:NavigableParents) pairs to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfdabce2-e96a-43d0-b182-9d63bd3b47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take these hand-picked HTML strings and add them to the database\n",
    "from IPython.display import clear_output\n",
    "\n",
    "child_strs_list = [\n",
    "    '<b>Advertisement Date</b>', '<b>Announced On:</b>', '<b>Announcement Date:</b>', '<b>Announcement Date</b>', '<b>Announcement Release Date:</b>',\n",
    "    '<b>Commencement Date:</b>', '<b>Date Announced:</b>', '<b>Date Posted:</b>', '<b>Date Updated:</b>', '<b>Date of Advertisement:</b>',\n",
    "    '<b>Date of Posting:</b>', '<b>Date of Publication:</b>', '<b>Effective From:</b>', '<b>Job Ad Date:</b>', '<b>Job Advertisement:</b>',\n",
    "    '<b>Job Posted On:</b>', '<b>Job Posted:</b>', '<b>Job Posting :</b>', '<b>Job Posting Date:</b>', '<b>Job Posting</b>', '<b>Last Updated:</b>',\n",
    "    '<b>Launch Date:</b>', '<b>Post Date:</b>', '<b>Post Date</b>', '<b>Posted On:</b>', '<b>Posted on:</b>', '<b>Publication Date:</b>',\n",
    "    '<b>Published on:</b>', '<b>Recent Posting:</b>', '<b>Recent Update</b>', '<b>Release Date:</b>', '<b>Time of Posting:</b>',\n",
    "    '<b>Update Date:</b>', '<div class=\"job-date\">Posted on</div>', '<div class=\"job-meta\">Posted on</div>',\n",
    "    '<div class=\"job-posting-date\">Posted</div>', '<div class=\"post-date\">Date:</div>', '<div class=\"post-date\">Posted on</div>',\n",
    "    '<div class=\"post-date\">Posted:</div>', '<div class=\"post-date\">Posted</div>', '<div>Date Posted</div>', '<div>Date Published:</div>',\n",
    "    '<div>Date Published</div>', '<div>Date of Publication</div>', '<div>Job Posted:</div>', '<div>Published</div>', '<div>Update Date</div>',\n",
    "    '<h3>Date Posted:</h3>', '<h3>Date Posted</h3>', '<h3>Job Posted on:</h3>', '<h3>Job Posting Date:</h3>', '<h3>Post Date</h3>', '<h3>Posted on:</h3>',\n",
    "    '<h3>Publication</h3>', '<h4>Job Posting</h4>', '<label>Job Listing Date:</label>', '<label>Job Posting</label>', '<label>Post Date:</label>',\n",
    "    '<label>Posted:</label>', '<label>Published:</label>', '<p>Date Posted:</p>', '<p>Date Published:</p>', '<p>Date of Publication:</p>',\n",
    "    '<p>Job Posted:</p>', '<p>Job Posting Date:</p>', '<p>Post Date</p>', '<p>Posted Date:</p>', 'Available From:', 'Job Posted:', 'Posted', 'Posted on:',\n",
    "    'Published on:', 'We posted this job on', 'date-posted', 'post-date'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e3b8186-ec77-4f9c-b561-b998016eebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            // Set the characteristics of the navigable_parent\n",
      "            MERGE (np:NavigableParents {navigable_parent: \"post-date\"})\n",
      "            SET\n",
      "                np.is_job_title = false,\n",
      "                np.is_corporate_scope = false,\n",
      "                np.is_task_scope = false,\n",
      "                np.is_minimum_qualification = false,\n",
      "                np.is_preferred_qualification = false,\n",
      "                np.is_supplemental_pay = false,\n",
      "                np.is_office_location = false,\n",
      "                np.is_job_duration = false,\n",
      "                np.is_interview_procedure = false,\n",
      "                np.is_legal_notification = false,\n",
      "                np.is_other = false,\n",
      "                np.is_posting_date = true,\n",
      "                np.is_header = true\n",
      "            RETURN\n",
      "                np.navigable_parent AS navigable_parent,\n",
      "                np.is_posting_date AS is_np_posting_date,\n",
      "                np.is_header AS is_np_header;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navigable_parent</th>\n",
       "      <th>is_np_posting_date</th>\n",
       "      <th>is_np_header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post-date</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  navigable_parent  is_np_posting_date  is_np_header\n",
       "0        post-date                True          True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Take the hand-picked HTML strings and add their characteristics to the database\n",
    "for child_str in child_strs_list:\n",
    "    def create_characteristics(tx, navigable_parent, verbose=True):\n",
    "        cypher_str = '''\n",
    "            // Set the characteristics of the navigable_parent\n",
    "            MERGE (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "            SET\n",
    "                np.is_job_title = false,\n",
    "                np.is_corporate_scope = false,\n",
    "                np.is_task_scope = false,\n",
    "                np.is_minimum_qualification = false,\n",
    "                np.is_preferred_qualification = false,\n",
    "                np.is_supplemental_pay = false,\n",
    "                np.is_office_location = false,\n",
    "                np.is_job_duration = false,\n",
    "                np.is_interview_procedure = false,\n",
    "                np.is_legal_notification = false,\n",
    "                np.is_other = false,\n",
    "                np.is_posting_date = true,\n",
    "                np.is_header = true\n",
    "            RETURN\n",
    "                np.navigable_parent AS navigable_parent,\n",
    "                np.is_posting_date AS is_np_posting_date,\n",
    "                np.is_header AS is_np_header;'''\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(cypher_str.replace('$navigable_parent', f'\"{navigable_parent}\"'))\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    row_objs_list = []\n",
    "    with cu.driver.session() as session:\n",
    "        row_objs_list = session.write_transaction(create_characteristics, navigable_parent=child_str)\n",
    "    if row_objs_list:\n",
    "        df = DataFrame(row_objs_list)\n",
    "        if df.shape[0]:\n",
    "            display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2edc5a26-ecf2-4b2b-93ac-4e8de9855fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            // Remove the SUMMARIZES relationships that are not pos_symbol\n",
      "            MATCH (pos:PartsOfSpeech)-[r:SUMMARIZES]->(np:NavigableParents {navigable_parent: \"post-date\"})\n",
      "            WHERE NOT (pos.pos_symbol = \"H-PD\")\n",
      "            DELETE r\n",
      "            RETURN pos, r, np;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Take the hand-picked HTML strings and remove their bad relationships to the database\n",
    "for child_str in child_strs_list:\n",
    "    def remove_relationships(tx, navigable_parent, pos_symbol, verbose=True):\n",
    "        cypher_str = '''\n",
    "            // Remove the SUMMARIZES relationships that are not pos_symbol\n",
    "            MATCH (pos:PartsOfSpeech)-[r:SUMMARIZES]->(np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "            WHERE NOT (pos.pos_symbol = $pos_symbol)\n",
    "            DELETE r\n",
    "            RETURN pos, r, np;'''\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(cypher_str.replace('$navigable_parent', f'\"{navigable_parent}\"').replace('$pos_symbol', f'\"{pos_symbol}\"'))\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent, 'pos_symbol': pos_symbol})]\n",
    "    row_objs_list = []\n",
    "    with cu.driver.session() as session:\n",
    "        row_objs_list = session.write_transaction(remove_relationships, navigable_parent=child_str, pos_symbol=min_recall_pos_symbol)\n",
    "    if row_objs_list:\n",
    "        df = DataFrame(row_objs_list)\n",
    "        if df.shape[0]:\n",
    "            display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d4fbf14-57a1-4f93-90ca-91f39a1818df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            // Create a SUMMARIZES relationship if it doesn't already exist\n",
      "            MATCH (pos:PartsOfSpeech {pos_symbol: \"H-PD\"})\n",
      "            MATCH (np:NavigableParents {navigable_parent: \"post-date\"})\n",
      "            MERGE (pos)-[r:SUMMARIZES]->(np)\n",
      "            RETURN\n",
      "                pos.pos_explanation AS pos_explanation,\n",
      "                pos.pos_symbol AS pos_symbol,\n",
      "                pos.is_posting_date AS is_pos_posting_date,\n",
      "                pos.is_header AS is_pos_header,\n",
      "                type(r) AS relationship_type,\n",
      "                np.navigable_parent AS navigable_parent,\n",
      "                np.is_posting_date AS is_np_posting_date,\n",
      "                np.is_header AS is_np_header;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pos_explanation</th>\n",
       "      <td>Post Date Header</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_symbol</th>\n",
       "      <td>H-PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pos_posting_date</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pos_header</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_type</th>\n",
       "      <td>SUMMARIZES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>navigable_parent</th>\n",
       "      <td>post-date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_np_posting_date</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_np_header</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "pos_explanation      Post Date Header\n",
       "pos_symbol                       H-PD\n",
       "is_pos_posting_date              True\n",
       "is_pos_header                    True\n",
       "relationship_type          SUMMARIZES\n",
       "navigable_parent            post-date\n",
       "is_np_posting_date               True\n",
       "is_np_header                     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Take the hand-picked HTML strings and add the correct relationships\n",
    "for child_str in child_strs_list:\n",
    "    def create_relationship(tx, navigable_parent, pos_symbol, verbose=True):\n",
    "        cypher_str = '''\n",
    "            // Create a SUMMARIZES relationship if it doesn't already exist\n",
    "            MATCH (pos:PartsOfSpeech {pos_symbol: $pos_symbol})\n",
    "            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "            MERGE (pos)-[r:SUMMARIZES]->(np)\n",
    "            RETURN\n",
    "                pos.pos_explanation AS pos_explanation,\n",
    "                pos.pos_symbol AS pos_symbol,\n",
    "                pos.is_posting_date AS is_pos_posting_date,\n",
    "                pos.is_header AS is_pos_header,\n",
    "                type(r) AS relationship_type,\n",
    "                np.navigable_parent AS navigable_parent,\n",
    "                np.is_posting_date AS is_np_posting_date,\n",
    "                np.is_header AS is_np_header;'''\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(cypher_str.replace('$navigable_parent', f'\"{navigable_parent}\"').replace('$pos_symbol', f'\"{pos_symbol}\"'))\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent, 'pos_symbol': pos_symbol})]\n",
    "    row_objs_list = []\n",
    "    with cu.driver.session() as session:\n",
    "        row_objs_list = session.write_transaction(create_relationship, navigable_parent=child_str, pos_symbol=min_recall_pos_symbol)\n",
    "    if row_objs_list:\n",
    "        df = DataFrame(row_objs_list)\n",
    "        if df.shape[0]:\n",
    "            display(df.head(5).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d82f1-f027-4f6c-8377-446b95f6ab97",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1640928d-719a-48ec-adcf-1e15f22783f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "element_strs_set = set(['<b>Advertisement Date</b>', '<b>Announced On:</b>', '<b>Announcement Date:</b>', '<b>Announcement Date</b>', '<b>Announcement Release Date:</b>', '<b>Commencement Date:</b>', '<b>Date Announced:</b>', '<b>Date Posted:</b>', '<b>Date Updated:</b>', '<b>Date of Advertisement:</b>', '<b>Date of Posting:</b>', '<b>Date of Publication:</b>', '<b>Effective From:</b>', '<b>Job Ad Date:</b>', '<b>Job Advertisement:</b>', '<b>Job Posted On:</b>', '<b>Job Posted:</b>', '<b>Job Posting :</b>', '<b>Job Posting Date:</b>', '<b>Job Posting</b>', '<b>Last Updated:</b>', '<b>Launch Date:</b>', '<b>Post Date:</b>', '<b>Post Date</b>', '<b>Posted On:</b>', '<b>Posted on:</b>', '<b>Publication Date:</b>', '<b>Published on:</b>', '<b>Recent Posting:</b>', '<b>Recent Update</b>', '<b>Release Date:</b>', '<b>Time of Posting:</b>', '<b>Update Date:</b>', '<div class=\"job-date\">Posted on</div>', '<div class=\"job-meta\">Posted on</div>', '<div class=\"job-posting-date\">Posted</div>', '<div class=\"post-date\">Date:</div>', '<div class=\"post-date\">Posted on</div>', '<div class=\"post-date\">Posted:</div>', '<div class=\"post-date\">Posted</div>', '<div>Application Deadline:</div>', '<div>Date Posted</div>', '<div>Date Published:</div>', '<div>Date Published</div>', '<div>Date of Publication</div>', '<div>Date:</div>', '<div>Job Posted:</div>', '<div>Job Posting Details</div>', '<div>Published</div>', '<div>Update Date</div>', '<h3>Date Posted:</h3>', '<h3>Date Posted</h3>', '<h3>Job Posted on:</h3>', '<h3>Job Posting Date:</h3>', '<h3>Post Date</h3>', '<h3>Posted on:</h3>', '<h3>Publication</h3>', '<h4>Job Posting</h4>', '<label>Job Listing Date:</label>', '<label>Job Posting</label>', '<label>Post Date:</label>', '<label>Posted:</label>', '<label>Published:</label>', '<p>Application Due:</p>', '<p>Date Posted:</p>', '<p>Date Published:</p>', '<p>Date of Publication:</p>', '<p>Job Posted:</p>', '<p>Job Posting Date:</p>', '<p>Post Date</p>', '<p>Posted Date:</p>', 'Application Deadline:', 'Available From:', 'Date:', 'Job Posted:', 'Posted', 'Posted on:', 'Published on:', 'We posted this job on', 'date-posted', 'post-date'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'''\n",
    "element_strs_set = set({sorted(element_strs_set)})''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e2f4a7-0890-4f3c-b195-08086dab3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all at-least-partially tagged file names\n",
    "cypher_str = '''\n",
    "    // Remove the SUMMARIZES relationships that are not \"O-PD\"\n",
    "    MATCH (pos:PartsOfSpeech)-[r1:SUMMARIZES]->(np1:NavigableParents)\n",
    "    WHERE\n",
    "        np1.navigable_parent IN ['<span class=\"jobsearch-HiringInsights-entry--text\">Posted 7 days ago</span>']\n",
    "        AND NOT (pos.pos_symbol = \"O-PD\")\n",
    "    DELETE r1;'''\n",
    "pyperclip.copy(cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33803fb7-a46e-4ed4-8009-97aec162111c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
