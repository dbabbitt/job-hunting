{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e829f53-af4c-424e-aaad-fb0db1a1b57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c6d02f-463e-4436-bafd-086f5e6db870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/5.24.2 ========\n",
      "Utility libraries created in 5 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "executable_path = sys.executable; scripts_folder = osp.join(osp.dirname(executable_path), 'Scripts')\n",
    "py_folder = osp.abspath('../py'); ffmpeg_folder = r'C:\\ffmpeg\\bin'\n",
    "if (scripts_folder not in sys.path): sys.path.insert(1, scripts_folder)\n",
    "if (py_folder not in sys.path): sys.path.insert(1, py_folder)\n",
    "if (ffmpeg_folder not in sys.path): sys.path.insert(1, ffmpeg_folder)\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import pyperclip\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9105c78-5d63-4c59-bce2-45daa98b6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "element_strs_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "447e3500-39be-4252-8551-a553e961fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter model is not a valid field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some professional examples similar to the given Post Date Headers:\n",
      "\n",
      "- ['<b>Date Posted:</b>', '<b>Date of Publication:</b>', '<b>Posted On:</b>']\n",
      "- ['<b>Application Deadline:</b>', '<b>Closing Date:</b>', '<b>Last Date to Apply:</b>']\n",
      "- ['<b>Date Announced:</b>', '<b>Announcement Date:</b>', '<b>Announced On:</b>']\n",
      "- ['<b>Date Updated:</b>', '<b>Last Updated:</b>', '<b>Update Date:</b>']\n",
      "- ['<b>Release Date:</b>', '<b>Launch Date:</b>', '<b>Product Release:</b>']\n",
      "- ['<b>Effective From:</b>', '<b>Start Date:</b>', '<b>Commencement Date:</b>']\n",
      "- ['<b>Event Date:</b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cohere\n",
    "\n",
    "# Initialize the Cohere client\n",
    "co_key = wsu.secrets_json['Cohere_API_Key']\n",
    "co = cohere.Client(co_key)\n",
    "\n",
    "# Define the base headers for Post Date Headers\n",
    "base_headers = ['<b>Publication Date:</b>', '<b>Job Posting :</b>', '<b>Job Posting</b>', '<div>Published</div>']\n",
    "prompt = \"Generate (in a python list) professional examples similar to these Post Date Headers (H-PD):\\n\" + str(base_headers)\n",
    "\n",
    "# Generate synthetic headers\n",
    "response = co.generate(\n",
    "    prompt=prompt,\n",
    "    model='command-xlarge-nightly',\n",
    "    num_generations=5,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(response.generations[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b76b3a6-32a5-488c-9cb4-de55308bc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cohere_generation_obj in response.generations:\n",
    "    generation_text = cohere_generation_obj.text\n",
    "    # display(generation_text)\n",
    "    element_strs_list = re.findall(r\"\"\"['`]([^\\\\'`\\]\\[]+)['`],?\"\"\", generation_text)\n",
    "    for element_str in element_strs_list:\n",
    "        html_str = element_str.strip('\\'`').strip()\n",
    "        if html_str.startswith('<') or html_str.endswith('>'):\n",
    "            element_strs_set.add(hau.get_navigable_children(hau.get_body_soup(html_str), [])[0].strip())\n",
    "        else:\n",
    "            element_strs_set.add(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e45ade7-65c8-4b94-9a09-fbeaf2e5b403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<b>Advertisement Date</b>', '<b>Announced On:</b>', '<b>Announcement Date:</b>', '<b>Announcement Date</b>', '<b>Application Deadline:</b>', '<b>Closing Date:</b>', '<b>Closing Date</b>', '<b>Commencement Date:</b>', '<b>Date Announced:</b>', '<b>Date Posted:</b>', '<b>Date Updated:</b>', '<b>Date of Posting:</b>', '<b>Date of Publication:</b>', '<b>Date:</b>', '<b>Effective From:</b>', '<b>Job Ad Date:</b>', '<b>Last Date to Apply:</b>', '<b>Last Updated:</b>', '<b>Launch Date:</b>', '<b>Post Date</b>', '<b>Posted On:</b>', '<b>Posted on:</b>', '<b>Posting Date</b>', '<b>Product Release:</b>', '<b>Recent Posting:</b>', '<b>Recent Update</b>', '<b>Release Date:</b>', '<b>Start Date:</b>', '<b>Time Stamp</b>', '<b>Time of Posting:</b>', '<b>Timestamp:</b>', '<b>Update Date:</b>', '<div>Application Date</div>', '<div>Date Posted</div>', '<div>Date Published</div>', '<div>Date of Publication</div>', '<div>Date:</div>', '<div>Date</div>', '<div>Update Date</div>', '<h3>Publication</h3>', '<i>Date</i>', '<i>Job Posted:</i>', '<p>Post Date</p>', '<span>Date Posted</span>', '<span>Post Date</span>', 'Available From:', 'Date:', 'Job Posted:', 'Published on:']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted(element_strs_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d82f1-f027-4f6c-8377-446b95f6ab97",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a97f0f-cd00-48ab-813e-125ea2ca5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "def generate_post_date_headers(api_key, base_headers, num_variations=10):\n",
    "    \"\"\"\n",
    "    Generate synthetic variations for Post Date Headers (H-PD) using an LLM.\n",
    "\n",
    "    Args:\n",
    "        api_key (str): OpenAI API key for authenticating requests.\n",
    "        base_headers (list): List of existing Post Date Headers to use as reference.\n",
    "        num_variations (int): Number of synthetic headers to generate.\n",
    "\n",
    "    Returns:\n",
    "        list: Combined list of base headers and generated synthetic headers.\n",
    "    \"\"\"\n",
    "    # Validate the input\n",
    "    if not isinstance(base_headers, list) or not all(isinstance(header, str) for header in base_headers):\n",
    "        raise ValueError(\"Base headers must be a list of strings.\")\n",
    "    \n",
    "    # Construct the prompt for the LLM\n",
    "    prompt = (\n",
    "        \"Generate unique, creative, and professional examples of Post Date Headers (H-PD) \"\n",
    "        \"similar to the following examples:\\n\"\n",
    "        f\"{base_headers}\\n\"\n",
    "        \"The output should be a list of headers formatted like the examples provided. \"\n",
    "        \"Make sure they are concise, relevant, and follow a similar structure.\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Set the OpenAI API key\n",
    "        openai.api_key = api_key\n",
    "\n",
    "        # Call the OpenAI API to generate text\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=150,\n",
    "            n=1,\n",
    "            temperature=0.7  # Adjust temperature for creativity\n",
    "        )\n",
    "        \n",
    "        # Extract and clean up the generated text\n",
    "        generated_text = response.choices[0].text.strip()\n",
    "        \n",
    "        # Convert generated text to a list of headers\n",
    "        synthetic_headers = [header.strip() for header in generated_text.split('\\n') if header.strip()]\n",
    "        \n",
    "        # Combine base headers with the synthetic ones\n",
    "        return base_headers + synthetic_headers[:num_variations]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating synthetic headers: {e}\")\n",
    "        return base_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4789ea7-b556-4d6e-a034-d2811b40af0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while generating synthetic headers: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "['<b>Publication Date:</b>', '<b>Job Posting :</b>', '<b>Job Posting</b>', '<div>Published</div>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "synthetic_headers = generate_post_date_headers(api_key, base_headers, num_variations=10)\n",
    "print(synthetic_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047d2fda-a790-4731-a8a8-67edd8d048d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01d8930362142a99fac5d143de81669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\daveb\\.cache\\huggingface\\hub\\models--EleutherAI--gpt-neo-125M. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81049e0ecff845828783fee990426438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a37ab8c9c34685b0cd157f871583ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6d418c809b46a8afa8e50586a83389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d081ff9799343e0812a6d09714c5077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cda13802e24dddab8829ad8d850098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ef46c80a094ccb81100de4acff267d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472a8f0de115464d9842b2001bfc65ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate professional examples of Post Date Headers:\n",
      "['<b>Publication Date:</b>', '<b>Job Posting :</b>', '<b>Job Posting</b>', '<div>Published</div>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate professional examples of Post Date Headers:\n",
      "['<b>Publication Date:</b>', '<b>Job Posting :</b>', '<b>Job Posting</b>', '<div>Published</div>']\n",
      "\n",
      "I have a list of all the Post Date Headers that I want to create. I have a list of all the Post Date Headers that I want to create. I have a list of all the Post Date\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained model pipeline for text generation\n",
    "generator = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-125M\")\n",
    "\n",
    "# Define a prompt to generate post date headers\n",
    "prompt = f\"Generate professional examples of Post Date Headers:\\n{base_headers}\"\n",
    "print(prompt)\n",
    "\n",
    "# Generate synthetic headers\n",
    "results = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "print(results[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640928d-719a-48ec-adcf-1e15f22783f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
