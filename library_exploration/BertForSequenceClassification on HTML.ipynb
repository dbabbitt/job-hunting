{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3776e6-4e2c-4a20-b08e-bbd53c974ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/5.24.2 ========\n",
      "Utility libraries created in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "if (osp.join(os.pardir, 'py') not in sys.path): sys.path.insert(1, osp.join(os.pardir, 'py'))\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bba0c-0164-47b8-82c7-9b849f6b1890",
   "metadata": {},
   "source": [
    "\n",
    "How do I pretrain an encoder model that has for its labeled training data HTML text surrounded by its parent HTML tag (if any) labeled with one of these categories: Job Title, Corporate Scope, Task Scope, Educational Requirements, Minimum Qualifications, Preferred Qualifications, Supplemental Pay, Legal Notifications, Office Location, Job Duration, Interview Procedures, Other, and Posting Date (Header or Non-header)? For instance, the navigable_parent \"&lt;li>Troubleshooting and triaging issues with multiple teams to drive towards root cause identification and resolution.&lt;/li>\" would be labeled \"O-TS\" (Task Scope Non-header)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c435f5e-17a0-4167-8205-40b3a55ccb85",
   "metadata": {},
   "source": [
    "\n",
    "To pretrain an encoder model for this task, you can follow these steps:\n",
    "\n",
    "1. Data Preparation:\n",
    "   - Ensure your dataset consists of HTML text snippets with their corresponding parent tags.\n",
    "   - Create a label mapping for your categories. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297794d1-fb87-4f8e-858f-9f4756d5b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_mapping = {\n",
    "     'Job Title': 'JT',\n",
    "     'Corporate Scope': 'CS',\n",
    "     'Task Scope': 'TS',\n",
    "     'Educational Requirements': 'ER',\n",
    "     'Minimum Qualifications': 'RQ',\n",
    "     'Preferred Qualifications': 'PQ',\n",
    "     'Supplemental Pay': 'SP',\n",
    "     'Legal Notifications': 'LN',\n",
    "     'Office Location': 'OL',\n",
    "     'Job Duration': 'JD',\n",
    "     'Interview Procedures': 'IP',\n",
    "     'Other': 'OT',\n",
    "     'Posting Date': 'PD'\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f8104-3f25-44bb-b446-192cae73c163",
   "metadata": {},
   "source": [
    "\n",
    "1. Data Preparation (continued):\n",
    "   - Add a prefix 'H-' for header and 'O-' for non-header items.\n",
    "\n",
    "2. Tokenization:\n",
    "   - Use a tokenizer that can handle HTML tags (e.g., a custom tokenizer or adapt an existing one like BERT's tokenizer).\n",
    "   - Ensure the tokenizer preserves the HTML structure.\n",
    "\n",
    "3. Model Architecture:\n",
    "   - Choose a suitable encoder architecture (e.g., BERT, RoBERTa, or a custom transformer-based model).\n",
    "   - Modify the final layer to output predictions for your specific categories.\n",
    "\n",
    "4. Pretraining Objective:\n",
    "   - Use a combination of masked language modeling (MLM) and sequence classification.\n",
    "   - For MLM, randomly mask some tokens and train the model to predict them.\n",
    "   - For sequence classification, use the labeled data to train the model to predict the correct category.\n",
    "\n",
    "5. Training Process:\n",
    "   - Implement the training loop, including:\n",
    "     - Batching the data\n",
    "     - Applying MLM\n",
    "     - Computing loss for both MLM and classification tasks\n",
    "     - Backpropagation and optimization\n",
    "\n",
    "Here's a basic outline of how you might implement this in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d265a34-4f83-41a4-b445-7d5402f5940a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>np_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>temp_Statistician_(Data_Scientist)_12_month_Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>Statistician_(Data_Scientist)_12_month_Roster_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>Statistician_(Data_Scientist)_12_month_Roster_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>Senior_Data_Scientist–Statistics_and_Machine_L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>548ece40cf23703d_Information_Technology_Cybers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Automation_Engineer_Remote_ISite_Technologies_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Sr._AI_Data_Science_Engineer_-_Minneapolis,_MN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NATURAL_LANGUAGE_UNDERSTANDING_AND_MACHINE_LEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ea38cd78e8491710_Applied_Machine_Learning_Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6012</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>dd9f8d76cb43a790_Applied_Machine_Learning_Scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      np_count  edge_count                                          file_name\n",
       "0          264         264  temp_Statistician_(Data_Scientist)_12_month_Ro...\n",
       "1          242         242  Statistician_(Data_Scientist)_12_month_Roster_...\n",
       "2          242         242  Statistician_(Data_Scientist)_12_month_Roster_...\n",
       "3          210         210  Senior_Data_Scientist–Statistics_and_Machine_L...\n",
       "4          201         201  548ece40cf23703d_Information_Technology_Cybers...\n",
       "...        ...         ...                                                ...\n",
       "6008         5           5  Automation_Engineer_Remote_ISite_Technologies_...\n",
       "6009         4           4  Sr._AI_Data_Science_Engineer_-_Minneapolis,_MN...\n",
       "6010         3           3  NATURAL_LANGUAGE_UNDERSTANDING_AND_MACHINE_LEA...\n",
       "6011         3           3  ea38cd78e8491710_Applied_Machine_Learning_Scie...\n",
       "6012         3           3  dd9f8d76cb43a790_Applied_Machine_Learning_Scie...\n",
       "\n",
       "[6013 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    // Get the edge and node counts for each file, tag-agnostic\n",
    "    MATCH (np1:NavigableParents)-[r:NEXT]->(np2:NavigableParents)\n",
    "    WITH\n",
    "        r.file_name AS file_name,\n",
    "        COUNT(r) AS edge_count,\n",
    "        COUNT(np1) AS np_count\n",
    "    RETURN np_count, edge_count, file_name\n",
    "    ORDER BY edge_count DESC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    node_counts_df = DataFrame(row_objs_list)\n",
    "    if node_counts_df.shape[0]:\n",
    "        display(node_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a186cd-2d9b-462e-b04f-a901b594cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>np_count</th>\n",
       "      <th>tagged_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>f217ae62af41916b_Senior_Developer_Big_Data_Dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>Statistician_-_Anchorage,_AK_99501_-_Indeed.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>184b817c6eaf7172_Data_Scientist_Remote_Indeed_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>9772f70e3d9f27cd_Python_Web_Developer_Remote_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>14885afaa7bbd01e_Software_Developer_Engineer_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53b28529e19024d9_Geospatial_Analytics_Engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>caed7f6362eed7e1_Lead_Software_Engineer_Backen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7022cb918f8424ec_Senior_Software_Engineer_C_AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>c0139ec70b6a4800_Data_Scientist_Chicago_IL_Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5322</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dc9d3213b84fd191_Principle_Predictive_Analytic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5323 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      np_count  tagged_count  edge_count  \\\n",
       "0          104           104         104   \n",
       "1           96            96          96   \n",
       "2           95            95          95   \n",
       "3           94            94          94   \n",
       "4           92            92          92   \n",
       "...        ...           ...         ...   \n",
       "5318         1             1           1   \n",
       "5319         1             1           1   \n",
       "5320         1             1           1   \n",
       "5321         1             1           1   \n",
       "5322         1             1           1   \n",
       "\n",
       "                                              file_name  \n",
       "0     f217ae62af41916b_Senior_Developer_Big_Data_Dev...  \n",
       "1     Statistician_-_Anchorage,_AK_99501_-_Indeed.co...  \n",
       "2     184b817c6eaf7172_Data_Scientist_Remote_Indeed_...  \n",
       "3     9772f70e3d9f27cd_Python_Web_Developer_Remote_I...  \n",
       "4     14885afaa7bbd01e_Software_Developer_Engineer_i...  \n",
       "...                                                 ...  \n",
       "5318  53b28529e19024d9_Geospatial_Analytics_Engineer...  \n",
       "5319  caed7f6362eed7e1_Lead_Software_Engineer_Backen...  \n",
       "5320  7022cb918f8424ec_Senior_Software_Engineer_C_AI...  \n",
       "5321  c0139ec70b6a4800_Data_Scientist_Chicago_IL_Ind...  \n",
       "5322  dc9d3213b84fd191_Principle_Predictive_Analytic...  \n",
       "\n",
       "[5323 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    // Get the tagged node counts for each file\n",
    "    MATCH (pos:PartsOfSpeech)-[r1:SUMMARIZES]->(np1:NavigableParents)-[r2:NEXT]->(np2:NavigableParents)\n",
    "    WITH\n",
    "        r2.file_name AS file_name,\n",
    "        COUNT(r1) AS tagged_count,\n",
    "        COUNT(r2) AS edge_count,\n",
    "        COUNT(np1) AS np_count\n",
    "    RETURN np_count, tagged_count, edge_count, file_name\n",
    "    ORDER BY edge_count DESC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    tagged_node_counts_df = DataFrame(row_objs_list)\n",
    "    if tagged_node_counts_df.shape[0]:\n",
    "        display(tagged_node_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a71265a-bfdc-45e0-9336-75dd8785530e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>np_count_untagged</th>\n",
       "      <th>edge_count_untagged</th>\n",
       "      <th>file_name</th>\n",
       "      <th>np_count_tagged</th>\n",
       "      <th>tagged_count</th>\n",
       "      <th>edge_count_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>14885afaa7bbd01e_Software_Developer_Engineer_i...</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>Senior_Cloud_Data_Engineer_Texas_Indeed_com.html</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>Senior_Cloud_Data_Engineer_Salem_OR_97302_Inde...</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>Senior_Cloud_Data_Engineer_Oregon_Indeed_com.html</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>86cf17672d5bf560_Senior_Cloud_Data_Engineer_Sa...</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4656009_Accenture_CIO_62812_439400_Data_Scient...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4656043_Accenture_CIO_62812_439399_Data_Scient...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4656042_Accenture_CIO_62812_439276_Data_Scient...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>297b0a7515e65134_Big_Data_Developer_Pittsburgh...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Remote_Programmer_Frederick_MD_21703_Indeed_co...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      np_count_untagged  edge_count_untagged  \\\n",
       "162                  92                   92   \n",
       "186                  89                   89   \n",
       "187                  89                   89   \n",
       "188                  89                   89   \n",
       "189                  89                   89   \n",
       "...                 ...                  ...   \n",
       "5250                 15                   15   \n",
       "5251                 15                   15   \n",
       "5252                 15                   15   \n",
       "5257                 14                   14   \n",
       "5310                 10                   10   \n",
       "\n",
       "                                              file_name  np_count_tagged  \\\n",
       "162   14885afaa7bbd01e_Software_Developer_Engineer_i...               92   \n",
       "186    Senior_Cloud_Data_Engineer_Texas_Indeed_com.html               89   \n",
       "187   Senior_Cloud_Data_Engineer_Salem_OR_97302_Inde...               89   \n",
       "188   Senior_Cloud_Data_Engineer_Oregon_Indeed_com.html               89   \n",
       "189   86cf17672d5bf560_Senior_Cloud_Data_Engineer_Sa...               89   \n",
       "...                                                 ...              ...   \n",
       "5250  4656009_Accenture_CIO_62812_439400_Data_Scient...               15   \n",
       "5251  4656043_Accenture_CIO_62812_439399_Data_Scient...               15   \n",
       "5252  4656042_Accenture_CIO_62812_439276_Data_Scient...               15   \n",
       "5257  297b0a7515e65134_Big_Data_Developer_Pittsburgh...               14   \n",
       "5310  Remote_Programmer_Frederick_MD_21703_Indeed_co...               10   \n",
       "\n",
       "      tagged_count  edge_count_tagged  \n",
       "162             92                 92  \n",
       "186             89                 89  \n",
       "187             89                 89  \n",
       "188             89                 89  \n",
       "189             89                 89  \n",
       "...            ...                ...  \n",
       "5250            15                 15  \n",
       "5251            15                 15  \n",
       "5252            15                 15  \n",
       "5257            14                 14  \n",
       "5310            10                 10  \n",
       "\n",
       "[68 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = node_counts_df.merge(tagged_node_counts_df, on=['file_name'], suffixes=('_untagged', '_tagged'))\n",
    "mask_series = (df.np_count_untagged == df.np_count_tagged)\n",
    "# filenames_list = df[mask_series].file_name.tolist()\n",
    "df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd73d1b4-9d5e-44ef-883c-1f9b5ed03ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;b&gt;ACCOUNTABILITIES:&lt;/b&gt;</td>\n",
       "      <td>H-TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;These skills will help you succeed in this ...</td>\n",
       "      <td>H-TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;These skills will help you succeed in this ...</td>\n",
       "      <td>H-TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;These skills will help you succeed in this ...</td>\n",
       "      <td>H-TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;These skills will help you succeed in this ...</td>\n",
       "      <td>H-TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57582</th>\n",
       "      <td>&lt;span aria-hidden=\"true\"&gt;|&lt;/span&gt;</td>\n",
       "      <td>O-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57583</th>\n",
       "      <td>&lt;span aria-hidden=\"true\"&gt;|&lt;/span&gt;</td>\n",
       "      <td>O-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57584</th>\n",
       "      <td>&lt;span aria-hidden=\"true\"&gt;|&lt;/span&gt;</td>\n",
       "      <td>O-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57585</th>\n",
       "      <td>&lt;i&gt;Learn why&lt;/i&gt;</td>\n",
       "      <td>O-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57586</th>\n",
       "      <td>&lt;font size=\"2\"&gt;Regards,&lt;/font&gt;</td>\n",
       "      <td>O-O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57587 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text pos_symbol\n",
       "0                               <b>ACCOUNTABILITIES:</b>       H-TS\n",
       "1      <p>These skills will help you succeed in this ...       H-TS\n",
       "2      <p>These skills will help you succeed in this ...       H-TS\n",
       "3      <p>These skills will help you succeed in this ...       H-TS\n",
       "4      <p>These skills will help you succeed in this ...       H-TS\n",
       "...                                                  ...        ...\n",
       "57582                  <span aria-hidden=\"true\">|</span>        O-O\n",
       "57583                  <span aria-hidden=\"true\">|</span>        O-O\n",
       "57584                  <span aria-hidden=\"true\">|</span>        O-O\n",
       "57585                                   <i>Learn why</i>        O-O\n",
       "57586                     <font size=\"2\">Regards,</font>        O-O\n",
       "\n",
       "[57587 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "filenames_list = tagged_node_counts_df.file_name.tolist()\n",
    "filenames_str = '\", \"'.join(filenames_list)\n",
    "cypher_str = f'''\n",
    "    // Get child string and POS for each at-least-partially tagged file\n",
    "    MATCH (pos:PartsOfSpeech)-[r1:SUMMARIZES]->(np1:NavigableParents)-[r2:NEXT]->(np2:NavigableParents)\n",
    "    WHERE\n",
    "        r2.file_name IN [\"{filenames_str}\"]\n",
    "    RETURN\n",
    "        np1.navigable_parent AS text,\n",
    "        pos.pos_symbol AS pos_symbol;'''\n",
    "# print(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    file_tags_df = DataFrame(row_objs_list)\n",
    "    if file_tags_df.shape[0]:\n",
    "        display(file_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d27d8ff6-3d07-4f9c-a8e6-834784e981fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<b>Publication Date:</b>', '<b>Job Posting :</b>', '<b>Job Posting</b>', '<div>Published</div>']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pos_symbol = file_tags_df.groupby('pos_symbol').count().reset_index().rename(columns={'text': 'labeled_count'}).sort_values('labeled_count').iloc[0].pos_symbol\n",
    "cypher_str = f'''\n",
    "    // Get example child strings\n",
    "    MATCH (pos:PartsOfSpeech)-[r1:SUMMARIZES]->(np1:NavigableParents)-[r2:NEXT]->(np2:NavigableParents)\n",
    "    WHERE pos.pos_symbol IN [\"{pos_symbol}\"]\n",
    "    RETURN DISTINCT np1.navigable_parent AS text;'''\n",
    "# print(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    if df.shape[0]:\n",
    "        display(df.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca741d7e-5934-453b-aecf-5e9efa721bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\file_tags_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\file_tags_mapping.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sequence = file_tags_df.pos_symbol.tolist()\n",
    "new_sequence, mapping = nu.convert_strings_to_integers(sequence)\n",
    "file_tags_df['label'] = new_sequence\n",
    "nu.store_objects(file_tags_df=file_tags_df, file_tags_mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca92658d-bb62-4e14-99eb-b12319e840d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import read_pickle\n",
    "\n",
    "file_tags_mapping = read_pickle('../saves/pkl/file_tags_mapping.pkl')\n",
    "file_tags_df = read_pickle('../saves/pkl/file_tags_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e49a55-3e08-497b-8ad6-731faa0eaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "\n",
    "# Custom dataset class\n",
    "class HTMLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            item['text'],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(item['label'], dtype=torch.long)\n",
    "        }\n",
    "model_path = '../saves/models/sequence_classification.model'\n",
    "tokenizer_path = '../saves/tokenizers/sequence_classification.tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a5ce517-b576-49d8-b77f-5ab9e58e3135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Starting training for 10 epochs...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def get_latest_epoch(model_path):\n",
    "    epochs = []\n",
    "    try:\n",
    "        epochs = [int(d.split('-')[-1]) for d in os.listdir(model_path) if d.startswith('epoch-')]\n",
    "    except:\n",
    "        return 0\n",
    "    return max(epochs) if epochs else 0\n",
    "\n",
    "# Model setup\n",
    "num_labels = len(file_tags_mapping)\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "#model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
    "\n",
    "# Tokenizer setup\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "dataset = HTMLDataset(file_tags_df, tokenizer, max_length=128)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 10\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "\n",
    "# Get the latest epoch\n",
    "latest_epoch = get_latest_epoch(model_path)\n",
    "start_epoch = latest_epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9df886d2-dd15-42d2-b3ac-c250796b504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run this only once\n",
    "remaining_epochs_list = list(reversed([epoch for epoch in range(start_epoch, start_epoch + num_epochs)]))\n",
    "remaining_epochs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef499dc5-fcf0-412d-8c04-de7eb0fe6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch = remaining_epochs_list.pop()\n",
    "print(f\"Epoch {epoch}/{start_epoch + num_epochs - 1}\")\n",
    "\n",
    "# Load the model from the latest snapshot or initialize if it's the first epoch\n",
    "if epoch == start_epoch:\n",
    "    if latest_epoch > 0:\n",
    "        model = BertForSequenceClassification.from_pretrained(f\"{model_path}/epoch-{latest_epoch}\")\n",
    "        print(f\"Loaded model from epoch {latest_epoch}\")\n",
    "    else:\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
    "        print(\"Initialized new model\")\n",
    "else:\n",
    "    model = BertForSequenceClassification.from_pretrained(f\"{model_path}/epoch-{epoch-1}\")\n",
    "    print(f\"Loaded model from epoch {epoch-1}\")\n",
    "\n",
    "model.to(device)  # Move model to GPU if available\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "epoch_loss = 0.0\n",
    "num_batches = len(dataloader)\n",
    "\n",
    "# Use tqdm for a progress bar\n",
    "progress_bar = tqdm(dataloader, total=num_batches, desc=f\"Epoch {epoch}\")\n",
    "\n",
    "model.train()\n",
    "for batch in progress_bar:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to GPU if available\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    epoch_loss += loss.item()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Update progress bar description with current loss\n",
    "    progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "# Print average loss for the epoch\n",
    "avg_loss = epoch_loss / num_batches\n",
    "print(f\"Epoch {epoch} completed. Average loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the model after each epoch\n",
    "epoch_dir = f\"{model_path}/epoch-{epoch}\"\n",
    "print(f\"Saving model to {epoch_dir}\")\n",
    "model.save_pretrained(epoch_dir)\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2116b1-e6ac-455c-bd4a-0d167584a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Save the tokenizer\n",
    "print(f\"Saving tokenizer to {tokenizer_path}\")\n",
    "tokenizer.save_pretrained(tokenizer_path)\n",
    "print(\"Tokenizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59303f-90bd-4327-9b16-632034bb7615",
   "metadata": {},
   "source": [
    "\n",
    "Now that I've trained and saved my model and tokenizer, I can use them for inference on new data. Here's how I load and use my saved model and tokenizer:\n",
    "\n",
    "1. First, load the saved model and tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90622afa-abc7-4b51-85c2-8621fcae3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the saved model\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedd72c-a3a0-44a4-9cc6-ecbdc5f04398",
   "metadata": {},
   "source": [
    "\n",
    "2. Create a function to predict the label for a given text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f71bd2a-ec77-4abe-a583-eed6a893d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "def predict_label(text, max_length=128):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Map the predicted class back to its label\n",
    "    reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "    predicted_label = reverse_mapping[predicted_class]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Example usage\n",
    "text = \"<li>Troubleshooting and triaging issues with multiple teams to drive towards root cause identification and resolution.</li>\"\n",
    "predicted_label = predict_label(text)\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a42fe2-3bc0-421a-8bc4-5ab05766ed17",
   "metadata": {},
   "source": [
    "\n",
    "3. I want to process multiple texts at once, so I create a batch prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef9f4d-4d79-412e-a6cf-65c809d344c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_batch(texts, max_length=128):\n",
    "    # Tokenize the input texts\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    # Get the model's predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Get the predicted classes\n",
    "    predicted_classes = torch.argmax(logits, dim=1).tolist()\n",
    "    \n",
    "    # Map the predicted classes back to their labels\n",
    "    reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "    predicted_labels = [reverse_mapping[cls] for cls in predicted_classes]\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "# Example usage\n",
    "texts = [\n",
    "    \"<li>Troubleshooting and triaging issues with multiple teams to drive towards root cause identification and resolution.</li>\",\n",
    "    \"<h2>Job Requirements</h2>\",\n",
    "    \"<p>Bachelor's degree in Computer Science or related field required.</p>\"\n",
    "]\n",
    "predicted_labels = predict_batch(texts)\n",
    "for text, label in zip(texts, predicted_labels):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted label: {label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c77a5-8ac7-44da-81dc-c09c4cc3b020",
   "metadata": {},
   "source": [
    "\n",
    "4. I want to get the probabilities for each class, so I modify the prediction functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a3516-16dd-4db0-9275-7ed6579367c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_labels = model.num_labels\n",
    "print(f\"Number of labels in the model: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd512919-582e-4e3b-bf6d-bd57f0ecd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Mapping:\")\n",
    "for k, v in mapping.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2e0eca4-872f-4ca1-adca-fa9b7a3f089f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "24",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     31\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<li>Troubleshooting and triaging issues with multiple teams to drive towards root cause identification and resolution.</li>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 32\u001b[0m predicted_label, probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_with_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbabilities:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m, in \u001b[0;36mpredict_with_probabilities\u001b[1;34m(text, max_length)\u001b[0m\n\u001b[0;32m     21\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     23\u001b[0m reverse_mapping \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m---> 24\u001b[0m label_probs \u001b[38;5;241m=\u001b[39m {reverse_mapping[i]: prob \u001b[38;5;28;01mfor\u001b[39;00m i, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(probabilities)}\n\u001b[0;32m     26\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(label_probs, key\u001b[38;5;241m=\u001b[39mlabel_probs\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_class, label_probs\n",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     23\u001b[0m reverse_mapping \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m---> 24\u001b[0m label_probs \u001b[38;5;241m=\u001b[39m {\u001b[43mreverse_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m: prob \u001b[38;5;28;01mfor\u001b[39;00m i, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(probabilities)}\n\u001b[0;32m     26\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(label_probs, key\u001b[38;5;241m=\u001b[39mlabel_probs\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_class, label_probs\n",
      "\u001b[1;31mKeyError\u001b[0m: 24"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_with_probabilities(text, max_length=128):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    probabilities = F.softmax(logits, dim=1).squeeze().tolist()\n",
    "    \n",
    "    reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "    label_probs = {reverse_mapping[i]: prob for i, prob in enumerate(probabilities)}\n",
    "    \n",
    "    predicted_class = max(label_probs, key=label_probs.get)\n",
    "    \n",
    "    return predicted_class, label_probs\n",
    "\n",
    "# Example usage\n",
    "text = \"<li>Troubleshooting and triaging issues with multiple teams to drive towards root cause identification and resolution.</li>\"\n",
    "predicted_label, probabilities = predict_with_probabilities(text)\n",
    "print(f\"Predicted label: {predicted_label}\")\n",
    "print(\"Probabilities:\")\n",
    "for label, prob in probabilities.items():\n",
    "    print(f\"{label}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e6b7f-db5e-4f71-865c-2fefa055f5d6",
   "metadata": {},
   "source": [
    "```\r\n",
    "\r\n",
    "These functions allow you to use your trained model for inference on new, unseen data. You can now classify HTML text snippets into your predefined categories.\r\n",
    "\r\n",
    "Remember to preprocess your input data in the same way you did during training. If you applied any specific transformations or cleaning steps to your training data, make sure to apply the same steps to your input data during inference.\r\n",
    "\r\n",
    "Would you like me to explain any part of this process in more detail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5cb135-6780-4826-8aaf-d53417c804d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
