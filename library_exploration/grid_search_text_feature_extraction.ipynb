{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sample pipeline for text feature extraction and evaluation\n",
    "\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset which will be\n",
    "automatically downloaded and then cached and reused for the document\n",
    "classification example.\n",
    "\n",
    "You can adjust the number of categories by giving their names to the dataset\n",
    "loader or setting them to None to get the 20 of them.\n",
    "\n",
    "Here is a sample output of a run on a quad-core machine::\n",
    "\n",
    "  Loading 20 newsgroups dataset for categories:\n",
    "  ['alt.atheism', 'talk.religion.misc']\n",
    "  1427 documents\n",
    "  2 categories\n",
    "\n",
    "  Performing grid search...\n",
    "  pipeline: ['vect', 'tfidf', 'clf']\n",
    "  parameters:\n",
    "  {'clf__alpha': (1.0000000000000001e-05, 9.9999999999999995e-07),\n",
    "   'clf__max_iter': (10, 50, 80),\n",
    "   'clf__penalty': ('l2', 'elasticnet'),\n",
    "   'tfidf__use_idf': (True, False),\n",
    "   'vect__max_n': (1, 2),\n",
    "   'vect__max_df': (0.5, 0.75, 1.0),\n",
    "   'vect__max_features': (None, 5000, 10000, 50000)}\n",
    "  done in 1737.030s\n",
    "\n",
    "  Best score: 0.940\n",
    "  Best parameters set:\n",
    "      clf__alpha: 9.9999999999999995e-07\n",
    "      clf__max_iter: 50\n",
    "      clf__penalty: 'elasticnet'\n",
    "      tfidf__use_idf: True\n",
    "      vect__max_n: 2\n",
    "      vect__max_df: 0.75\n",
    "      vect__max_features: 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import Bunch\n",
    "from time import time\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../load_magic/storage.py\n",
    "s = Storage()\n",
    "navigable_parent_is_header_dict = s.load_object('navigable_parent_is_header_dict')\n",
    "rows_list = [{'navigable_parent': navigable_parent, 'is_header': is_header} for navigable_parent, is_header in navigable_parent_is_header_dict.items()]\n",
    "child_str_df = pd.DataFrame(rows_list)\n",
    "data = Bunch(data=child_str_df.navigable_parent.tolist(), target=child_str_df.is_header.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "fit_estimators_dict = s.load_object('fit_estimators_dict')\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(**{'analyzer': 'char_wb', 'binary': True, 'decode_error': 'strict', 'lowercase': False, 'max_df': 0.5,\n",
    "                                'max_features': 100, 'min_df': 0.0, 'ngram_range': (1, 2), 'stop_words': 'english',\n",
    "                                'strip_accents': 'ascii'})),\n",
    "    ('tfidf', TfidfTransformer(**{'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': False, 'use_idf': True})),\n",
    "    ('clf', LogisticRegression(**{'C': 85.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'max_iter': 6, 'penalty': 'l2',\n",
    "                                  'solver': 'sag', 'tol': 1e-08})),\n",
    "    #('clf', fit_estimators_dict['LogisticRegression']),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\n",
    "    'clf__C': (85.0,),\n",
    "    'clf__class_weight': ('balanced',),\n",
    "    'clf__dual': (False,),\n",
    "    'clf__fit_intercept': (True,),\n",
    "    'clf__max_iter': (6,),\n",
    "    'clf__penalty': ('l2',),\n",
    "    'clf__solver': ('sag',),\n",
    "    'clf__tol': (1e-08,),\n",
    "    'tfidf__norm': ('l2',),\n",
    "    'tfidf__smooth_idf': (True,),\n",
    "    'tfidf__sublinear_tf': (False,),\n",
    "    'tfidf__use_idf': (True,),\n",
    "    'vect__analyzer': ('char_wb',),\n",
    "    'vect__binary': (True,),\n",
    "    'vect__decode_error': ('strict',),\n",
    "    'vect__lowercase': (False,),\n",
    "    'vect__max_df': (0.5,),\n",
    "    'vect__max_features': (100,),\n",
    "    'vect__min_df': (0.0,),\n",
    "    'vect__ngram_range': ((1, 2),),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__strip_accents': ('ascii',),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find the best parameters for both the feature extraction and the\n",
    "# classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (85.0,),\n",
      " 'clf__class_weight': ('balanced',),\n",
      " 'clf__dual': (False,),\n",
      " 'clf__fit_intercept': (True,),\n",
      " 'clf__max_iter': (6,),\n",
      " 'clf__penalty': ('l2',),\n",
      " 'clf__solver': ('sag',),\n",
      " 'clf__tol': (1e-08,),\n",
      " 'tfidf__norm': ('l2',),\n",
      " 'tfidf__smooth_idf': (True,),\n",
      " 'tfidf__sublinear_tf': (False,),\n",
      " 'tfidf__use_idf': (True,),\n",
      " 'vect__analyzer': ('char_wb',),\n",
      " 'vect__binary': (True,),\n",
      " 'vect__decode_error': ('strict',),\n",
      " 'vect__lowercase': (False,),\n",
      " 'vect__max_df': (0.5,),\n",
      " 'vect__max_features': (100,),\n",
      " 'vect__min_df': (0.0,),\n",
      " 'vect__ngram_range': ((1, 2),),\n",
      " 'vect__stop_words': ('english',),\n",
      " 'vect__strip_accents': ('ascii',)}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.871s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.6s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "C:\\Users\\dev\\Anaconda3\\envs\\jh\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(data.data, data.target)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.760\n",
      "Best parameters set:\n",
      "\tclf__C: 85.0\n",
      "\tclf__class_weight: 'balanced'\n",
      "\tclf__dual: False\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__max_iter: 6\n",
      "\tclf__penalty: 'l2'\n",
      "\tclf__solver: 'sag'\n",
      "\tclf__tol: 1e-08\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__smooth_idf: True\n",
      "\ttfidf__sublinear_tf: False\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__analyzer: 'char_wb'\n",
      "\tvect__binary: True\n",
      "\tvect__decode_error: 'strict'\n",
      "\tvect__lowercase: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 100\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "\tvect__strip_accents: 'ascii'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "        True,  True, False,  True, False, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False, False, False,  True, False,  True, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.9.0)",
   "language": "python",
   "name": "jh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
