{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80247e27-3d5c-4747-989c-7fc5258ca737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 5 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn off Pretty Print, enable inline plotting with Matplotlib, add py folder to system path, import jobpostlib modules\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "if ('../py' not in sys.path): \n",
    "    sys.path.insert(1, '../py')\n",
    "from jobpostlib import (\n",
    "    crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, \n",
    "    scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine\n",
    ")\n",
    "from huggingface_hub import login\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AlbertForSequenceClassification,\n",
    "    AlbertTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b38f2876-173d-4443-bb21-91fb7de12008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 532,546 is-qualified vocabulary tokens in here\n",
      "Is-qualified LR elements built in 5 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has built its is-qualified classifier\n",
    "t1 = time.time()\n",
    "if not (hasattr(lru, 'ISQUALIFIED_LR') and hasattr(lru, 'ISQUALIFIED_CV')):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified LR elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e41b3f-61b8-4588-b132-85b6941f904c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3720fc6-6b1d-405a-8e04-ba0efb158cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 19,430 hand-labeled qualification strings in here\n",
      "I have 543,710 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 9 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary below or in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified classifer retrained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf66a04-4614-491c-8df3-09bb710f8a42",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03094f9-c8c8-48a6-a392-307893102905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (manager).\n",
      "Your token has been saved to C:\\Users\\daveb\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "write_access_token = wsu.secrets_json['huggingface']['write_access_token']\n",
    "login(token=write_access_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5adbef0-9d47-4cf0-8afb-d3eda08bbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into features and target\n",
    "df = lru.basic_quals_df.sample(1_000)\n",
    "\n",
    "# The shape of the Bag-of-words count vector here\n",
    "# should be n html strings * m unique tokens\n",
    "sents_list = df.qualification_str.tolist()\n",
    "\n",
    "# Re-transform the bag-of-words and tf-idf from the new manual scores\n",
    "bow_matrix = lru.ISQUALIFIED_CV.fit_transform(sents_list)\n",
    "\n",
    "# Tf-idf must get from Bag-of-words first\n",
    "tfidf_matrix = lru.ISQUALIFIED_TT.fit_transform(bow_matrix).toarray()\n",
    "\n",
    "y = df.is_qualified.to_numpy().astype(int)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecf2253-600b-43e6-848b-7bb7114f82b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.826463</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.577280</td>\n",
       "      <td>0.246381</td>\n",
       "      <td>0.701613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>5.573913</td>\n",
       "      <td>0.028932</td>\n",
       "      <td>0.693548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10.674767</td>\n",
       "      <td>0.052678</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>139.224958</td>\n",
       "      <td>0.080412</td>\n",
       "      <td>0.862903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Time (s)  Inference Time (s)    Recall\n",
       "0  Logistic Regression           1.826463            0.014592  1.000000\n",
       "1          Naive Bayes           0.577280            0.246381  0.701613\n",
       "2        Decision Tree           5.573913            0.028932  0.693548\n",
       "3        Random Forest          10.674767            0.052678  0.967742\n",
       "4    Gradient Boosting         139.224958            0.080412  0.862903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "\n",
    "    start_infer = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_infer = time.time()\n",
    "\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Training Time (s)\": end_train - start_train,\n",
    "        \"Inference Time (s)\": end_infer - start_infer,\n",
    "        \"Recall\": recall\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "display(DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5915142a-5ccc-42e9-8d3a-3dc8c8f27eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom Dataset Class for Hugging Face Models\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        qualification_str = self.data.iloc[index]['qualification_str']\n",
    "        is_qualified = self.data.iloc[index]['is_qualified']\n",
    "        encoding = self.tokenizer(\n",
    "            qualification_str,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(is_qualified, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9903fa3-d470-433b-910b-113534a2f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate a Hugging Face model (DistilBERT, ALBERT)\n",
    "def evaluate_transformer_model(model, tokenizer, train_df, test_df, batch_size=8, max_length=128):\n",
    "    # Prepare datasets\n",
    "    train_dataset = CustomDataset(train_df, tokenizer, max_length)\n",
    "    test_dataset = CustomDataset(test_df, tokenizer, max_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Training\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Measure training time\n",
    "    start_train_time = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(1):  # For evaluation purposes, use 1 epoch\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    train_time = time.time() - start_train_time\n",
    "\n",
    "    # Inference\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    start_inference_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    inference_time = time.time() - start_inference_time\n",
    "\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    return train_time, inference_time, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84f6a2d-aaa3-4814-8238-30b711a295f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate FastText\n",
    "def evaluate_fasttext_model(train_df, test_df):\n",
    "    # Save training data to file\n",
    "    train_df[['qualification_str', 'is_qualified']].to_csv('train_fasttext.txt', sep='\\t', index=False, header=False)\n",
    "    \n",
    "    # Train FastText model\n",
    "    start_train_time = time.time()\n",
    "    model = fasttext.train_supervised('train_fasttext.txt')\n",
    "    train_time = time.time() - start_train_time\n",
    "\n",
    "    # Inference\n",
    "    start_inference_time = time.time()\n",
    "    preds = [model.predict(text)[0][0][-1] for text in test_df['qualification_str']]\n",
    "    inference_time = time.time() - start_inference_time\n",
    "\n",
    "    recall = recall_score(test_df['is_qualified'], [int(p) for p in preds])\n",
    "    return train_time, inference_time, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301db111-d498-492a-bbb2-d89c4425c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# Evaluate DistilBERT\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "distilbert_train_time, distilbert_inference_time, distilbert_recall = evaluate_transformer_model(\n",
    "    distilbert_model, distilbert_tokenizer, train_df, test_df\n",
    ")\n",
    "\n",
    "# Evaluate ALBERT\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=2)\n",
    "albert_train_time, albert_inference_time, albert_recall = evaluate_transformer_model(\n",
    "    albert_model, albert_tokenizer, train_df, test_df\n",
    ")\n",
    "\n",
    "# Evaluate FastText\n",
    "fasttext_train_time, fasttext_inference_time, fasttext_recall = evaluate_fasttext_model(train_df, test_df)\n",
    "\n",
    "# Output the results\n",
    "print(\"DistilBERT - Training Time: {:.2f}s, Inference Time: {:.2f}s, Recall: {:.2f}\".format(\n",
    "    distilbert_train_time, distilbert_inference_time, distilbert_recall\n",
    "))\n",
    "print(\"ALBERT - Training Time: {:.2f}s, Inference Time: {:.2f}s, Recall: {:.2f}\".format(\n",
    "    albert_train_time, albert_inference_time, albert_recall\n",
    "))\n",
    "print(\"FastText - Training Time: {:.2f}s, Inference Time: {:.2f}s, Recall: {:.2f}\".format(\n",
    "    fasttext_train_time, fasttext_inference_time, fasttext_recall\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6802a5a-3957-43ff-ac10-e00f7f20465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the models to evaluate\n",
    "models = {\n",
    "    \"Gemma\": \"google/gemma-7b\",\n",
    "    \"Mistral\": \"mistral-7b\",\n",
    "    \"OLMo\": \"allenai/olmo-7b\"\n",
    "}\n",
    "\n",
    "# Prepare the dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model_name, model_checkpoint):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"qualification_str\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    train_encodings = tokenize_function(train_df)\n",
    "    test_encodings = tokenize_function(test_df)\n",
    "\n",
    "    train_dataset = DataFrame(train_encodings)\n",
    "    test_dataset = DataFrame(test_encodings)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=lambda p: {\"recall\": recall_score(p.label_ids, p.predictions.argmax(-1))}\n",
    "    )\n",
    "\n",
    "    # Measure training speed\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Measure inference speed\n",
    "    start_time = time.time()\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    # Measure inference recall\n",
    "    recall = recall_score(test_df[\"is_qualified\"], predictions.predictions.argmax(-1))\n",
    "\n",
    "    return training_time, inference_time, recall\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for model_name, model_checkpoint in models.items():\n",
    "    training_time, inference_time, recall = evaluate_model(model_name, model_checkpoint)\n",
    "    results[model_name] = {\n",
    "        \"Training Time (s)\": training_time,\n",
    "        \"Inference Time (s)\": inference_time,\n",
    "        \"Recall\": recall\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdb325-c38a-4e19-91db-e85b573e5dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
