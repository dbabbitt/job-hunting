{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from hc_utils import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "\n",
    "from lr_utils import LrUtilities\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2023-02-12 07:19:01.740213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import humanize\n",
    "from datetime import datetime\n",
    "import winsound\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "width_inches = 18.0\n",
    "height_inches = 3.0\n",
    "bin_count = 12\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Create the Child Strings List Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cypher_str = \"\"\"\n",
    "    MATCH (:PartsOfSpeech)-[r:SUMMARIZES]->(:NavigableParents)\n",
    "    DELETE r;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            MATCH (np:NavigableParents)-[r:NEXT]->(:NavigableParents)\n",
      "            RETURN\n",
      "                np.navigable_parent AS navigable_parent,\n",
      "                np.is_header AS is_header,\n",
      "                r.sequence_order AS sequence_order,\n",
      "                r.file_name AS file_name\n",
      "            ORDER BY\n",
      "                r.file_name,\n",
      "                r.sequence_order;\n",
      "364 file names added to the list dictionary in 2 minutes and 48 seconds, for a total of 1,427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1 file names added to the list dictionary in 4 minutes and 22 seconds, for a total of 1,063\n",
    "t0 = time.time()\n",
    "old_child_strs_list_dict = cu.s.load_object('CHILD_STRS_LIST_DICT')\n",
    "old_length = len(old_child_strs_list_dict)\n",
    "new_child_strs_list_dict = cu.get_rebuilt_child_strs_list_dictionary(verbose=True)\n",
    "new_length = len(new_child_strs_list_dict)\n",
    "strings_added = new_length - old_length\n",
    "if (strings_added > 0):\n",
    "    cu.CHILD_STRS_LIST_DICT = new_child_strs_list_dict\n",
    "    cu.s.store_objects(CHILD_STRS_LIST_DICT=cu.CHILD_STRS_LIST_DICT, verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'{strings_added} file names added to the list dictionary in {duration_str}, for a total of {new_length:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (np:NavigableParents {navigable_parent: \"<p>Job Type: Full-time</p>\"})<-[s:SUMMARIZES]-(ht:HeaderTags) RETURN ht.header_tag AS header_tag;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\HEADER_PATTERN_DICT.pkl\n",
      "I have 1,424 hand-labeled parts-of-speech patterns in here\n",
      "Training the Conditional Random Fields model with 1,424 parts-of-speech labels\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\CRF.pkl\n",
      "Retraining complete\n",
      "Parts-of-speech classifier retrained in 2 hours, 14 minutes and 23 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# I have 1,060 hand-labeled parts-of-speech patterns in here\n",
    "t0 = time.time()\n",
    "lru.build_pos_logistic_regression_elements(verbose=False)\n",
    "crf.retrain_pos_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Parts-of-speech classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try to find a part-of-speech for every orphan child string\n",
    "t0 = time.time()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def do_cypher_tx(tx, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (np:NavigableParents)\n",
    "        WHERE\n",
    "           NOT EXISTS {\n",
    "                MATCH (:PartsOfSpeech)-[:SUMMARIZES]->(np:NavigableParents)\n",
    "            }\n",
    "            AND NOT (\n",
    "                np.is_header IS NULL\n",
    "                AND np.is_task_scope IS NULL\n",
    "                AND np.is_minimum_qualification IS NULL\n",
    "                AND np.is_preferred_qualification IS NULL\n",
    "                AND np.is_educational_requirement IS NULL\n",
    "                AND np.is_legal_notification IS NULL\n",
    "                AND np.is_other IS NULL\n",
    "                AND np.is_corporate_scope IS NULL\n",
    "                AND np.is_job_title IS NULL\n",
    "                AND np.is_office_location IS NULL\n",
    "                AND np.is_job_duration IS NULL\n",
    "                AND np.is_supplemental_pay IS NULL\n",
    "                AND np.is_interview_procedure IS NULL\n",
    "                AND np.is_posting_date IS NULL\n",
    "            )\n",
    "        RETURN\n",
    "            np.navigable_parent AS navigable_parent,\n",
    "            np.is_header AS np_is_header,\n",
    "            np.is_task_scope AS np_is_task_scope,\n",
    "            np.is_minimum_qualification AS np_is_minimum_qualification,\n",
    "            np.is_preferred_qualification AS np_is_preferred_qualification,\n",
    "            np.is_educational_requirement AS np_is_educational_requirement,\n",
    "            np.is_legal_notification AS np_is_legal_notification,\n",
    "            np.is_other AS np_is_other,\n",
    "            np.is_corporate_scope AS np_is_corporate_scope,\n",
    "            np.is_job_title AS np_is_job_title,\n",
    "            np.is_office_location AS np_is_office_location,\n",
    "            np.is_job_duration AS np_is_job_duration,\n",
    "            np.is_supplemental_pay AS np_is_supplemental_pay,\n",
    "            np.is_interview_procedure AS np_is_interview_procedure,\n",
    "            np.is_posting_date AS np_is_posting_date;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str)\n",
    "    results_list = tx.run(query=cypher_str, parameters=None)\n",
    "    values_list = []\n",
    "    for record in results_list:\n",
    "        values_list.append(dict(record.items()))\n",
    "\n",
    "    return values_list\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.read_transaction(do_cypher_tx, verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "# winsound.Beep(freq, duration)\n",
    "print(f'Orphan child strings found in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "columns_list = ['np_is_header', 'np_is_task_scope', 'np_is_minimum_qualification', 'np_is_preferred_qualification', 'np_is_educational_requirement', 'np_is_legal_notification',\n",
    "                'np_is_other', 'np_is_corporate_scope', 'np_is_job_title', 'np_is_office_location', 'np_is_job_duration', 'np_is_supplemental_pay', 'np_is_interview_procedure',\n",
    "                'np_is_posting_date']\n",
    "df = pd.DataFrame(row_objs_list).replace([None], np.nan).groupby(columns_list).count().sort_values('navigable_parent', ascending=False)\n",
    "for row_index, row_series in df.iterrows():\n",
    "    \n",
    "    # Iterate over the values and variable names\n",
    "    for value, var_name in zip(row_index, columns_list):\n",
    "        exec(f'{var_name} = {value}')\n",
    "    \n",
    "    cypher_str = f\"\"\"\n",
    "        MATCH\n",
    "            (pos:PartsOfSpeech {{\n",
    "                is_header: '{np_is_header}',\n",
    "                is_task_scope: '{np_is_task_scope}',\n",
    "                is_minimum_qualification: '{np_is_minimum_qualification}',\n",
    "                is_preferred_qualification: '{np_is_preferred_qualification}',\n",
    "                is_educational_requirement: '{np_is_educational_requirement}',\n",
    "                is_legal_notification: '{np_is_legal_notification}',\n",
    "                is_other: '{np_is_other}',\n",
    "                is_corporate_scope: '{np_is_corporate_scope}',\n",
    "                is_job_title: '{np_is_job_title}',\n",
    "                is_office_location: '{np_is_office_location}',\n",
    "                is_job_duration: '{np_is_job_duration}',\n",
    "                is_supplemental_pay: '{np_is_supplemental_pay}',\n",
    "                is_interview_procedure: '{np_is_interview_procedure}',\n",
    "                is_posting_date: '{np_is_posting_date}'\n",
    "            }}),\n",
    "            (np:NavigableParents {{\n",
    "                is_header: '{np_is_header}',\n",
    "                is_task_scope: '{np_is_task_scope}',\n",
    "                is_minimum_qualification: '{np_is_minimum_qualification}',\n",
    "                is_preferred_qualification: '{np_is_preferred_qualification}',\n",
    "                is_educational_requirement: '{np_is_educational_requirement}',\n",
    "                is_legal_notification: '{np_is_legal_notification}',\n",
    "                is_other: '{np_is_other}',\n",
    "                is_corporate_scope: '{np_is_corporate_scope}',\n",
    "                is_job_title: '{np_is_job_title}',\n",
    "                is_office_location: '{np_is_office_location}',\n",
    "                is_job_duration: '{np_is_job_duration}',\n",
    "                is_supplemental_pay: '{np_is_supplemental_pay}',\n",
    "                is_interview_procedure: '{np_is_interview_procedure}',\n",
    "                is_posting_date: '{np_is_posting_date}'\n",
    "            }})\n",
    "        MERGE (pos)-[r: SUMMARIZES]->(np);\"\"\"\n",
    "    with cu.driver.session() as session:\n",
    "        session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "# winsound.Beep(freq, duration)\n",
    "print(f'Parts-of-speech resummarized in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
