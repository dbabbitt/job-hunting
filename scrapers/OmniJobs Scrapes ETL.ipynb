{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/5.24.2 ========\n",
      "Utility libraries created in 11 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "executable_path = sys.executable; scripts_folder = osp.join(osp.dirname(executable_path), 'Scripts')\n",
    "py_folder = osp.abspath('../py'); ffmpeg_folder = r'C:\\ffmpeg\\bin'\n",
    "if (scripts_folder not in sys.path): sys.path.insert(1, scripts_folder)\n",
    "if (py_folder not in sys.path): sys.path.insert(1, py_folder)\n",
    "if (ffmpeg_folder not in sys.path): sys.path.insert(1, ffmpeg_folder)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4.formatter import  HTMLFormatter\n",
    "from jobpostlib import (cu, datetime, hau, humanize, nu, time, wsu, speech_engine, su)\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['powershell.exe', '-ExecutionPolicy', 'Bypass', '-Command', 'Start-Process \"C:\\\\Program Files\\\\Notepad++\\\\notepad++.exe\" -ArgumentList \"C:\\\\Users\\\\daveb\\\\OneDrive\\\\Documents\\\\GitHub\\\\job-hunting\\\\data\\\\html\\\\omnijobs_email.html\"']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wsu.save_email_to_file('omnijobs', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OmniJobs Pandas Remote\n",
      "I found 14 urls in omnijobs_email.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = wsu.get_driver(verbose=False)\n",
    "page_soup = wsu.get_page_soup('../data/html/omnijobs_email.html')\n",
    "div_soup = page_soup.select('div')[0]\n",
    "css_selector = 'div:nth-child(4)'\n",
    "search_type = ('OmniJobs ' + re.sub(r'\\s+', ' ', div_soup.select(css_selector)[0].text.strip())).replace('Remote', ' Remote')\n",
    "print(search_type)\n",
    "link_soups_list = [s for s in div_soup.children if (s.name == 'a')]\n",
    "\n",
    "# Get rid of the duplicate URLs\n",
    "url_strs_set = set()\n",
    "for link_soup in link_soups_list:\n",
    "    url_strs_set.add(link_soup['href'])\n",
    "\n",
    "speech_str = f'I found {len(url_strs_set)} urls in omnijobs_email.html'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1395552_Principal_Data_Scientist_IL_Mellanox_Technologies_Ltd.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1394074_Principal_Data_Engineer_Aviva_Employment_Services_Limited.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1396143_Commercial_Data_Analyst_Glovo.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1397600_Data_Science_Intern_ICF_Incorporated_LLC.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1393587_Principal_Data_Scientist_RAPP.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1396113_Data_Analyst_Glovo.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1393806_Jr_Developer_WhiteWater_Midstream.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1396798_Software_Integrator_CACI_INC_FEDERAL.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1397416_Software_Engineering_Manager_AI_Recommender_Systems_IND_Thomson_Reuters_International_Services_Private_Limited.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1399627_Marketing_Data_Engineer_CrowdStrike_Mexico_S_de_R_L_de_C_V.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1396806_Enterprise_Data_Scientist_CACI_INC_FEDERAL.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1395049_AI_Data_Architect_LEIDOS_INNOVATIONS_UK_LTD.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1398753_Machine_Learning_Engineer_ASAPP.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\1393724_Python_Developer_Vitol.html\n",
      "Fileing 14 postings out of 14 urls complete. Delete the email.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_list = []\n",
    "for url_str in url_strs_set:\n",
    "    file_node_dict, files_list = su.store_omnijobs_file_attributes(driver, url_str, files_list=files_list, search_type=search_type, verbose=False)\n",
    "speech_str = f'Fileing {len(files_list)} postings out of {len(url_strs_set)} urls complete. Delete the email.'; print(speech_str)\n",
    "speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1395552_Principal_Data_Scientist_IL_Mellanox_Technologies_Ltd.html', '1394074_Principal_Data_Engineer_Aviva_Employment_Services_Limited.html', '1396143_Commercial_Data_Analyst_Glovo.html', '1397600_Data_Science_Intern_ICF_Incorporated_LLC.html', '1393587_Principal_Data_Scientist_RAPP.html', '1396113_Data_Analyst_Glovo.html', '1393806_Jr_Developer_WhiteWater_Midstream.html', '1396798_Software_Integrator_CACI_INC_FEDERAL.html', '1397416_Software_Engineering_Manager_AI_Recommender_Systems_IND_Thomson_Reuters_International_Services_Private_Limited.html', '1399627_Marketing_Data_Engineer_CrowdStrike_Mexico_S_de_R_L_de_C_V.html', '1396806_Enterprise_Data_Scientist_CACI_INC_FEDERAL.html', '1395049_AI_Data_Architect_LEIDOS_INNOVATIONS_UK_LTD.html', '1398753_Machine_Learning_Engineer_ASAPP.html', '1393724_Python_Developer_Vitol.html']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "try:\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__.__name__} error: {str(e).strip()}')\n",
    "cu.ensure_navigableparent('END', verbose=False)\n",
    "for file_name in files_list:\n",
    "    file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "    wsu.clean_job_posting(file_path)\n",
    "    page_soup = wsu.get_page_soup(file_path)\n",
    "    row_div_list = page_soup.find_all(name='div', id='jobDescriptionText')\n",
    "    assert row_div_list, f'{file_name} is missing <div id=\"jobDescriptionText\">'\n",
    "    for div_soup in row_div_list:\n",
    "        child_strs_list = hau.get_navigable_children(div_soup, [])\n",
    "        assert child_strs_list, f'{file_name} is missing its child strings'\n",
    "        cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Populating {len(files_list)} out of {len(url_strs_set)} postings completed in {duration_str}'; speech_engine.say(speech_str); speech_engine.runAndWait()\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
