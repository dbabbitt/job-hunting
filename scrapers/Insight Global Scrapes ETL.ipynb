{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(s=s)\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from is_header_sgd_classifier import IsHeaderSgdClassifier\n",
    "ihu = IsHeaderSgdClassifier(ha=ha, cu=cu, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "try:\n",
    "    version_str = cu.driver.verify_connectivity()\n",
    "    \n",
    "    from hc_utils import HeaderCategories\n",
    "    hc = HeaderCategories(cu=cu, verbose=False)\n",
    "\n",
    "    from section_utils import SectionUtilities\n",
    "    su = SectionUtilities(verbose=False)\n",
    "\n",
    "    from lr_utils import LrUtilities\n",
    "    lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "    slrcu.build_pos_logistic_regression_elements()\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except ServiceUnavailable as e:\n",
    "    # print(str(e).strip())\n",
    "    raise ServiceUnavailable('You need to start Neo4j as a console')\n",
    "except Exception as e:\n",
    "    print(e.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2022-07-18 07:35:17.708511\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%run ../load_magic/dataframes.py\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from urllib.error import HTTPError, URLError\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import requests\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query_dict = {\n",
    "    'ff': 'Location,LessThanOrEq,42.4173,-71.684,100',\n",
    "    'zip': 'Clinton, MA 01510',\n",
    "    'rd': '100',\n",
    "    'miles': true,\n",
    "    'remote': true,\n",
    "    'srch': 'data'\n",
    "}\n",
    "prefix_str = 'https://jobs.insightglobal.com/find_a_job/massachusetts/clinton/?'\n",
    "url_str = prefix_str + '&'.join([f'{k}=' + v.replace(' ', '+') for k, v in query_dict.items()])\n",
    "response_obj = requests.get(url_str)\n",
    "html_str = response_obj.text\n",
    "file_path = '../data/html/insight_searchresults.html'\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\n",
    "    print(html_str, file=f)\n",
    "page_soup = wsu.get_page_soup(file_path)\n",
    "link_css = 'div.result > div.job-title > a'\n",
    "link_soups_list = page_soup.select(link_css)\n",
    "len(link_soups_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "url_strs_list = []\n",
    "rows_list = []\n",
    "for link_soup in link_soups_list:\n",
    "    url_str = link_soup['href']\n",
    "    row_dict = {k: v[0] for k, v in parse_qs(urlparse(url_str).query).items()}\n",
    "    row_dict['url_str'] = url_str\n",
    "    rows_list.append(row_dict)\n",
    "df = pd.DataFrame(rows_list)\n",
    "url_strs_list = df.url_str.tolist()\n",
    "len(url_strs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://jobs.insightglobal.com/find_a_job/texas/plano/sr-data-analyst-data-scientist/job-153005/'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'https://jobs.insightglobal.com' + url_strs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       true
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import webbrowser\n",
    "\n",
    "webbrowser.open('https://jobs.insightglobal.com' + url_strs_list[0], new=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nojobs_css = '#results-main-data > div.results-panel > div.no-jobs'\n",
    "nojobs_regex = re.compile('Your search has returned 0 results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fileing 0 postings complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_list = []\n",
    "for url_str in url_strs_list:\n",
    "    url_str = 'https://jobs.insightglobal.com' + url_str\n",
    "    response_obj = requests.get(url_str, cookies=cookies_dict, headers=headers_dict)\n",
    "    webpage_html = response_obj.text\n",
    "    match_obj = nojobs_regex.search(webpage_html)\n",
    "    if match_obj:\n",
    "        cu.set_is_closed(file_name, verbose=False)\n",
    "    else:\n",
    "    page_title = eval(f'{{{match_obj.group()}}}')['jobTitleText']\n",
    "    file_name = re.sub(r'[^A-Za-z0-9]+', ' ', page_title).strip().replace(' ', '_')\n",
    "    jobListingId = parse_qs(urlparse(url_str).query).get('jobListingId', [''])[0]\n",
    "    if len(jobListingId):\n",
    "        file_name = f'{jobListingId}_{file_name}.html'\n",
    "    else:\n",
    "        file_name = f'{file_name}.html'\n",
    "        file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_name = datetime.now().strftime('%Y%m%d%H%M%S%f') + f'_{file_name}'\n",
    "    file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        with open(file_path, 'w', encoding=s.encoding_type) as f:\n",
    "            print(f'Saving to {file_path}')\n",
    "            f.write('<html><head><title>')\n",
    "            f.write(page_title)\n",
    "            f.write('</title></head><body><div id=\"jobDescriptionText\">')\n",
    "            match_obj = desc_regex.search(webpage_html)\n",
    "            html_str = eval(f'{{{match_obj.group()}}}')['job']['description']\n",
    "            f.write(html_str)\n",
    "            f.write('</div></body></html>')\n",
    "        files_list.append(file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.set_posting_url(file_name, url_str, verbose=False)\n",
    "print(f'Fileing {len(files_list)} postings complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cu.ensure_navigableparent('END', verbose=False)\n",
    "for file_name in files_list:\n",
    "    file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "    page_soup = wsu.get_page_soup(file_path)\n",
    "    row_div_list = page_soup.find_all(name='body')\n",
    "    for div_soup in row_div_list:\n",
    "        child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "        assert child_strs_list, f'Something is wrong with {file_name}'\n",
    "        cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
