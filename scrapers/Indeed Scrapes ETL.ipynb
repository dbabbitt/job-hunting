{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import humanize\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import winsound\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility libraries created in 7 seconds\n",
      "Last run on 2024-01-11 18:37:49.569574\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage(\n",
    "    data_folder_path=os.path.abspath('../data'),\n",
    "    saves_folder_path=os.path.abspath('../saves')\n",
    ")\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(\n",
    "    s=s,\n",
    "    secrets_json_path=os.path.abspath('../data/secrets/jh_secrets.json')\n",
    ")\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "# Get the neo4j object\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(\n",
    "    uri=uri, user=user, password=password, driver=None, s=s, ha=ha\n",
    ")\n",
    "\n",
    "from section_classifier_utils import SectionLRClassifierUtilities, SectionCRFClassifierUtilities\n",
    "slrcu = SectionLRClassifierUtilities(ha=ha, cu=cu, verbose=False)\n",
    "scrfcu = SectionCRFClassifierUtilities(cu=cu, ha=ha, verbose=False)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(wsu=wsu, ihu=None, hc=None, crf=None, slrcu=slrcu, verbose=False)\n",
    "\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Utility libraries created in {duration_str}')\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C:\\Program Files\\Notepad++\\notepad++.exe\" C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\html\\indeed_email.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = os.path.abspath('../data/html/indeed_email.html'); command_str = fr'\"C:\\Program Files\\Notepad++\\notepad++.exe\" {file_path}'\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the FireFox driver\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "try: driver = wsu.get_driver(); winsound.Beep(freq, int(duration/2))\n",
    "finally:\n",
    "    file_path = '../data/html/indeed_email.html'\n",
    "    page_soup = wsu.get_page_soup(file_path)\n",
    "    css_selector = 'table > tbody > tr > td > a > table > tbody > tr > td > a'\n",
    "    link_soups_list = page_soup.select(css_selector)\n",
    "    url_strs_set = set()\n",
    "    for link_soup in link_soups_list: url_strs_set.add(link_soup['href'])\n",
    "    display(len(url_strs_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fileing 1 postings complete. Delete the email.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_list = []\n",
    "for url_str in url_strs_set: file_node_dict, files_list = su.load_indeed_posting_url(viewjob_url=url_str, driver=driver, files_list=files_list, verbose=False)\n",
    "print(f'Fileing {len(files_list)} postings complete. Delete the email.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b82af252adf198ab_Data_Scientist_US_Remote_Remote_Indeed_com.html']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "try: driver.close()\n",
    "except Exception as e: print(f'{e.__class__.__name__} error: {str(e).strip()}')\n",
    "cu.ensure_navigableparent('END', verbose=False)\n",
    "for file_name in files_list:\n",
    "    file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "    page_soup = wsu.get_page_soup(file_path)\n",
    "    row_div_list = page_soup.find_all(name='div', id='jobDescriptionText')\n",
    "    for div_soup in row_div_list:\n",
    "        child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "        cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "winsound.Beep(freq, duration)\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<div>We are a growth stage company that creates software solutions combining lean principles, predictive and prescriptive analytics, and machine learning to transform hospital and infusion center operations. More than 180 health systems and over 1,000 hospitals and centers across 49 states rely on our award-winning products to increase patient access, decrease wait times, and reduce healthcare delivery costs. We have raised more than $300 million from top-tier investors such as Bain Capital, Insight Partners, and Goldman Sachs. We have been named among the top 100 AI companies in the world.</div>', 'Please note that while this role is listed as available for remote, we are currently employing in the following states:', '<i>AK, AZ, CA, CO, CT, DC, FL, GA, IL, IN, KS, LA, MD, MA, MI, MO, MT, NH, NJ, NC, OH, OR, PA, SC, TN, TX, UT, VA, WA, WI</i>', '<i>. If your state is not listed, we may not be able to proceed with your application. We have offices in Santa Clara, CA and Charlotte, NC for employees who prefer to work regularly or occasionally from an office.</i>', '<b>WHAT YOU’LL DO</b>', '<li>Make sense of complex electronic health record (EHR) data related to surgeries, doctors, patients, etc. and help us derive greater value from our data</li>', '<li>Enhance our simulation, optimization, and AI/ML capabilities</li>', '<li>Own your projects end-to-end including a technology stack, data consumption, modeling development and evaluation, and production deployment and maintenance</li>', '<li>Wear a product hat to ideate and iterate on features and experiences that allow your users to run hospitals like a clock</li>', '<b>WHAT YOU’LL BRING</b>', '<li>Masters or PhD degree in operations research, machine learning, or a related field and 2+ years of relevant industry or academic experience</li>', '<li>Strong analytical and problem solving skills and a deep understanding in at least one sub-area of operations research or machine learning</li>', '<li>Excellent command of Python and SQL and a passion for writing readable code</li>', '<li>Experience with Jupyter Notebooks</li>', '<li>Proven collaboration skills with cross-functional teams like product managers, data engineers, and data analysts</li>', '<li>Data skills and the ability to communicate complex quantitative matters in a clear, precise, and actionable manner</li>', '<b>BONUS POINTS IF YOU HAVE</b>', '<li>Experience in causal analysis</li>', '<li>Experience working on healthcare products</li>', \"<b>WHAT YOU'LL GET</b>\", '<li>Intellectual and emotional satisfaction of solving tough operational problems in healthcare while improving patient access and saving lives!</li>', '<li>Competitive compensation package that includes base salary, annual bonus, and stock options</li>', '<li>401(k) Match</li>', '<li>Comprehensive healthcare benefits</li>', '<li>Generous Paid Time Off and Parental Leave</li>', '<li>Monthly reimbursement for Skill Building</li>', '<li>Monthly reimbursement for Wellness, Transportation, and/or Home Office</li>', '<li>Education Reimbursement for select courses/programs</li>', '<div>$120,000 - $165,000 a year</div>', '<div>The offered base salary will reflect careful consideration of a number of factors, including your location, skills and qualifications, prior relevant experience, internal equity and market conditions. This range may be modified in the future.</div>', '<b>Vaccination policy</b>', '<div>We have an obligation to protect our employees, our customers, and the patients of our customers. Therefore employees are required to be vaccinated to work from the office, attend in-person company events, or to travel on behalf of the company.</div>', 'Candidates must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. Visa sponsorship is not available for this position.', 'LeanTaaS is an equal opportunity employer committed to promoting an inclusive work environment free of discrimination and harassment. We value diversity, inclusion, and aim to provide a sense of belonging for everyone. All qualified applicants for employment will be considered without regard to race, color, sex, gender identity, gender expression, religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws. If you require assistance during the application process, please reach out to accommodations@leantaas.com. LeanTaaS will reasonably accommodate qualified individuals with disabilities to the extent required by applicable law.', 'Please note: LeanTaaS is not accepting agency resumes at this time, and we are not responsible for any fees related to unsolicited resumes. Thank you.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "child_strs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
