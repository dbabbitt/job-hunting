{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/5.24.2 ========\n",
      "Utility libraries created in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "executable_path = sys.executable; scripts_folder = osp.join(osp.dirname(executable_path), 'Scripts')\n",
    "py_folder = osp.abspath('../py'); ffmpeg_folder = r'C:\\ffmpeg\\bin'\n",
    "if (scripts_folder not in sys.path): sys.path.insert(1, scripts_folder)\n",
    "if (py_folder not in sys.path): sys.path.insert(1, py_folder)\n",
    "if (ffmpeg_folder not in sys.path): sys.path.insert(1, ffmpeg_folder)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4.formatter import  HTMLFormatter\n",
    "from jobpostlib import (cu, datetime, hau, humanize, nu, time, wsu, speech_engine, su)\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['powershell.exe', '-ExecutionPolicy', 'Bypass', '-Command', 'Start-Process \"C:\\\\Program Files\\\\Notepad++\\\\notepad++.exe\" -ArgumentList \"C:\\\\Users\\\\daveb\\\\OneDrive\\\\Documents\\\\GitHub\\\\job-hunting\\\\data\\\\html\\\\linkedin_email.html\"']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "search_type = 'Linkedin data scientist jobs in Clinton'\n",
    "wsu.save_email_to_file('linkedin', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 5 urls in linkedin_email.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = wsu.get_driver(verbose=False)\n",
    "wsu.log_into_linkedin(driver, verbose=False)\n",
    "speech_engine.say('Enter the verification code'); speech_engine.runAndWait()\n",
    "\n",
    "page_soup = wsu.get_page_soup('../data/html/linkedin_email.html')\n",
    "css_selector = 'a[href^=\"https://www.linkedin.com/comm/jobs/view\"]'\n",
    "link_soups_list = page_soup.select(css_selector)\n",
    "\n",
    "# Get rid of the duplicate URLs\n",
    "url_strs_set = set()\n",
    "for link_soup in link_soups_list:\n",
    "    \n",
    "    # URL string\n",
    "    url_str = link_soup['href']\n",
    "    \n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url_str)\n",
    "    \n",
    "    # Get query parameters as dictionary\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    \n",
    "    # Remove trk and trkEmail parameters if they exist\n",
    "    if 'trk' in query_params:\n",
    "        del query_params['trk']\n",
    "    if 'trkEmail' in query_params:\n",
    "        del query_params['trkEmail']\n",
    "    \n",
    "    # Construct the updated query string\n",
    "    updated_query_str = urlencode(query_params, doseq=True)\n",
    "    \n",
    "    # Reconstruct the URL with the updated query string\n",
    "    updated_url = parsed_url.scheme + '://' + parsed_url.netloc + parsed_url.path\n",
    "    if updated_query_str:\n",
    "        updated_url += '?' + updated_query_str\n",
    "    \n",
    "    url_strs_set.add(updated_url)\n",
    "\n",
    "speech_str = f'I found {len(url_strs_set)} urls in linkedin_email.html'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\nEk3rkDV2ClXStZJx5EwzQ_Data_Scientist_Worcester_MA.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\HYdnEntE59PvWPc_5qC8rg_Data_Scientist_Lowell_MA.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\G_CzDSs2dQkShbjHzh8O_g_Data_Scientist_Lexington_MA.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\3g7J8YpCmEqWcg7N6efZfQ_Data_Scientist_Wellesley_MA.html\n",
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\dNofF1KW39RUdJUrc5bUQw_Senior_Battery_Data_Scientist_Billerica_MA.html\n",
      "Fileing 5 postings out of 5 urls complete. Delete the email.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assumes this is the first time you've run this cell\n",
    "files_list = []\n",
    "for url_str in url_strs_set:\n",
    "    files_list = su.store_linkedin_file_attributes(driver, url_str, search_type, files_list=files_list, verbose=False)\n",
    "speech_str = f'Fileing {len(files_list)} postings out of {len(url_strs_set)} urls complete. Delete the email.'; print(speech_str)\n",
    "speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populate the Child Strings: 100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:32<00:00, 30.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nEk3rkDV2ClXStZJx5EwzQ_Data_Scientist_Worcester_MA.html', 'HYdnEntE59PvWPc_5qC8rg_Data_Scientist_Lowell_MA.html', 'G_CzDSs2dQkShbjHzh8O_g_Data_Scientist_Lexington_MA.html', '3g7J8YpCmEqWcg7N6efZfQ_Data_Scientist_Wellesley_MA.html', 'dNofF1KW39RUdJUrc5bUQw_Senior_Battery_Data_Scientist_Billerica_MA.html']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "su.populate_postings(driver, len(url_strs_set), files_list=files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
