{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/5.24.2 ========\n",
      "Utility libraries created in 14 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "executable_path = sys.executable; scripts_folder = osp.join(osp.dirname(executable_path), 'Scripts')\n",
    "py_folder = osp.abspath('../py'); ffmpeg_folder = r'C:\\ffmpeg\\bin'\n",
    "if (scripts_folder not in sys.path): sys.path.insert(1, scripts_folder)\n",
    "if (py_folder not in sys.path): sys.path.insert(1, py_folder)\n",
    "if (ffmpeg_folder not in sys.path): sys.path.insert(1, ffmpeg_folder)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4.formatter import  HTMLFormatter\n",
    "from jobpostlib import (cu, datetime, hau, humanize, nu, time, wsu, speech_engine, su)\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['powershell.exe', '-ExecutionPolicy', 'Bypass', '-Command', 'Start-Process \"C:\\\\Program Files\\\\Notepad++\\\\notepad++.exe\" -ArgumentList \"C:\\\\Users\\\\daveb\\\\OneDrive\\\\Documents\\\\GitHub\\\\job-hunting\\\\data\\\\html\\\\linkedin_email.html\"']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wsu.save_email_to_file('linkedin', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get page soup\n",
    "driver = wsu.get_driver(verbose=False); wsu.log_into_linkedin(driver, verbose=False)\n",
    "speech_engine.say('Enter the verification code'); speech_engine.runAndWait()\n",
    "page_soup = wsu.get_page_soup('../data/html/linkedin_email.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linkedin machine learning engineer jobs in Clinton\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get search type\n",
    "search_type = 'Linkedin data scientist jobs in Clinton'\n",
    "type_css = 'table > tbody > tr:nth-child(1)'\n",
    "tr_list = page_soup.select(type_css)\n",
    "if tr_list:\n",
    "    search_type = re.sub(r\"^Your job alert for \", \"Linkedin \", tr_list[0].text.strip())\n",
    "type_css = 'table > tbody > tr:nth-child(2)'\n",
    "tr_list = page_soup.select(type_css)\n",
    "if tr_list:\n",
    "    search_type += re.sub(r\"^\\d+ new\", \"\", tr_list[0].text.strip()).replace('job ', 'jobs ').replace('match ', 'matches ').replace(' matches your preferences.', '')\n",
    "    print(search_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 urls in linkedin_email.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "css_selector = 'a[href^=\"https://www.linkedin.com/comm/jobs/view\"]'\n",
    "link_soups_list = page_soup.select(css_selector)\n",
    "\n",
    "# Get rid of the duplicate URLs\n",
    "url_strs_set = set()\n",
    "for link_soup in link_soups_list:\n",
    "    \n",
    "    # URL string\n",
    "    url_str = link_soup['href']\n",
    "    \n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url_str)\n",
    "    \n",
    "    # Get query parameters as dictionary\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    \n",
    "    # Remove trk and trkEmail parameters if they exist\n",
    "    if 'trk' in query_params:\n",
    "        del query_params['trk']\n",
    "    if 'trkEmail' in query_params:\n",
    "        del query_params['trkEmail']\n",
    "    \n",
    "    # Construct the updated query string\n",
    "    updated_query_str = urlencode(query_params, doseq=True)\n",
    "    \n",
    "    # Reconstruct the URL with the updated query string\n",
    "    updated_url = parsed_url.scheme + '://' + parsed_url.netloc + parsed_url.path\n",
    "    if updated_query_str:\n",
    "        updated_url += '?' + updated_query_str\n",
    "    \n",
    "    url_strs_set.add(updated_url)\n",
    "\n",
    "speech_str = f'I found {len(url_strs_set)} urls in linkedin_email.html'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\XVyF3K3sC68_F2C2mYAcyA_Machine_Learning_Engineer_Wayland_MA.html\n",
      "Fileing 1 postings out of 1 urls complete. Delete the email.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assumes this is the first time you've run this cell\n",
    "files_list = []\n",
    "for url_str in url_strs_set:\n",
    "    files_list = su.store_linkedin_file_attributes(driver, url_str, search_type, files_list=files_list, verbose=False)\n",
    "speech_str = f'Fileing {len(files_list)} postings out of {len(url_strs_set)} urls complete. Delete the email.'; print(speech_str)\n",
    "speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populate the Child Strings: 100%|█████████████████| 1/1 [00:24<00:00, 24.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XVyF3K3sC68_F2C2mYAcyA_Machine_Learning_Engineer_Wayland_MA.html']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "su.populate_postings(driver, len(url_strs_set), files_list=files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
