{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import humanize\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import winsound\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility libraries created in 9 seconds\n",
      "Last run on 2023-03-16 12:11:38.409148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage(\n",
    "    data_folder_path=os.path.abspath('../data'),\n",
    "    saves_folder_path=os.path.abspath('../saves')\n",
    ")\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(\n",
    "    s=s,\n",
    "    secrets_json_path=os.path.abspath('../data/secrets/jh_secrets.json')\n",
    ")\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "# Get the neo4j object\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(\n",
    "    uri=uri, user=user, password=password, driver=None, s=s, ha=ha\n",
    ")\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, wsu=wsu, cu=cu, crf=None, verbose=False)\n",
    "\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Utility libraries created in {duration_str}')\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140_1_3_16_2023_3_15_2024_Remote_Professional_US_Data_Scientist_IV.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\html\\other_email.html'\n",
    "file_name = re.sub(r'[^A-Za-z0-9]+', ' ', '''\n",
    "    1140-1\n",
    "    3/16/2023 - 3/15/2024\n",
    "    Remote\n",
    "    Professional - US - Data Scientist IV\n",
    "    ''').strip().replace(' ', '_') + '.html'\n",
    "new_file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if os.path.isfile(new_file_path):\n",
    "    file_name = datetime.now().strftime('%Y%m%d%H%M%S%f') + f'_{file_name}'\n",
    "    new_file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if not os.path.isfile(new_file_path):\n",
    "    shutil.copy(file_path, os.path.join(cu.SAVES_HTML_FOLDER, file_name))\n",
    "    page_soup = wsu.get_page_soup(file_path)\n",
    "    div_soup = page_soup.find_all(name='div', id='jobDescriptionText')[0]\n",
    "    child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the posting URL to the file name only if you have one\n",
    "posting_url = ''\n",
    "if posting_url:\n",
    "    cypher_str = f'''\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        SET fn.posting_url = \"{posting_url}\"\n",
    "        RETURN fn;'''\n",
    "    with cu.driver.session() as session:\n",
    "        row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "    display(row_objs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 81,693 hand-labeled header htmls in here\n",
      "Is-header classifier retrained in 29 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has retrained its is-header classifier\n",
    "t1 = time.time()\n",
    "from hc_utils import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "from lr_utils import LrUtilities\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "if not hasattr(lru, 'ISHEADER_PREDICT_PERCENT_FIT'):\n",
    "    if not hasattr(lru, 'ISHEADER_LR'):\n",
    "        lru.build_isheader_logistic_regression_elements(verbose=True)\n",
    "    lru.retrain_isheader_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-header classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, pos_lr_predict_single=None, pos_crf_predict_single=None))\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, lru=lru, verbose=True)\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-O', 'O-RQ', 'O-RQ', 'O-IP', 'O-JT', 'O-JD', 'O-OL', 'O-JT', 'H-TS', 'O-JT', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'H-RQ', 'O-RQ', 'H-RQ', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'H-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'H-O', 'O-TS', 'O-O', 'O-CS', 'O-O', 'O-O', 'O-TS', 'O-O', 'O-CS', 'O-IP', 'O-CS', 'O-IP', 'O-TS', 'O-SP', 'O-CS', 'O-TS', 'O-OL']\n",
      "[1, 2, 16, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-O) <span style=\"color:#8c564bff;\"><span style='font-size:12pt;font-family:\"Times New Roman\",serif'>Hi, (H-O Other Header)</span></span><br /><hr />1 O-RQ) <span style=\"color:#bcbd2280;\">MUST have 10/10 comm skills. (O-RQ Required Qualifications Non-header)</span><br />2 O-RQ) <span style=\"color:#bcbd2280;\">MUST have current Machine Learning. (O-RQ Required Qualifications Non-header)</span><br />3 O-IP) <span style=\"color:#ffbb7880;\">MUST have matching Linkedin profile. (O-IP Interview Procedures Non-header)</span><br />4 O-JT) <span style=\"color:#d6272880;\">Request ID: 1140-1 (O-JT Job Title Non-header)</span><br />5 O-JD) <span style=\"color:#98df8a80;\">Start/End Dates: 3/16/2023 - 3/15/2024 (O-JD Job Duration Non-header)</span><br />6 O-OL) <span style=\"color:#c49c9480;\">Tax Work Location: Remote (O-OL Office Location Non-header)</span><br />7 O-JT) <span style=\"color:#d6272880;\">Role Title: Professional - US - Data Scientist IV (O-JT Job Title Non-header)</span><br />8 H-TS) <span style=\"color:#9edae5ff;\">Role Description: This role is a Machine Learning Engineer, see attached description (H-TS Task Scope Header)</span><br />9 O-JT) <span style=\"color:#d6272880;\">Machine Learning Platform Engineer (O-JT Job Title Non-header)</span><br />10 O-TS) <span style=\"color:#9edae580;\">Member of ODH’s Analytics Platform team; hands-on hybrid role, responsible for developing analytics and machine learning applications that leverage and build upon the ODH Analytics platform. This role will also contribute to the research and development work for the ODH Analytics platform, with special focus on artificial intelligence applications to enhance the platform’s analytic capabilities. (O-TS Task Scope Non-header)</span><br />11 H-TS) <span style=\"color:#9edae5ff;\">Description (H-TS Task Scope Header)</span><br />12 O-TS) <span style=\"color:#9edae580;\">The Machine Learning Platform Engineer is a cross-disciplinary role on the ODH’s Analytics team where the candidate will use a background in ML research and technical skills to contribute to new analytics product development. (O-TS Task Scope Non-header)</span><br />13 O-TS) <span style=\"color:#9edae580;\">The research aspects of the role include the study and application of state-of-the-art machine learning methods in the context of the Analytics Platform. The candidate will work with ODH leadership and research teams to help guide new and existing predictive analytics efforts; the candidate will provide up-to-date literature reviews and appropriate methodological knowledge for complex predictive analytics problems. (O-TS Task Scope Non-header)</span><br />14 O-TS) <span style=\"color:#9edae580;\">The development aspects of the role involve the translation of the research into new analytics functionality for ODH’s platform. The candidate will support the building of predictive analytics capacity for the platform. This means direct feedback to leadership on appropriate methods, techniques, and feasibility of developing machine learning applications. The willingness to explore and deeply understand the data ODH works with is a must. The candidate will require the ability to propose methods for solving predictive analytics problems and provide experience-based solutions. The candidate will require the ability to convey complex ideas, learn on the fly, and to put newly acquired knowledge into practice. The candidate will work closely with the following groups: ODH Advanced Analytics, ODH Software Engineering, and other Otsuka clinical and commercial teams. (O-TS Task Scope Non-header)</span><br />15 H-RQ) <span style=\"color:#bcbd22ff;\">Experience (H-RQ Required Qualifications Header)</span><br />16 O-RQ) <span style=\"color:#bcbd2280;\">Ideal candidates will require experience in the following areas: research using statistical modeling, machine learning, and general data analytics methodologies. Some experience with cloud-based analytics technologies and an understanding of healthcare data is strongly recommended. The candidate must have a research-oriented mindset. They must be able to adjust their communication style to diverse types of stakeholders (analyst, business, technical). (O-RQ Required Qualifications Non-header)</span><br />17 H-RQ) <span style=\"color:#bcbd22ff;\">Qualifications (H-RQ Required Qualifications Header)</span><br />18 H-RQ) <span style=\"color:#bcbd22ff;\">Required (H-RQ Required Qualifications Header)</span><br />19 O-RQ) <span style=\"color:#bcbd2280;\">•             Experience with Python and one or more ML libraries, i.e., TensorFlow, PyTorch, scikit-learn (O-RQ Required Qualifications Non-header)</span><br />20 O-RQ) <span style=\"color:#bcbd2280;\">•             Experience in data pre-processing techniques for statistical and machine learning applications (O-RQ Required Qualifications Non-header)</span><br />21 O-RQ) <span style=\"color:#bcbd2280;\">•             Experience developing and defending rationale for analytics research (O-RQ Required Qualifications Non-header)</span><br />22 O-RQ) <span style=\"color:#bcbd2280;\">•             Experience driving the development of new research technology (O-RQ Required Qualifications Non-header)</span><br />23 O-RQ) <span style=\"color:#bcbd2280;\">•             Experience with creating data visualizations to support communication of ideas (O-RQ Required Qualifications Non-header)</span><br />24 O-RQ) <span style=\"color:#bcbd2280;\">•             Excellent communicator (O-RQ Required Qualifications Non-header)</span><br />25 O-RQ) <span style=\"color:#bcbd2280;\">•             BA/BS Degree (O-RQ Required Qualifications Non-header)</span><br /><hr />26 H-PQ) <span style=\"color:#c7c7c7ff;\">Preferred (H-PQ Preferred Qualifications Header)</span><br />27 O-PQ) <span style=\"color:#c7c7c780;\">•             Experience with cloud-based, distributed data systems, i.e., Snowflake, Hadoop, Spark (O-PQ Preferred Qualifications Non-header)</span><br />28 O-PQ) <span style=\"color:#c7c7c780;\">•             Experience in the healthcare industry (O-PQ Preferred Qualifications Non-header)</span><br />29 O-PQ) <span style=\"color:#c7c7c780;\">•             Experience with population-level analytics (O-PQ Preferred Qualifications Non-header)</span><br />30 O-PQ) <span style=\"color:#c7c7c780;\">•             Experience developing presentations to convey ideas (story telling) (O-PQ Preferred Qualifications Non-header)</span><br />31 O-PQ) <span style=\"color:#c7c7c780;\">•             Authorship in machine learning literature or publication (O-PQ Preferred Qualifications Non-header)</span><br />32 O-PQ) <span style=\"color:#c7c7c780;\">•             Academic and/or industry research experience (O-PQ Preferred Qualifications Non-header)</span><br />33 O-PQ) <span style=\"color:#c7c7c780;\">•             Degree in Quantitative Discipline (e.g. physics, engineering, computer science, applied mathematics, etc.) (O-PQ Preferred Qualifications Non-header)</span><br />34 H-O) <span style=\"color:#8c564bff;\"><span>-- (H-O Other Header)</span></span><br />35 O-TS) <span style=\"color:#9edae580;\"><font size=\"2\">Regards, (O-TS Task Scope Non-header)</font></span><br />36 O-O) <span style=\"color:#8c564b80;\"><font color=\"#999999\" face=\"trebuchet ms, sans-serif\">Ramkumar S (O-O Other Non-header)</font></span><br />37 O-CS) <span style=\"color:#1f77b480;\"><font color=\"#0b5394\">Boston Technology Corporation (O-CS Corporate Scope Non-header)</font></span><br />38 O-O) <span style=\"color:#8c564b80;\">PH: 781-544-4799 EXT 119 (O-O Other Non-header)</span><br />39 O-O) <span style=\"color:#8c564b80;\">F: (O-O Other Non-header)</span><br />40 O-TS) <span style=\"color:#9edae580;\"><span style=\"font-size:12.8px\">781-214-7259 (O-TS Task Scope Non-header)</span></span><br />41 O-O) <span style=\"color:#8c564b80;\">Email : (O-O Other Non-header)</span><br />42 O-CS) <span style=\"color:#1f77b480;\">ramkumars@boston-technology. (O-CS Corporate Scope Non-header)</span><br />43 O-IP) <span style=\"color:#ffbb7880;\">com (O-IP Interview Procedures Non-header)</span><br />44 O-CS) <span style=\"color:#1f77b480;\">http://www.boston-technology. (O-CS Corporate Scope Non-header)</span><br />45 O-IP) <span style=\"color:#ffbb7880;\">com/ (O-IP Interview Procedures Non-header)</span><br />46 O-TS) <span style=\"color:#9edae580;\"><span style='font-family:\"trebuchet ms\",sans-serif'>225 Cedar Hill Street, Suite 200, Marlborough, MA  01752. (O-TS Task Scope Non-header)</span></span><br />47 O-SP) <span style=\"color:#17becf80;\">\"An Inc 500/5000 Company for 2010,2011 & 2012\" (O-SP Supplemental Pay Non-header)</span><br />48 O-CS) <span style=\"color:#1f77b480;\">Certified Minority Owned Business Enterprise (MBE)) (O-CS Corporate Scope Non-header)</span><br />49 O-TS) <span style=\"color:#9edae580;\">Notice of Confidentiality: (O-TS Task Scope Non-header)</span><br />50 O-OL) <span style=\"color:#c49c9480;\">The information contained herein is intended only for the confidential use of the recipient. If the reader of this message is neither the intended recipient, nor the person responsible for delivering it to the intended recipient, you are hereby notified that you have received this communication in error, and that any review, dissemination, distribution, or copying of this communication is strictly prohibited. If you receive this in error, please notify the sender immediately by telephone, and destroy this e-mail message OR reply with the subject “REMOVE” such that your email would be taken out of our distribution list. (O-OL Office Location Non-header)</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 16, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 16, 19, 21, 22, 23, 24, 25, 30, 32, 33]\n",
      "34 O-O) <span>--</span>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 34\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"•             Degree in Quantitative Discipline (e.g. physics, engineering, computer science, applied mathematics, etc.)\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<span>--</span>', 'is_header': 'True', 'is_task_scope': 'False', 'is_qualification': None, 'is_minimum_qualification': 'False', 'is_preferred_qualification': 'False', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'False', 'is_interview_procedure': 'False', 'is_corporate_scope': 'False', 'is_posting_date': 'False', 'is_other': 'True'}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = \"\"\"MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = 'True',\n",
    "            np.is_task_scope = 'False',\n",
    "            np.is_minimum_qualification = 'False',\n",
    "            np.is_preferred_qualification = 'False',\n",
    "            np.is_educational_requirement = 'False',\n",
    "            np.is_legal_notification = 'False',\n",
    "            np.is_other = 'True',\n",
    "            np.is_corporate_scope = 'False',\n",
    "            np.is_job_title = 'False',\n",
    "            np.is_office_location = 'False',\n",
    "            np.is_job_duration = 'False',\n",
    "            np.is_supplemental_pay = 'False',\n",
    "            np.is_interview_procedure = 'False',\n",
    "            np.is_posting_date = 'False'\n",
    "        \"\"\" + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<span>--</span>', 'is_header': None, 'is_task_scope': None, 'is_qualification': None, 'is_minimum_qualification': None, 'is_preferred_qualification': None, 'is_legal_notification': None, 'is_job_title': None, 'is_office_location': None, 'is_job_duration': None, 'is_supplemental_pay': None, 'is_educational_requirement': None, 'is_interview_procedure': None, 'is_corporate_scope': None, 'is_posting_date': None, 'is_other': None}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
