{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from notebook_utils import NotebookUtilities\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a list of notebook names\n",
    "black_list = ['.ipynb_checkpoints', '$Recycle.Bin']\n",
    "this_folder = osp.dirname(osp.abspath(osp.curdir))\n",
    "\n",
    "# List of documents\n",
    "documents = []\n",
    "\n",
    "# List of words for each document\n",
    "words_list = []\n",
    "\n",
    "file_type = '.ipynb'\n",
    "# import_regex = re.compile(r'\"\\s*(?:from\\s+(\\w+)(?:\\.\\w+)?\\s+)?import\\s+([^\\s,.]+)(?:\\.\\w+)?((\\s*,\\s*\\w+)*)?\\\\n\",?')\n",
    "import_regex = re.compile(r'\"\\s*(from [a-z._]+ )?import ([a-z._]+(, )?)+( as [a-z]+)?\\\\n\",?')\n",
    "for sub_directory, directories_list, files_list in os.walk(this_folder):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith(file_type):\n",
    "                notebook_name = file_name.replace(file_type, '')\n",
    "                documents.append(notebook_name)\n",
    "                file_path = osp.join(sub_directory, file_name)\n",
    "                with open(file_path, 'r', encoding=nu.encoding_type) as f:\n",
    "                    lines_list = f.readlines()\n",
    "                    imports_list = []\n",
    "                    for line in lines_list:\n",
    "                        if import_regex.search(line): imports_list.extend(re.sub(r'\\\\n\",?', '', line.split('import ')[-1]).split(' as ')[0].strip().split(', '))\n",
    "                    words_list.append(imports_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Load Jobs from list on Indeed', 'Indeed API', 'Indeed Application Status', 'Indeed.com Sequence Analysis', 'Indeed.com Web Spoofing', 'Indeed Scrapes ETL', 'Scrape Indeed.com View Job Pages', 'Indeed Header Classifier Scores', 'Get Requirements Lists from Indeed.com']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[dn for dn in documents if 'Indeed' in dn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine document names and words for each document\n",
    "document_data = [' '.join(words_list[i]) for i in range(len(words_list))]\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(document_data)\n",
    "\n",
    "# Get feature names (words) and document names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "document_names = [f'Document_{i}' for i in range(len(documents))]\n",
    "\n",
    "# Create a data frame to display the TF-IDF matrix\n",
    "tfidf_df = DataFrame(data=tfidf_matrix.toarray(), index=documents, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tarfile</th>\n",
       "      <th>inspect</th>\n",
       "      <th>sklearn_crfsuite</th>\n",
       "      <th>atmodel</th>\n",
       "      <th>jupyter_config_path</th>\n",
       "      <th>winshell</th>\n",
       "      <th>webbrowser</th>\n",
       "      <th>scrapeghost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Update NavigableParentSequence Table from Examples</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Create the NavigableParent is Header Dictionary</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Installs</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Build a Complete Part-of-Speech Dictionary</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Build Other Non-headers List</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evaluate LDA on Labeled Data</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Build O-TS Dictionary from Examples</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indeed Application Status</th>\n",
       "      <td>0.433038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Build the Child Strings List Dictionary from Examples</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Build NavigableParents SQL from Examples</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     request  datetime  \\\n",
       "Update NavigableParentSequence Table from Examples  0.000000       0.0   \n",
       "Create the NavigableParent is Header Dictionary     0.000000       0.0   \n",
       "Installs                                            0.000000       0.0   \n",
       "Build a Complete Part-of-Speech Dictionary          0.000000       0.0   \n",
       "Build Other Non-headers List                        0.000000       0.0   \n",
       "Evaluate LDA on Labeled Data                        0.000000       0.0   \n",
       "Build O-TS Dictionary from Examples                 0.000000       0.0   \n",
       "Indeed Application Status                           0.433038       0.0   \n",
       "Build the Child Strings List Dictionary from Ex...  0.000000       0.0   \n",
       "Build NavigableParents SQL from Examples            0.000000       0.0   \n",
       "\n",
       "                                                    tarfile  inspect  \\\n",
       "Update NavigableParentSequence Table from Examples      0.0      0.0   \n",
       "Create the NavigableParent is Header Dictionary         0.0      0.0   \n",
       "Installs                                                0.0      0.0   \n",
       "Build a Complete Part-of-Speech Dictionary              0.0      0.0   \n",
       "Build Other Non-headers List                            0.0      0.0   \n",
       "Evaluate LDA on Labeled Data                            0.0      0.0   \n",
       "Build O-TS Dictionary from Examples                     0.0      0.0   \n",
       "Indeed Application Status                               0.0      0.0   \n",
       "Build the Child Strings List Dictionary from Ex...      0.0      0.0   \n",
       "Build NavigableParents SQL from Examples                0.0      0.0   \n",
       "\n",
       "                                                    sklearn_crfsuite  atmodel  \\\n",
       "Update NavigableParentSequence Table from Examples               0.0      0.0   \n",
       "Create the NavigableParent is Header Dictionary                  0.0      0.0   \n",
       "Installs                                                         0.0      0.0   \n",
       "Build a Complete Part-of-Speech Dictionary                       0.0      0.0   \n",
       "Build Other Non-headers List                                     0.0      0.0   \n",
       "Evaluate LDA on Labeled Data                                     0.0      0.0   \n",
       "Build O-TS Dictionary from Examples                              0.0      0.0   \n",
       "Indeed Application Status                                        0.0      0.0   \n",
       "Build the Child Strings List Dictionary from Ex...               0.0      0.0   \n",
       "Build NavigableParents SQL from Examples                         0.0      0.0   \n",
       "\n",
       "                                                    jupyter_config_path  \\\n",
       "Update NavigableParentSequence Table from Examples                  0.0   \n",
       "Create the NavigableParent is Header Dictionary                     0.0   \n",
       "Installs                                                            0.0   \n",
       "Build a Complete Part-of-Speech Dictionary                          0.0   \n",
       "Build Other Non-headers List                                        0.0   \n",
       "Evaluate LDA on Labeled Data                                        0.0   \n",
       "Build O-TS Dictionary from Examples                                 0.0   \n",
       "Indeed Application Status                                           0.0   \n",
       "Build the Child Strings List Dictionary from Ex...                  0.0   \n",
       "Build NavigableParents SQL from Examples                            0.0   \n",
       "\n",
       "                                                    winshell  webbrowser  \\\n",
       "Update NavigableParentSequence Table from Examples       0.0         0.0   \n",
       "Create the NavigableParent is Header Dictionary          0.0         0.0   \n",
       "Installs                                                 0.0         0.0   \n",
       "Build a Complete Part-of-Speech Dictionary               0.0         0.0   \n",
       "Build Other Non-headers List                             0.0         0.0   \n",
       "Evaluate LDA on Labeled Data                             0.0         0.0   \n",
       "Build O-TS Dictionary from Examples                      0.0         0.0   \n",
       "Indeed Application Status                                0.0         0.0   \n",
       "Build the Child Strings List Dictionary from Ex...       0.0         0.0   \n",
       "Build NavigableParents SQL from Examples                 0.0         0.0   \n",
       "\n",
       "                                                    scrapeghost  \n",
       "Update NavigableParentSequence Table from Examples          0.0  \n",
       "Create the NavigableParent is Header Dictionary             0.0  \n",
       "Installs                                                    0.0  \n",
       "Build a Complete Part-of-Speech Dictionary                  0.0  \n",
       "Build Other Non-headers List                                0.0  \n",
       "Evaluate LDA on Labeled Data                                0.0  \n",
       "Build O-TS Dictionary from Examples                         0.0  \n",
       "Indeed Application Status                                   0.0  \n",
       "Build the Child Strings List Dictionary from Ex...          0.0  \n",
       "Build NavigableParents SQL from Examples                    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(tfidf_df.sample(10).T.sample(10).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get distinctive words for each document\n",
    "distinctive_words = {}\n",
    "for i, document_name in enumerate(documents):\n",
    "    \n",
    "    # Get the TF-IDF scores for the current document\n",
    "    tfidf_scores = tfidf_df.loc[document_name]\n",
    "    \n",
    "    # Get the indices of the top N TF-IDF scores\n",
    "    top_indices = tfidf_scores.argsort()[-5:][::-1]\n",
    "    \n",
    "    # Get the corresponding words for the top N indices\n",
    "    top_words = [feature_names[index] for index in top_indices]\n",
    "    \n",
    "    # Store distinctive words for the document\n",
    "    distinctive_words[document_name] = top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert these notebook names (and the libraries they used) into bullet points for a resume describing significant accomplishments for my position as Machine Learning Engineer. Keep the libraries used as a parenthetical suffix on the bullet point:\n",
      "\n",
      "Add file_name column to HeaderTagSequence.csv, Add Hashes of File Contents to FileNames, Indeed API, and Installs: (sys, zipfile, matplotlib, itertools, and json)\n",
      "Build a Complete Part-of-Speech Dictionary, _Untitled_2, and Cypher Exploration: (pandas, zipfile, matplotlib, itertools, and json)\n",
      "Build Corporate Scope Non-headers List, Build Educational Requirement Non-headers List, Build Interview Procedure Non-headers List, Build Job Duration Non-headers List, Build Job Title Non-headers List, Build Legal Notifications Non-headers List, Build Office Location Non-headers List, Build Other Non-headers List, Build Posting Date Non-headers List, Build Preferred Requirements Non-headers List, Build Qualification Non-headers List, and Build Supplemental Pay Non-headers List: (random, os, zipfile, matplotlib, and itertools)\n",
      "Build Estimators List: (signature, zipfile, matplotlib, itertools, and json)\n",
      "Build grid_search_params: (enable_hist_gradient_boosting, logging, signature, pickle, and numpy)\n",
      "Build H-RQ Dictionary from Examples and Build O-RQ Dictionary from Examples: (pandas, re, random, zipfile, and jupyter_runtime_dir)\n",
      "Build Headers Lists, Build Task Scope Headers List, Get Longest Path, and Set Is Header Attribute: (urlparse, parse_qs, datetime, sys, and json)\n",
      "Build NavigableParents SQL from Examples: (textwrap, re, random, zipfile, and load_qa_chain)\n",
      "Build NP Graph from Examples and Set Educational Flags in NP Graph: (textwrap, pandas, re, random, and zipfile)\n",
      "Build O-TS Dictionary from Examples: (re, random, zipfile, matplotlib, and itertools)\n",
      "Build POS Conditional Random Field Elements, SQL Table Creation, Truncate Repeating NP IDs from NPS Table, _Untitled_1, Create The Corp Scope List, Create The Educ Reqs List, Create the H-RQ Dictionary from the Database, Create the Header Pattern Dictionary from the Database, Create The Interv Proc List, Create The Job Duration List, Create The Job Title List, Create The Legal Notifs List, Create the NavigableParent is Header Dictionary, Create the NavigableParent Qual Dictionary, Create the O-RQ Dictionary from the Database, Create the O-TS Dictionary from the Database, Create The Office Loc List, Create The Other List, Create The Post Date List, Create The Preff Quals List, Create The Req Quals List, Create The Supp Pay List, LaTex Exploration, Create Suffix Tree Class using Lists, Debug get_feature_dict_list, DS_Content_Contributor_Writing_Sample_Template, Linear Discriminant Analysis, Recreate the Header Pattern Dictionary, and SQL Maintenance: (zipfile, inspect, itertools, json, and jupyter_config_path)\n",
      "Build Resume Work Experience from Notebook Names: (defaultdict, path, os, re, and sys)\n",
      "Build the Child Strings List Dictionary from Examples: (pandas, random, zipfile, matplotlib, and itertools)\n",
      "Get Parts-of-Speech Value Counts: (pandas, sys, zipfile, matplotlib, and itertools)\n",
      "Ingest CSV and HTML Files: (pandas, sent_tokenize, tqdm, winsound, and humanize)\n",
      "Load Jobs from list on Indeed: (parse_qs, urlparse, warnings, re, and os)\n",
      "Populate All Child Tag Sequences for FileNames: (tqdm, winsound, humanize, datetime, and time)\n",
      "Populate Cypher Tables and Relationships: (copyfile, warnings, os, sys, and jupyter_path)\n",
      "Populate the HeaderTagSequence Table: (random, sys, zipfile, matplotlib, and itertools)\n",
      "Update NavigableParentSequence Table from Examples: (textwrap, random, zipfile, matplotlib, and itertools)\n",
      "Nightly Retraining: (winsound, numpy, humanize, datetime, and time)\n",
      "Evaluate CRF on Labeled Data: (confusion_matrix, sklearn_crfsuite, classification_report, pyplot, and matplotlib)\n",
      "Evaluate Getting a Feature Dictionary, MassUI Job Search Log, and Complete Percent-fit Values: (winsound, humanize, datetime, warnings, and time)\n",
      "Evaluate LDA on Labeled Data: (confusion_matrix, classification_report, pyplot, matplotlib, and numpy)\n",
      "Evaluate LR on Labeled Data: (confusion_matrix, classification_report, pyplot, matplotlib, and random)\n",
      "Evaluate POS LR and CRF on Labeled NavigableParents: (pos_tag, sklearn_crfsuite, nltk, train_test_split, and classification_report)\n",
      "Evaluate pos_tag on Labeled NavigableParents: (random, tqdm_notebook, pos_tag, groupby, and nltk)\n",
      "Character CNN Exploration: (torch, pyplot, matplotlib, optim, and transforms)\n",
      "Classifier Signatures Exploration: (enable_hist_gradient_boosting, time, pprint, logging, and inspect)\n",
      "DocX Exploration: (mammoth, zipfile, os, matplotlib, and itertools)\n",
      "GenSim Exploration: (signature, gensim, pickle, matplotlib, and pyplot)\n",
      "Job Hunting Data Exploration: (hashlib, datetime, tarfile, random, and gensim)\n",
      "Job Hunting Demo: (string, numpy, zipfile, matplotlib, and itertools)\n",
      "Jupyter Configuration Exploration: (jupyter_config_path, jupyter_core, version, jupyter_data_dir, and jupyter_path)\n",
      "Multilingual_Search_with_Cohere_and_Langchain: (load_qa_chain, tensorflow_datasets, os, zipfile, and matplotlib)\n",
      "PyTorch Exploration: (transformers, pandas, sys, zipfile, and jupyter_path)\n",
      "Quals Dictionary Exploration: (pandas, warnings, sys, jupyter_data_dir, and logging)\n",
      "Scraping Websites using OpenAI's GPT: (pprint, openai, scrapeghost, winsound, and humanize)\n",
      "SGDClassifier Exploration: (classification_report, humanize, time, re, and os)\n",
      "TensorFlow Exploration: (tensorflow, sys, zipfile, humanize, and ipywidgets)\n",
      "torch_test: (torch, matutils, itertools, json, and jupyter_config_path)\n",
      "Version Exploration: (os, numpy, pandas, re, and random)\n",
      "Extract Reqs from Clipboard: (pyperclip, re, sys, zipfile, and jupyter_runtime_dir)\n",
      "atmodel_tutorial: (smart_open, atmodel, output_notebook, spacy, and locale)\n",
      "Build an HtmlAnalysis Calling Graph: (matplotlib, set_matplotlib_formats, pyplot, copy, and patches)\n",
      "CoNLL2002: (scipy, cross_val_score, make_scorer, sklearn, and scorers)\n",
      "Get Demo Function Relationships: (matplotlib, patches, networkx, pyperclip, and set_matplotlib_formats)\n",
      "Get Reqs from URL: (quote_plus, zipfile, matutils, itertools, and json)\n",
      "Import CSV Tables into Neo4j: (copyfile, os, pandas, zipfile, and jupyter_runtime_dir)\n",
      "Indeed Application Status: (sys, request, transformers, urllib, and networkx)\n",
      "Indeed.com Sequence Analysis: (re, requests, urlparse, parse_qs, and pyplot)\n",
      "Indeed.com Web Spoofing: (scrape_utils, parse_qs, urlparse, sys, and jupyter_path)\n",
      "Job Hunting Classifier Scores: (entropy, inspect, set_matplotlib_formats, pyplot, and matplotlib)\n",
      "Job Hunting: (string, numpy, datetime, zipfile, and itertools)\n",
      "Job Hunting_old: (ipywidgets, pickle, pandas, re, and os)\n",
      "Job Hunting_old2: (pdist, squareform, euclidean, pandas, and jupyter_core)\n",
      "Load SQL Tables into Neo4j: (copyfile, pandas, os, zipfile, and jupyter_runtime_dir)\n",
      "NER System with Header Pattern Data: (random, metrics, sklearn_crfsuite, scorers, and sklearn)\n",
      "OS Path Navigation: (os, subprocess, winshell, timedelta, and path)\n",
      "Populate the NavigableParentSequence Table: (pyodbc, sys, random, zipfile, and jupyter_runtime_dir)\n",
      "Position Description Based on my Current Work: (ipywidgets, inspect, itertools, json, and jupyter_config_path)\n",
      "train_test_split: (train_test_split, numpy, zipfile, matplotlib, and itertools)\n",
      "Tweet Clustering: (pairwise_distances_argmin, combinations, tee, distance, and cosine)\n",
      "Undersampling: (winsound, matplotlib, pyplot, humanize, and datetime)\n",
      "_Untitled_: (pandas, re, os, sys, and zipfile)\n",
      "Attempt to JSONify a CRF object: (json, pos_tag, requests, nltk, and train_test_split)\n",
      "Label Required Qualification Non-headers: (to_hex, numpy, pandas, warnings, and re)\n",
      "Sectionize and Store Postings: (shuffle, groupby, random, zipfile, and matplotlib)\n",
      "CRF Hyperparameter Optimization: (stats, scipy, make_scorer, metrics, and sklearn_crfsuite)\n",
      "Builtin Scrapes ETL: (shutil, parse_qs, urlparse, humanize, and datetime)\n",
      "Dice Scrapes ETL: (winsound, humanize, datetime, time, and os)\n",
      "Glassdoor Scrapes ETL: (requests, parse_qs, urlparse, datetime, and warnings)\n",
      "Indeed Scrapes ETL: (os, winsound, humanize, datetime, and warnings)\n",
      "Insight Global Scrapes ETL: (webbrowser, requests, parse_qs, urlparse, and datetime)\n",
      "Linkedin Scrapes ETL: (parse_qs, urlparse, winsound, humanize, and datetime)\n",
      "Scrape Indeed.com View Job Pages: (scrape_utils, logging, warnings, os, and sys)\n",
      "Single Email Scrapes ETL: (shutil, winsound, humanize, datetime, and time)\n",
      "benchmarking: (numpy, tabulate, time, zipfile, and cross_val_score)\n",
      "Indeed Header Classifier Scores: (entropy, inspect, gensim, set_matplotlib_formats, and pyplot)\n",
      "IsQualified Classifier Scores: (pyplot, matplotlib, time, entropy, and inspect)\n",
      "Test Decorators: (os, sys, zipfile, matplotlib, and itertools)\n",
      "Test Element Analysis module: (warnings, os, sys, jupyter_data_dir, and logging)\n",
      "Test Section Utilities: (to_hex, sys, warnings, os, and ipywidgets)\n",
      "Test Word2Features and Train LR on Labeled Data and Evaluate: (random, zipfile, matutils, itertools, and json)\n",
      "Fix null is_headers: (re, ipywidgets, winsound, numpy, and humanize)\n",
      "Fix POS and Quals for Select Postings: (tokenize, sent_tokenize, re, nltk, and winsound)\n",
      "Get Requirements Lists from Indeed.com: (requests, parse_qs, urlparse, pandas, and random)\n",
      "NER System with Child Strings Data: (groupby, metrics, os, train_test_split, and random)\n",
      "Plot Coherence by Filter Params and Plot Coherence by Topics: (pyplot, matplotlib, zipfile, matutils, and itertools)\n",
      "Plot Coherence by Model Params: (itertools, matplotlib, pyplot, numpy, and time)\n",
      "Prepare Cover Sheet: (parse, enchant, urllib, winsound, and humanize)\n",
      "Train a CRF on our Labeled Data and Evaluate it: (flatten, sklearn_crfsuite, train_test_split, classification_report, and warnings)\n",
      "Train on Quals List: (datetime, zipfile, matplotlib, itertools, and json)\n",
      "Bias vs Variance: (pyplot, matplotlib, accuracy_score, confusion_matrix, and winsound)\n",
      "Minimum Requirements Header Wordcloud: (winsound, pyplot, matplotlib, humanize, and datetime)\n",
      "Progress by Date: (matplotlib, pyplot, graph_objects, peakutils, and cycler)\n",
      "Visualize Basic Qual Section in File: (to_hex, warnings, os, sys, and json)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "d = {k: str(v) for k, v in distinctive_words.items()}\n",
    "grouped_dict = defaultdict(list)\n",
    "for k, v in d.items(): grouped_dict[v].append(k)\n",
    "\n",
    "# Display distinctive words for each document group\n",
    "print(\n",
    "    'Convert these notebook names (and the libraries they used) into bullet points for a resume describing significant accomplishments'\n",
    "    ' for my position as Machine Learning Engineer. Keep the libraries used as a parenthetical suffix on the bullet point:\\n'\n",
    ")\n",
    "for distinctive_words, document_group in grouped_dict.items():\n",
    "    print(f'{nu.conjunctify_nouns(document_group)}: ({nu.conjunctify_nouns(eval(distinctive_words))})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (Python 3.10.9)",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
