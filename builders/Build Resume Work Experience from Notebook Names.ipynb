{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from notebook_utils import NotebookUtilities\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a list of notebook names\n",
    "black_list = ['.ipynb_checkpoints', '$Recycle.Bin']\n",
    "this_folder = osp.dirname(osp.abspath(osp.curdir))\n",
    "\n",
    "# List of documents\n",
    "documents = []\n",
    "\n",
    "# List of words for each document\n",
    "words_list = []\n",
    "\n",
    "import_regex = re.compile(r'\"\\s*(from [a-z._]+ )?import ([a-z._]+(, )?)+( as [a-z]+)?\\\\n\",?')\n",
    "for sub_directory, directories_list, files_list in os.walk(this_folder):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith('.ipynb'):\n",
    "                notebook_name = file_name.split('.')[0]\n",
    "                documents.append(notebook_name)\n",
    "                file_path = osp.join(sub_directory, file_name)\n",
    "                with open(file_path, 'r', encoding=nu.encoding_type) as f:\n",
    "                    lines_list = f.readlines()\n",
    "                    imports_list = []\n",
    "                    for line in lines_list:\n",
    "                        if import_regex.search(line): imports_list.extend(re.sub(r'\\\\n\",?', '', line.split('import ')[-1]).split(' as ')[0].strip().split(', '))\n",
    "                    words_list.append(imports_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine document names and words for each document\n",
    "document_data = [' '.join(words_list[i]) for i in range(len(words_list))]\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(document_data)\n",
    "\n",
    "# Get feature names (words) and document names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "document_names = [f'Document_{i}' for i in range(len(documents))]\n",
    "\n",
    "# Create a data frame to display the TF-IDF matrix\n",
    "tfidf_df = DataFrame(data=tfidf_matrix.toarray(), index=documents, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_test_split</th>\n",
       "      <th>sent_tokenize</th>\n",
       "      <th>generate_item_bank</th>\n",
       "      <th>nltk</th>\n",
       "      <th>get_unique_ngrams</th>\n",
       "      <th>util</th>\n",
       "      <th>copy</th>\n",
       "      <th>get_routine_scores</th>\n",
       "      <th>plot_element_counts</th>\n",
       "      <th>get_ndistinct_subsequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Analyze Patient Engaged Events</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Develop the Treatment Placement Error Metric</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calculate Results for Abstract Submission</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visualize Location Points</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visualize Elapsed Time Spent on Patient</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orientation-Normal Sequence Analysis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Find Negative Metrics in Jeremy's DCEMS Data</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visualize every Player Gaze</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Replace UUIDs with Cleaned and Revised File Info</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analyze TOOL_HOVERing as Indicative of Next Patient Choice</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    train_test_split  \\\n",
       "Analyze Patient Engaged Events                                   0.0   \n",
       "Develop the Treatment Placement Error Metric                     0.0   \n",
       "Calculate Results for Abstract Submission                        0.0   \n",
       "Visualize Location Points                                        0.0   \n",
       "Visualize Elapsed Time Spent on Patient                          0.0   \n",
       "Orientation-Normal Sequence Analysis                             0.0   \n",
       "Find Negative Metrics in Jeremy's DCEMS Data                     0.0   \n",
       "Visualize every Player Gaze                                      0.0   \n",
       "Replace UUIDs with Cleaned and Revised File Info                 0.0   \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...               0.0   \n",
       "\n",
       "                                                    sent_tokenize  \\\n",
       "Analyze Patient Engaged Events                                0.0   \n",
       "Develop the Treatment Placement Error Metric                  0.0   \n",
       "Calculate Results for Abstract Submission                     0.0   \n",
       "Visualize Location Points                                     0.0   \n",
       "Visualize Elapsed Time Spent on Patient                       0.0   \n",
       "Orientation-Normal Sequence Analysis                          0.0   \n",
       "Find Negative Metrics in Jeremy's DCEMS Data                  0.0   \n",
       "Visualize every Player Gaze                                   0.0   \n",
       "Replace UUIDs with Cleaned and Revised File Info              0.0   \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...            0.0   \n",
       "\n",
       "                                                    generate_item_bank  nltk  \\\n",
       "Analyze Patient Engaged Events                                     0.0   0.0   \n",
       "Develop the Treatment Placement Error Metric                       0.0   0.0   \n",
       "Calculate Results for Abstract Submission                          0.0   0.0   \n",
       "Visualize Location Points                                          0.0   0.0   \n",
       "Visualize Elapsed Time Spent on Patient                            0.0   0.0   \n",
       "Orientation-Normal Sequence Analysis                               0.0   0.0   \n",
       "Find Negative Metrics in Jeremy's DCEMS Data                       0.0   0.0   \n",
       "Visualize every Player Gaze                                        0.0   0.0   \n",
       "Replace UUIDs with Cleaned and Revised File Info                   0.0   0.0   \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...                 0.0   0.0   \n",
       "\n",
       "                                                    get_unique_ngrams  util  \\\n",
       "Analyze Patient Engaged Events                                    0.0   0.0   \n",
       "Develop the Treatment Placement Error Metric                      0.0   0.0   \n",
       "Calculate Results for Abstract Submission                         0.0   0.0   \n",
       "Visualize Location Points                                         0.0   0.0   \n",
       "Visualize Elapsed Time Spent on Patient                           0.0   0.0   \n",
       "Orientation-Normal Sequence Analysis                              0.0   0.0   \n",
       "Find Negative Metrics in Jeremy's DCEMS Data                      0.0   0.0   \n",
       "Visualize every Player Gaze                                       0.0   0.0   \n",
       "Replace UUIDs with Cleaned and Revised File Info                  0.0   0.0   \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...                0.0   0.0   \n",
       "\n",
       "                                                        copy  \\\n",
       "Analyze Patient Engaged Events                      0.000000   \n",
       "Develop the Treatment Placement Error Metric        0.000000   \n",
       "Calculate Results for Abstract Submission           0.000000   \n",
       "Visualize Location Points                           0.000000   \n",
       "Visualize Elapsed Time Spent on Patient             0.000000   \n",
       "Orientation-Normal Sequence Analysis                0.593187   \n",
       "Find Negative Metrics in Jeremy's DCEMS Data        0.000000   \n",
       "Visualize every Player Gaze                         0.000000   \n",
       "Replace UUIDs with Cleaned and Revised File Info    0.000000   \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...  0.000000   \n",
       "\n",
       "                                                    get_routine_scores  \\\n",
       "Analyze Patient Engaged Events                                     0.0   \n",
       "Develop the Treatment Placement Error Metric                       0.0   \n",
       "Calculate Results for Abstract Submission                          0.0   \n",
       "Visualize Location Points                                          0.0   \n",
       "Visualize Elapsed Time Spent on Patient                            0.0   \n",
       "Orientation-Normal Sequence Analysis                               0.0   \n",
       "Find Negative Metrics in Jeremy's DCEMS Data                       0.0   \n",
       "Visualize every Player Gaze                                        0.0   \n",
       "Replace UUIDs with Cleaned and Revised File Info                   0.0   \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...                 0.0   \n",
       "\n",
       "                                                    plot_element_counts  \\\n",
       "Analyze Patient Engaged Events                                      0.0   \n",
       "Develop the Treatment Placement Error Metric                        0.0   \n",
       "Calculate Results for Abstract Submission                           0.0   \n",
       "Visualize Location Points                                           0.0   \n",
       "Visualize Elapsed Time Spent on Patient                             0.0   \n",
       "Orientation-Normal Sequence Analysis                                0.0   \n",
       "Find Negative Metrics in Jeremy's DCEMS Data                        0.0   \n",
       "Visualize every Player Gaze                                         0.0   \n",
       "Replace UUIDs with Cleaned and Revised File Info                    0.0   \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...                  0.0   \n",
       "\n",
       "                                                    get_ndistinct_subsequences  \n",
       "Analyze Patient Engaged Events                                             0.0  \n",
       "Develop the Treatment Placement Error Metric                               0.0  \n",
       "Calculate Results for Abstract Submission                                  0.0  \n",
       "Visualize Location Points                                                  0.0  \n",
       "Visualize Elapsed Time Spent on Patient                                    0.0  \n",
       "Orientation-Normal Sequence Analysis                                       0.0  \n",
       "Find Negative Metrics in Jeremy's DCEMS Data                               0.0  \n",
       "Visualize every Player Gaze                                                0.0  \n",
       "Replace UUIDs with Cleaned and Revised File Info                           0.0  \n",
       "Analyze TOOL_HOVERing as Indicative of Next Pat...                         0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(tfidf_df.sample(10).T.sample(10).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get distinctive words for each document\n",
    "def get_distinctive_words(tfidf_matrix, document_names, top_n=5):\n",
    "    distinctive_words = {}\n",
    "\n",
    "    for i, document_name in enumerate(document_names):\n",
    "        # Get the TF-IDF scores for the current document\n",
    "        tfidf_scores = tfidf_matrix.loc[document_name]\n",
    "\n",
    "        # Get the indices of the top N TF-IDF scores\n",
    "        top_indices = tfidf_scores.argsort()[-top_n:][::-1]\n",
    "\n",
    "        # Get the corresponding words for the top N indices\n",
    "        top_words = [feature_names[index] for index in top_indices]\n",
    "\n",
    "        # Store distinctive words for the document\n",
    "        distinctive_words[document_name] = top_words\n",
    "\n",
    "    return distinctive_words\n",
    "\n",
    "# Get distinctive words for each document\n",
    "distinctive_words_per_document = get_distinctive_words(tfidf_df, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert these notebook names (and the libraries they used) into bullet points for a resume describing significant accomplishments for my position as Machine Learning Engineer. Keep the libraries used as a parenthetical suffix on the bullet point:\n",
      "\n",
      "Add a Responder Type Column to the OSU dataset of FRVRS Logs: (re, path, os, numpy, and timedelta)\n",
      "Build a Model to Predict Tag Applied Type: (train_test_split, tqdm, permutation_importance, numpy, and humanize)\n",
      "Build Patient Engagement timeline CSV and Analyze Patient Engaged Events: (apriori, association_rules, re, numpy, and timedelta)\n",
      "Build the OSU dataset of FRVRS Logs: (en_core_web_sm, spacy, re, path, and os)\n",
      "Analyze Deidentified Simulation Voice Captures: (timedelta, re, numpy, humanize, and pandas)\n",
      "Analyze Elapsed Time Estimation for Operations: (apriori, association_rules, numpy, humanize, and timedelta)\n",
      "Analyze Gaze and Intent, Identify any Anomalous Files, Replace the tool applied sender missing patient ID, Develop the Number of Pulses Taken Metric, Develop the Triage Accuracy Metric, Develop the Triage Efficiency Metric, and Plot Grouped Box and Whiskers for Time to First Engagement: (numpy, humanize, timedelta, re, and pandas)\n",
      "Analyze Issue with Logging Multiple TOOL_APPLIEDs: (random, numpy, humanize, timedelta, and pyplot)\n",
      "Analyze Preliminary Research Questions and Develop the R-squared Triage Accuracy Metric: (path, os, humanize, timedelta, and re)\n",
      "Analyze START Triage vs SALT Triage: (random, path, numpy, humanize, and timedelta)\n",
      "Analyze Time Spent on Task, Develop the Correct Count Triage Accuracy Metric, Develop the Number of Patients Engaged Metric, Develop the Number of Voice Captures per Session Metric, Develop the Patient Accuracy Rate Metric, Develop the Time to First Engagement Metric, Develop the Time to First Treatment Metric, Develop the Time To Hemorrhage Control Metric, Develop the Total Number of Teleports Metric, Develop the Total User Actions Taken Metric, Develop the Treatment Placement Error Metric, and Visualize Elapsed Time Spent on Patient: (humanize, timedelta, pyplot, re, and pandas)\n",
      "Analyze TOOL_HOVERing as Indicative of Next Patient Choice: (numpy, pandas, re, pyplot, and matplotlib)\n",
      "Catsim Exploration and Rasch Analysis: (icc, catsim, generate_item_bank, plot, and random)\n",
      "Explore Bleeping Proper Nouns out of Audio Files: (soundfile, tempfile, speech_recognition, platform, and re)\n",
      "Exploring Voice Capture Ngrams: (word_tokenize, nltk, pos_tag, words, and stopwords)\n",
      "Find Negative Metrics in Jeremy's DCEMS Data: (random, path, os, numpy, and humanize)\n",
      "Near-engagement Transactions for Affinity Analysis: (apriori, association_rules, random, path, and sys)\n",
      "Orientation-Normal Sequence Analysis: (cm, copy, matplotlib, numpy, and pyplot)\n",
      "Tool Applied Exploration and Plot Pie Charts for Tag to SALT Dataset: (path, os, numpy, humanize, and timedelta)\n",
      "Walk-Wave Sequence Analysis: (get_transition_matrix, get_synchrony, get_all_ngrams, get_element_frequency, and get_ndistinct_subsequences)\n",
      "Attic: (docx, colors, random, pandas, and matplotlib)\n",
      "Installs: (os, sys, words, get_subsequences, and get_motif)\n",
      "OS Path Navigation: (platform, re, path, os, and sys)\n",
      "Build Resume Work Experience from Notebook Names: (defaultdict, path, os, re, and sys)\n",
      "Fix Elapsed Time Simultaneity: (re, numpy, timedelta, pyplot, and pandas)\n",
      "Rename elapsed time columns in DataFrame pickles and Rename time group columns in DataFrame pickles: (path, numpy, timedelta, pyplot, and re)\n",
      "Rename Files: (datetime, shutil, csv, os, and sys)\n",
      "Replace UUIDs with Cleaned and Revised File Info: (en_core_web_sm, spacy, path, numpy, and timedelta)\n",
      "Calculate Results for Abstract Submission: (numpy, path, os, humanize, and timedelta)\n",
      "Develop the Correct Count by Tag Triage Accuracy Metric: (seaborn, numpy, humanize, timedelta, and pyplot)\n",
      "Develop the Number of Patients Treated Metric: (humanize, re, pandas, pyplot, and matplotlib)\n",
      "Plot Stacked Horizontal Bar Charts for Over-Under Triage Errors: (seaborn, colors, matplotlib, numpy, and humanize)\n",
      "Recompute Visualizations for the SDMPH 2023 Poster: (string, arange, operator, seaborn, and path)\n",
      "Visualize every Patient Interaction: (colors, matplotlib, pyplot, path, and os)\n",
      "Visualize every Player Gaze: (colors, random, matplotlib, path, and os)\n",
      "Visualize Location Points and Visualize Non-cumulative Teleportation Events: (pandas, re, pyplot, matplotlib, and os)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "d = {k: str(v) for k, v in distinctive_words_per_document.items()}\n",
    "grouped_dict = defaultdict(list)\n",
    "for k, v in d.items(): grouped_dict[v].append(k)\n",
    "\n",
    "# Display distinctive words for each document group\n",
    "print(\n",
    "    'Convert these notebook names (and the libraries they used) into bullet points for a resume describing significant accomplishments'\n",
    "    ' for my position as Machine Learning Engineer. Keep the libraries used as a parenthetical suffix on the bullet point:\\n'\n",
    ")\n",
    "for distinctive_words, document_group in grouped_dict.items():\n",
    "    print(f'{nu.conjunctify_nouns(document_group)}: ({nu.conjunctify_nouns(eval(distinctive_words))})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (Python 3.10.9)",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
