{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.23 s\n",
      "Wall time: 4.6 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "from html_analysis import ElementAnalysis\n",
    "ea = ElementAnalysis(ha=ha, hc=None, verbose=False)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from IPython.display import clear_output\n",
    "%run ../load_magic/dataframes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files_list = sorted([fn for fn in os.listdir(cu.SAVES_HTML_FOLDER) if fn.endswith('.html')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            MATCH\n",
      "                (np:NavigableParents {navigable_parent: \": Adaptive Biotechnologies values our relationships with our Recruitment Partners and will only accept resumes from those partners whom have been contracted by a member of our Human Resources team to collaborate with us. Adaptive Biotechnologies is not responsible for any fees related to resumes that are unsolicited or are received by any employee of Adaptive Biotechnologies who is not a member of the Human Resources team.\"}),\n",
      "                (ht:HeaderTags {header_tag: \"plaintext\"})\n",
      "            MERGE (ht)-[r:SUMMARIZES]->(np);\n",
      "MERGE (:FileNames {file_name: \"temp_Data_Scientist_(Services)_63b23e3bd4672ef3.html\"});\n",
      "MERGE (:FileNames {file_name: \"temp_Data_Scientist_00ba1a22ba67ffd2.html\"});\n",
      "MERGE (:FileNames {file_name: \"temp_Senior_Data_Analyst_-_Madison,_WI_-_Indeed.com_2cbc31c960500ae6.html\"});\n",
      "MERGE (:FileNames {file_name: \"temp_Sr._Data_Scientist_ed6a921f486e2019.html\"});\n",
      "MERGE (:FileNames {file_name: \"temp_Sr._Data_Scientist_efa5ad2d82bd1fcd.html\"});\n",
      "MERGE (:FileNames {file_name: \"temp_Statistician_(Data_Scientist)_12_month_Roster_Direct_Hire__ff6d88fe8a9a7879.html\"});\n"
     ]
    }
   ],
   "source": [
    "\n",
    "verbose = True\n",
    "for file_name in files_list:\n",
    "    cu.ensure_filename(file_name, verbose=verbose)\n",
    "    file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "    page_soup = get_page_soup(file_path)\n",
    "    row_div_list = page_soup.find_all(name='div', id='jobDescriptionText')\n",
    "    for div_soup in row_div_list:\n",
    "        child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "        cu.populate_from_child_strings(child_strs_list, file_name, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
