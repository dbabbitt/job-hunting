{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 20s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from pandas import DataFrame\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from hc_utils import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "from lr_utils import LrUtilities\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "lru.build_isheader_logistic_regression_elements()\n",
    "lru.build_pos_logistic_regression_elements()\n",
    "\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from IPython.display import clear_output\n",
    "%run ../load_magic/dataframes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "navigable_parent_cypher_str = '''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{}'}})\n",
    "    ''' + cu.return_everything_str + ';'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_Scientist_at_Array_Remote.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import shutil\n",
    "\n",
    "file_path = r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\html\\other_email.html'\n",
    "file_name = re.sub(r'[^A-Za-z0-9]+', ' ',\n",
    "                   '''Data Scientist at Array Remote''').strip().replace(' ', '_') + '.html'\n",
    "new_file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if os.path.isfile(new_file_path):\n",
    "    file_name = datetime.now().strftime('%Y%m%d%H%M%S%f') + f'_{file_name}'\n",
    "    new_file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if not os.path.isfile(new_file_path):\n",
    "    print(file_name)\n",
    "    shutil.copy(file_path, os.path.join(cu.SAVES_HTML_FOLDER, file_name))\n",
    "    page_soup = get_page_soup(file_path)\n",
    "    div_soup = page_soup.find_all(name='div', id='jobDescriptionText')[0]\n",
    "    child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    MATCH (fn:FileNames {file_name: \"Data_Scientist_at_Array_Remote.html\"})\n",
      "    SET fn.posting_url = NULL\n",
      "    RETURN fn;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node id=800898 labels=frozenset({'FileNames'}) properties={'file_name': 'Data_Scientist_at_Array_Remote.html'}>}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Add the posting URL to the file name\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.posting_url = NULL\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-O', 'O-SP', 'O-OL', 'O-CS', 'O-LN', 'O-TS', 'H-TS', 'O-CS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-RQ', 'O-TS', 'O-RQ', 'O-ER', 'O-RQ', 'O-TS', 'O-RQ', 'O-RQ', 'O-TS', 'O-RQ', 'O-RQ', 'O-CS', 'O-CS', 'O-LN', 'O-LN', 'O-TS', 'O-TS', 'O-SP', 'O-TS', 'O-OL', 'O-TS', 'O-CS', 'O-LN']\n",
      "[12, 14, 15, 16, 18, 19, 21, 22]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-O) <span style=\"color:#8c564bff;\"><h1 class=\"app-title\">Data Scientist (H-O Other Header)</h1></span><br />1 O-SP) <span style=\"color:#17becf80;\"><span class=\"company-name\">at Array (O-SP Supplemental Pay Non-header)</span></span><br />2 O-OL) <span style=\"color:#c49c9480;\"><div class=\"location\">Remote (O-OL Office Location Non-header)</div></span><br />3 O-CS) <span style=\"color:#1f77b480;\"><span style=\"font-weight: 400;\">Array is revolutionizing how businesses leverage and enhance consumer data. Our platform enables innovative companies and developers to seamlessly integrate credit and identity data into their apps, websites or workflows. As a remote-first company, weâ€™re focused on providing opportunities for autonomous individuals to have high levels of impact at the forefront of the fintech space. Continuous improvement, experimentation, and a clear mission stretch us individually and together in service of delivering the best products for our clients and users. (O-CS Corporate Scope Non-header)</span></span><br />4 O-LN) <span style=\"color:#9467bd80;\"><strong>Job Description (O-LN Legal Notifications Non-header)</strong></span><br />5 O-TS) <span style=\"color:#9edae580;\"><p>Insights from data power decisions at Array. This Data Scientist role will work with product, engineering, sales and design teams to analyze data from all parts of our business. You will use data science to help improve adoption and usage of our existing products and create new products. Data Scientists at Array will have a tremendous opportunity to make an impact to the top line and bottom line of a growing company. (O-TS Task Scope Non-header)</p></span><br />6 H-TS) <span style=\"color:#9edae5ff;\"><strong>Responsibilities (H-TS Task Scope Header)</strong></span><br />7 O-CS) <span style=\"color:#1f77b480;\"><li>Understand how our business works and guide the vision for how we share analytics with our users (O-CS Corporate Scope Non-header)</li></span><br />8 O-TS) <span style=\"color:#9edae580;\"><li>Work with complex data sets to solve multiple challenging problems using a statistical approaches (O-TS Task Scope Non-header)</li></span><br />9 O-TS) <span style=\"color:#9edae580;\"><li>Work with product, marketing and sales teams to improve products and feature to create new revenue streams (O-TS Task Scope Non-header)</li></span><br />10 O-TS) <span style=\"color:#9edae580;\"><li>Design quick proof-of-concept experiments to validate hypothesis and demonstrate viability (O-TS Task Scope Non-header)</li></span><br />11 O-TS) <span style=\"color:#9edae580;\"><li>Own the full lifecycle of model development: ideation and data exploration, algorithm design and testing, algorithm development and deployment, and algorithm monitoring and tuning in production. (O-TS Task Scope Non-header)</li></span><br /><hr />12 O-RQ) <span style=\"color:#bcbd2280;\"><li>Share insights and technical approaches verbally and in writing, including documenting analytical methodologies and other outputs appropriate for use by specialist and non-specialists (O-RQ Required Qualifications Non-header)</li></span><br />13 O-TS) <span style=\"color:#9edae580;\"><li>Knowledge in the data products including developing QA/QC strategies to ensure they are production-ready (O-TS Task Scope Non-header)</li></span><br />14 O-RQ) <span style=\"color:#bcbd2280;\"><strong>Essential Skills (O-RQ Required Qualifications Non-header)</strong></span><br />15 O-ER) <span style=\"color:#aec7e880;\"><li>Master's or Ph.D. in a quantitative field such as statistics, economics, industrial engineering and operations research, applied math, or other relevant quantitative field (O-ER Education Requirements Non-header)</li></span><br />16 O-RQ) <span style=\"color:#bcbd2280;\"><li>3+ years of experience designing models for product analytics using statistical and machine learning techniques. Experience in financial services (O-RQ Required Qualifications Non-header)</li></span><br />17 O-TS) <span style=\"color:#9edae580;\"><li>3+ years of experience using advanced statistical techniques for experiment design, model development and deployment. Must have multiple, examples of using these techniques to measure the effectiveness of data driven insights to solve business problems on large-scale data sets (O-TS Task Scope Non-header)</li></span><br />18 O-RQ) <span style=\"color:#bcbd2280;\"><li>5+ years of experience with one or more programming languages such as Python, R, PySpark (O-RQ Required Qualifications Non-header)</li></span><br />19 O-RQ) <span style=\"color:#bcbd2280;\"><li>Expert-level knowledge of SQL with data exploration and manipulation skills (O-RQ Required Qualifications Non-header)</li></span><br />20 O-TS) <span style=\"color:#9edae580;\"><li>Experience using cloud platforms such as GCP and AWS for model development and operationalization (O-TS Task Scope Non-header)</li></span><br />21 O-RQ) <span style=\"color:#bcbd2280;\"><li>Must have  quantitative reasoning and interpretation skills with an ability to provide analysis inspired by business insight and recommendations (O-RQ Required Qualifications Non-header)</li></span><br />22 O-RQ) <span style=\"color:#bcbd2280;\"><li>|Ability to work well with peers and leaders across data science, product, marketing, and engineering organizations (O-RQ Required Qualifications Non-header)</li></span><br /><hr />23 O-CS) <span style=\"color:#1f77b480;\"><li>Problem-solver who simplifies problems to their core elements (O-CS Corporate Scope Non-header)</li></span><br />24 O-CS) <span style=\"color:#1f77b480;\"><li>Experience with credit, transaction or other types of financial data is a big plus (O-CS Corporate Scope Non-header)</li></span><br />25 O-LN) <span style=\"color:#9467bd80;\"><span style=\"font-weight: 400;\">Array Offers All Employees the Following Benefits and Perks: (O-LN Legal Notifications Non-header)</span></span><br />26 O-LN) <span style=\"color:#9467bd80;\"><span style=\"font-weight: 400;\">Full medical, dental, and vision, premiums covered at 100% for employees and 50% for dependents (O-LN Legal Notifications Non-header)</span></span><br />27 O-TS) <span style=\"color:#9edae580;\"><span style=\"font-weight: 400;\">Unlimited PTO and sick leave + 14 company holidays to encourage a healthy work-life blend (O-TS Task Scope Non-header)</span></span><br />28 O-TS) <span style=\"color:#9edae580;\"><span style=\"font-weight: 400;\">In-house wellness concierge and partnership with TalkSpace to support mental health (O-TS Task Scope Non-header)</span></span><br />29 O-SP) <span style=\"color:#17becf80;\"><span style=\"font-weight: 400;\">100% 401k match with immediate vesting (O-SP Supplemental Pay Non-header)</span></span><br />30 O-TS) <span style=\"color:#9edae580;\"><span style=\"font-weight: 400;\">Generous and competitive parental leave for all parents (O-TS Task Scope Non-header)</span></span><br />31 O-OL) <span style=\"color:#c49c9480;\"><span style=\"font-weight: 400;\">$1,000 desk setup subsidy to set-up your unique remote office (O-OL Office Location Non-header)</span></span><br />32 O-TS) <span style=\"color:#9edae580;\"><span style=\"font-weight: 400;\">$100/month to subsidize wifi/cell phone expenses (O-TS Task Scope Non-header)</span></span><br />33 O-CS) <span style=\"color:#1f77b480;\"><span style=\"font-weight: 400;\">One of our core values at Array is to care and support one another, and thatâ€™s why we strive to create an environment where everyone feels empowered to bring their full, authentic selves to work. Diversity, equity, and inclusion foster collaboration, comfort, and confidence.Â  Weâ€™re at our collective best when we each feel our best. (O-CS Corporate Scope Non-header)</span></span><br />34 O-LN) <span style=\"color:#9467bd80;\"><span style=\"font-weight: 400;\">We are proud to be an equal opportunity workplace, we are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. (O-LN Legal Notifications Non-header)</span></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 14, 15, 16, 18, 19, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\n",
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hand-label individual child strings\n",
    "idx = 12\n",
    "child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "if(child_str in basic_quals_dict):\n",
    "    print(basic_quals_dict[child_str])\n",
    "child_str = cu.clean_text(child_str); print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "# child_str = 'Spark, Camel, Python, R, Pyspark, Zepplin, Java, Scala'\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{child_str}'}})\n",
    "    SET\n",
    "        np.is_header = 'False',\n",
    "        np.is_task_scope = 'False',\n",
    "        np.is_minimum_qualification = 'True',\n",
    "        np.is_preferred_qualification = 'False',\n",
    "        np.is_educational_requirement = 'False',\n",
    "        np.is_legal_notification = 'False',\n",
    "        np.is_other = 'False',\n",
    "        np.is_corporate_scope = 'False',\n",
    "        np.is_job_title = 'False',\n",
    "        np.is_office_location = 'False',\n",
    "        np.is_job_duration = 'False',\n",
    "        np.is_supplemental_pay = 'False',\n",
    "        np.is_interview_procedure = 'False',\n",
    "        np.is_posting_date = 'False'\n",
    "    {cu.return_everything_str};'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "# print(navigable_parent_cypher_str.format(child_str))\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, navigable_parent_cypher_str.format(child_str))\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# file_name = 'Senior_Data_Analyst_Scientist-_Rider_Insights_-_Remote_-_Indeed.com_8e2e678241df1d58.html'\n",
    "lru.build_isqualified_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_from_dictionary(verbose=False)\n",
    "# child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, crf_list=crf_list, file_name=file_name)\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "lru.basic_quals_dict = basic_quals_dict\n",
    "quals_str, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "display(HTML(f'I only meet {job_fitness:.1%} of the minimum requirements for {file_name}:'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add URL\n",
    "posting_url = 'https://boards.greenhouse.io/array/jobs/4098049004?gh_jid=4098049004'\n",
    "posting_url = cu.clean_text(posting_url)\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.posting_url = \"{posting_url}\"\n",
    "    RETURN fn;'''\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "    print(row_objs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# file_name = 'Senior_Backend_Engineer_(Data_Science_Software_Engineering_Support)_-_Remote_-_Indeed.com_3e34ac4ae73849ba.html'\n",
    "mask_series = (hunting_df.file_name != file_name)\n",
    "for row_index, row_series in hunting_df[~mask_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)\n",
    "display(HTML(f'I only meet {job_fitness:.1%} of the minimum requirements:'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
