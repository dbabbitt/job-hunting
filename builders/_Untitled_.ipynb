{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f50483-4c5c-4270-9eae-b52faed2323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae56d24e-1102-4e4d-9521-90d982db0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b3135ff-d876-4404-9cc9-69d9943618ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            MATCH (np:NavigableParents {is_task_scope: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\TASK_SCOPE_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_minimum_qualification: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\REQ_QUALS_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_preferred_qualification: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\PREFF_QUALS_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_legal_notification: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\LEGAL_NOTIFS_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_job_title: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\JOB_TITLE_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_office_location: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\OFFICE_LOC_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_job_duration: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\JOB_DURATION_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_supplemental_pay: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\SUPP_PAY_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_educational_requirement: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\EDUC_REQS_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_interview_procedure: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\INTERV_PROC_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_corporate_scope: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\CORP_SCOPE_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_posting_date: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\POST_DATE_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (np:NavigableParents {is_other: 'True', is_header: 'True'})\n",
      "            RETURN np.navigable_parent AS navigable_parent;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\OTHER_HEADERS_LIST.pkl\n",
      "\n",
      "            MATCH (pos:PartsOfSpeech)\n",
      "            RETURN\n",
      "                pos.pos_symbol AS pos_symbol,\n",
      "                pos.pos_explanation AS pos_explanation;\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\POS_EXPLANATION_DICT.pkl\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from html_analysis import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=True)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from html_analysis import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6b054a-dba5-494f-a234-a01453b9d2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-TS: <b>The Role:</b>\n",
      "O: <p>As the Director of Data Science at Brightloom, you'll lead the data science team and partner acro\n",
      "O: <p>You're a person who loves helping others work together to do interesting data science. You can ev\n",
      "H-TS: <b>What you'll do:</b>\n",
      "O: <li>Lead the data science team as their manager - helping devise projects, removing blockers, and en\n",
      "O: <li>Represent the data science discipline throughout the organization. You will have a powerful voic\n",
      "O: <li>Partner across Brightloom engineering groups; evangelizing our culture of using data to measure,\n",
      "O: <li>Be a strong leader - you will give team members clear feedback that helps them grow and inspires\n",
      "O: <li>Be an expert in interpreting data and understanding its conclusions - your team will be creating\n",
      "O: <li>Own the data science technical roadmap - take the business priorities from the product team and \n",
      "O: <li>Be involved in new product development - as the product team thinks of new ways to take customer\n",
      "H-RQ: <b>About you:</b>\n",
      "O: <li>Demonstrated experience building and developing a team</li>\n",
      "O: <li>Demonstrated experience putting a data science product into market, ideally in a startup</li>\n",
      "O: <li>Experience in the marketing, retail, or restaurant domain</li>\n",
      "O: <li>Foundational understanding of the data science ecosystem</li>\n",
      "H-CS: <b>About Us</b>\n",
      "O: <p>At Brightloom (formerly eatsa), we are working to revolutionize restaurants through innovative te\n",
      "O: <p>Led by our CEO, industry veteran and former Starbucks and J.Crew executive Adam Brotman, our uniq\n",
      "O: <p>We believe any restaurant brand should be able to engage customers digitally using a seamless com\n",
      "H-SP: <b>What We Offer</b>\n",
      "O: <li>Fun, creative and collaborative remote work environment</li>\n",
      "O: <li>Competitive pay and equity/stock options</li>\n",
      "O: <li>Health, Dental &amp; Vision Insurance Coverage</li>\n",
      "O: <li>Life Insurance, Short-Term Disability, Long-Term Disability</li>\n",
      "O: <li>Phone/Internet Reimbursement</li>\n",
      "O: <li>Home Office Refresh Reimbursement</li>\n",
      "O: <li>Employee Assistance Program</li>\n",
      "O: <li>Flexible Spending Account &amp; Health Savings Account</li>\n",
      "O: <li>Flexible Time Off</li>\n",
      "O: <li>401(k)</li>\n",
      "O: <p>Brightloom is an Equal Employment Opportunity Employer. All qualified applicants will receive con\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_child_strs_list = ['<b>The Role:</b>', \"<p>As the Director of Data Science at Brightloom, you'll lead the data science team and \" +\n",
    "                        \"partner across the organization to help grow our data science capabilities. You'll be \" +\n",
    "                        \"taking business needs from product and engineering teams and creating a comprehensive data \" +\n",
    "                        \"science strategy around them. From there, you help prioritize the work for the data science \" +\n",
    "                        \"team, balancing the work for the team and helping the independent contributors be their best. \" +\n",
    "                        \"You will heavily engage with the application engineering, data engineering, and data science \" +\n",
    "                        \"technical leads to ensure that your data science strategies are operationalized effectively.</p>\",\n",
    "                        \"<p>You're a person who loves helping others work together to do interesting data science. You \" +\n",
    "                        \"can evangelize a data science idea to non-technical people, and you can deal with the \" +\n",
    "                        \"realities of a complex business and figure out how to have data science contribute in a \" +\n",
    "                        \"positive way. You enjoy leading data scientists so they can do strong work, and helping to \" +\n",
    "                        \"elevate the data scientist's concerns when they raise them.</p>\", \"<b>What you'll do:</b>\",\n",
    "                        \"<li>Lead the data science team as their manager - helping devise projects, removing blockers, \" +\n",
    "                        \"and engaging with independent contributors. You'll be hiring more data scientists and \" +\n",
    "                        \"eventually hire managers to do this part of the job for you.</li>\",\n",
    "                        '<li>Represent the data science discipline throughout the organization. You will have a ' +\n",
    "                        'powerful voice in the company and represent data scientists across different parts of the ' + 'business.</li>',\n",
    "                        '<li>Partner across Brightloom engineering groups; evangelizing our culture of using data to ' +\n",
    "                        'measure, understand, and improve our product and features.</li>',\n",
    "                        '<li>Be a strong leader - you will give team members clear feedback that helps them grow ' +\n",
    "                        'and inspires thought leadership. You will lead by example, have compassion for everyone in ' +\n",
    "                        'the company and their challenges, and will take controversial directions when necessary.</li>',\n",
    "                        '<li>Be an expert in interpreting data and understanding its conclusions - your team will ' +\n",
    "                        'be creating lots of powerful insights and you will be finding the valuable implications of ' + 'that data.</li>',\n",
    "                        '<li>Own the data science technical roadmap - take the business priorities from the product ' +\n",
    "                        'team and turn them into a set of projects the data science team will focus on delivering.</li>',\n",
    "                        \"<li>Be involved in new product development - as the product team thinks of new ways to take \" +\n",
    "                        \"customer feedback and create a better product, you'll be heavily involved with assessing \" +\n",
    "                        \"what is feasible from a data science perspective.</li>\", '<b>About you:</b>',\n",
    "                        '<li>Demonstrated experience building and developing a team</li>',\n",
    "                        '<li>Demonstrated experience putting a data science product into market, ideally in a startup</li>',\n",
    "                        '<li>Experience in the marketing, retail, or restaurant domain</li>',\n",
    "                        '<li>Foundational understanding of the data science ecosystem</li>', '<b>About Us</b>',\n",
    "                        '<p>At Brightloom (formerly eatsa), we are working to revolutionize restaurants through ' +\n",
    "                        'innovative technology and design. We are disrupting an industry worth $900 billion globally ' +\n",
    "                        'with partnerships in North America, Asia, and soon other continents.</p>',\n",
    "                        '<p>Led by our CEO, industry veteran and former Starbucks and J.Crew executive Adam Brotman, our ' +\n",
    "                        'unique, world-class team combines software and hardware engineers, designers, and industry ' +\n",
    "                        'experts to push the boundaries on re-engineering every aspect of the restaurant experience.</p>',\n",
    "                        \"<p>We believe any restaurant brand should be able to engage customers digitally using a \" +\n",
    "                        \"seamless combination of mobile, omni-channel ordering and loyalty offerings. Up until now, \" +\n",
    "                        \"only a select few brands could afford, or knew how to put together a top-notch digital \" +\n",
    "                        \"engagement and ordering platform. With key Starbucks technology components integrated into \" +\n",
    "                        \"our platform, Brightloom will now allow any restaurant brand to create their own version of a \" +\n",
    "                        \"world-class digital flywheel ecosystem. Brightloom's configurable technology suite combines \" +\n",
    "                        \"convenience (digital ordering channels), personal connection (personalized marketing) and \" +\n",
    "                        \"engagement (loyalty) for restaurant brands in today's new digital era.</p>\", '<b>What We Offer</b>',\n",
    "                        '<li>Fun, creative and collaborative remote work environment</li>', '<li>Competitive pay and equity/stock options</li>',\n",
    "                        '<li>Health, Dental &amp; Vision Insurance Coverage</li>', '<li>Life Insurance, Short-Term Disability, Long-Term Disability</li>',\n",
    "                        '<li>Phone/Internet Reimbursement</li>', '<li>Home Office Refresh Reimbursement</li>', '<li>Employee Assistance Program</li>',\n",
    "                        '<li>Flexible Spending Account &amp; Health Savings Account</li>', '<li>Flexible Time Off</li>', '<li>401(k)</li>',\n",
    "                        '<p>Brightloom is an Equal Employment Opportunity Employer. All qualified applicants will ' +\n",
    "                        'receive consideration for employment without regard to race, color, religion, sex, national ' +\n",
    "                        'origin, sexual orientation, gender identity, disability and protected veterans status or any ' +\n",
    "                        'other characteristic protected by law.</p>']\n",
    "pos_list = []\n",
    "for navigable_parent in test_child_strs_list:\n",
    "    pos_list = hc.append_parts_of_speech_list(navigable_parent, pos_list)\n",
    "for navigable_parent, speech_part in zip(test_child_strs_list, pos_list):\n",
    "    print(f'{speech_part}: {navigable_parent[:100]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d07553f-e653-4c3c-a75f-e033e9367cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_tag': 'h2', 'is_header': True, 'is_task_scope': True, 'is_minimum_qualification': False, 'is_preferred_qualification': False, 'is_legal_notification': False, 'is_job_title': False, 'is_office_location': False, 'is_job_duration': False, 'is_supplemental_pay': False, 'is_educational_requirement': False, 'is_interview_procedure': False, 'is_corporate_scope': False, 'is_posting_date': False, 'is_other': False, 'child_str': '<h2 class=\"jobsearch-JobDescriptionSection-jobDescriptionTitle icl-u-xs-my--md\" id=\"jobDescriptionTitle\">Full Job Description</h2>'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "HEADER_PATTERN_DICT = s.load_object('HEADER_PATTERN_DICT')\n",
    "sorted(list(HEADER_PATTERN_DICT.values()), key=lambda x: len(str(x)))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdde86f6-27dc-4b92-8892-6fbafd54f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'p', 'p', 'b', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'b', 'li', 'li', 'li', 'li', 'b', 'p', 'p', 'p', 'b', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'p']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "child_tags_list = ['b', 'p', 'p', 'b', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'b', 'li', 'li',\n",
    "                   'li', 'li', 'b', 'p', 'p', 'p', 'b', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef90440b-f70e-4fe8-b2e6-eb106dfcfe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>What We Offer</b>\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\SUPP_PAY_HEADERS_LIST.pkl\n",
      "\n",
      "    MATCH (np:NavigableParents {navigable_parent: '<b>What We Offer</b>'})\n",
      "    SET np.is_supplemental_pay = 'True', np.is_header = 'True';\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tag_str = '<b>What We Offer</b>'\n",
    "print(tag_str)\n",
    "ha.store_unique_list('SUPP_PAY_HEADERS_LIST', tag_str)\n",
    "cypher_str = f\"\"\"\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{tag_str}'}})\n",
    "    SET np.is_supplemental_pay = 'True', np.is_header = 'True';\"\"\"\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fcd765c-9108-4e38-bbe2-091d333c270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>About you:</b>\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\REQ_QUALS_HEADERS_LIST.pkl\n",
      "\n",
      "    MATCH (np:NavigableParents {navigable_parent: '<b>About you:</b>'})\n",
      "    SET np.is_minimum_qualification = 'True', np.is_header = 'True';\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tag_str = '<b>About you:</b>'\n",
    "print(tag_str)\n",
    "ha.store_unique_list('REQ_QUALS_HEADERS_LIST', tag_str)\n",
    "cypher_str = f\"\"\"\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{tag_str}'}})\n",
    "    SET np.is_minimum_qualification = 'True', np.is_header = 'True';\"\"\"\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348150fb-90c1-40bd-a417-df048c91d005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<b>About This Role</b>', '<b>About the Python Software Engineer Position:</b>', '<b>About the</b>', '<b>About this role</b>', '<b>Build our analytics practice:</b>', '<b>Client engagement (25%) :</b>', '<b>Core Responsibilities:</b>', '<b>Core Responsibilities</b>', '<b>DESCRIPTION</b>', '<b>Description</b>', '<b>Duties included but not limited to:</b>', '<b>Employees at all levels are expected to:</b>', \"<b>Here's What Data Scientists do at Demandbase:</b>\", '<b>JOB DESCRIPTION:</b>', '<b>Job Description:</b>', '<b>Job Description</b>', '<b>Job Duties and Responsibilities</b>', '<b>Job Specification:</b>', '<b>Job Summary:</b>', '<b>Job Summary</b>', '<b>Key Responsibilities:</b>', '<b>Key Responsibilities</b>', '<b>Maintain Webroot’s Machine Learning systems:</b>', '<b>Modeling and Hands-on Analytics (50%):</b>', '<b>OVERVIEW</b>', '<b>Outcomes</b>', '<b>Overview</b>', '<b>Position Description</b>', '<b>Position description</b>', '<b>Primary Responsibilities:</b>', '<b>Principal Duties &amp; Responsibilities</b>', '<b>Python Software Engineer Responsibilities:</b>', '<b>RESPONSIBILITIES:</b>', '<b>RESPONSIBILITIES</b>', '<b>ROLE RESPONSIBILITIES</b>', '<b>ROLE SUMMARY</b>', '<b>Responsibilities:</b>', '<b>Responsibilities</b>', '<b>SUMMARY</b>', '<b>Summary</b>', '<b>THE ROLE</b>', '<b>The Role:</b>', '<b>The Role</b>', '<b>The role:</b>', '<b>This job also involves the following responsibilities:</b>', '<b>This means you will:</b>', '<b>This role works hands-on within our Data Science and Data Engineering team to:</b>', \"<b>WHAT YOU'LL DO</b>\", '<b>WHAT YOU’LL BE DOING:</b>', '<b>What Will You Do?</b>', '<b>What You Will Do:</b>', \"<b>What You'll Do:</b>\", \"<b>What You'll Do</b>\", '<b>What does your success look like in the first 90 days?</b>', '<b>What will you do?</b>', '<b>What you will do:</b>', \"<b>What you'll do:</b>\", \"<b>What you'll do</b>\", \"<b>What you'll work on:</b>\", '<b>What you’ll be doing:</b>', '<b>Where You Come In:</b>', '<b>Your team will:</b>', '<div>Key responsibilities in this role include:</div>', '<div>What you will be doing:</div>', '<h2 class=\"jobsearch-JobDescriptionSection-jobDescriptionTitle icl-u-xs-my--md\" id=\"jobDescriptionTitle\">Full Job Description</h2>', '<li>Assignments vary by task and may require you to:</li>', '<li>Design, Develop and Deploy:</li>', '<p>DESCRIPTION:</p>', '<p>DESCRIPTION</p>', '<p>Description</p>', '<p>Key Areas of Responsibility:</p>', '<p>RESPONSIBILITIES:</p>', '<p>Responsibilities and Duties</p>', '<p>Responsibilities:</p>', '<p>This role will be initially for approximately half-time (~20 hr/week), with opportunity to move to full time. A senior associate is expected to have all the responsibilities and abilities below:</p>', 'Develop efficient solutions to complex data management problems:', 'Explore / Enlighten:', 'Measure / Quantify / Expand:', 'Overview:', 'Primary Responsibilities:', 'Responsibilities for this Position:', 'Responsibilities:', 'Translate / Interpret:', 'You will be rated on the following Competencies as part of the assessment questionnaire for this position:']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hc.TASK_SCOPE_HEADERS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "467ed059-41fd-4ed9-a079-22aecf2cb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_tag': 'h2', 'is_header': True, 'is_task_scope': True, 'is_minimum_qualification': False, 'is_preferred_qualification': False, 'is_legal_notification': False, 'is_job_title': False, 'is_office_location': False, 'is_job_duration': False, 'is_supplemental_pay': False, 'is_educational_requirement': False, 'is_interview_procedure': False, 'is_corporate_scope': False, 'is_posting_date': False, 'is_other': False, 'child_str': '<h2 class=\"jobsearch-JobDescriptionSection-jobDescriptionTitle icl-u-xs-my--md\" id=\"jobDescriptionTitle\">Full Job Description</h2>'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "HEADER_PATTERN_DICT = s.load_object('HEADER_PATTERN_DICT')\n",
    "list(HEADER_PATTERN_DICT.values())[0][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "427eadca-9ee0-4724-8f99-073664336fd8",
   "metadata": {},
   "source": [
    "\n",
    "cu.ensure_navigableparent_is_header_from_dictionary(verbose=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebcc1e18-d8f7-4dcd-b1d6-3ae8efaa6e31",
   "metadata": {},
   "source": [
    "\n",
    "file_name = '9dc7201db74605e8_Data_Business_Analyst_Remote_Indeed_com.html'\n",
    "child_strs_list = ha.get_child_strs_from_file(file_name)\n",
    "cu.find_basic_quals_section(child_strs_list, hc=None, ea=None, verbose=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44bea10a-3ae4-4f32-9a9a-40deee0d26ae",
   "metadata": {},
   "source": [
    "\n",
    "verbose = True\n",
    "child_tags_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    navigable_parent = cu.clean_text(navigable_parent)\n",
    "    cypher_str = cu.select_header_tag_where_navigable_parent_cypher_str.format(navigable_parent)\n",
    "    if verbose:\n",
    "        print(cypher_str)\n",
    "    row_objs_list = cu.get_execution_results(cypher_str, verbose=verbose)\n",
    "    header_tag = [row_obj['fn'].get('header_tag') for row_obj in row_objs_list][0]\n",
    "    child_tags_list.append(header_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f49373b-5309-4cb2-8e9e-cef28cf44c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            MATCH (pos:PartsOfSpeech)-[r:SUMMARIZES]->(np:NavigableParents)\n",
      "            RETURN\n",
      "                np.navigable_parent AS navigable_parent,\n",
      "                pos.pos_symbol AS pos_symbol;\n",
      "pos_df.columns = Index(['navigable_parent', 'pos_symbol'], dtype='object')\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('O', 15), ('H-TS', 1), ('O', 15), ('H-RQ', 1), ('O', 13), ('H-SP', 1), ('O', 29)], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'H-TS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'H-RQ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'H-SP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from html_analysis import ElementAnalysis\n",
    "\n",
    "file_name = '9dc7201db74605e8_Data_Business_Analyst_Remote_Indeed_com.html'\n",
    "child_strs_list = ha.get_child_strs_from_file(file_name)\n",
    "ea = ElementAnalysis(ha=ha, hc=None)\n",
    "ea.find_basic_quals_section(child_strs_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cce788d-30f3-4c59-8696-369a87fa43dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    MATCH (pos:PartsOfSpeech)\n",
      "    UNWIND pos.pos_symbol as s\n",
      "    RETURN count(DISTINCT s) AS num_topics;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cypher_str = '''\n",
    "    MATCH (pos:PartsOfSpeech)\n",
    "    UNWIND pos.pos_symbol as s\n",
    "    RETURN count(DISTINCT s) AS num_topics;'''\n",
    "row_objs_list = cu.get_execution_results(cypher_str, verbose=True)\n",
    "row_objs_list[0]['num_topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dc870a-1c82-4ab5-b993-95b2241d3564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Requirements</b><b>WHAT YOU WILL BRING TO OUR COMPANY</b><li>Bachelor's degree required.</li><li>3+ years’ experience in business analysis or related field.</li><li>Advanced technical skills with SQL, Excel, BI.</li><li>Excellent presentation building skills using PowerPoint/keynotes and graphic design skills.</li><li>Experience in creating detailed reports and presentations while being able to work independently to deliver in-depth insights based on varying requirements.</li><li>Property Insurance domain knowledge and experience in the industry – especially around data and analytics – is highly desired.</li><li>Light Python/Jupyter Notebooks knowledge is a plus.</li><i>THE SUCCESSFUL CANDIDATE</i><li>Has the ability to merge, consolidate, cleanse data from multiple non-standardized sources to perform analytics combined with internal datasets.</li><li>Can identify flags based on book analysis and retro results.</li><li>Has in depth analytical and conceptual thinking skills.</li><li>Has the ability/willingness to travel up to 10%.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ea.display_basic_requirements(child_strs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7d169-e2ee-478b-b724-a24b4093b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from html_analysis import LrUtilities\n",
    "\n",
    "lu = LrUtilities(ha=ha, hc=None, cu=cu, verbose=False)\n",
    "predict_percent_fit = lu.build_lr_predict_percent_is_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a783d59-2053-497a-aee9-64fbc6042cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "if s.pickle_exists('CS_CV'):\n",
    "    lu.CS_CV = s.load_object('CS_CV')\n",
    "else:\n",
    "    lu.CS_CV = CountVectorizer(\n",
    "        analyzer='word',\n",
    "        binary=False,\n",
    "        decode_error='strict',\n",
    "        lowercase=False,\n",
    "        max_df=1.0,\n",
    "        max_features=None,\n",
    "        min_df=0.0,\n",
    "        ngram_range=(1,5),\n",
    "        stop_words=None,\n",
    "        strip_accents='ascii',\n",
    "        tokenizer=ha.html_regex_tokenizer)\n",
    "    s.store_objects(CS_CV=lu.CS_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "532d2ff7-dddb-4657-8756-3080b64d45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Re-transform the bag-of-words and tf-idf from the new manual scores\n",
    "rows_list = [{'navigable_parent': navigable_parent,\n",
    "              'is_header': is_header} for navigable_parent, is_header in ha.NAVIGABLE_PARENT_IS_HEADER_DICT.items()]\n",
    "child_str_df = pd.DataFrame(rows_list)\n",
    "child_str_df.is_header = child_str_df.is_header.astype('bool')\n",
    "\n",
    "# The shape of the Bag-of-words count vector here should be n sentences * m unique words\n",
    "sents_list = child_str_df.navigable_parent.tolist()\n",
    "bow_matrix = lu.CS_CV.fit_transform(sents_list)\n",
    "\n",
    "# Tf-idf must get from Bag-of-words first\n",
    "tfidf_matrix = lu.TT.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a099e5d1-febc-4b0a-abfe-505fdf69840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.core._exceptions._ArrayMemoryError'> error: Unable to allocate 62.0 GiB for an array with shape (11712, 710081) and data type float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Re-train the classifier\n",
    "try:\n",
    "    import gc\n",
    "\n",
    "    gc.collect()\n",
    "    X = tfidf_matrix.toarray()\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__} error: {str(e).strip()}')\n",
    "    X = tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96329bdb-de56-4063-8905-6556823093a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s.pickle_exists('CHILD_STR_CLF'):\n",
    "    lu.CHILD_STR_CLF = s.load_object('CHILD_STR_CLF')\n",
    "else:\n",
    "    lu.CHILD_STR_CLF = LogisticRegression(\n",
    "        C=375.0,\n",
    "        class_weight='balanced',\n",
    "        dual=False,\n",
    "        fit_intercept=True,\n",
    "        intercept_scaling=1,\n",
    "        l1_ratio=None,\n",
    "        max_iter=1000,\n",
    "        multi_class='auto',\n",
    "        n_jobs=None,\n",
    "        penalty='l1',\n",
    "        random_state=None,\n",
    "        solver='liblinear',\n",
    "        tol=0.0001,\n",
    "        verbose=0,\n",
    "        warm_start=False)\n",
    "    s.store_objects(CHILD_STR_CLF=lu.CHILD_STR_CLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daf809c4-455f-484a-ba81-f21b6162b732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight='balanced', max_iter=1000, penalty='l1',\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = child_str_df.is_header.to_numpy()\n",
    "lu.CHILD_STR_CLF.fit(tfidf_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4edcb42b-2a20-4173-8afc-9f57e5e7303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\CHILD_STR_CLF.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(CHILD_STR_CLF=lu.CHILD_STR_CLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "068fc13f-47e0-4241-985e-73e2b5698f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Re-calibrate the inference engine\n",
    "cv = CountVectorizer(vocabulary=lu.CS_CV.vocabulary_)\n",
    "cv._validate_vocabulary()\n",
    "\n",
    "def predict_percent_fit(navigable_parent):\n",
    "    X_test = lu.TT.transform(cv.transform([navigable_parent])).toarray()\n",
    "    y_predict_proba = lu.CHILD_STR_CLF.predict_proba(X_test)[0][1]\n",
    "\n",
    "    return y_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eec20d1f-ee63-4e24-9aa3-2d3969c293b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "child_str_df['predict_percent_fit'] = child_str_df.navigable_parent.map(lambda x: predict_percent_fit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01938ecc-f549-42ef-9c7c-27137ff7c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999944673\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navigable_parent</th>\n",
       "      <th>is_header</th>\n",
       "      <th>predict_percent_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>&lt;b&gt;will not&lt;/b&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>&lt;b&gt;Great analytics&lt;/b&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>&lt;li&gt;Telerik &amp;amp; Kendo UI Tools, NodeJS, Angu...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>. See below for more information.</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>&lt;b&gt;Python &amp;amp; AIMMS;&lt;/b&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>&lt;b&gt;or&lt;/b&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>4.271966e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>&lt;b&gt;OR&lt;/b&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>4.271966e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>&lt;b&gt;5+ years&lt;/b&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>4.162431e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>*: 3-6 years</td>\n",
       "      <td>False</td>\n",
       "      <td>4.162431e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>&lt;b&gt;3+ years&lt;/b&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>4.162431e-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10287 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        navigable_parent  is_header  \\\n",
       "1498                                     <b>will not</b>      False   \n",
       "648                               <b>Great analytics</b>      False   \n",
       "10937  <li>Telerik &amp; Kendo UI Tools, NodeJS, Angu...      False   \n",
       "138                    . See below for more information.      False   \n",
       "979                           <b>Python &amp; AIMMS;</b>      False   \n",
       "...                                                  ...        ...   \n",
       "1487                                           <b>or</b>      False   \n",
       "863                                            <b>OR</b>      False   \n",
       "249                                      <b>5+ years</b>      False   \n",
       "53                                          *: 3-6 years      False   \n",
       "246                                      <b>3+ years</b>      False   \n",
       "\n",
       "       predict_percent_fit  \n",
       "1498          1.000000e+00  \n",
       "648           1.000000e+00  \n",
       "10937         1.000000e+00  \n",
       "138           1.000000e+00  \n",
       "979           1.000000e+00  \n",
       "...                    ...  \n",
       "1487          4.271966e-18  \n",
       "863           4.271966e-18  \n",
       "249           4.162431e-21  \n",
       "53            4.162431e-21  \n",
       "246           4.162431e-21  \n",
       "\n",
       "[10287 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0143009290415106e-07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navigable_parent</th>\n",
       "      <th>is_header</th>\n",
       "      <th>predict_percent_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>&lt;b&gt;6 years of analytics experience:&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3.014301e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>&lt;b&gt;Big Data:&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>2.746350e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>&lt;b&gt;Careers with Optum.&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>6.361448e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>Collaborate with the:</td>\n",
       "      <td>True</td>\n",
       "      <td>2.182146e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>&lt;b&gt;Data storyteller:&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>7.441793e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>&lt;b&gt;You will:&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>&lt;b&gt;You:&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>&lt;b&gt;At Compass You Will:&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>&lt;b&gt;You Will:&lt;/b&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>REQUIRED below:</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1425 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              navigable_parent  is_header  predict_percent_fit\n",
       "250    <b>6 years of analytics experience:</b>       True         3.014301e-07\n",
       "380                           <b>Big Data:</b>       True         2.746350e-06\n",
       "409                 <b>Careers with Optum.</b>       True         6.361448e-06\n",
       "9574                     Collaborate with the:       True         2.182146e-05\n",
       "480                   <b>Data storyteller:</b>       True         7.441793e-05\n",
       "...                                        ...        ...                  ...\n",
       "1432                          <b>You will:</b>       True         1.000000e+00\n",
       "1435                               <b>You:</b>       True         1.000000e+00\n",
       "349                <b>At Compass You Will:</b>       True         1.000000e+00\n",
       "1422                          <b>You Will:</b>       True         1.000000e+00\n",
       "10019                          REQUIRED below:       True         1.000000e+00\n",
       "\n",
       "[1425 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mask_series = child_str_df.is_header\n",
    "max_false_percent_fit = child_str_df[~mask_series].predict_percent_fit.max()\n",
    "print(max_false_percent_fit)\n",
    "display(child_str_df[~mask_series].sort_values('predict_percent_fit', ascending=False))\n",
    "min_true_percent_fit = child_str_df[mask_series].predict_percent_fit.min()\n",
    "print(min_true_percent_fit)\n",
    "display(child_str_df[mask_series].sort_values('predict_percent_fit', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c25c0-7685-4290-b096-10347bd6a628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
