{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "if (osp.join(os.pardir, 'py') not in sys.path): sys.path.insert(1, osp.join(os.pardir, 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2 s\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "%run ../load_magic/storage.py\n",
    "from ha_utils import HeaderAnalysis\n",
    "from cypher_utils import CypherUtilities\n",
    "\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "s = Storage()\n",
    "ha = HeaderAnalysis()\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "%run ../load_magic/dataframes.py\n",
    "from html_analysis import ElementAnalysis\n",
    "from IPython.display import clear_output\n",
    "\n",
    "ea = ElementAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_child_strs(verbose=False):\n",
    "    file_path = '../data/html/indeed_email.html'\n",
    "    page_soup = get_page_soup(file_path)\n",
    "    css_selector = 'body > table > tbody > tr > td > a > table > tbody > tr > td > a'\n",
    "    link_soups_list = page_soup.select(css_selector)\n",
    "    for link_soup in link_soups_list:\n",
    "        url_str = link_soup['href']\n",
    "        page_soup = get_page_soup(url_str)\n",
    "        page_title = page_soup.find('title').string.strip()\n",
    "        file_name = re.sub(r'\\W+', ' ', page_title).strip().replace(' ', '_')\n",
    "        jk = parse_qs(urlparse(url_str).query).get('jk', [''])[0]\n",
    "        if len(jk):\n",
    "            file_name = f'{jk}_{file_name}.html'\n",
    "        else:\n",
    "            # file_name = datetime.now().strftime('%Y%m%d%H%M%S%f') + f'_{file_name}.html'\n",
    "            file_name = f'{file_name}.html'\n",
    "        file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "            with open(file_path, 'w', encoding=s.encoding_type) as f:\n",
    "                if verbose:\n",
    "                    print(f'Saving to {file_path}')\n",
    "                f.write('<html><head><title>')\n",
    "                f.write(page_title)\n",
    "                f.write('</title></head><body>')\n",
    "                row_div_list = page_soup.find_all(name='div', attrs={'class': ['jobsearch-JobComponent-description']})\n",
    "                for div_soup in row_div_list:\n",
    "                    f.write(str(div_soup))\n",
    "                f.write('</body></html>')\n",
    "        clear_output(wait=True)\n",
    "        file_name_id = cu.get_filename_id(file_name, verbose=verbose)\n",
    "        row_div_list = page_soup.find_all(name='div', id='jobDescriptionText')\n",
    "        for div_soup in row_div_list:\n",
    "            child_strs_list = ea.ha.get_navigable_children(div_soup, [])\n",
    "            child_tags_list = ea.ha.construct_child_tags_list(child_strs_list)\n",
    "            for sequence_order, (navigable_parent, header_tag) in enumerate(zip(child_strs_list, child_tags_list)):\n",
    "                clear_output(wait=True)\n",
    "                header_tag_id = cu.get_headertag_id(header_tag, verbose=verbose)\n",
    "                header_tag_sequence_id = cu.get_headertagsequence_id(file_name_id, header_tag_id, sequence_order, verbose=verbose)\n",
    "                cu.ensure_headertagsequence_filename_relationship(file_name_id, verbose=verbose)\n",
    "                cu.ensure_headertagsequence_headertag_relationship(header_tag_id, verbose=verbose)\n",
    "                \n",
    "                navigable_parent_id = cu.get_navigableparent_id(navigable_parent, verbose=verbose)\n",
    "                cu.ensure_headertag_navigableparent_relationship(header_tag_id, navigable_parent_id, verbose=verbose)\n",
    "                \n",
    "                navigable_parent_sequence_id = cu.get_navigableparentsequence_id(file_name_id, navigable_parent_id, sequence_order, verbose=verbose)\n",
    "                cu.ensure_navigableparentsequence_filename_relationship(file_name_id, verbose=verbose)\n",
    "                cu.ensure_navigableparentsequence_navigableparent_relationship(navigable_parent_id, verbose=verbose)\n",
    "                \n",
    "                yield navigable_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHILD_STRS_LIST = list(generate_child_strs(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ZMQInteractiveShell_obj = get_ipython()\n",
    "NAVIGABLE_PARENT_IS_HEADER_DICT = s.load_object('NAVIGABLE_PARENT_IS_HEADER_DICT')\n",
    "def get_dictionary_code():\n",
    "    output_str = ''\n",
    "    tag_str = CHILD_STRS_LIST.pop()\n",
    "    while tag_str in NAVIGABLE_PARENT_IS_HEADER_DICT:\n",
    "        tag_str = CHILD_STRS_LIST.pop()\n",
    "    output_str += f'\\n# {len(CHILD_STRS_LIST)} to go\\n'\n",
    "    if \"'\" in tag_str:\n",
    "        tag_str = tag_str.replace('\"', '\\\\\"')\n",
    "        output_str += f'tag_str = \"{tag_str}\"\\n'\n",
    "    else:\n",
    "        output_str += f\"tag_str = '{tag_str}'\\n\"\n",
    "    output_str += 'NAVIGABLE_PARENT_IS_HEADER_DICT[tag_str] = False\\n'\n",
    "    output_str += 'print(len(NAVIGABLE_PARENT_IS_HEADER_DICT.keys()))\\n'\n",
    "    output_str += 's.store_objects(NAVIGABLE_PARENT_IS_HEADER_DICT=NAVIGABLE_PARENT_IS_HEADER_DICT)\\n'\n",
    "    output_str += 'navigable_parent = cu.clean_text(tag_str)\\n'\n",
    "    output_str += 'if NAVIGABLE_PARENT_IS_HEADER_DICT[tag_str]:\\n'\n",
    "    output_str += '    cypher_str = cu.set_is_header1_cypher_str.format(navigable_parent)\\n'\n",
    "    output_str += 'else:\\n'\n",
    "    output_str += '    cypher_str = cu.set_is_header0_cypher_str.format(navigable_parent)\\n'\n",
    "    output_str += 'print(cypher_str)\\n'\n",
    "    output_str += 'with cu.driver.session() as session:\\n'\n",
    "    output_str += '    session.write_transaction(cu.do_cypher_tx, cypher_str)'\n",
    "    \n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ZMQInteractiveShell_obj.set_next_input(text=get_dictionary_code(), replace=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
