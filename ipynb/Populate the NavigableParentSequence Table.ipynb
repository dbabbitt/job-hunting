{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.pickle_exists', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../load_magic/storage.py\n",
    "s = Storage()\n",
    "[f's.{fn}' for fn in dir(s) if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_tags: thing for our employees, because we know that thei...,  leads us to great places. Life. Happiness. Innovat..., etc.\n",
      "child_strs_list: Sr._Data_Analyst_-_Redmond,_WA_-_Indeed.com_a3bcc3...,  Sr._Data_Scientist-_Machine_Learning_AI_REMOTE_-_S..., etc.\n",
      "description: training_duration...,  inference_duration..., etc.\n",
      "fit_estimators: BaggingClassifier...,  ExtraTreesClassifier..., etc.\n",
      "header_pattern: AVP,_Data_Science_-_Fort_Mill,_SC_29715_-_Indeed.c...,  Big_Data_Engineer_-_New_York,_NY_10001_-_Indeed.co..., etc.\n",
      "navigable_parent_is_header: <li>Bonus pay</li>...,  <p>Education:</p>..., etc.\n",
      "navigable_parent_is_qual: <b>Benefits</b>...,  <li>Competitive salary and equity</li>..., etc.\n",
      "pos_explanation: H-JD...,  H-SP..., etc.\n",
      "remaining_quals_child_strs_list: Data_Scientist_-_Plano,_TX_-_Indeed.com_4c8feeee8e...,  Data_Scientist_-_Princeton,_NJ_08540_-_Indeed.com_..., etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "type_suffix_list = ['dict', 'df', 'list', 'DICT', 'LIST']\n",
    "dict_suffix_list = ['dict', 'DICT']\n",
    "for file_name in os.listdir(s.saves_pickle_folder):\n",
    "    if file_name.endswith('.pickle'):\n",
    "        obj_name = file_name.split('.')[0]\n",
    "        type_suffix = obj_name.split('_')[-1]\n",
    "        if type_suffix in dict_suffix_list:\n",
    "            column_name = obj_name[:-5].lower()\n",
    "            exec_str = f\"{obj_name} = s.load_object('{obj_name}')\"\n",
    "            eval_str = f\"s.load_object('{obj_name}')\"\n",
    "            dict_obj = eval(eval_str)\n",
    "            keys_list = list(dict_obj.keys())\n",
    "            idx = random.randint(0, len(keys_list))\n",
    "            print(f'{column_name}: {keys_list[idx][:50]}...,  {keys_list[idx+1][:50]}..., etc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2224"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "NAVIGABLE_PARENT_IS_HEADER_DICT = s.load_object('NAVIGABLE_PARENT_IS_HEADER_DICT')\n",
    "max(len(child_str) for child_str in NAVIGABLE_PARENT_IS_HEADER_DICT.keys())*2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "I need to store some sequences/lists in the database (SQL Server 2008), and then find the ID for a particular sequence from the DB if any exists.\n",
    "\n",
    "For example, I have two sequences:\n",
    "\n",
    "Sequence 1: A,B,C Sequence 2: A,C,M,N\n",
    "\n",
    "Currently they are stored in the following table. (I am OK with changing the table if it makes things easier.)\n",
    "\n",
    "seq_id   token   order\n",
    "1        A       0\n",
    "1        B       1\n",
    "1        C       2\n",
    "2        A       0\n",
    "2        C       1\n",
    "2        M       2\n",
    "2        N       3\n",
    "I'd like to write a query to return the id of a given sequence, e.g. \"A,B,C\", if there is an exact match. The length of the sequence is unknown beforehand. Thank you!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "What you need is called relational division (see Celko). The best solution will depend on your rdb engine. If you are able to do so - the most popular solution would be:\n",
    "\n",
    "Express you query as a table (a table of A,B,C)\n",
    "Inner join your table to the existing table, group by seq_id, count the elements of groups\n",
    "Use count to filter out sequences that are not exact (ie. when looking for A,B,C the count must be 3)\n",
    "Let's say you have a #query table holding tokens and sorts you wish to find (I use sort instead of order to avoid conflicts with reserved keywords)\n",
    "\n",
    "create table #query\n",
    "(\n",
    "token nvarchar(1)\n",
    ",sort int\n",
    ")\n",
    "\n",
    "insert into #query select 'A',0\n",
    "insert into #query select 'B',1\n",
    "insert into #query select 'C',2\n",
    "go\n",
    "\n",
    "select  seq_id\n",
    "from    dbo.sequences s\n",
    "inner join  #query q\n",
    "    on  q.token = s.token\n",
    "        and q.sort = s.sort\n",
    "group by s.seq_id\n",
    "having count(*) = (select count(*) from #query)\n",
    "Will return seq_id(s) that match your query. In newer versions of MsSql one would use a table variable instead of #query but the technique can be applied universally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../py/html_analysis.py\n",
    "ha = HeaderAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_execution_results(sql_str, database='Jobhunting'):\n",
    "    if database == 'Jobhunting':\n",
    "        conn, cursor = get_jh_conn_cursor()\n",
    "    else:\n",
    "        conn = pyodbc.connect(\n",
    "            driver='{SQL Server}',\n",
    "            server='localhost\\MSSQLSERVER01',\n",
    "            database=database,\n",
    "            trusted_connection=True\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "    #print(sql_str)\n",
    "    cursor.execute(sql_str)\n",
    "    try:\n",
    "        row_objs_list = cursor.fetchall()\n",
    "        row_tuples_list = [tuple(row_obj) for row_obj in row_objs_list]\n",
    "    except:\n",
    "        row_tuples_list = []\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    \n",
    "    return row_tuples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_jh_conn_cursor():\n",
    "    conn = pyodbc.connect(\n",
    "        driver='{SQL Server}',\n",
    "        server='localhost\\MSSQLSERVER01',\n",
    "        database='Jobhunting',\n",
    "        trusted_connection=True\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    return conn, cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_navigable_parent_sequence_table_dataframe():\n",
    "    files_list = os.listdir(ha.SAVES_HTML_FOLDER)\n",
    "    rows_list = []\n",
    "    for file_name in files_list:\n",
    "        child_strs_list = ha.get_child_strs_from_file(file_name)\n",
    "        for i, child_str in enumerate(child_strs_list):\n",
    "            row_dict = {}\n",
    "            row_dict['file_name'] = file_name\n",
    "            row_dict['navigable_parent'] = child_str\n",
    "            row_dict['sequence_order'] = i\n",
    "            rows_list.append(row_dict)\n",
    "    navigable_parent_sequence_table_df = pd.DataFrame(rows_list)\n",
    "    navigable_parent_sequence_table_df.index.name = 'navigable_parent_sequence_id'\n",
    "    #s.save_dataframes(include_index=True, navigable_parent_sequence_table_df=navigable_parent_sequence_table_df)\n",
    "    \n",
    "    return navigable_parent_sequence_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyodbc\n",
    "\n",
    "create_database_sql_str = '''\n",
    "IF (EXISTS (\n",
    "    SELECT * FROM master.dbo.sysdatabases\n",
    "    WHERE name = N'Jobhunting'\n",
    "    ))\n",
    "    BEGIN\n",
    "        SELECT 'DATABASE already EXISTS' AS Message\n",
    "    END\n",
    "ELSE\n",
    "    BEGIN\n",
    "        CREATE DATABASE [Jobhunting];\n",
    "        SELECT * FROM master.dbo.sysdatabases\n",
    "        WHERE name = N'Jobhunting'\n",
    "    END;'''\n",
    "create_table_sql_str = '''\n",
    "IF (EXISTS (\n",
    "    SELECT * FROM INFORMATION_SCHEMA.TABLES\n",
    "    WHERE TABLE_NAME = N'NavigableParentSequence'\n",
    "    ))\n",
    "    BEGIN\n",
    "        SELECT 'TABLE_NAME already EXISTS' AS Message\n",
    "    END\n",
    "ELSE\n",
    "    BEGIN\n",
    "        CREATE TABLE NavigableParentSequence(\n",
    "            navigable_parent_sequence_id INT PRIMARY KEY,\n",
    "            file_name VARCHAR (255) NOT NULL,\n",
    "            navigable_parent NVARCHAR (2224) NOT NULL,\n",
    "            sequence_order INT NOT NULL\n",
    "        );\n",
    "        SELECT * FROM INFORMATION_SCHEMA.TABLES\n",
    "        WHERE TABLE_NAME = N'NavigableParentSequence'\n",
    "    END;'''\n",
    "insert_columns_sql_str = '''\n",
    "SET QUOTED_IDENTIFIER OFF\n",
    "SET ANSI_NULLS ON\n",
    "IF (EXISTS (\n",
    "    SELECT * FROM NavigableParentSequence WHERE\n",
    "        file_name = ? AND\n",
    "        sequence_order = ?\n",
    "    ))\n",
    "    BEGIN\n",
    "        SELECT 'Row already EXISTS' AS Message\n",
    "    END\n",
    "ELSE\n",
    "    BEGIN\n",
    "        INSERT INTO NavigableParentSequence (\n",
    "            navigable_parent_sequence_id,\n",
    "            file_name,\n",
    "            navigable_parent,\n",
    "            sequence_order\n",
    "        ) values(\n",
    "            ?,\n",
    "            ?,\n",
    "            ?,\n",
    "            ?\n",
    "        );\n",
    "        SELECT * FROM NavigableParentSequence WHERE\n",
    "            file_name = ? AND\n",
    "            sequence_order = ?\n",
    "    END;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/5160742/how-to-store-and-search-for-a-sequence-in-a-rdbms\n",
    "def create_navigable_parent_sequence_table():\n",
    "    row_tuples_list = get_execution_results(create_database_sql_str, database='master')\n",
    "    row_tuples_list = get_execution_results(create_table_sql_str)\n",
    "    \n",
    "    # Create the navigable html strings dataset\n",
    "    navigable_parent_sequence_table_df = create_navigable_parent_sequence_table_dataframe()\n",
    "    \n",
    "    # Insert Dataframe into SQL Server:\n",
    "    conn, cursor = get_jh_conn_cursor()\n",
    "    for row_index, row_series in navigable_parent_sequence_table_df.iterrows():\n",
    "        #print(insert_columns_sql_str)\n",
    "        try:\n",
    "            cursor.execute(insert_columns_sql_str, row_series.file_name, row_series.sequence_order, row_index, row_series.file_name,\n",
    "                           row_series.navigable_parent, row_series.sequence_order, row_series.file_name, row_series.sequence_order)\n",
    "        except Exception as e:\n",
    "            print(str(e).strip())\n",
    "            print(insert_columns_sql_str.replace('?', '\"{}\"').format(row_series.file_name, row_series.sequence_order, row_index,\n",
    "                                                                     row_series.file_name, row_series.navigable_parent, row_series.sequence_order,\n",
    "                                                                     row_series.file_name, row_series.sequence_order))\n",
    "            break\n",
    "        try:\n",
    "            row_objs_list = cursor.fetchall()\n",
    "        except:\n",
    "            pass\n",
    "    conn.commit()\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_navigable_parent_sequence_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Explore existing columns on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sqlcmd -S DAVEZ-ASUS-LAPT\\MSSQLSERVER01 -E\n",
    "connection_str = 'Server=localhost\\MSSQLSERVER01;Database=master;Trusted_Connection=True;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_cat_idx = 0\n",
    "table_schem_idx = 1\n",
    "table_name_idx = 2\n",
    "column_name_idx = 3\n",
    "data_type_idx = 4\n",
    "type_name_idx = 5\n",
    "column_size_idx = 6\n",
    "buffer_length_idx = 7\n",
    "decimal_digits_idx = 8\n",
    "num_prec_radix_idx = 9\n",
    "nullable_idx = 10\n",
    "remarks_idx = 11\n",
    "column_def_idx = 12\n",
    "sql_data_type_idx = 13\n",
    "sql_datetime_sub_idx = 14\n",
    "char_octet_length_idx = 15\n",
    "ordinal_position_idx = 16\n",
    "is_nullable_idx = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['master', 'tempdb', 'model', 'msdb', 'Jobhunting']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conn = pyodbc.connect(\n",
    "    driver='{SQL Server}',\n",
    "    server='localhost\\MSSQLSERVER01',\n",
    "    database='master',\n",
    "    trusted_connection=True\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('SELECT name FROM master.dbo.sysdatabases;')\n",
    "\n",
    "databases_list = []\n",
    "for database_row_obj in cursor:\n",
    "    database_row_tuple = tuple(database_row_obj)\n",
    "    database_name = database_row_tuple[0]\n",
    "    databases_list.append(database_name)\n",
    "conn.close()\n",
    "databases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows_list = []\n",
    "for database_name in databases_list:\n",
    "    database_conn = pyodbc.connect(\n",
    "        driver='{SQL Server}',\n",
    "        server='localhost\\MSSQLSERVER01',\n",
    "        database=database_name,\n",
    "        trusted_connection=True\n",
    "    )\n",
    "    database_cursor = database_conn.cursor()\n",
    "    sql_str = f'SELECT * FROM {database_name}.INFORMATION_SCHEMA.TABLES;'\n",
    "    #print(sql_str)\n",
    "    database_cursor.execute(sql_str)\n",
    "    table_row_objs_list = database_cursor.fetchall()\n",
    "    for table_row_obj in table_row_objs_list:\n",
    "        table_row_tuple = tuple(table_row_obj)\n",
    "        if len(table_row_tuple) >= 3:\n",
    "            row_dict = {}\n",
    "            row_dict['database_name'] = database_name\n",
    "            table_name = table_row_tuple[2]\n",
    "            row_dict['table_name'] = table_name\n",
    "            rows_list.append(row_dict.copy())\n",
    "    database_conn.close()\n",
    "column_names_df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>91</th>\n",
       "      <th>71</th>\n",
       "      <th>150</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>database_name</th>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table_name</th>\n",
       "      <td>syspolicy_object_sets</td>\n",
       "      <td>syscollector_collection_sets_internal</td>\n",
       "      <td>syspolicy_policies</td>\n",
       "      <td>sysmail_server</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 91                                     71   \\\n",
       "database_name                   msdb                                   msdb   \n",
       "table_name     syspolicy_object_sets  syscollector_collection_sets_internal   \n",
       "\n",
       "                              150             89   \n",
       "database_name                msdb            msdb  \n",
       "table_name     syspolicy_policies  sysmail_server  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "column_names_df.sample(4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows_list = []\n",
    "for row_index, row_series in column_names_df.iterrows():\n",
    "    database_name = row_series.database_name\n",
    "    table_name = row_series.table_name\n",
    "    database_conn = pyodbc.connect(\n",
    "        driver='{SQL Server}',\n",
    "        server='localhost\\MSSQLSERVER01',\n",
    "        database=database_name,\n",
    "        trusted_connection=True\n",
    "    )\n",
    "    database_cursor = database_conn.cursor()\n",
    "    column_row_objs_list = database_cursor.columns(table=table_name)\n",
    "    for column_row_obj in column_row_objs_list:\n",
    "        column_row_tuple = tuple(column_row_obj)\n",
    "        row_dict = {}\n",
    "        row_dict['database_name'] = database_name\n",
    "        row_dict['table_name'] = column_row_tuple[table_name_idx]\n",
    "        row_dict['column_name'] = column_row_tuple[column_name_idx]\n",
    "        row_dict['table_cat'] = column_row_tuple[table_cat_idx]\n",
    "        row_dict['table_schem'] = column_row_tuple[table_schem_idx]\n",
    "        row_dict['data_type'] = column_row_tuple[data_type_idx]\n",
    "        row_dict['type_name'] = column_row_tuple[type_name_idx]\n",
    "        row_dict['column_size'] = column_row_tuple[column_size_idx]\n",
    "        row_dict['buffer_length'] = column_row_tuple[buffer_length_idx]\n",
    "        row_dict['decimal_digits'] = column_row_tuple[decimal_digits_idx]\n",
    "        row_dict['num_prec_radix'] = column_row_tuple[num_prec_radix_idx]\n",
    "        row_dict['nullable'] = column_row_tuple[nullable_idx]\n",
    "        row_dict['remarks'] = column_row_tuple[remarks_idx]\n",
    "        row_dict['column_def'] = column_row_tuple[column_def_idx]\n",
    "        row_dict['sql_data_type'] = column_row_tuple[sql_data_type_idx]\n",
    "        row_dict['sql_datetime_sub'] = column_row_tuple[sql_datetime_sub_idx]\n",
    "        row_dict['char_octet_length'] = column_row_tuple[char_octet_length_idx]\n",
    "        row_dict['ordinal_position'] = column_row_tuple[ordinal_position_idx]\n",
    "        row_dict['is_nullable'] = column_row_tuple[is_nullable_idx]\n",
    "        rows_list.append(row_dict.copy())\n",
    "    database_conn.close()\n",
    "column_names_df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1744</th>\n",
       "      <th>1985</th>\n",
       "      <th>1991</th>\n",
       "      <th>1929</th>\n",
       "      <th>711</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>database_name</th>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table_name</th>\n",
       "      <td>backupset</td>\n",
       "      <td>sysutility_ucp_mi_database_health_internal</td>\n",
       "      <td>restorefile</td>\n",
       "      <td>backupfile</td>\n",
       "      <td>sysutility_ucp_mi_health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column_name</th>\n",
       "      <td>last_recovery_fork_guid</td>\n",
       "      <td>over_utilized_count</td>\n",
       "      <td>destination_phys_drive</td>\n",
       "      <td>filegroup_guid</td>\n",
       "      <td>mi_processor_health_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table_cat</th>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "      <td>msdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table_schem</th>\n",
       "      <td>dbo</td>\n",
       "      <td>dbo</td>\n",
       "      <td>dbo</td>\n",
       "      <td>dbo</td>\n",
       "      <td>dbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <td>-11</td>\n",
       "      <td>4</td>\n",
       "      <td>-9</td>\n",
       "      <td>-11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_name</th>\n",
       "      <td>uniqueidentifier</td>\n",
       "      <td>int</td>\n",
       "      <td>nvarchar</td>\n",
       "      <td>uniqueidentifier</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column_size</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>260</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buffer_length</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>520</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decimal_digits</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_prec_radix</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nullable</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remarks</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column_def</th>\n",
       "      <td>None</td>\n",
       "      <td>((0))</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql_data_type</th>\n",
       "      <td>-11</td>\n",
       "      <td>4</td>\n",
       "      <td>-9</td>\n",
       "      <td>-11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql_datetime_sub</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_octet_length</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal_position</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_nullable</th>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      1744  \\\n",
       "database_name                         msdb   \n",
       "table_name                       backupset   \n",
       "column_name        last_recovery_fork_guid   \n",
       "table_cat                             msdb   \n",
       "table_schem                            dbo   \n",
       "data_type                              -11   \n",
       "type_name                 uniqueidentifier   \n",
       "column_size                             36   \n",
       "buffer_length                           16   \n",
       "decimal_digits                         NaN   \n",
       "num_prec_radix                         NaN   \n",
       "nullable                                 1   \n",
       "remarks                               None   \n",
       "column_def                            None   \n",
       "sql_data_type                          -11   \n",
       "sql_datetime_sub                       NaN   \n",
       "char_octet_length                      NaN   \n",
       "ordinal_position                        54   \n",
       "is_nullable                            YES   \n",
       "\n",
       "                                                         1985  \\\n",
       "database_name                                            msdb   \n",
       "table_name         sysutility_ucp_mi_database_health_internal   \n",
       "column_name                               over_utilized_count   \n",
       "table_cat                                                msdb   \n",
       "table_schem                                               dbo   \n",
       "data_type                                                   4   \n",
       "type_name                                                 int   \n",
       "column_size                                                10   \n",
       "buffer_length                                               4   \n",
       "decimal_digits                                              0   \n",
       "num_prec_radix                                             10   \n",
       "nullable                                                    0   \n",
       "remarks                                                  None   \n",
       "column_def                                              ((0))   \n",
       "sql_data_type                                               4   \n",
       "sql_datetime_sub                                          NaN   \n",
       "char_octet_length                                         NaN   \n",
       "ordinal_position                                            3   \n",
       "is_nullable                                                NO   \n",
       "\n",
       "                                     1991              1929  \\\n",
       "database_name                        msdb              msdb   \n",
       "table_name                    restorefile        backupfile   \n",
       "column_name        destination_phys_drive    filegroup_guid   \n",
       "table_cat                            msdb              msdb   \n",
       "table_schem                           dbo               dbo   \n",
       "data_type                              -9               -11   \n",
       "type_name                        nvarchar  uniqueidentifier   \n",
       "column_size                           260                36   \n",
       "buffer_length                         520                16   \n",
       "decimal_digits                        NaN               NaN   \n",
       "num_prec_radix                        NaN               NaN   \n",
       "nullable                                1                 1   \n",
       "remarks                              None              None   \n",
       "column_def                           None              None   \n",
       "sql_data_type                          -9               -11   \n",
       "sql_datetime_sub                      NaN               NaN   \n",
       "char_octet_length                     520               NaN   \n",
       "ordinal_position                        3                24   \n",
       "is_nullable                           YES               YES   \n",
       "\n",
       "                                        711   \n",
       "database_name                           msdb  \n",
       "table_name          sysutility_ucp_mi_health  \n",
       "column_name        mi_processor_health_state  \n",
       "table_cat                               msdb  \n",
       "table_schem                              dbo  \n",
       "data_type                                  4  \n",
       "type_name                                int  \n",
       "column_size                               10  \n",
       "buffer_length                              4  \n",
       "decimal_digits                             0  \n",
       "num_prec_radix                            10  \n",
       "nullable                                   1  \n",
       "remarks                                 None  \n",
       "column_def                              None  \n",
       "sql_data_type                              4  \n",
       "sql_datetime_sub                         NaN  \n",
       "char_octet_length                        NaN  \n",
       "ordinal_position                           5  \n",
       "is_nullable                              YES  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "column_names_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('TABLE_CATALOG', str, None, 128, 128, 0, True),\n",
       " ('TABLE_SCHEMA', str, None, 128, 128, 0, True),\n",
       " ('TABLE_NAME', str, None, 128, 128, 0, False),\n",
       " ('TABLE_TYPE', str, None, 10, 10, 0, True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "row_obj.cursor_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\Anaconda3\\envs\\jh\\python.exe -m pip install C:\\Users\\dev\\Downloads\\pymssql-2.1.5-cp39-cp39-win_amd64.whl\n",
      "Processing c:\\users\\dev\\downloads\\pymssql-2.1.5-cp39-cp39-win_amd64.whl\n",
      "Installing collected packages: pymssql\n",
      "Successfully installed pymssql-2.1.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "command_str = f'{sys.executable} -m pip install C:\\\\Users\\\\dev\\\\Downloads\\\\pymssql-2.1.5-cp39-cp39-win_amd64.whl'\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\Anaconda3\\envs\\jh\\python.exe -m pip install --upgrade pymssql\n",
      "Collecting pymssql\n",
      "  Using cached pymssql-2.1.5.tar.gz (167 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\dev\\Anaconda3\\envs\\jh\\python.exe' 'C:\\Users\\dev\\Anaconda3\\envs\\jh\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' build_wheel 'C:\\Users\\dev\\AppData\\Local\\Temp\\tmpblqdrc6c'\n",
      "       cwd: C:\\Users\\dev\\AppData\\Local\\Temp\\pip-install-4a2_b6cz\\pymssql\n",
      "  Complete output (16 lines):\n",
      "  setup.py: platform.system() => 'Windows'\n",
      "  setup.py: platform.architecture() => ('64bit', 'WindowsPE')\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  cythoning src\\_mssql.pyx to src\\_mssql.c\n",
      "  cythoning src\\pymssql.pyx to src\\pymssql.c\n",
      "  building '_mssql' extension\n",
      "  creating build\n",
      "  creating build\\temp.win-amd64-3.9\n",
      "  creating build\\temp.win-amd64-3.9\\Release\n",
      "  creating build\\temp.win-amd64-3.9\\Release\\src\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.23.28105\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -Ifreetds\\include -IC:\\Users\\dev\\AppData\\Local\\Temp\\pip-install-4a2_b6cz\\pymssql\\build\\include -IC:\\Users\\dev\\Anaconda3\\envs\\jh\\include -IC:\\Users\\dev\\Anaconda3\\envs\\jh\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.23.28105\\include -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt /Tcsrc\\_mssql.c /Fobuild\\temp.win-amd64-3.9\\Release\\src\\_mssql.obj -DMSDBLIB\n",
      "  _mssql.c\n",
      "  src\\_mssql.c(611): fatal error C1083: Cannot open include file: 'sqlfront.h': No such file or directory\n",
      "  error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.23.28105\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pymssql\n",
      "ERROR: Could not build wheels for pymssql which use PEP 517 and cannot be installed directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: pymssql\n",
      "  Building wheel for pymssql (PEP 517): started\n",
      "  Building wheel for pymssql (PEP 517): finished with status 'error'\n",
      "Failed to build pymssql\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "command_str = f'{sys.executable} -m pip install --upgrade pymssql'\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.9.0)",
   "language": "python",
   "name": "jh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
