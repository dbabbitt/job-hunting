{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nu.github_folder']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import timedelta\n",
    "from notebook_utils import NotebookUtilities\n",
    "from pandas import DataFrame\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")\n",
    "[f'nu.{fn}' for fn in dir(nu) if 'github' in fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<quote>\"The universe is bigger than your life; your life is bigger than your self; your self is bigger than your self-expression; your self-expression is bigger than your signaled preferences, your signaled preferences are bigger than your politics, your politics are bigger than your creative identity.\"</quote> Venkatesh Rao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize all the notebook utilities in the GitHub folder\n",
    "from itertools import combinations\n",
    "import subprocess\n",
    "\n",
    "paths_list = []\n",
    "for sub_directory, directories_list, files_list in os.walk(osp.abspath('../../')):\n",
    "    for file_name in files_list:\n",
    "        if file_name == 'notebook_utils.py':\n",
    "            file_path = osp.join(sub_directory, file_name)\n",
    "            paths_list.append(file_path)\n",
    "\n",
    "# Get all unique pairs (order doesn't matter)\n",
    "pairs = combinations(paths_list, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate through pairs and compare them\n",
    "comparator_path = r\"C:\\Program Files (x86)\\Compare It!\\wincmp3.exe\"\n",
    "for pair in pairs:\n",
    "    # print(pair)\n",
    "    subprocess.run([comparator_path, pair[0], pair[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\bible\\saves\\pkl\\ESV2011_modules.pkl\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\bible\\zip\\ESV2001.zip\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\bible\\zip\\ESV2011.zip\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\bin\\libGLESv2.dll\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\include\\qt\\Qt3DRender\\5.15.8\\Qt3DRender\\private\\trianglesvisitor_p.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\include\\qt\\QtQuickParticles\\QtQuickParticlesVersion\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\include\\qt\\QtQuickParticles\\qtquickparticlesversion.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\include\\qt\\QtQuickShapes\\QtQuickShapesVersion\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\include\\qt\\QtQuickShapes\\qtquickshapesversion.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\lib\\libGLESv2.lib\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\lib\\libGLESv2.prl\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\Library\\mkspecs\\modules\\qt_ext_libGLESv2.pri\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.d.ts\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\gs_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.js.map\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\bin\\libGLESv2.dll\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\include\\qt\\Qt3DRender\\5.15.2\\Qt3DRender\\private\\trianglesvisitor_p.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\include\\qt\\QtQuickParticles\\QtQuickParticlesVersion\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\include\\qt\\QtQuickParticles\\qtquickparticlesversion.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\include\\qt\\QtQuickShapes\\QtQuickShapesVersion\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\include\\qt\\QtQuickShapes\\qtquickshapesversion.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\lib\\libGLESv2.lib\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Library\\lib\\libGLESv2.prl\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\.bin\\esvalidate\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\.bin\\esvalidate.cmd\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.d.ts\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.js.map\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\escodegen\\node_modules\\.bin\\esvalidate\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\escodegen\\node_modules\\.bin\\esvalidate.cmd\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\share\\jupyter\\lab\\staging\\node_modules\\esprima\\bin\\esvalidate.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\057aecbdc80b37cf_Data_Science_Engineer_Temporary_Gainesville_FL_32608_Indeed_com.html\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\8fc0ed7481ff426b_Data_Scientist_Gainesville_FL_Indeed_com.html\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\Data_Scientist_-_Charlottesville,_VA_22911_-_Indeed.com_38d0121b18b25ad5.html\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html\\tlVStEHcIFoYAONIJhmrIw_Data_Science_Instructor_Tutor_for_Neurodiverse_Young_Adults_Staff_Wage_Remote_University_of_Virginia_Charlottesville_VA_Remote.html\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\.bin\\esvalidate\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\.bin\\esvalidate.cmd\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\.bin\\esvalidate.ps1\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\esprima\\bin\\esvalidate.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\js-yaml\\node_modules\\.bin\\esvalidate\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\js-yaml\\node_modules\\.bin\\esvalidate.cmd\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\js-yaml\\node_modules\\.bin\\esvalidate.ps1\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\jupyterlab-form\\node_modules\\js-yaml\\node_modules\\esprima\\bin\\esvalidate.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\data\\txt\\esv.txt\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\bin\\libGLESv2.dll\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\include\\qt\\Qt3DRender\\5.12.9\\Qt3DRender\\private\\trianglesvisitor_p.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\include\\qt\\QtQuickParticles\\QtQuickParticlesVersion\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\include\\qt\\QtQuickParticles\\qtquickparticlesversion.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\include\\qt\\QtQuickShapes\\QtQuickShapesVersion\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\include\\qt\\QtQuickShapes\\qtquickshapesversion.h\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\include\\xercesc\\util\\XercesVersion.hpp\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\lib\\libGLESv2.lib\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\Library\\lib\\libGLESv2.prl\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\share\\jupyter\\lab\\staging\\node_modules\\.bin\\esvalidate\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\share\\jupyter\\lab\\staging\\node_modules\\.bin\\esvalidate.cmd\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.d.ts\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\lib\\icon\\widgets\\commandpalettesvg.js.map\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\share\\jupyter\\lab\\staging\\node_modules\\@jupyterlab\\ui-components\\src\\icon\\widgets\\commandpalettesvg.ts\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\rpc_env\\share\\jupyter\\lab\\staging\\node_modules\\esprima\\bin\\esvalidate.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\sql-server-samples\\samples\\development-frameworks\\laravel\\vendor\\classpreloader\\classpreloader\\src\\Parser\\StrictTypesVisitor.php\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial1\\skill\\code\\mineFiveCoalOresV2.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial1\\skill\\code\\mineFiveCopperOresV2.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial1\\skill\\code\\mineFiveIronOresV2.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial1\\skill\\description\\mineFiveCoalOresV2.txt\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial1\\skill\\description\\mineFiveCopperOresV2.txt\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial1\\skill\\description\\mineFiveIronOresV2.txt\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial2\\skill\\code\\exploreCaveAndGatherResourcesV2.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial2\\skill\\code\\mineFiveCoalOresV2.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial2\\skill\\description\\exploreCaveAndGatherResourcesV2.txt\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\skill_library\\trial2\\skill\\description\\mineFiveCoalOresV2.txt\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\voyager\\env\\mineflayer\\node_modules\\.bin\\esvalidate\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\voyager\\env\\mineflayer\\node_modules\\.bin\\esvalidate.cmd\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\voyager\\env\\mineflayer\\node_modules\\.bin\\esvalidate.ps1\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Voyager\\voyager\\env\\mineflayer\\node_modules\\esprima\\bin\\esvalidate.js\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\web-scrapers\\saves\\Donald Trump Speeches\\Donald Trump’s speech in Janesville, Wisconsin.txt\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\web-scrapers\\saves\\Donald Trump Speeches\\Donald Trump’s speech in Janesville, Wisconsin13.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "black_list = ['.ipynb_checkpoints', '$Recycle.Bin']\n",
    "for sub_directory, directories_list, files_list in os.walk(osp.dirname(nu.github_folder)):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if 'esv' in file_name.lower():\n",
    "                file_path = osp.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MATCH (fn:FileNames)\n",
      "WHERE\n",
      "    (fn.file_name IN [\"382154c63ba6b00e_Data_Scientist_Remote_Indeed_com.html\", \"b7dc35c0738d1cb2_Clojure_Software_Engineer_Remote_Indeed_com.html\"]) AND\n",
      "    ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
      "    (fn.rejection_email_text IS NULL) AND\n",
      "    (fn.rejection_email_date IS NULL)\n",
      "RETURN\n",
      "    fn.percent_fit AS percent_fit,\n",
      "    fn.file_name AS file_name,\n",
      "    fn.posting_url AS posting_url\n",
      "ORDER BY fn.percent_fit DESC;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "black_list = ['$RECYCLE.BIN', '$Recycle.Bin', '.git']\n",
    "root_dir = r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\html'\n",
    "file_names_list = []\n",
    "for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if (file_name.endswith('.html')):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                with open(file_path, 'r', encoding=nu.encoding_type) as f:\n",
    "                    html_str = f.read()\n",
    "                    hit_count = 0\n",
    "                    for text_str in ['Buyers', 'Edge', 'Platform']:\n",
    "                        if re.search(text_str, html_str): hit_count += 1\n",
    "                    if hit_count == 3: file_names_list.append(file_name)\n",
    "print(f'''\n",
    "MATCH (fn:FileNames)\n",
    "WHERE\n",
    "    (fn.file_name IN {str(file_names_list).replace(\"'\", '\"')}) AND\n",
    "    ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "    (fn.rejection_email_text IS NULL) AND\n",
    "    (fn.rejection_email_date IS NULL)\n",
    "RETURN\n",
    "    fn.percent_fit AS percent_fit,\n",
    "    fn.file_name AS file_name,\n",
    "    fn.posting_url AS posting_url\n",
    "ORDER BY fn.percent_fit DESC;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to copy files while skipping existing files\n",
    "import shutil\n",
    "\n",
    "zoneinfo_folder = 'C:\\\\Users\\\\daveb\\\\OneDrive\\\\Documents\\\\GitHub\\\\job-hunting\\\\jh_env\\\\lib\\\\site-packages\\\\tzdata\\\\zoneinfo'\n",
    "def copy_files(src, dst):\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        \n",
    "        # Create the corresponding directory structure in the destination\n",
    "        for dir in dirs:\n",
    "            src_dir = os.path.join(root, dir)\n",
    "            dst_dir = os.path.join(dst, os.path.relpath(src_dir, src))\n",
    "            if not os.path.exists(dst_dir):\n",
    "                os.makedirs(dst_dir)\n",
    "\n",
    "        # Copy files, skipping existing files in the destination\n",
    "            dst_file = os.path.join(dst, os.path.relpath(src_file, src))\n",
    "            if not os.path.exists(dst_file):\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "\n",
    "# Copy files from tz_path to zoneinfo_folder\n",
    "for tz_path in tz_paths_list: copy_files(tz_path, zoneinfo_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = tz_paths_list.pop()\n",
    "!explorer.exe {folder_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = 'C:\\\\Users\\\\daveb\\\\OneDrive\\\\Documents\\\\GitHub\\\\job-hunting\\\\jh_env\\\\lib\\\\site-packages\\\\tzdata\\\\zoneinfo'\n",
    "!explorer.exe {folder_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "black_list = ['$RECYCLE.BIN', '$Recycle.Bin', '.git']\n",
    "root_dir = 'C:\\\\'\n",
    "for sub_directory, directories_list, files_list in os.walk(osp.dirname(nu.github_folder)):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        full_sub_dir_path = os.path.join(root_dir, sub_directory)\n",
    "        if not osp.isdir(full_sub_dir_path): continue\n",
    "        for file_name in os.listdir(full_sub_dir_path):\n",
    "                # file_path = os.path.join(full_sub_dir_path, file_name)\n",
    "                print(full_sub_dir_path)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!start %windir%\\explorer.exe \"{os.path.abspath(nu.github_folder)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "black_list = ['$RECYCLE.BIN', '$Recycle.Bin', '.git', 'jh_env', '.ipynb_checkpoints', 'explorations', 'Microsoft', 'npm',\n",
    "              'Theme', 'Assets', 'Lib', 'site-packages']\n",
    "suffixes_list = ['.cer']\n",
    "neo4j_certs_list = []\n",
    "for root_dir in ['C:\\\\', 'D:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if any(map(lambda x: file_name.lower().endswith(x), suffixes_list)):\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    print(file_path)\n",
    "                    if (file_name == 'neo4j.cer'): neo4j_certs_list.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "black_list = ['data', 'saves', '.ipynb_checkpoints']\n",
    "for root_dir in [r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if ('prompt' in file_name):\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime, date\n",
    "from pandas import DataFrame\n",
    "\n",
    "white_list = ['load_magic']\n",
    "rows_list = []\n",
    "for root_dir in [r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x in sub_directory, white_list)):\n",
    "            for file_name in files_list:\n",
    "                if 'environment.py' == file_name:\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    \n",
    "                    # Get the last modification time of the file in seconds since epoch\n",
    "                    modification_time = os.path.getmtime(file_path)\n",
    "                    \n",
    "                    # Convert the modification time to a date object\n",
    "                    modification_date = datetime.fromtimestamp(modification_time).date()\n",
    "                    \n",
    "                    # Add it to the rows list\n",
    "                    row_dict = {}\n",
    "                    row_dict['file_path'] = file_path\n",
    "                    row_dict['modification_date'] = modification_date\n",
    "                    rows_list.append(row_dict)\n",
    "soup_df = DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "\n",
    "comparator_path = r'C:\\Program Files (x86)\\Compare It!\\wincmp3.exe'\n",
    "file_paths_list = soup_df.sort_values('modification_date', ascending=False).file_path.tolist()\n",
    "print(len(file_paths_list))\n",
    "subprocess.run([comparator_path, file_paths_list[0], file_paths_list[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup_groupby = soup_df.sort_values('modification_date', ascending=True).groupby('modification_date', group_keys=True)\n",
    "print(soup_groupby.min().head(1).values[0][0])\n",
    "def f(df):\n",
    "    display(df)\n",
    "    \n",
    "    return df\n",
    "_ = soup_groupby.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\ipynb'):\n",
    "    for file_name in files_list:\n",
    "        if (not file_name.endswith('-checkpoint.ipynb')) and ('explor' in file_name.lower()):\n",
    "            print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for root_dir in ['C:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        for file_name in files_list:\n",
    "            if file_name == 'neo4j_job_hunting_export.csv':\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "max_bytes = 0\n",
    "max_file_path = ''\n",
    "black_list = ['$RECYCLE.BIN', '$Recycle.Bin', '.git']\n",
    "for root_dir in [r'D:\\Documents\\GitHub\\job-hunting\\saves\\html']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir, topdown=False):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if file_name.endswith('.html') and 'sphere' in file_name.lower():\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    # file_size = os.path.getsize(file_path)\n",
    "                    print(file_name)\n",
    "                    # if file_size > max_bytes:\n",
    "                    #     max_bytes = file_size\n",
    "                    #     max_file_path = file_path\n",
    "                    #     print(max_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_directories_containing(root_dir=r'C:\\Users\\dev\\anaconda3\\envs', contains_str='activate',\n",
    "                                   black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git']):\n",
    "    dir_path_list = []\n",
    "    if type(root_dir) == list:\n",
    "        root_dir_list = root_dir\n",
    "    else:\n",
    "        root_dir_list = [root_dir]\n",
    "    if type(contains_str) == list:\n",
    "        contains_list = contains_str\n",
    "    else:\n",
    "        contains_list = [contains_str]\n",
    "    for root_dir in root_dir_list:\n",
    "        for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "            if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "                for dir_name in directories_list:\n",
    "                    contains_bool = False\n",
    "                    for contains_str in contains_list:\n",
    "                        contains_bool = contains_bool or (contains_str in dir_name)\n",
    "                    if contains_bool:\n",
    "                        dir_path = os.path.join(sub_directory, dir_name)\n",
    "                        dir_path_list.append(dir_path)\n",
    "    \n",
    "    return dir_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "dirs_list = ['C:\\\\', 'D:\\\\']\n",
    "for file_path in get_all_directories_containing(root_dir=dirs_list, contains_str='minecraft', black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git']):\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for root_dir in [r'D:\\Documents\\GitHub\\MineCraft\\data\\1.18.1_Default_Resource_Pack']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith('.class'):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for root_dir in ['C:\\\\', 'D:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith('xlsx') and (('walk' in file_name.lower()) or ('talk' in file_name.lower())):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import winshell\n",
    "import random\n",
    "\n",
    "# List the original path of all the all items in the recycling bin\n",
    "binned_files_list = list(winshell.recycle_bin())\n",
    "\n",
    "# Determine the index of your file\n",
    "ShellRecycledItem_obj = winshell.ShellRecycledItem.from_path(r'D:\\$RECYCLE.BIN\\S-1-5-21-1161412072-3680630389-113359315-1003\\$RB7DVL4\\data\\txt\\gradient.txt')\n",
    "binned_file_index = binned_files_list.index(ShellRecycledItem_obj)\n",
    "\n",
    "winshell.undelete(binned_files_list[binned_file_index].original_filename())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\html'):\n",
    "    for old_file_name in files_list:\n",
    "        if \"['\" in old_file_name:\n",
    "            old_file_path = os.path.join(sub_directory, old_file_name)\n",
    "            new_file_name = old_file_name.replace(\"['\", '').replace(\"']\", '')\n",
    "            new_file_path = os.path.join(sub_directory, new_file_name)\n",
    "            os.rename(old_file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_all_files_ending_starting_with(\n",
    "    root_dir=[r'C:\\\\'],\n",
    "    ends_with='.exe',\n",
    "    starts_with='speedtest',\n",
    "    black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_all_files_ending_with(\n",
    "    root_dir=[r'C:\\Users\\dev\\Documents\\Repositories'],\n",
    "    ends_with='.bat',\n",
    "    black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git', 'pkgs'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contains_str = 'job_hunting'\n",
    "file_path_list = get_all_files_containing(root_dir=r'C:\\Users\\dev\\Documents\\Repositories\\rpc\\ps1', contains_str=contains_str)\n",
    "for file_path in file_path_list:\n",
    "    os.rename(file_path, file_path.replace(contains_str, 'rpc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for key, value in dict(os.environ).items():\n",
    "    if 'dev' in value:\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%windir%\\System32\\cmd.exe \"/K\" C:\\Users\\dev\\anaconda3\\Scripts\\activate.bat C:\\Users\\dev\\anaconda3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "\n",
    "repos_list = [r'C:\\Users\\dev\\Documents\\Repositories\\covid19', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\flask',\n",
    "              r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\pt', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\pymc3',\n",
    "              r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\rpc', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\test',\n",
    "              r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\tf', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\x']\n",
    "envs_list = ['covid19', 'flask', 'pt', 'pymc3', 'rpc', 'test', 'tf', 'x']\n",
    "for repo_path, env_name in zip(repos_list, envs_list):\n",
    "    print()\n",
    "    print('-'*len(env_name))\n",
    "    print(env_name)\n",
    "    print('-'*len(env_name))\n",
    "    command_str = f'''\n",
    "cd \"{repo_path}\"\n",
    "conda activate {env_name}\n",
    "conda env export --name {env_name} -f tmp_environment.yml\n",
    "conda deactivate\n",
    "'''\n",
    "    process = subprocess.Popen(r'C:\\Program Files\\PowerShell\\7\\pwsh.exe', stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    std_out, std_err = process.communicate(command_str.encode(encoding='utf-8'))\n",
    "    #print(std_out.decode())\n",
    "    if std_err is not None:\n",
    "        print(std_err.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "union_set = set()\n",
    "for env_name, pkgs_set in env_pkgs_dict.items():\n",
    "    union_set = union_set.union(pkgs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intersection_set = union_set.copy()\n",
    "for env_name, pkgs_set in env_pkgs_dict.items():\n",
    "    intersection_set = intersection_set.intersection(pkgs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repo_path = r'C:\\Users\\dev\\Documents\\Repositories\\job-hunting'\n",
    "file_path = os.path.join(repo_path, 'tmp_environment.yml')\n",
    "with open(file_path, 'r') as file:\n",
    "    lines_list = file.read().split('\\n')[5:-2]\n",
    "    pkgs_list = [line_str.split('=')[0].split(' ')[-1] for line_str in lines_list]\n",
    "    pkgs_set = set(pkgs_list)\n",
    "missing_set = intersection_set - pkgs_set\n",
    "for pkg_name in missing_set:\n",
    "    print(f'  - {pkg_name}')\n",
    "print(f'({\"|\".join(missing_set)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_specific_gitignore_files('data-foundations', repository_dir=r'D:\\Documents\\Repositories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "\n",
    "columns_list = jira_df.columns.tolist()\n",
    "[item for item, count in collections.Counter(columns_list).items() if count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = get_column_descriptions(jira_df)\n",
    "mask_series = column_descriptions_df.has_dates & column_descriptions_df.only_integers.isnull()\n",
    "column_descriptions_df[mask_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt_regex = re.compile(r'([\\r\\n]+)    \"import matplotlib\\.pyplot as plt\\\\n\",')\n",
    "notebooks_dir = r'D:\\Documents\\Repositories\\notebooks'\n",
    "stopped = False\n",
    "for sub_directory, directories_list, files_list in os.walk(notebooks_dir):\n",
    "    if stopped:\n",
    "        break\n",
    "    for file_name in files_list:\n",
    "        if stopped:\n",
    "            break\n",
    "        if file_name.endswith('.ipynb'):\n",
    "            file_path = os.path.join(sub_directory, file_name)\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    file_str = f.read()\n",
    "                    if plt_regex.search(file_str):\n",
    "                        print(file_path)\n",
    "                        stopped = True\n",
    "                        break\n",
    "            except UnicodeDecodeError as e:\n",
    "                try:\n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        file_str = f.read().decode('utf-8')\n",
    "                        if plt_regex.search(file_str):\n",
    "                            print(file_path)\n",
    "                except Exception as e:\n",
    "                    message = str(e).strip()\n",
    "                    print()\n",
    "                    print('{} had an error after trying to decode: {}'.format(file_path, message))\n",
    "                    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyperclip\n",
    "\n",
    "pyperclip.copy(str(file_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gi = get_ipython()\n",
    "#print([fn for fn in dir(gi) if not fn.startswith('_')])\n",
    "gi.run_line_magic('who', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remove_empty_folders(folder_path=r'D:\\VirtualBox VMs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "magic_dict_list = magic_dict['test.py']\n",
    "print(len(magic_dict_list))\n",
    "subprocess.run([comparator_path, os.path.abspath(magic_dict_list[0]), os.path.abspath(magic_dict_list[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_specific_gitignore_files('notebooks', repository_dir=r'C:\\Users\\dev\\Documents\\repositories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "for key, value in sys.modules.items():\n",
    "    if 'xdist' in key.lower():\n",
    "        #print('{}: {}'.format(key, value))\n",
    "        print('{}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
