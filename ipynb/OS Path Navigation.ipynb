{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nu.github_folder']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import timedelta\n",
    "from notebook_utils import NotebookUtilities\n",
    "from pandas import DataFrame\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")\n",
    "[f'nu.{fn}' for fn in dir(nu) if 'github' in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\Downloads\\mixtral-8x7b-32kseqlen\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\n"
     ]
    }
   ],
   "source": [
    "\n",
    "black_list = ['$RECYCLE.BIN', '$Recycle.Bin', '.git']\n",
    "root_dir = 'C:\\\\'\n",
    "for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        full_sub_dir_path = os.path.join(root_dir, sub_directory)\n",
    "        if not osp.isdir(full_sub_dir_path): continue\n",
    "        for file_name in os.listdir(full_sub_dir_path):\n",
    "            if (file_name == 'tokenizer.model'):\n",
    "                # file_path = os.path.join(full_sub_dir_path, file_name)\n",
    "                print(full_sub_dir_path)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!start %windir%\\explorer.exe \"{os.path.abspath(nu.github_folder)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "black_list = ['.ipynb_checkpoints', '$Recycle.Bin']\n",
    "for sub_directory, directories_list, files_list in os.walk(osp.dirname(nu.github_folder)):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name == 'notebook_utils.py':\n",
    "                file_path = osp.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backups_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file_path in backups_list:\n",
    "    try: os.remove(file_path)\n",
    "    except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "black_list = ['$RECYCLE.BIN', '$Recycle.Bin', '.git', 'jh_env', '.ipynb_checkpoints', 'explorations', 'Microsoft', 'npm',\n",
    "              'Theme', 'Assets', 'Lib', 'site-packages']\n",
    "suffixes_list = ['.cer']\n",
    "neo4j_certs_list = []\n",
    "for root_dir in ['C:\\\\', 'D:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if any(map(lambda x: file_name.lower().endswith(x), suffixes_list)):\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    print(file_path)\n",
    "                    if (file_name == 'neo4j.cer'): neo4j_certs_list.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "black_list = ['data', 'saves', '.ipynb_checkpoints']\n",
    "for root_dir in [r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if ('prompt' in file_name):\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime, date\n",
    "from pandas import DataFrame\n",
    "\n",
    "white_list = ['load_magic']\n",
    "rows_list = []\n",
    "for root_dir in [r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x in sub_directory, white_list)):\n",
    "            for file_name in files_list:\n",
    "                if 'environment.py' == file_name:\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    \n",
    "                    # Get the last modification time of the file in seconds since epoch\n",
    "                    modification_time = os.path.getmtime(file_path)\n",
    "                    \n",
    "                    # Convert the modification time to a date object\n",
    "                    modification_date = datetime.fromtimestamp(modification_time).date()\n",
    "                    \n",
    "                    # Add it to the rows list\n",
    "                    row_dict = {}\n",
    "                    row_dict['file_path'] = file_path\n",
    "                    row_dict['modification_date'] = modification_date\n",
    "                    rows_list.append(row_dict)\n",
    "soup_df = DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "\n",
    "comparator_path = r'C:\\Program Files (x86)\\Compare It!\\wincmp3.exe'\n",
    "file_paths_list = soup_df.sort_values('modification_date', ascending=False).file_path.tolist()\n",
    "print(len(file_paths_list))\n",
    "subprocess.run([comparator_path, file_paths_list[0], file_paths_list[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup_groupby = soup_df.sort_values('modification_date', ascending=True).groupby('modification_date', group_keys=True)\n",
    "print(soup_groupby.min().head(1).values[0][0])\n",
    "def f(df):\n",
    "    display(df)\n",
    "    \n",
    "    return df\n",
    "_ = soup_groupby.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\ipynb'):\n",
    "    for file_name in files_list:\n",
    "        if (not file_name.endswith('-checkpoint.ipynb')) and ('explor' in file_name.lower()):\n",
    "            print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for root_dir in ['C:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        for file_name in files_list:\n",
    "            if file_name == 'neo4j_job_hunting_export.csv':\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "max_bytes = 0\n",
    "max_file_path = ''\n",
    "black_list = ['$RECYCLE.BIN', '$Recycle.Bin', '.git']\n",
    "for root_dir in [r'D:\\Documents\\GitHub\\job-hunting\\saves\\html']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir, topdown=False):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if file_name.endswith('.html') and 'sphere' in file_name.lower():\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    # file_size = os.path.getsize(file_path)\n",
    "                    print(file_name)\n",
    "                    # if file_size > max_bytes:\n",
    "                    #     max_bytes = file_size\n",
    "                    #     max_file_path = file_path\n",
    "                    #     print(max_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_directories_containing(root_dir=r'C:\\Users\\dev\\anaconda3\\envs', contains_str='activate',\n",
    "                                   black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git']):\n",
    "    dir_path_list = []\n",
    "    if type(root_dir) == list:\n",
    "        root_dir_list = root_dir\n",
    "    else:\n",
    "        root_dir_list = [root_dir]\n",
    "    if type(contains_str) == list:\n",
    "        contains_list = contains_str\n",
    "    else:\n",
    "        contains_list = [contains_str]\n",
    "    for root_dir in root_dir_list:\n",
    "        for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "            if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "                for dir_name in directories_list:\n",
    "                    contains_bool = False\n",
    "                    for contains_str in contains_list:\n",
    "                        contains_bool = contains_bool or (contains_str in dir_name)\n",
    "                    if contains_bool:\n",
    "                        dir_path = os.path.join(sub_directory, dir_name)\n",
    "                        dir_path_list.append(dir_path)\n",
    "    \n",
    "    return dir_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "dirs_list = ['C:\\\\', 'D:\\\\']\n",
    "for file_path in get_all_directories_containing(root_dir=dirs_list, contains_str='minecraft', black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git']):\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for root_dir in [r'D:\\Documents\\GitHub\\MineCraft\\data\\1.18.1_Default_Resource_Pack']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith('.class'):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for root_dir in ['C:\\\\', 'D:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith('xlsx') and (('walk' in file_name.lower()) or ('talk' in file_name.lower())):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import winshell\n",
    "import random\n",
    "\n",
    "# List the original path of all the all items in the recycling bin\n",
    "binned_files_list = list(winshell.recycle_bin())\n",
    "\n",
    "# Determine the index of your file\n",
    "ShellRecycledItem_obj = winshell.ShellRecycledItem.from_path(r'D:\\$RECYCLE.BIN\\S-1-5-21-1161412072-3680630389-113359315-1003\\$RB7DVL4\\data\\txt\\gradient.txt')\n",
    "binned_file_index = binned_files_list.index(ShellRecycledItem_obj)\n",
    "\n",
    "winshell.undelete(binned_files_list[binned_file_index].original_filename())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\html'):\n",
    "    for old_file_name in files_list:\n",
    "        if \"['\" in old_file_name:\n",
    "            old_file_path = os.path.join(sub_directory, old_file_name)\n",
    "            new_file_name = old_file_name.replace(\"['\", '').replace(\"']\", '')\n",
    "            new_file_path = os.path.join(sub_directory, new_file_name)\n",
    "            os.rename(old_file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_all_files_ending_starting_with(\n",
    "    root_dir=[r'C:\\\\'],\n",
    "    ends_with='.exe',\n",
    "    starts_with='speedtest',\n",
    "    black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_all_files_ending_with(\n",
    "    root_dir=[r'C:\\Users\\dev\\Documents\\Repositories'],\n",
    "    ends_with='.bat',\n",
    "    black_list=['$RECYCLE.BIN', '$Recycle.Bin', '.git', 'pkgs'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contains_str = 'job_hunting'\n",
    "file_path_list = get_all_files_containing(root_dir=r'C:\\Users\\dev\\Documents\\Repositories\\rpc\\ps1', contains_str=contains_str)\n",
    "for file_path in file_path_list:\n",
    "    os.rename(file_path, file_path.replace(contains_str, 'rpc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "for key, value in dict(os.environ).items():\n",
    "    if 'dev' in value:\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%windir%\\System32\\cmd.exe \"/K\" C:\\Users\\dev\\anaconda3\\Scripts\\activate.bat C:\\Users\\dev\\anaconda3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "\n",
    "repos_list = [r'C:\\Users\\dev\\Documents\\Repositories\\covid19', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\flask',\n",
    "              r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\pt', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\pymc3',\n",
    "              r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\rpc', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\test',\n",
    "              r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\tf', r'C:\\Users\\dev\\Documents\\Repositories\\notebooks\\x']\n",
    "envs_list = ['covid19', 'flask', 'pt', 'pymc3', 'rpc', 'test', 'tf', 'x']\n",
    "for repo_path, env_name in zip(repos_list, envs_list):\n",
    "    print()\n",
    "    print('-'*len(env_name))\n",
    "    print(env_name)\n",
    "    print('-'*len(env_name))\n",
    "    command_str = f'''\n",
    "cd \"{repo_path}\"\n",
    "conda activate {env_name}\n",
    "conda env export --name {env_name} -f tmp_environment.yml\n",
    "conda deactivate\n",
    "'''\n",
    "    process = subprocess.Popen(r'C:\\Program Files\\PowerShell\\7\\pwsh.exe', stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    std_out, std_err = process.communicate(command_str.encode(encoding='utf-8'))\n",
    "    #print(std_out.decode())\n",
    "    if std_err is not None:\n",
    "        print(std_err.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_pkgs_dict = {}\n",
    "for repo_path, env_name in zip(repos_list, envs_list):\n",
    "    file_path = os.path.join(repo_path, 'tmp_environment.yml')\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines_list = file.read().split('\\n')[5:-2]\n",
    "        pkgs_list = [line_str.split('=')[0].split(' ')[-1] for line_str in lines_list]\n",
    "        env_pkgs_dict[env_name] = set(pkgs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "union_set = set()\n",
    "for env_name, pkgs_set in env_pkgs_dict.items():\n",
    "    union_set = union_set.union(pkgs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intersection_set = union_set.copy()\n",
    "for env_name, pkgs_set in env_pkgs_dict.items():\n",
    "    intersection_set = intersection_set.intersection(pkgs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repo_path = r'C:\\Users\\dev\\Documents\\Repositories\\job-hunting'\n",
    "file_path = os.path.join(repo_path, 'tmp_environment.yml')\n",
    "with open(file_path, 'r') as file:\n",
    "    lines_list = file.read().split('\\n')[5:-2]\n",
    "    pkgs_list = [line_str.split('=')[0].split(' ')[-1] for line_str in lines_list]\n",
    "    pkgs_set = set(pkgs_list)\n",
    "missing_set = intersection_set - pkgs_set\n",
    "for pkg_name in missing_set:\n",
    "    print(f'  - {pkg_name}')\n",
    "print(f'({\"|\".join(missing_set)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_specific_gitignore_files('data-foundations', repository_dir=r'D:\\Documents\\Repositories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "\n",
    "columns_list = jira_df.columns.tolist()\n",
    "[item for item, count in collections.Counter(columns_list).items() if count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = get_column_descriptions(jira_df)\n",
    "mask_series = column_descriptions_df.has_dates & column_descriptions_df.only_integers.isnull()\n",
    "column_descriptions_df[mask_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt_regex = re.compile(r'([\\r\\n]+)    \"import matplotlib\\.pyplot as plt\\\\n\",')\n",
    "notebooks_dir = r'D:\\Documents\\Repositories\\notebooks'\n",
    "stopped = False\n",
    "for sub_directory, directories_list, files_list in os.walk(notebooks_dir):\n",
    "    if stopped:\n",
    "        break\n",
    "    for file_name in files_list:\n",
    "        if stopped:\n",
    "            break\n",
    "        if file_name.endswith('.ipynb'):\n",
    "            file_path = os.path.join(sub_directory, file_name)\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    file_str = f.read()\n",
    "                    if plt_regex.search(file_str):\n",
    "                        print(file_path)\n",
    "                        stopped = True\n",
    "                        break\n",
    "            except UnicodeDecodeError as e:\n",
    "                try:\n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        file_str = f.read().decode('utf-8')\n",
    "                        if plt_regex.search(file_str):\n",
    "                            print(file_path)\n",
    "                except Exception as e:\n",
    "                    message = str(e).strip()\n",
    "                    print()\n",
    "                    print('{} had an error after trying to decode: {}'.format(file_path, message))\n",
    "                    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyperclip\n",
    "\n",
    "pyperclip.copy(str(file_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gi = get_ipython()\n",
    "#print([fn for fn in dir(gi) if not fn.startswith('_')])\n",
    "gi.run_line_magic('who', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remove_empty_folders(folder_path=r'D:\\VirtualBox VMs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "magic_dict_list = magic_dict['test.py']\n",
    "print(len(magic_dict_list))\n",
    "subprocess.run([comparator_path, os.path.abspath(magic_dict_list[0]), os.path.abspath(magic_dict_list[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_specific_gitignore_files('notebooks', repository_dir=r'C:\\Users\\dev\\Documents\\repositories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "for key, value in sys.modules.items():\n",
    "    if 'xdist' in key.lower():\n",
    "        #print('{}: {}'.format(key, value))\n",
    "        print('{}'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
