{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../load_magic/storage.py\n",
    "%run ../load_magic/environment.py\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from scipy.stats import entropy\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import gensim\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "set_matplotlib_formats('retina')\n",
    "notebook_path = get_notebook_path()\n",
    "s = Storage()\n",
    "if s.pickle_exists('BASIC_TAGS_DICT'):\n",
    "    BASIC_TAGS_DICT = s.load_object('BASIC_TAGS_DICT')\n",
    "else:\n",
    "    BASIC_TAGS_DICT = {}\n",
    "    s.store_objects(BASIC_TAGS_DICT=BASIC_TAGS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\ipynb\\Classifier Signatures Exploration.ipynb\n",
      "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.pickle_exists', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']\n",
      "['AdaBoostClassifier', 'BASIC_TAGS_DICT', 'BaggingClassifier', 'Config', 'CountVectorizer', 'ExtraTreesClassifier', 'GradientBoostingClassifier', 'In', 'LogisticRegression', 'Out', 'RandomForestClassifier', 'SVC', 'StackingClassifier', 'Storage', 'TfidfTransformer', 'VotingClassifier', 'csv', 'entropy', 'exit', 'gensim', 'get_all_files_containing', 'get_classifier', 'get_data_structs_dataframe', 'get_datastructure_prediction', 'get_dir_tree', 'get_importances', 'get_input_sample', 'get_ipython', 'get_module_version', 'get_modules_dataframe', 'get_notebook_path', 'get_struct_name', 'inspect', 'ipykernel', 'json', 'jupyter_config_dir', 'notebook_path', 'notebookapp', 'np', 'os', 'pd', 'pickle', 'plt', 'preprocess_data', 'quit', 're', 's', 'set_matplotlib_formats', 'subprocess', 'sys', 'time', 'urllib']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(notebook_path)\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "print([fn for fn in dir() if not fn.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(BASIC_TAGS_DICT.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "params_dict = {}\n",
      "params_dict['AdaBoostClassifier'] = \"\"\"\n",
      "        'clf__base_estimator': (None,),\n",
      "        'clf__n_estimators': (50,),\n",
      "        'clf__learning_rate': (1.0,),\n",
      "        'clf__algorithm': ('SAMME.R',),\n",
      "        'clf__random_state': (None,),\n",
      "\"\"\"\n",
      "params_dict['BaggingClassifier'] = \"\"\"\n",
      "        'clf__base_estimator': (None,),\n",
      "        'clf__n_estimators': (10,),\n",
      "        'clf__max_samples': (1.0,),\n",
      "        'clf__max_features': (1.0,),\n",
      "        'clf__bootstrap': (True,),\n",
      "        'clf__bootstrap_features': (False,),\n",
      "        'clf__oob_score': (False,),\n",
      "        'clf__warm_start': (False,),\n",
      "        'clf__n_jobs': (None,),\n",
      "        'clf__random_state': (None,),\n",
      "        'clf__verbose': (0,),\n",
      "\"\"\"\n",
      "params_dict['ExtraTreesClassifier'] = \"\"\"\n",
      "        'clf__n_estimators': (100,),\n",
      "        'clf__criterion': ('gini',),\n",
      "        'clf__max_depth': (None,),\n",
      "        'clf__min_samples_split': (2,),\n",
      "        'clf__min_samples_leaf': (1,),\n",
      "        'clf__min_weight_fraction_leaf': (0.0,),\n",
      "        'clf__max_features': ('auto',),\n",
      "        'clf__max_leaf_nodes': (None,),\n",
      "        'clf__min_impurity_decrease': (0.0,),\n",
      "        'clf__min_impurity_split': (None,),\n",
      "        'clf__bootstrap': (False,),\n",
      "        'clf__oob_score': (False,),\n",
      "        'clf__n_jobs': (None,),\n",
      "        'clf__random_state': (None,),\n",
      "        'clf__verbose': (0,),\n",
      "        'clf__warm_start': (False,),\n",
      "        'clf__class_weight': (None,),\n",
      "        'clf__ccp_alpha': (0.0,),\n",
      "        'clf__max_samples': (None,),\n",
      "\"\"\"\n",
      "params_dict['GradientBoostingClassifier'] = \"\"\"\n",
      "        'clf__loss': ('deviance',),\n",
      "        'clf__learning_rate': (0.1,),\n",
      "        'clf__n_estimators': (100,),\n",
      "        'clf__subsample': (1.0,),\n",
      "        'clf__criterion': ('friedman_mse',),\n",
      "        'clf__min_samples_split': (2,),\n",
      "        'clf__min_samples_leaf': (1,),\n",
      "        'clf__min_weight_fraction_leaf': (0.0,),\n",
      "        'clf__max_depth': (3,),\n",
      "        'clf__min_impurity_decrease': (0.0,),\n",
      "        'clf__min_impurity_split': (None,),\n",
      "        'clf__init': (None,),\n",
      "        'clf__random_state': (None,),\n",
      "        'clf__max_features': (None,),\n",
      "        'clf__verbose': (0,),\n",
      "        'clf__max_leaf_nodes': (None,),\n",
      "        'clf__warm_start': (False,),\n",
      "        'clf__presort': ('deprecated',),\n",
      "        'clf__validation_fraction': (0.1,),\n",
      "        'clf__n_iter_no_change': (None,),\n",
      "        'clf__tol': (0.0001,),\n",
      "        'clf__ccp_alpha': (0.0,),\n",
      "\"\"\"\n",
      "params_dict['RandomForestClassifier'] = \"\"\"\n",
      "        'clf__n_estimators': (100,),\n",
      "        'clf__criterion': ('gini',),\n",
      "        'clf__max_depth': (None,),\n",
      "        'clf__min_samples_split': (2,),\n",
      "        'clf__min_samples_leaf': (1,),\n",
      "        'clf__min_weight_fraction_leaf': (0.0,),\n",
      "        'clf__max_features': ('auto',),\n",
      "        'clf__max_leaf_nodes': (None,),\n",
      "        'clf__min_impurity_decrease': (0.0,),\n",
      "        'clf__min_impurity_split': (None,),\n",
      "        'clf__bootstrap': (True,),\n",
      "        'clf__oob_score': (False,),\n",
      "        'clf__n_jobs': (None,),\n",
      "        'clf__random_state': (None,),\n",
      "        'clf__verbose': (0,),\n",
      "        'clf__warm_start': (False,),\n",
      "        'clf__class_weight': (None,),\n",
      "        'clf__ccp_alpha': (0.0,),\n",
      "        'clf__max_samples': (None,),\n",
      "\"\"\"\n",
      "params_dict['LogisticRegression'] = \"\"\"\n",
      "        'clf__penalty': ('l2',),\n",
      "        'clf__dual': (False,),\n",
      "        'clf__tol': (0.0001,),\n",
      "        'clf__C': (1.0,),\n",
      "        'clf__fit_intercept': (True,),\n",
      "        'clf__intercept_scaling': (1,),\n",
      "        'clf__class_weight': (None,),\n",
      "        'clf__random_state': (None,),\n",
      "        'clf__solver': ('lbfgs',),\n",
      "        'clf__max_iter': (100,),\n",
      "        'clf__multi_class': ('auto',),\n",
      "        'clf__verbose': (0,),\n",
      "        'clf__warm_start': (False,),\n",
      "        'clf__n_jobs': (None,),\n",
      "        'clf__l1_ratio': (None,),\n",
      "\"\"\"\n",
      "params_dict['SVC'] = \"\"\"\n",
      "        'clf__C': (1.0,),\n",
      "        'clf__kernel': ('rbf',),\n",
      "        'clf__degree': (3,),\n",
      "        'clf__gamma': ('scale',),\n",
      "        'clf__coef0': (0.0,),\n",
      "        'clf__shrinking': (True,),\n",
      "        'clf__probability': (False,),\n",
      "        'clf__tol': (0.001,),\n",
      "        'clf__cache_size': (200,),\n",
      "        'clf__class_weight': (None,),\n",
      "        'clf__verbose': (False,),\n",
      "        'clf__max_iter': (-1,),\n",
      "        'clf__decision_function_shape': ('ovr',),\n",
      "        'clf__break_ties': (False,),\n",
      "        'clf__random_state': (None,),\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from inspect import signature\n",
    "\n",
    "estimators_list = ['AdaBoostClassifier',\n",
    "                   'BaggingClassifier',\n",
    "                   'ExtraTreesClassifier',\n",
    "                   'GradientBoostingClassifier',\n",
    "                   'RandomForestClassifier',\n",
    "                   'LogisticRegression',\n",
    "                   'SVC']\n",
    "print()\n",
    "print('params_dict = {}')\n",
    "for estimator in estimators_list:\n",
    "    sig_eval_str = f'signature({estimator})'\n",
    "    try:\n",
    "        sig = eval(sig_eval_str)\n",
    "        params_dict = sig.parameters\n",
    "        print(f'params_dict[\\'{estimator}\\'] = \"\"\"')\n",
    "        for key, value in params_dict.items():\n",
    "            print(f\"\"\"        'clf__{key}': ({str(value).split('=')[1]},),\"\"\")\n",
    "        print('\"\"\"')\n",
    "    except Exception as e:\n",
    "        print(f'The evaluated list {sig_eval_str} gets this error: {str(e).strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "Pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sadfsad():\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadfsad'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_params_dict = {}\n",
    "clf_params_dict['AdaBoostClassifier'] = \"\"\"\n",
    "        'clf__base_estimator': (None,),\n",
    "        'clf__n_estimators': (50,),\n",
    "        'clf__learning_rate': (1.0,),\n",
    "        'clf__algorithm': ('SAMME.R',),\n",
    "        'clf__random_state': (None,),\"\"\"\n",
    "clf_params_dict['BaggingClassifier'] = \"\"\"\n",
    "        'clf__base_estimator': (None,),\n",
    "        'clf__n_estimators': (10,),\n",
    "        'clf__max_samples': (1.0,),\n",
    "        'clf__max_features': (1.0,),\n",
    "        'clf__bootstrap': (True,),\n",
    "        'clf__bootstrap_features': (False,),\n",
    "        'clf__oob_score': (False,),\n",
    "        'clf__warm_start': (False,),\n",
    "        'clf__n_jobs': (None,),\n",
    "        'clf__random_state': (None,),\n",
    "        'clf__verbose': (0,),\"\"\"\n",
    "clf_params_dict['ExtraTreesClassifier'] = \"\"\"\n",
    "        'clf__n_estimators': (100,),\n",
    "        'clf__criterion': ('gini',),\n",
    "        'clf__max_depth': (None,),\n",
    "        'clf__min_samples_split': (2,),\n",
    "        'clf__min_samples_leaf': (1,),\n",
    "        'clf__min_weight_fraction_leaf': (0.0,),\n",
    "        'clf__max_features': ('auto',),\n",
    "        'clf__max_leaf_nodes': (None,),\n",
    "        'clf__min_impurity_decrease': (0.0,),\n",
    "        'clf__min_impurity_split': (None,),\n",
    "        'clf__bootstrap': (False,),\n",
    "        'clf__oob_score': (False,),\n",
    "        'clf__n_jobs': (None,),\n",
    "        'clf__random_state': (None,),\n",
    "        'clf__verbose': (0,),\n",
    "        'clf__warm_start': (False,),\n",
    "        'clf__class_weight': (None,),\n",
    "        'clf__ccp_alpha': (0.0,),\n",
    "        'clf__max_samples': (None,),\"\"\"\n",
    "clf_params_dict['GradientBoostingClassifier'] = \"\"\"\n",
    "        'clf__loss': ('deviance',),\n",
    "        'clf__learning_rate': (0.1,),\n",
    "        'clf__n_estimators': (100,),\n",
    "        'clf__subsample': (1.0,),\n",
    "        'clf__criterion': ('friedman_mse',),\n",
    "        'clf__min_samples_split': (2,),\n",
    "        'clf__min_samples_leaf': (1,),\n",
    "        'clf__min_weight_fraction_leaf': (0.0,),\n",
    "        'clf__max_depth': (3,),\n",
    "        'clf__min_impurity_decrease': (0.0,),\n",
    "        'clf__min_impurity_split': (None,),\n",
    "        'clf__init': (None,),\n",
    "        'clf__random_state': (None,),\n",
    "        'clf__max_features': (None,),\n",
    "        'clf__verbose': (0,),\n",
    "        'clf__max_leaf_nodes': (None,),\n",
    "        'clf__warm_start': (False,),\n",
    "        'clf__presort': ('deprecated',),\n",
    "        'clf__validation_fraction': (0.1,),\n",
    "        'clf__n_iter_no_change': (None,),\n",
    "        'clf__tol': (0.0001,),\n",
    "        'clf__ccp_alpha': (0.0,),\"\"\"\n",
    "clf_params_dict['RandomForestClassifier'] = \"\"\"\n",
    "        'clf__n_estimators': (100,),\n",
    "        'clf__criterion': ('gini',),\n",
    "        'clf__max_depth': (None,),\n",
    "        'clf__min_samples_split': (2,),\n",
    "        'clf__min_samples_leaf': (1,),\n",
    "        'clf__min_weight_fraction_leaf': (0.0,),\n",
    "        'clf__max_features': ('auto',),\n",
    "        'clf__max_leaf_nodes': (None,),\n",
    "        'clf__min_impurity_decrease': (0.0,),\n",
    "        'clf__min_impurity_split': (None,),\n",
    "        'clf__bootstrap': (True,),\n",
    "        'clf__oob_score': (False,),\n",
    "        'clf__n_jobs': (None,),\n",
    "        'clf__random_state': (None,),\n",
    "        'clf__verbose': (0,),\n",
    "        'clf__warm_start': (False,),\n",
    "        'clf__class_weight': (None,),\n",
    "        'clf__ccp_alpha': (0.0,),\n",
    "        'clf__max_samples': (None,),\"\"\"\n",
    "clf_params_dict['LogisticRegression'] = \"\"\"\n",
    "        'clf__penalty': ('l2',),\n",
    "        'clf__dual': (False,),\n",
    "        'clf__tol': (0.0001,),\n",
    "        'clf__C': (1.0,),\n",
    "        'clf__fit_intercept': (True,),\n",
    "        'clf__intercept_scaling': (1,),\n",
    "        'clf__class_weight': (None,),\n",
    "        'clf__random_state': (None,),\n",
    "        'clf__solver': ('lbfgs',),\n",
    "        'clf__max_iter': (100,),\n",
    "        'clf__multi_class': ('auto',),\n",
    "        'clf__verbose': (0,),\n",
    "        'clf__warm_start': (False,),\n",
    "        'clf__n_jobs': (None,),\n",
    "        'clf__l1_ratio': (None,),\"\"\"\n",
    "clf_params_dict['SVC'] = \"\"\"\n",
    "        'clf__C': (1.0,),\n",
    "        'clf__kernel': ('rbf',),\n",
    "        'clf__degree': (3,),\n",
    "        'clf__gamma': ('scale',),\n",
    "        'clf__coef0': (0.0,),\n",
    "        'clf__shrinking': (True,),\n",
    "        'clf__probability': (False,),\n",
    "        'clf__tol': (0.001,),\n",
    "        'clf__cache_size': (200,),\n",
    "        'clf__class_weight': (None,),\n",
    "        'clf__verbose': (False,),\n",
    "        'clf__max_iter': (-1,),\n",
    "        'clf__decision_function_shape': ('ovr',),\n",
    "        'clf__break_ties': (False,),\n",
    "        'clf__random_state': (None,),\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__algorithm': ('SAMME.R',),\n",
      " 'clf__base_estimator': (None,),\n",
      " 'clf__learning_rate': (1.0,),\n",
      " 'clf__n_estimators': (50,),\n",
      " 'clf__random_state': (None,),\n",
      " 'tfidf__norm': ('l1',),\n",
      " 'tfidf__smooth_idf': (True,),\n",
      " 'tfidf__sublinear_tf': (False,),\n",
      " 'tfidf__use_idf': (True,),\n",
      " 'vect__analyzer': ('word',),\n",
      " 'vect__binary': (False,),\n",
      " 'vect__decode_error': ('strict',),\n",
      " 'vect__lowercase': (False,),\n",
      " 'vect__max_df': (1.0,),\n",
      " 'vect__max_features': (None,),\n",
      " 'vect__min_df': (0.0,),\n",
      " 'vect__ngram_range': ((1, 5),),\n",
      " 'vect__stop_words': (None,),\n",
      " 'vect__strip_accents': ('ascii',),\n",
      " 'vect__tokenizer': (<function regex_tokenizer at 0x0000011E45FF5820>,)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "estimators_list = [AdaBoostClassifier(),\n",
    "                   BaggingClassifier(),\n",
    "                   ExtraTreesClassifier(),\n",
    "                   GradientBoostingClassifier(),\n",
    "                   RandomForestClassifier(),\n",
    "                   LogisticRegression(),\n",
    "                   SVC()]\n",
    "for estimator in estimators_list:\n",
    "    clf_name = str(estimator.__class__).split('.')[-1].split(\"'\")[0]\n",
    "    params_dict = eval(f'{{{clf_params_dict[clf_name]}}}')\n",
    "    params_dict.update({\n",
    "        'tfidf__norm': ('l1',),\n",
    "        'tfidf__smooth_idf': (True,),\n",
    "        'tfidf__sublinear_tf': (False,),\n",
    "        'tfidf__use_idf': (True,),\n",
    "        'vect__analyzer': ('word',),\n",
    "        'vect__binary': (False,),\n",
    "        'vect__decode_error': ('strict',),\n",
    "        'vect__lowercase': (False,),\n",
    "        'vect__max_df': (1.0,),\n",
    "        'vect__max_features': (None,),\n",
    "        'vect__min_df': (0.0,),\n",
    "        'vect__ngram_range': ((1, 5),),\n",
    "        'vect__stop_words': (None,),\n",
    "        'vect__strip_accents': ('ascii',),\n",
    "        'vect__tokenizer': (regex_tokenizer,),\n",
    "    })\n",
    "    pprint(params_dict)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoostClassifier'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[f'estimator.__class__.{fn}' for fn in dir(estimator.__class__) if 'name' in fn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcompact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort_dicts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m Pretty-print a Python object to a stream [default is sys.stdout].\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\dev\\anaconda3\\envs\\jh\\lib\\pprint.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pprint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.9.0)",
   "language": "python",
   "name": "jh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
