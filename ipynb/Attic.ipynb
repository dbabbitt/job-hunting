{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9570e-ff06-431c-8717-ea814001a6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "3631e18b-c492-4d36-a200-7853f280aaa3",
   "metadata": {},
   "source": [
    "\n",
    "file_path = '../data/html/indeed_email.html'\n",
    "page_soup = wsu.get_page_soup(file_path)\n",
    "css_selector = 'table > tbody > tr > td > a > table > tbody > tr > td > a'\n",
    "link_soups_list = page_soup.select(css_selector)\n",
    "display(len(link_soups_list))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed2ae1b1-4e4e-49c2-abbe-448adbdf8825",
   "metadata": {},
   "source": [
    "\n",
    "page_soup = wsu.get_page_soup(file_path)\n",
    "css_selector = 'table > tbody > tr > td > a > table > tbody > tr > td > a'\n",
    "link_soups_list = page_soup.select(css_selector)\n",
    "\n",
    "# Get rid of the duplicate URLs\n",
    "url_strs_set = set()\n",
    "for link_soup in link_soups_list:\n",
    "    url_str = link_soup['href']\n",
    "    url_strs_set.add(url_str)\n",
    "\n",
    "display(len(url_strs_set))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a7a3892-7553-42da-a99b-e122258fecbc",
   "metadata": {},
   "source": [
    "\n",
    "file_path = os.path.abspath(os.path.expanduser(r'~\\OneDrive\\Documents\\GitHub\\job-hunting\\scrapers\\../py\\section_classifier_utils.py'))\n",
    "command_str = fr'\"C:\\Program Files\\Notepad++\\notepad++.exe\" {file_path}'\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8d7494-5552-438f-8dec-ea25a74666c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mtextwrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minitial_indent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubsequent_indent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexpand_tabs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mreplace_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfix_sentence_endings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbreak_long_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdrop_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbreak_on_hyphens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtabsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mplaceholder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' [...]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Object for wrapping/filling text.  The public interface consists of\n",
       "the wrap() and fill() methods; the other methods are just there for\n",
       "subclasses to override in order to tweak the default behaviour.\n",
       "If you want to completely replace the main wrapping algorithm,\n",
       "you'll probably have to override _wrap_chunks().\n",
       "\n",
       "Several instance attributes control various aspects of wrapping:\n",
       "  width (default: 70)\n",
       "    the maximum width of wrapped lines (unless break_long_words\n",
       "    is false)\n",
       "  initial_indent (default: \"\")\n",
       "    string that will be prepended to the first line of wrapped\n",
       "    output.  Counts towards the line's width.\n",
       "  subsequent_indent (default: \"\")\n",
       "    string that will be prepended to all lines save the first\n",
       "    of wrapped output; also counts towards each line's width.\n",
       "  expand_tabs (default: true)\n",
       "    Expand tabs in input text to spaces before further processing.\n",
       "    Each tab will become 0 .. 'tabsize' spaces, depending on its position\n",
       "    in its line.  If false, each tab is treated as a single character.\n",
       "  tabsize (default: 8)\n",
       "    Expand tabs in input text to 0 .. 'tabsize' spaces, unless\n",
       "    'expand_tabs' is false.\n",
       "  replace_whitespace (default: true)\n",
       "    Replace all whitespace characters in the input text by spaces\n",
       "    after tab expansion.  Note that if expand_tabs is false and\n",
       "    replace_whitespace is true, every tab will be converted to a\n",
       "    single space!\n",
       "  fix_sentence_endings (default: false)\n",
       "    Ensure that sentence-ending punctuation is always followed\n",
       "    by two spaces.  Off by default because the algorithm is\n",
       "    (unavoidably) imperfect.\n",
       "  break_long_words (default: true)\n",
       "    Break words longer than 'width'.  If false, those words will not\n",
       "    be broken, and some lines might be longer than 'width'.\n",
       "  break_on_hyphens (default: true)\n",
       "    Allow breaking hyphenated words. If true, wrapping will occur\n",
       "    preferably on whitespaces and right after hyphens part of\n",
       "    compound words.\n",
       "  drop_whitespace (default: true)\n",
       "    Drop leading and trailing whitespace from lines.\n",
       "  max_lines (default: None)\n",
       "    Truncate wrapped lines.\n",
       "  placeholder (default: ' [...]')\n",
       "    Append to the last line of truncated text.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\daveb\\onedrive\\documents\\github\\job-hunting\\jh_env\\lib\\textwrap.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import textwrap\n",
    "\n",
    "textwrap.TextWrapper?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37033465-790f-464e-ba75-1462f0b4d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualize the clusters in a scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=new_sequence, cmap='viridis')\n",
    "plt.title('Document Cluster Analysis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "integer_to_string_map = {v: k for k, v in string_to_integer_map.items()}\n",
    "plt.legend(*scatter.legend_elements(), title='Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bbbd254-16d5-4f50-9315-ee09ba39799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wikipedia_url = 'https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3'\n",
    "page_soup = nu.get_page_soup(wikipedia_url, verbose=False)\n",
    "\n",
    "# <div class=\"div-col\" style=\"column-width: 20em;\">\n",
    "div_soups_list = page_soup.find_all('div', attrs={'class': 'div-col'})\n",
    "li_soups_list = div_soups_list[0].find_all('li')\n",
    "alpha3_to_country_dict = {}\n",
    "country_to_alpha3_dict = {}\n",
    "for li_soup in li_soups_list:\n",
    "    for span_soup in li_soup.find_all('span', attrs={'class': 'monospaced'}):\n",
    "        tla = span_soup.text\n",
    "    for a_soup in li_soup.find_all('a', attrs={'title': True}):\n",
    "        country = a_soup.text\n",
    "    alpha3_to_country_dict[tla] = country\n",
    "    country_to_alpha3_dict[country] = tla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a6e3fe-d2c6-4ac2-aa36-3fb338308077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03854b7e-276c-44dd-a9d4-55ca50bb4fec",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8528c715-7ed7-48de-8675-3f35973ff7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170bffd6-f9e9-4aa2-b6bc-13cfb693fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the Storage object\n",
    "from storage import Storage\n",
    "s = Storage(\n",
    "    data_folder_path=os.path.abspath('../data'),\n",
    "    saves_folder_path=os.path.abspath('../saves')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882f3b8f-defb-445f-a7a7-73010c04d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all our file names data\n",
    "import pandas as pd\n",
    "\n",
    "# Get the HeaderAnalysis object\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "# Get the WebScrapingUtilities object\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(\n",
    "    s=s,\n",
    "    secrets_json_path=os.path.abspath('../data/secrets/jh_secrets.json')\n",
    ")\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "# Get the CypherUtilities object and Neo4j driver\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(\n",
    "    uri=uri, user=user, password=password, driver=None, s=s, ha=ha\n",
    ")\n",
    "\n",
    "cypher_str = '''\n",
    "    MATCH (fn:FileNames)\n",
    "    RETURN fn;'''\n",
    "row_objs_list = cu.get_execution_results(cypher_str, verbose=False)\n",
    "hunting_df = pd.DataFrame(\n",
    "    [{k: v for k, v in row_obj['fn'].items()} for row_obj in row_objs_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebcf1e05-ea1d-4e77-8db1-960d219fd762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\csv\\hunting_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.save_dataframes(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5387dd1-7da4-45f4-9732-a8dad97cc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the databased quals\n",
    "cypher_str = '''\n",
    "    MATCH (qs:QualificationStrings)\n",
    "    RETURN qs;'''\n",
    "row_objs_list = cu.get_execution_results(cypher_str, verbose=False)\n",
    "basic_quals_df = pd.DataFrame(\n",
    "    [{k: v for k, v in row_obj['qs'].items()} for row_obj in row_objs_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d4be2d-8e87-4a6f-bb55-ee8585295f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\csv\\basic_quals_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.save_dataframes(basic_quals_df=basic_quals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850af3b-8e34-4295-8549-6ac35f75defc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
