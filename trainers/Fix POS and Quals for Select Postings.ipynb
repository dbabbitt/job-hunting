{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7675b025-b593-4d53-9759-6c1e01772c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e9a76f-08eb-4a9c-9c53-4bf043e26661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee342571-b35a-4688-850c-8aad13befcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(s=s)\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7dd43f-2080-40e0-84a3-f9a7fdd934dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Neo4j/4.4.7 ========\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "try:\n",
    "    version_str = cu.driver.verify_connectivity()\n",
    "    print(f'======== {version_str} ========')\n",
    "    \n",
    "    from hc_utils import HeaderCategories\n",
    "    hc = HeaderCategories(cu=cu, verbose=False)\n",
    "    \n",
    "    from section_utils import SectionUtilities\n",
    "    su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "    \n",
    "    from lr_utils import LrUtilities\n",
    "    lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "    \n",
    "    from crf_utils import CrfUtilities\n",
    "    crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except ServiceUnavailable as e:\n",
    "    # print(str(e).strip())\n",
    "    raise ServiceUnavailable('You need to start Neo4j as a console')\n",
    "except Exception as e:\n",
    "    print(e.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2c759f-11f4-4bf8-bc61-35c4b4d1c31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2022-12-22 06:10:13.477234\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import humanize\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "from datetime import datetime\n",
    "import winsound\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d85a2e-5f1b-4cbe-a2df-944f8bf19523",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "51e3644d-7c49-46d0-9af8-e559dff89a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is-header classifier retrained in 14 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Is-header must be retrained before parts-of-speech\n",
    "t0 = time.time()\n",
    "lru.build_isheader_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_isheader_classifier(verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Is-header classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bf51ee4a-d5bd-4354-9ca6-be20dabf65b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts-of-speech classifier retrained in 9 minutes and 57 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "lru.build_pos_logistic_regression_elements(verbose=False)\n",
    "crf.retrain_pos_classifier(verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Parts-of-speech classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ccd80ea2-341e-4672-b810-f4c500ab8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 6,755 hand-labeled qualification strings in here\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_VOCAB.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_TT.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_LR.pkl\n",
      "Retraining complete\n",
      "Is-qualified classifer retrained in 17 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rebuild the classifer from the quals dictionary\n",
    "t0 = time.time()\n",
    "lru.build_isqualified_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "82dab229-b28c-4ddd-812d-6abf153aae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 0 more mis-estimated minimum-requirements-met percentages to go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "navigable_parent_cypher_str = '''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{}'}})\n",
    "    ''' + cu.return_everything_str + ';'\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit < 0.4 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_verified IS NULL) OR (fn.is_verified = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR\n",
    "        (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name,\n",
    "        fn.posting_url AS url\n",
    "    ORDER BY fn.percent_fit ASC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "print(f'Only {len(files_list)} more mis-estimated minimum-requirements-met percentages to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2f3ec-44ee-4be3-b13e-02badca41da4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cdf71-a078-43b6-9a1b-649bb51461e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_name = '6cd512fc61cd4572_Data_Scientist_II_JR14367_Remote_Indeed_com.html'\n",
    "file_name = files_list.pop()\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "page_soup = wsu.get_page_soup(file_path)\n",
    "div_soup = page_soup.find_all(name='div', id='jobDescriptionText')[0]\n",
    "child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "cu.ensure_filename(file_name, verbose=False)\n",
    "cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcd0c5-e0ac-431d-bacd-b22a7b5ed4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32ce35-6670-4523-9d03-015542cb3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 8, 10, 11, 14, 16, 17, 20, 21, 23, 25, 26, 27, 29, 30, 31, 33]\n",
      "34 O-JD) <p>Job Type: Contract</p>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 34\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end=''); print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3f1b210b-8651-4291-8c80-046a9c896392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<p>· Proficiency in French</p>\" in basic_quals_dict: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5bb3f749-0a02-4266-876d-08983725feb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<p>· Proficiency in French</p>', 'is_header': 'False', 'is_task_scope': 'False', 'is_qualification': None, 'is_minimum_qualification': 'False', 'is_preferred_qualification': 'True', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'False', 'is_interview_procedure': 'False', 'is_corporate_scope': 'False', 'is_posting_date': 'False', 'is_other': 'False'}]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = \"\"\"MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = 'False',\n",
    "            np.is_task_scope = 'False',\n",
    "            np.is_minimum_qualification = 'False',\n",
    "            np.is_preferred_qualification = 'True',\n",
    "            np.is_educational_requirement = 'False',\n",
    "            np.is_legal_notification = 'False',\n",
    "            np.is_other = 'False',\n",
    "            np.is_corporate_scope = 'False',\n",
    "            np.is_job_title = 'False',\n",
    "            np.is_office_location = 'False',\n",
    "            np.is_job_duration = 'False',\n",
    "            np.is_supplemental_pay = 'False',\n",
    "            np.is_interview_procedure = 'False',\n",
    "            np.is_posting_date = 'False'\n",
    "        \"\"\" + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28836b66-b8d4-48cb-92a0-f28efbb39c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "# print(navigable_parent_cypher_str.format(child_str))\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, navigable_parent_cypher_str.format(child_str))\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<p>REQS: This position requires a Bachelor’s degree or foreign equivalent in Computer Science, Computer Engineering or a related field, plus 3 years of experience programming, database management, stakeholder management and automation. In the alternative the business will accept a Master’s degree or foreign equivalent in Computer Science, Computer Engineering or a related field, plus 1 year of experience programming, database management, stakeholder management and automation. Per 20 CFR 656.17(h)(4), any suitable combination of education, training, or experience is acceptable. Additionally, the applicant must have professional experience with: (1) SQL and Python or R with Data Science libraries; (2) Designing, developing, deploying, and maintaining production grade data processing and deep learning code, pipelines, and systems; (3) Jupyter notebooks to perform analytics over the data and set up automated jobs; (4) Developing dashboards and reports to share compelling storytelling through visualizations using popular BI tools; (5) Build reliable end-to-end processes and solutions with high quality data and deliver within defined timelines; (6) Data governance with a focus on securing member’s sensitive data; and (7) Agile and Scrum development methodologies. Apply below.</p>\" in basic_quals_dict: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b08e-874a-41db-a163-2232b9c7cc55",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f00b97db-00ab-4ab9-8a22-323bbb5c6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        MATCH (fn:FileNames {file_name: \"a94e3fa2025128cf_Software_Engineer_in_Test_CRM_Columbus_OH_Indeed_com.html\"})\n",
      "        SET fn.is_verified = true\n",
      "        RETURN fn;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node id=863352 labels=frozenset({'FileNames'}) properties={'file_name': 'a94e3fa2025128cf_Software_Engineer_in_Test_CRM_Columbus_OH_Indeed_com.html', 'percent_fit': 0.36363636363636365, 'posting_url': 'https://www.indeed.com/rc/clk/dl?jk=a94e3fa2025128cf&from=ja&qd=RnZhMybXSk4M3QtTVGXWofXa_863hzyu1-CtxUSUXCcNCNEz7KLainVVZ7JoYzAcGwjDVmfDSoD32LE0RBTwwtaQk5RWMtRgfLybHd1LhLQ&rd=xe_ZA5EbIC2o4Q49301XSK0iUsIn_91tuBORm3KY9sQ&tk=1gl3cr9nigsb9800&alid=62cdb0067c78606171e5793c', 'is_verified': True}>}]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# You've made no changes to the qualification dictionary (regardless of parts-of-speech changes)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.is_verified = true\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    parameter_dict = {'file_name': file_name}\n",
    "    results_list = tx.run(query=cypher_str, parameters=parameter_dict)\n",
    "    values_list = []\n",
    "    for record in results_list:\n",
    "        values_list.append(dict(record.items()))\n",
    "\n",
    "    return values_list\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=True)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "dbe5ce2c-5c8c-4196-96de-ee38953e10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\hunting_df.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node id=863475 labels=frozenset({'FileNames'}) properties={'file_name': '68a357a8af300ddf_Senior_Quality_Engineer_Remote_Indeed_com.html', 'posting_url': 'https://www.indeed.com/rc/clk/dl?jk=68a357a8af300ddf&from=ja&qd=RnZhMybXSk4M3QtTVGXWofXa_863hzyu1-CtxUSUXCer4QObmh059jWilV-osXec1bBSoXu6CplwtwiHyweFgZzKmO0WBwBi3k9clySDizI&rd=v1-HcdjGhgpDNCskhCHpOQbXCHXgJEVMrHKBS2mW9rM&tk=1glb766h1gsb9800&alid=62cdb0067c78606171e5793c', 'is_verified': False}>}]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Mark the file name as needing retraining everywhere\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# file_name = '6b754ceaefd0a1f3_Lead_Data_Engineer_Brooklyn_NY_11201_Indeed_com.html'\n",
    "mask_series = lru.hunting_df.percent_fit.isin([file_name])\n",
    "lru.hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=lru.hunting_df)\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.percent_fit = NULL, fn.is_verified = false\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    results_list = tx.run(query=cypher_str, parameters={'file_name': file_name})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8adbd-5b7c-43d8-8680-aea4da63a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the file name as closed\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_closed = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9664-96e1-43cb-8de7-99e40d5524f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[13]\n",
    "print(qualification_str)\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4a2c62-661a-4652-b743-efa5e336ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "# file_name = '3c031ea6ad293e92_General_Service_Technician_Westborough_MA_01581_Indeed_com.html'\n",
    "cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe3a9a-8b2b-4bfc-b348-ce01a188c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
