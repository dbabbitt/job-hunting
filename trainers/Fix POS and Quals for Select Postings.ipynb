{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7675b025-b593-4d53-9759-6c1e01772c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3ad81-7ac1-4a85-ba90-62ccbde24f49",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1febade-58e7-47f1-8c6d-5447b5737d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 14 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "from jobpostlib import (duration, freq, t0, nu, hau, wsu, cu, ihu, hc, lru, slrcu, ssgdcu, scrfcu, crf, su, time, humanize, winsound)\n",
    "from os import path as osp\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b062dfbb-7833-4809-9fea-565ae14a865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "Parts-of-speech conditional random field elements built in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parts-of-speech CRF elements built in 28 minutes and 51 seconds\n",
    "t1 = time.time()\n",
    "if not (hasattr(scrfcu, 'pos_symbol_crf') or crf.is_flask_running()):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    print('predict_single is now available')\n",
    "else:\n",
    "    print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Parts-of-speech conditional random field elements built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b60aeb5-2919-449b-aec2-f115c2d94c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,102 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech stochastic gradient decent elements built in 17 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parts-of-speech stochastic gradient decent elements built in 17 seconds\n",
    "t1 = time.time()\n",
    "if not (hasattr(ssgdcu, 'pos_predict_percent_fit_dict') or crf.is_flask_running()):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    print('predict_single is now available')\n",
    "else:\n",
    "    print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Parts-of-speech stochastic gradient decent elements built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b92034-a498-4e1f-b4f9-a37038c4f432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS classifier trained in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the crf has built its parts-of-speech classifier\n",
    "# POS classifier trained in 12 hours, 15 minutes and 36 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(crf, 'CRF'):\n",
    "    if nu.pickle_exists('crf_CRF'):\n",
    "        crf.CRF = nu.load_object('crf_CRF')\n",
    "    else:\n",
    "        crf.retrain_pos_classifier(header_pattern_dict=nu.load_object('HEADER_PATTERN_DICT'), verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'POS classifier trained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86510da3-4df5-4f7e-93c2-e0534789cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,102 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech logistic regression elements built in 13 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parts-of-speech logistic regression elements built in 1 hour, 59 minutes and 41 seconds\n",
    "t1 = time.time()\n",
    "if not (hasattr(slrcu, 'pos_predict_percent_fit_dict') or crf.is_flask_running()):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    print('predict_single is now available')\n",
    "else:\n",
    "    print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Parts-of-speech logistic regression elements built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7075bbf4-e2ca-44e0-9516-81da82548dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is-qualified LR classifier built in 9 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Is-qualified LR classifier built in 5 seconds\n",
    "t1 = time.time()\n",
    "lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=5_000, verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified LR classifier built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60978370-e643-4d47-96ad-f8893714bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,856 hand-labeled header htmls prepared\n",
      "7 iterations seen during training fit for a total of 49,856 records trained\n",
      "Is-header SGD classifer built in 9 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Is-header SGD classifer built in 9 seconds\n",
    "t1 = time.time()\n",
    "ihu.build_pos_stochastic_gradient_descent_elements(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-header SGD classifer built in {duration_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c479f-c162-454d-b4a0-cccb123c567f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e57ef681-27d5-4610-8496-ff1d30b09c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 14,583 hand-labeled qualification strings in here\n",
      "I have 484,937 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 2 minutes and 3 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=8_000, verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82dab229-b28c-4ddd-812d-6abf153aae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 0 more mis-estimated minimum-requirements-met percentages to go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit = 0.0 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_verified IS NULL) OR (fn.is_verified = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR\n",
    "        (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name,\n",
    "        fn.posting_url AS url\n",
    "    ORDER BY fn.percent_fit ASC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "print(f'Only {len(files_list)} more mis-estimated minimum-requirements-met percentages to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c47ac4b-65a9-456a-a77f-77654fe158e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 0 more minimum-requirements-met percentages to confirm!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        (fn.percent_fit >= 0.8) AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_verified IS NULL) OR (fn.is_verified = false)) AND\n",
    "        (\n",
    "            (fn.is_opportunity_application_emailed IS NULL) OR\n",
    "            (fn.is_opportunity_application_emailed = false)\n",
    "        )\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name,\n",
    "        fn.posting_url AS posting_url\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "print(f'Only {len(files_list)} more minimum-requirements-met percentages to confirm!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed91ef-2d2e-46c9-be8b-f6458185fad8",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix POS and Quals for a job posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "151cdf71-a078-43b6-9a1b-649bb51461e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 2\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[43mfiles_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cu\u001b[38;5;241m.\u001b[39mSAVES_HTML_FOLDER, file_name)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file_path):\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "file_name = files_list.pop()\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if os.path.isfile(file_path):\n",
    "    child_strs_list = hau.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    child_tags_list = hau.get_child_tags_list(child_strs_list)\n",
    "    feature_dict_list = cu.get_feature_dict_list(child_tags_list, child_strs_list)\n",
    "    feature_tuple_list = []\n",
    "    for feature_dict in feature_dict_list:\n",
    "        feature_tuple_list.append(hc.get_feature_tuple(\n",
    "            feature_dict, pos_lr_predict_single=slrcu.predict_single, pos_crf_predict_single=scrfcu.predict_single,\n",
    "            pos_sgd_predict_single=ssgdcu.predict_single\n",
    "        ))\n",
    "    crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "    print(file_name)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'CRF and child strings list recreated in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e8afe8b-e9cc-4dca-866e-88cf37461f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-IP', 'O-IP', 'H-IP', 'O-IP', 'O-IP', 'O-IP', 'O-IP', 'O-IP', 'O-IP', 'O-IP', 'O-IP', 'O-IP', 'O-IP', 'H-JD', 'O-SP', 'H-JD', 'O-SP', 'O-IP', 'O-OL', 'O-OL', 'O-IP', 'H-SP', 'O-IP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'H-O', 'O-O', 'O-IP', 'H-O', 'H-JT', 'H-JT', 'O-JD', 'O-JD', 'O-JD', 'O-JD', 'O-CS', 'H-TS', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'O-RQ', 'H-PQ', 'O-RQ', 'H-RQ', 'O-RQ', 'H-TS', 'O-JT', 'O-JT', 'O-OL', 'H-SP', 'O-SP', 'H-SP', 'H-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-IP', 'O-IP', 'O-IP', 'O-LN', 'O-IP', 'O-IP']\n",
      "[59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 77]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-IP) <span style=\"color:#ffbb78ff;\"><h2 class=\"js-match-insights-provider-14dlqhn e1tiznh50\">Profile insights (H-IP Interview Procedures Header)</h2></span><br />1 O-IP) <span style=\"color:#ffbb7880;\"><span>Find out how your skills align with the job description (O-IP Interview Procedures Non-header)</span></span><br />2 H-IP) <span style=\"color:#ffbb78ff;\"><h3 class=\"js-match-insights-provider-11n8e9a e1tiznh50\">Skills (H-IP Interview Procedures Header)</h3></span><br />3 O-IP) <span style=\"color:#ffbb7880;\">Do you have experience in (O-IP Interview Procedures Non-header)</span><br />4 O-IP) <span style=\"color:#ffbb7880;\"><b>TensorFlow (O-IP Interview Procedures Non-header)</b></span><br />5 O-IP) <span style=\"color:#ffbb7880;\">? (O-IP Interview Procedures Non-header)</span><br />6 O-IP) <span style=\"color:#ffbb7880;\"><span>Yes (O-IP Interview Procedures Non-header)</span></span><br />7 O-IP) <span style=\"color:#ffbb7880;\"><span>No (O-IP Interview Procedures Non-header)</span></span><br />8 O-IP) <span style=\"color:#ffbb7880;\"><span>&amp;nbsp; (O-IP Interview Procedures Non-header)</span></span><br />9 O-IP) <span style=\"color:#ffbb7880;\"><h2 class=\"js-match-insights-provider-14dlqhn e1tiznh50\">Job details (O-IP Interview Procedures Non-header)</h2></span><br />10 O-IP) <span style=\"color:#ffbb7880;\">Here’s how the job details align with your (O-IP Interview Procedures Non-header)</span><br />11 O-IP) <span style=\"color:#ffbb7880;\"><a aria-label=\"job preferences (opens in a new window)\" class=\"js-match-insights-provider-1cr09u7 e19afand0\" href=\"https://profile.indeed.com/\" rel=\"noopener\" target=\"_blank\">profile (O-IP Interview Procedures Non-header)</a></span><br />12 O-IP) <span style=\"color:#ffbb7880;\">. (O-IP Interview Procedures Non-header)</span><br />13 H-JD) <span style=\"color:#98df8aff;\"><h3 class=\"js-match-insights-provider-11n8e9a e1tiznh50\">Job type (H-JD Job Duration Header)</h3></span><br />14 O-SP) <span style=\"color:#17becf80;\"><div class=\"js-match-insights-provider-tvvxwd ecydgvn1\">Full-time (O-SP Supplemental Pay Non-header)</div></span><br />15 H-JD) <span style=\"color:#98df8aff;\"><h3 class=\"js-match-insights-provider-11n8e9a e1tiznh50\">Shift and schedule (H-JD Job Duration Header)</h3></span><br />16 O-SP) <span style=\"color:#17becf80;\"><div class=\"js-match-insights-provider-tvvxwd ecydgvn1\">Monday to Friday (O-SP Supplemental Pay Non-header)</div></span><br />17 O-IP) <span style=\"color:#ffbb7880;\"><span>&amp;nbsp; (O-IP Interview Procedures Non-header)</span></span><br />18 O-OL) <span style=\"color:#c49c9480;\"><h2 class=\"css-1yytfzy e1tiznh50\" id=\"jobLocationSectionTitle\">Location (O-OL Office Location Non-header)</h2></span><br />19 O-OL) <span style=\"color:#c49c9480;\"><span>Remote (O-OL Office Location Non-header)</span></span><br />20 O-IP) <span style=\"color:#ffbb7880;\"><span>&amp;nbsp; (O-IP Interview Procedures Non-header)</span></span><br />21 H-SP) <span style=\"color:#17becfff;\">Benefits (H-SP Supplemental Pay Header)</span><br />22 O-IP) <span style=\"color:#ffbb7880;\"><div class=\"css-1opnqdm e1wnkr790\">Pulled from the full job description (O-IP Interview Procedures Non-header)</div></span><br />23 O-SP) <span style=\"color:#17becf80;\"><li class=\"css-kyg8or eu4oa1w0\">401(k) matching (O-SP Supplemental Pay Non-header)</li></span><br />24 O-SP) <span style=\"color:#17becf80;\"><li class=\"css-kyg8or eu4oa1w0\">AD&amp;D insurance (O-SP Supplemental Pay Non-header)</li></span><br />25 O-SP) <span style=\"color:#17becf80;\"><li class=\"css-kyg8or eu4oa1w0\">Cell phone reimbursement (O-SP Supplemental Pay Non-header)</li></span><br />26 O-SP) <span style=\"color:#17becf80;\"><li class=\"css-kyg8or eu4oa1w0\">Dental insurance (O-SP Supplemental Pay Non-header)</li></span><br />27 O-SP) <span style=\"color:#17becf80;\"><li class=\"css-kyg8or eu4oa1w0\">Disability insurance (O-SP Supplemental Pay Non-header)</li></span><br />28 O-SP) <span style=\"color:#17becf80;\"><li class=\"css-kyg8or eu4oa1w0\">Employee assistance program (O-SP Supplemental Pay Non-header)</li></span><br />29 O-SP) <span style=\"color:#17becf80;\"><li class=\"css-kyg8or eu4oa1w0\">Flexible spending account (O-SP Supplemental Pay Non-header)</li></span><br />30 H-O) <span style=\"color:#8c564bff;\"><span class=\"css-1ysvuef e1wnkr790\">Show more (H-O Other Header)</span></span><br />31 O-O) <span style=\"color:#8c564b80;\"><title>chevron down (O-O Other Non-header)</title></span><br />32 O-IP) <span style=\"color:#ffbb7880;\"><span>&amp;nbsp; (O-IP Interview Procedures Non-header)</span></span><br />33 H-O) <span style=\"color:#8c564bff;\"><h2 class=\"css-wpzt8u e1tiznh50\" id=\"jobDescriptionTitleHeading\" tabindex=\"-1\">Full job description (H-O Other Header)</h2></span><br />34 H-JT) <span style=\"color:#d62728ff;\"><b>Position: (H-JT Job Title Header)</b></span><br />35 H-JT) <span style=\"color:#d62728ff;\">Data Scientist II (H-JT Job Title Header)</span><br />36 O-JD) <span style=\"color:#98df8a80;\"><b>Hours of Work: (O-JD Job Duration Non-header)</b></span><br />37 O-JD) <span style=\"color:#98df8a80;\"><b>Monday through Friday: (O-JD Job Duration Non-header)</b></span><br />38 O-JD) <span style=\"color:#98df8a80;\">8:30AM-5:00PM (O-JD Job Duration Non-header)</span><br />39 O-JD) <span style=\"color:#98df8a80;\">Full-time, Exempt (O-JD Job Duration Non-header)</span><br />40 O-CS) <span style=\"color:#1f77b480;\">To the extent permitted by law, the Company may, in its sole discretion, change the work schedule to address business needs. Work hours will depend on the business hours of the time zone serviced. (O-CS Corporate Scope Non-header)</span><br />41 H-TS) <span style=\"color:#9edae5ff;\">In This Role, You Will… (H-TS Task Scope Header)</span><br />42 O-TS) <span style=\"color:#9edae580;\">Work within the Risk Management department utilizing data science to improve business results and reduce risk. Collaborate with data scientists and other teams by performing controlled experiments, including A/B testing, model building, and monitoring. Independently contribute to a wide range of data science projects, taking ownership while expanding data exploration skills and increasing data knowledge. Organize data reports and communicate findings to technical and non-technical audiences. (O-TS Task Scope Non-header)</span><br />43 H-TS) <span style=\"color:#9edae5ff;\"><b>Responsibilities and Essential Duties: (H-TS Task Scope Header)</b></span><br />44 O-TS) <span style=\"color:#9edae580;\"><li>Use modeling/statistical techniques, data processing skills, and tools such as SQL, Python, AWS, and SAS to develop and maintain credit and collection risk, pricing, fraud models, and analytical strategies that will optimize business decisions across channels. (O-TS Task Scope Non-header)</li></span><br />45 O-TS) <span style=\"color:#9edae580;\"><li>Design and implement A/B tests to evaluate the effectiveness of different strategies and features. Analyze test data to derive actionable insights and recommendations for business improvements. (O-TS Task Scope Non-header)</li></span><br />46 O-TS) <span style=\"color:#9edae580;\"><li>Maintain up-to-date model inventory and chronology of model prediction via visualization tools such as PBI. (O-TS Task Scope Non-header)</li></span><br />47 O-TS) <span style=\"color:#9edae580;\"><li>Develop and maintain systems to monitor the performance of predictive models. Identify performance degradation and recalibrate models as necessary to ensure accuracy and reliability. (O-TS Task Scope Non-header)</li></span><br />48 O-TS) <span style=\"color:#9edae580;\"><li>Support the business by conducting ad hoc portfolio analyses and developing recommendations aimed at improving portfolio performance and profitability. (O-TS Task Scope Non-header)</li></span><br />49 O-TS) <span style=\"color:#9edae580;\"><li>Collaborate with partners across the organization in cross-functional projects to execute on key business priorities. (O-TS Task Scope Non-header)</li></span><br />50 O-TS) <span style=\"color:#9edae580;\"><li>Organize data reports and communicate findings to technical and non-technical audiences. (O-TS Task Scope Non-header)</li></span><br />51 O-TS) <span style=\"color:#9edae580;\"><li>Work closely with internal teams to integrate machine learning models into production systems. Provide technical guidance on the use of AWS services for machine learning applications. (O-TS Task Scope Non-header)</li></span><br />52 O-TS) <span style=\"color:#9edae580;\"><li>Conduct evaluation of tools in AWS ML end-to-end pipeline environment. (O-TS Task Scope Non-header)</li></span><br />53 O-TS) <span style=\"color:#9edae580;\"><li>Assist in the development and deployment of machine learning models, including data preprocessing, feature engineering, model training, and evaluation. Ensure models are scalable, efficient, and integrated seamlessly into our AWS environment. (O-TS Task Scope Non-header)</li></span><br />54 O-TS) <span style=\"color:#9edae580;\"><li>Conduct evaluation of new statistical approaches and enhanced segmentation to optimize approval and advance assignment strategies. (O-TS Task Scope Non-header)</li></span><br />55 O-TS) <span style=\"color:#9edae580;\"><li>Study new data sources for additional lift to business decisions. Provide recommendations as to cost/benefit analyses of new data sources. (O-TS Task Scope Non-header)</li></span><br />56 O-TS) <span style=\"color:#9edae580;\"><li>Stay abreast of the latest trends and developments in machine learning and financial technologies. Propose and prototype new models or algorithms to address business challenges. Evaluate, recommend, and champion new modeling data, tools, techniques, and approaches. (O-TS Task Scope Non-header)</li></span><br />57 O-TS) <span style=\"color:#9edae580;\"><li>May perform additional functions depending on market demand and staffing in order to provide consistent quality customer service. (O-TS Task Scope Non-header)</li></span><br />58 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Required Qualifications: (H-RQ Required Qualifications Header)</b></span><br /><hr />59 O-RQ) <span style=\"color:#bcbd2280;\"><li>Undergraduate or a postgraduate degree in Mathematics, Statistics, Computer Science, Economics, Data Science, or a related field. (O-RQ Required Qualifications Non-header)</li></span><br />60 O-RQ) <span style=\"color:#bcbd2280;\"><li>At least three (3) years of experience in Data Science with a focus on A/B testing, model tracking, and ML engineering. (O-RQ Required Qualifications Non-header)</li></span><br />61 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong experience in programming languages such as SQL, Python. (O-RQ Required Qualifications Non-header)</li></span><br />62 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience with AWS cloud services, especially those related to machine learning (e.g., S3, EC2, Lambda, SageMaker). (O-RQ Required Qualifications Non-header)</li></span><br />63 O-RQ) <span style=\"color:#bcbd2280;\"><li>Working knowledge of machine learning frameworks (e.g., TensorFlow, PyTorch) and libraries (e.g., scikit-learn, Pandas). (O-RQ Required Qualifications Non-header)</li></span><br />64 O-RQ) <span style=\"color:#bcbd2280;\"><li>Advanced abilities to handle large datasets. (O-RQ Required Qualifications Non-header)</li></span><br />65 O-RQ) <span style=\"color:#bcbd2280;\"><li>Results-oriented individual with the ability to translate plans into actions. (O-RQ Required Qualifications Non-header)</li></span><br />66 O-RQ) <span style=\"color:#bcbd2280;\"><li>Ability to work in a fast-paced environment; ability to multi-task, change direction, effectively prioritize, and meet deadlines with both local and remote staff. (O-RQ Required Qualifications Non-header)</li></span><br />67 O-PQ) <span style=\"color:#c7c7c780;\"><li>Excellent interpersonal skills necessary to communicate professionally and effectively, verbally and in writing, with vendors, service dealers, customers, and all levels of company staff. (O-PQ Preferred Qualifications Non-header)</li></span><br />68 O-RQ) <span style=\"color:#bcbd2280;\"><li>Proficiency in Microsoft Office Suite. (O-RQ Required Qualifications Non-header)</li></span><br />69 O-RQ) <span style=\"color:#bcbd2280;\"><li>Highly-motivated self-starter with strong work ethic, exceptional attention to detail, and ability to support multiple initiatives simultaneously. (O-RQ Required Qualifications Non-header)</li></span><br />70 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong analytical, problem-solving, and organizational skills. (O-RQ Required Qualifications Non-header)</li></span><br />71 O-RQ) <span style=\"color:#bcbd2280;\"><li>Ability to work with minimal supervision and to independently determine tasks to complete on a daily basis. (O-RQ Required Qualifications Non-header)</li></span><br />72 O-PQ) <span style=\"color:#c7c7c780;\"><li>Demonstrate a strong commitment to continuous learning, actively seeking out opportunities to acquire new skills and stay abreast of industry trends. (O-PQ Preferred Qualifications Non-header)</li></span><br />73 O-RQ) <span style=\"color:#bcbd2280;\"><li>Ability to work both independently and collaboratively with teams across and at all levels of the organization. (O-RQ Required Qualifications Non-header)</li></span><br />74 H-PQ) <span style=\"color:#c7c7c7ff;\"><b>Preferred Qualifications: (H-PQ Preferred Qualifications Header)</b></span><br />75 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience in consumer lending/financial services. (O-RQ Required Qualifications Non-header)</li></span><br />76 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Physical Demands: (H-RQ Required Qualifications Header)</b></span><br />77 O-RQ) <span style=\"color:#bcbd2280;\">While performing the duties of this job, the employee is frequently required to sit for extended periods; reach with hands and arms; and talk or hear. The employee is occasionally required to move about. The employee must occasionally lift and/or move up to twenty (20) pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus. (O-RQ Required Qualifications Non-header)</span><br /><hr />78 H-TS) <span style=\"color:#9edae5ff;\">This job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee. Duties, responsibilities, and activities may change or new ones may be assigned at any time or without notice. (H-TS Task Scope Header)</span><br />79 O-JT) <span style=\"color:#d6272880;\">IND3 (O-JT Job Title Non-header)</span><br />80 O-JT) <span style=\"color:#d6272880;\">#LI-JA2 (O-JT Job Title Non-header)</span><br />81 O-OL) <span style=\"color:#c49c9480;\">LI-Remote (O-OL Office Location Non-header)</span><br />82 H-SP) <span style=\"color:#17becfff;\"><b>Compensation: (H-SP Supplemental Pay Header)</b></span><br />83 O-SP) <span style=\"color:#17becf80;\">$105,000-135,000+ Bonus (O-SP Supplemental Pay Non-header)</span><br />84 H-SP) <span style=\"color:#17becfff;\"><b>Benefits: (H-SP Supplemental Pay Header)</b></span><br />85 H-SP) <span style=\"color:#17becfff;\">Mariner Finance offers comprehensive benefits to eligible employees, including: (H-SP Supplemental Pay Header)</span><br />86 O-SP) <span style=\"color:#17becf80;\"><li>Health Insurance - Health Savings Account (HSA) with employer contributions if enrolled in a qualifying plan, Flexible Spending Account (FSA), and Dependent Care FSA (O-SP Supplemental Pay Non-header)</li></span><br />87 O-SP) <span style=\"color:#17becf80;\"><li>Vision Insurance (O-SP Supplemental Pay Non-header)</li></span><br />88 O-SP) <span style=\"color:#17becf80;\"><li>Dental Insurance (O-SP Supplemental Pay Non-header)</li></span><br />89 O-SP) <span style=\"color:#17becf80;\"><li>Company-paid Basic Life, Long-Term Disability, and AD&amp;D Insurance (O-SP Supplemental Pay Non-header)</li></span><br />90 O-SP) <span style=\"color:#17becf80;\"><li>Voluntary worksite benefits including Accident, Critical Illness, Hospital Indemnity, Short-Term Disability, Supplemental Life, and Supplemental AD&amp;D Insurance (O-SP Supplemental Pay Non-header)</li></span><br />91 O-SP) <span style=\"color:#17becf80;\"><li>401(k) and Company Matching Contributions (O-SP Supplemental Pay Non-header)</li></span><br />92 O-SP) <span style=\"color:#17becf80;\"><li>Paid Time Off - full-time employees may accrue a minimum of 120 hours per year (O-SP Supplemental Pay Non-header)</li></span><br />93 O-SP) <span style=\"color:#17becf80;\"><li>11 Paid Holidays (O-SP Supplemental Pay Non-header)</li></span><br />94 O-SP) <span style=\"color:#17becf80;\"><li>FMLA (O-SP Supplemental Pay Non-header)</li></span><br />95 O-SP) <span style=\"color:#17becf80;\"><li>Employee Assistance Program (EAP) (O-SP Supplemental Pay Non-header)</li></span><br />96 O-SP) <span style=\"color:#17becf80;\"><li>Paid Parental Leave (O-SP Supplemental Pay Non-header)</li></span><br />97 O-SP) <span style=\"color:#17becf80;\"><li>Referral Incentives (O-SP Supplemental Pay Non-header)</li></span><br />98 O-SP) <span style=\"color:#17becf80;\"><li>Education Assistance Program (O-SP Supplemental Pay Non-header)</li></span><br />99 O-SP) <span style=\"color:#17becf80;\"><li>Complimentary FIMC Membership Plan (O-SP Supplemental Pay Non-header)</li></span><br />100 O-SP) <span style=\"color:#17becf80;\"><li>Access to industry-specific training programs (O-SP Supplemental Pay Non-header)</li></span><br />101 O-SP) <span style=\"color:#17becf80;\"><li>Certain roles may qualify for additional benefits such as Relocation Assistance, Debt Assistance, Cell Phone Reimbursement, and Travel/Auto Reimbursement. Contact careers@marinerfinance.com for additional information. (O-SP Supplemental Pay Non-header)</li></span><br />102 O-IP) <span style=\"color:#ffbb7880;\">Benefits provided are consistent with applicable state laws and Company policies. Eligibility may vary based on full-time or part-time status, location, or management level. (O-IP Interview Procedures Non-header)</span><br />103 O-IP) <span style=\"color:#ffbb7880;\"><b>For additional information, please visit: (O-IP Interview Procedures Non-header)</b></span><br />104 O-IP) <span style=\"color:#ffbb7880;\">https://www.marinerfinance.com/careers/benefits/ (O-IP Interview Procedures Non-header)</span><br />105 O-LN) <span style=\"color:#9467bd80;\">Mariner Finance is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion, creed, sex, gender, gender identity or expression, marital status, age, religion, national origin, sexual orientation, familial or caregiver status, citizenship status, status as a victim of domestic violence, medical condition, genetic information, pregnancy, physical or mental disability, or status as a disabled or Vietnam era veteran. Employee must be able to perform the essential duties/functions of the position satisfactorily and, if requested, reasonable accommodations will be made to enable employees with disabilities to perform the essential duties/functions of their job, absent undue hardship. Drug/Alcohol/Smoke-free workplace. (O-LN Legal Notifications Non-header)</span><br />106 O-IP) <span style=\"color:#ffbb7880;\">Mariner Finance, LLC | NMLS #166564 (O-IP Interview Procedures Non-header)</span><br />107 O-IP) <span style=\"color:#ffbb7880;\"><span>&amp;nbsp; (O-IP Interview Procedures Non-header)</span></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 77]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91379a3d-1a77-4d8b-9ef6-a76f12204ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26c4dd4e-1418-4420-aff5-ea7b65273194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 H-RQ) <b>Required Qualifications:</b>\n",
      "1\n",
      "59 O-RQ) <li>Undergraduate or a postgraduate degree in Mathematics, Statistics, Computer Science, Economics, Data Science, or a related field.</li>\n",
      "60 O-RQ) <li>At least three (3) years of experience in Data Science with a focus on A/B testing, model tracking, and ML engineering.</li>\n",
      "1\n",
      "61 O-RQ) <li>Strong experience in programming languages such as SQL, Python.</li>\n",
      "62 O-RQ) <li>Experience with AWS cloud services, especially those related to machine learning (e.g., S3, EC2, Lambda, SageMaker).</li>\n",
      "63 O-RQ) <li>Working knowledge of machine learning frameworks (e.g., TensorFlow, PyTorch) and libraries (e.g., scikit-learn, Pandas).</li>\n",
      "1\n",
      "64 O-RQ) <li>Advanced abilities to handle large datasets.</li>\n",
      "1\n",
      "65 O-RQ) <li>Results-oriented individual with the ability to translate plans into actions.</li>\n",
      "1\n",
      "66 O-RQ) <li>Ability to work in a fast-paced environment; ability to multi-task, change direction, effectively prioritize, and meet deadlines with both local and remote staff.</li>\n",
      "67 O-PQ) <li>Excellent interpersonal skills necessary to communicate professionally and effectively, verbally and in writing, with vendors, service dealers, customers, and all levels of company staff.</li>\n",
      "1\n",
      "68 O-RQ) <li>Proficiency in Microsoft Office Suite.</li>\n",
      "69 O-RQ) <li>Highly-motivated self-starter with strong work ethic, exceptional attention to detail, and ability to support multiple initiatives simultaneously.</li>\n",
      "1\n",
      "70 O-RQ) <li>Strong analytical, problem-solving, and organizational skills.</li>\n",
      "1\n",
      "71 O-RQ) <li>Ability to work with minimal supervision and to independently determine tasks to complete on a daily basis.</li>\n",
      "72 O-PQ) <li>Demonstrate a strong commitment to continuous learning, actively seeking out opportunities to acquire new skills and stay abreast of industry trends.</li>\n",
      "73 O-RQ) <li>Ability to work both independently and collaboratively with teams across and at all levels of the organization.</li>\n",
      "76 H-RQ) <b>Physical Demands:</b>\n",
      "77 O-RQ) While performing the duties of this job, the employee is frequently required to sit for extended periods; reach with hands and arms; and talk or hear. The employee is occasionally required to move about. The employee must occasionally lift and/or move up to twenty (20) pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict'); column_name = 'is_minimum_qualification'\n",
    "for idx in list(range(58, 74)) + list(range(76, 78)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\n",
    "            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                np.is_educational_requirement = {str(column_name == 'is_educational_requirement').lower()},\n",
    "                np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 77]\n",
      "77 O-RQ) While performing the duties of this job, the employee is frequently required to sit for extended periods; reach with hands and arms; and talk or hear. The employee is occasionally required to move about. The employee must occasionally lift and/or move up to twenty (20) pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 77\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end=''); print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f1b210b-8651-4291-8c80-046a9c896392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"While performing the duties of this job, the employee is frequently required to sit for extended periods; reach with hands and arms; and talk or hear. The employee is occasionally required to move about. The employee must occasionally lift and/or move up to twenty (20) pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b08e-874a-41db-a163-2232b9c7cc55",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dbe5ce2c-5c8c-4196-96de-ee38953e10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\hunting_df.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node element_id='1006088' labels=frozenset({'FileNames'}) properties={'file_name': 'Data_Scientist_II_Remote_Indeed_com.html', 'posting_url': 'https://www.indeed.com/pagead/clk/dl?mo=r&ad=-6NYlbfkN0CRXJaX_ETJGlwN1sk8fjXo5yVXRvSeounu7t0bSIDpPtRyf9H7S5sByoi2jQ_0fiPvAWntulR0LmDy-Xg99bgMzdM7vjX7z2wUOGVcbckTanAEPHtlpW0EHlxxWyMHD_gQQcW0yrrv9YkqSt5OzkF9AwO5ocrAcO9Yslr0DzST3-PewVYSFWC59AutsQYwhD-kJZYd_2HsVgi-YKa2NnamR1PPp2sWw17ExQnYpicbrSwFA_YbIGQo7d196ogHDtl4v6UT36LORsf5lIy26gT-wZRnLMz2vyzH01yAHLDHI60GDz4ta9_eI0OHFOwtl0EToLKyMdxtMlvMb_rVbLVH7DLU4xjecRO8YF5DA0gWUKekGd5DA8bvhnaWZPcZrgvF4dIoMdOhtcPJAGC3vMxqv8rWN4QdiFcnNWW_iFSWf_rn6AZL-9Mi9MHeJ5U6_jFCxg6U_F_TExgaJWzfaBJnkzmqK-L7-KMzyKxkky6B9BTaAkcd0quJ5ZTQBtoB4C2u3tINWfI_wekgskmZs-TE3u2N4UshDDIn4gsIQ0V71qjKMqg5BeB0XuwFVMiwxgVl_Rur2oekfpMduLOwbhf-knaOoSXReIuB3YOTtOct--tuHd9f0KcdHHd73eMRObIuJFVWg-y2ZFUcm4FTOIZuKl-lj6G9GK-NKFSXDmKLWk6YRcchQyZsCZ1tF7s57sjMvVF8uKFIjr3CwOVX5Z7DIZORDDYdTYW4NjADZW0vCfCwDw0XWyZY4bivACkNle1em5inCN3H1kMMzIFocOH5-_2ch1PkdqBQ4hOSdhXuU6hsy839b96X&xkcb=SoDn6_M3CckHGCao0p0KbzkdCdPP&camk=f416UQcMBpClRT5aetmX9A%3D%3D&p=0&jsa=1734&rjs=1&tmtk=1hqsm24e7rb9e800&gdfvj=1&alid=63b02dca1ef86228dd5d5128&fvj=1&g1tAS=true', 'is_verified': True}>}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Mark the file name as needing retraining everywhere\n",
    "# file_name = 'b4e994e1d282ffa9_Digital_Platform_Services_Data_Analytics_and_Insights_Senior_Manager_Salt_Lake_City_UT_84111_Indeed_com.html'\n",
    "mask_series = lru.hunting_df.file_name.isin([file_name])\n",
    "lru.hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "nu.store_objects(hunting_df=lru.hunting_df)\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.percent_fit = NULL, fn.is_verified = true\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    results_list = tx.run(query=cypher_str, parameters={'file_name': file_name})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "feaaa3cc-128f-41f7-aceb-c762e5cd6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix preferred quals\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in list(range(58, 74)) + list(range(76, 78)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\n",
    "            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    if re.search(r'\\b(nice(er)?|a plus|advantageous|preferred|beneficial)\\b', child_str):\n",
    "        print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "        print(f'{idx} {pos_symbol}) {child_str}')\n",
    "        def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "            cypher_str = f'''\n",
    "                MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "                SET\n",
    "                    np.is_minimum_qualification = false,\n",
    "                    np.is_preferred_qualification = true\n",
    "                ''' + cu.return_everything_str + ';'\n",
    "            return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "        with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac6471bc-633a-467c-9ddc-cc0eafa25260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 H-TS) <p>Required Qualifications:</p>\n",
      "49 O-TS) <p>Skills and Abilities:</p>\n",
      "61 H-TS) <p>Experience:</p>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [40, 49, 61]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = true\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c966e64-2a0f-42c7-b926-ad14ead1187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "75 H-RQ) <div>\n",
      "     Education: Master’s degree in Statistics, Data Science, Data Analytics, Health Informatics, or related field of study\n",
      "   </div>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [75]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = false\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4064f03-a727-4d74-8e75-0514749f39e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                MATCH\n",
      "                    (np:NavigableParents {navigable_parent: \"is proud to be an equal opportunity workplace and is an affirmative action employer. We invite you to join us and feel the VIBES: https://vibronyx.com/about/\"}),\n",
      "                    (ht:HeaderTags {header_tag: \"plaintext\"})\n",
      "                MERGE (ht)-[r:SUMMARIZES]->(np);\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Ensure you have already displayed the context of an individual child string above\n",
    "# Don't close the Notepad++ window until you have replaced the child string\n",
    "def display_file_in_text_editor(file_name):\n",
    "    text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "    file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "    !\"{text_editor_path}\" \"{file_path}\"\n",
    "display_file_in_text_editor(file_name)\n",
    "cu.rebuild_filename_node(file_name, navigable_parent=None, verbose=True)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4157faba-d33d-45b7-afd6-1017ceec1902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<i>at least 5-7 years’ experience as a site </i>\" in basic_quals_dict: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary and database\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str, None)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e979caf-dc09-4193-a40d-411bb1f91935",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb3f749-0a02-4266-876d-08983725feb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iterations seen during updating fit for a total of 49,070 records trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<p>Selected candidate will be subject to a pre-employment background investigation and must be able to obtain and maintain a Secret level DoD security clearance.</p>', 'is_header': False, 'is_task_scope': False, 'is_minimum_qualification': True, 'is_preferred_qualification': False, 'is_legal_notification': False, 'is_job_title': False, 'is_office_location': False, 'is_job_duration': False, 'is_supplemental_pay': False, 'is_educational_requirement': False, 'is_interview_procedure': False, 'is_corporate_scope': False, 'is_posting_date': False, 'is_other': False}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = \"\"\"MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = false,\n",
    "            np.is_task_scope = false,\n",
    "            np.is_minimum_qualification = true,\n",
    "            np.is_preferred_qualification = false,\n",
    "            np.is_educational_requirement = false,\n",
    "            np.is_legal_notification = false,\n",
    "            np.is_other = false,\n",
    "            np.is_corporate_scope = false,\n",
    "            np.is_job_title = false,\n",
    "            np.is_office_location = false,\n",
    "            np.is_job_duration = false,\n",
    "            np.is_supplemental_pay = false,\n",
    "            np.is_interview_procedure = false,\n",
    "            np.is_posting_date = false\n",
    "        \"\"\" + cu.return_everything_str + ';'\n",
    "    return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=True)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28836b66-b8d4-48cb-92a0-f28efbb39c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<b>Who makes a DatOps Engineer?</b>', 'is_header': None, 'is_task_scope': None, 'is_minimum_qualification': None, 'is_preferred_qualification': None, 'is_legal_notification': None, 'is_job_title': None, 'is_office_location': None, 'is_job_duration': None, 'is_supplemental_pay': None, 'is_educational_requirement': None, 'is_interview_procedure': None, 'is_corporate_scope': None, 'is_posting_date': None, 'is_other': None}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f549b31a-da3c-4114-b015-e30ab12f172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qualification_str</th>\n",
       "      <th>is_qualified</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>&lt;li&gt;Hadoop and Machine Learning&lt;/li&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>&lt;p&gt;· Experience with API testing&lt;/p&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>&lt;orq&gt;3 - MySQL (P3 - Advanced)&lt;/orq&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>&lt;li&gt;An understanding of rating.&lt;/li&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>&lt;orq&gt;1 - MySQL (P1 - Beginner)&lt;/orq&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qualification_str  is_qualified  length\n",
       "1353  <li>Hadoop and Machine Learning</li>             0      36\n",
       "1573  <p>· Experience with API testing</p>             0      36\n",
       "4903  <orq>3 - MySQL (P3 - Advanced)</orq>             0      36\n",
       "2823  <li>An understanding of rating.</li>             0      36\n",
       "6492  <orq>1 - MySQL (P1 - Beginner)</orq>             1      36"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=8_000, verbose=False)\n",
    "df = lru.basic_quals_df.copy()\n",
    "df['length'] = df['qualification_str'].apply(len)\n",
    "df = df.sort_values('length')\n",
    "df.to_csv('../saves/csv/basic_quals_dict.csv')\n",
    "df.head(1000).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<orq>Ability to nice to have).</orq>\" in basic_quals_dict: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove the child string by idx from the quals dictionary and database\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "child_str = df.loc[13195].qualification_str\n",
    "basic_quals_dict.pop(child_str, None)\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b97db-00ab-4ab9-8a22-323bbb5c6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You've made no changes to the qualification dictionary (regardless of parts-of-speech changes)\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.is_verified = true\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    parameter_dict = {'file_name': file_name}\n",
    "    results_list = tx.run(query=cypher_str, parameters=parameter_dict)\n",
    "    values_list = []\n",
    "    for record in results_list:\n",
    "        values_list.append(dict(record.items()))\n",
    "\n",
    "    return values_list\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=True)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8adbd-5b7c-43d8-8680-aea4da63a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the file name as closed\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_closed = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9664-96e1-43cb-8de7-99e40d5524f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[13]\n",
    "print(qualification_str)\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4a2c62-661a-4652-b743-efa5e336ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "# file_name = '3c031ea6ad293e92_General_Service_Technician_Westborough_MA_01581_Indeed_com.html'\n",
    "cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aef40b-f090-4b8d-9cab-afb370407893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix the unhashable mess you made\n",
    "lru.basic_quals_df = lru.basic_quals_df.iloc[:-2]\n",
    "nu.store_objects(basic_quals_df=lru.basic_quals_df)\n",
    "lru.basic_quals_dict = lru.basic_quals_df.set_index(\n",
    "    'qualification_str'\n",
    ").is_qualified.to_dict()\n",
    "lru.nu.store_objects(basic_quals_dict=lru.basic_quals_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1033e0-944b-4770-b820-a4e6a3644e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix the unhashable mess you made\n",
    "def do_cypher_tx(tx, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings)\n",
    "        WHERE NOT qs.is_qualified IN [0, 1]\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, verbose=False)\n",
    "cypher_str = '''\n",
    "    MATCH (qs:QualificationStrings)\n",
    "    RETURN qs;'''\n",
    "row_objs_list = cu.get_execution_results(cypher_str, verbose=False)\n",
    "DataFrame(\n",
    "    [{k: v for k, v in row_obj['qs'].items()} for row_obj in row_objs_list]\n",
    ").tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646f71a-405a-44d9-aebd-18e70c97f08a",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Take a badly written requirements section and see if you can programmatically parse the qualification string out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb796bf8-0976-4f29-b731-ab41a311f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_adjacent(split_strs_list):\n",
    "    combined_list = []\n",
    "    for i, s in enumerate(split_strs_list):\n",
    "        if i == 0:\n",
    "            combined_list.append(s)\n",
    "        elif combined_list[-1].lower().endswith(' and'):\n",
    "            combined_list[-1] = combined_list[-1] + ' ' + s\n",
    "        else:\n",
    "            combined_list.append(s)\n",
    "    \n",
    "    return combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee1b865-e430-4859-8589-3a9b6a3af89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split O-RQs DataFrame built in 2 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Break the long HTML string into sentences and check if each is a qualification string\n",
    "t1 = time.time()\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "import re\n",
    "\n",
    "fake_stops_list = ['e.g.', 'etc.', 'M.nu.', 'B.nu.', 'Ph.D.', '(ex.', '(Ex.',\n",
    "                   'U.nu.', 'i.e.', '&amp;', 'E.g.', 'Bsc.', 'MSc.', 'incl.']\n",
    "replacements_list = ['eg', 'etc', 'MS', 'BS', 'PhD', '(eg', '(eg', 'US',\n",
    "                     'ie', '&', 'eg', 'BS', 'MS', 'include']\n",
    "text_splitter = SpacyTextSplitter()\n",
    "tag_regex = re.compile('<([a-z][a-z0-9]*)[^<>]*>')\n",
    "rows_list = []\n",
    "unhtml_str = re.sub('</?[^><]+>', '', child_str)\n",
    "for fake_stop, replacement in zip(fake_stops_list, replacements_list):\n",
    "    unhtml_str = unhtml_str.replace(fake_stop, replacement)\n",
    "split_strs_list = combine_adjacent([str(split_str) for split_str in text_splitter._tokenizer(unhtml_str).sents])\n",
    "for split_str in split_strs_list:\n",
    "    row_dict = {}\n",
    "    split_str = re.sub(r'\\s*[:;.*]+\\s*$', '', split_str)\n",
    "    row_dict['split_str'] = split_str\n",
    "    row_dict['char_count'] = len(split_str)\n",
    "    match_obj = tag_regex.search(child_str)\n",
    "    if match_obj:\n",
    "        tag_name = match_obj.group()\n",
    "        split_str = f'<{tag_name}>{split_str}</{tag_name}>'\n",
    "    else:\n",
    "        tag_name = 'plaintext'\n",
    "    row_dict['tag_name'] = tag_name\n",
    "    score = 1.0\n",
    "    score *= slrcu.pos_predict_percent_fit_dict['O-RQ'](split_str)\n",
    "    score *= scrfcu.pos_predict_percent_fit_dict['O-RQ'](split_str)\n",
    "    score *= ssgdcu.pos_predict_percent_fit_dict['O-RQ'](split_str)\n",
    "    row_dict['orq_score'] = score\n",
    "    score = 1.0\n",
    "    score *= slrcu.pos_predict_percent_fit_dict['O-PQ'](split_str)\n",
    "    score *= scrfcu.pos_predict_percent_fit_dict['O-PQ'](split_str)\n",
    "    score *= ssgdcu.pos_predict_percent_fit_dict['O-PQ'](split_str)\n",
    "    row_dict['opq_score'] = score\n",
    "    rows_list.append(row_dict)\n",
    "split_orqs_df = DataFrame(rows_list)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Split O-RQs DataFrame built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cebf9223-1670-472a-b245-6e0930fb2ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_str</th>\n",
       "      <th>char_count</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>orq_score</th>\n",
       "      <th>opq_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3-5 years of experience in data science and da...</td>\n",
       "      <td>78</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.818604e-01</td>\n",
       "      <td>1.237190e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Experience using AI/ML python libraries –PyTor...</td>\n",
       "      <td>259</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.729124e-01</td>\n",
       "      <td>1.369416e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Experience working with MLOps infrastructure s...</td>\n",
       "      <td>128</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.484962e-01</td>\n",
       "      <td>1.842955e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Proficient in Python programming</td>\n",
       "      <td>32</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>2.616722e-01</td>\n",
       "      <td>1.276113e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This position requires a motivated individual ...</td>\n",
       "      <td>280</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>1.635554e-01</td>\n",
       "      <td>1.455531e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Legally authorized to work in the US</td>\n",
       "      <td>36</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>7.631722e-02</td>\n",
       "      <td>1.789053e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Knowledge and experience in some of these: Dee...</td>\n",
       "      <td>219</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>6.289732e-02</td>\n",
       "      <td>4.190706e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Architect, develop, deploy, and maintain scala...</td>\n",
       "      <td>219</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>5.318624e-02</td>\n",
       "      <td>3.283486e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Work with cross-functional teams to derive the...</td>\n",
       "      <td>159</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>4.171702e-02</td>\n",
       "      <td>9.168556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Develop tools in analyzing diverse sets of imp...</td>\n",
       "      <td>222</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.348758e-02</td>\n",
       "      <td>7.542002e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Understand the system operations, limitations,...</td>\n",
       "      <td>63</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>9.729517e-03</td>\n",
       "      <td>4.782181e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The combination of excellence in battery techn...</td>\n",
       "      <td>205</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>8.384333e-03</td>\n",
       "      <td>4.784805e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>They must be able to work independently in a d...</td>\n",
       "      <td>82</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>5.564461e-03</td>\n",
       "      <td>3.445191e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGES Vertech empowers and expects its team mem...</td>\n",
       "      <td>179</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.759914e-03</td>\n",
       "      <td>8.587309e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Skills and Experience: Required: Master’s or B...</td>\n",
       "      <td>132</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.147256e-03</td>\n",
       "      <td>1.057429e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Work with DevOps team to architect software mo...</td>\n",
       "      <td>140</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>8.100080e-04</td>\n",
       "      <td>6.038575e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our systems address our customers' needs to re...</td>\n",
       "      <td>258</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>2.543704e-04</td>\n",
       "      <td>5.344878e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Work closely with cross-functional teams of da...</td>\n",
       "      <td>147</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>1.702549e-04</td>\n",
       "      <td>3.468670e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Position Overview The Senior Data Scientist is...</td>\n",
       "      <td>102</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>1.041647e-04</td>\n",
       "      <td>4.756000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our service capabilities include advanced moni...</td>\n",
       "      <td>134</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>7.431245e-05</td>\n",
       "      <td>1.202627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Key Responsibilities Be an individual contribu...</td>\n",
       "      <td>193</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>5.024301e-05</td>\n",
       "      <td>2.640119e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Desired: Masters or PhD Graduate with experien...</td>\n",
       "      <td>358</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>4.284255e-05</td>\n",
       "      <td>5.111316e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Overview LG Energy Solution Vertech, I...</td>\n",
       "      <td>128</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.892899e-05</td>\n",
       "      <td>1.107686e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Using our core strengths of expert service to ...</td>\n",
       "      <td>215</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.555921e-05</td>\n",
       "      <td>3.274243e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our AEROS® energy operating system is the engi...</td>\n",
       "      <td>176</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>3.170556e-05</td>\n",
       "      <td>1.334708e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The individual in this position will be respon...</td>\n",
       "      <td>162</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>1.693438e-06</td>\n",
       "      <td>2.533433e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>They will have the opportunity to innovate new...</td>\n",
       "      <td>234</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>2.267425e-07</td>\n",
       "      <td>2.202967e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our diverse and growing team enjoys competitiv...</td>\n",
       "      <td>175</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>1.544309e-07</td>\n",
       "      <td>1.143961e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>For more information about LGESVT, please visi...</td>\n",
       "      <td>66</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>4.586381e-08</td>\n",
       "      <td>4.033160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Work in MLOps infrastructure to automate ML mo...</td>\n",
       "      <td>236</td>\n",
       "      <td>plaintext</td>\n",
       "      <td>1.397907e-08</td>\n",
       "      <td>1.646237e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            split_str  char_count   tag_name  \\\n",
       "23  3-5 years of experience in data science and da...          78  plaintext   \n",
       "26  Experience using AI/ML python libraries –PyTor...         259  plaintext   \n",
       "27  Experience working with MLOps infrastructure s...         128  plaintext   \n",
       "25                   Proficient in Python programming          32  plaintext   \n",
       "10  This position requires a motivated individual ...         280  plaintext   \n",
       "28               Legally authorized to work in the US          36  plaintext   \n",
       "24  Knowledge and experience in some of these: Dee...         219  plaintext   \n",
       "16  Architect, develop, deploy, and maintain scala...         219  plaintext   \n",
       "18  Work with cross-functional teams to derive the...         159  plaintext   \n",
       "21  Develop tools in analyzing diverse sets of imp...         222  plaintext   \n",
       "17  Understand the system operations, limitations,...          63  plaintext   \n",
       "5   The combination of excellence in battery techn...         205  plaintext   \n",
       "13  They must be able to work independently in a d...          82  plaintext   \n",
       "6   LGES Vertech empowers and expects its team mem...         179  plaintext   \n",
       "22  Skills and Experience: Required: Master’s or B...         132  plaintext   \n",
       "19  Work with DevOps team to architect software mo...         140  plaintext   \n",
       "2   Our systems address our customers' needs to re...         258  plaintext   \n",
       "15  Work closely with cross-functional teams of da...         147  plaintext   \n",
       "9   Position Overview The Senior Data Scientist is...         102  plaintext   \n",
       "4   Our service capabilities include advanced moni...         134  plaintext   \n",
       "14  Key Responsibilities Be an individual contribu...         193  plaintext   \n",
       "29  Desired: Masters or PhD Graduate with experien...         358  plaintext   \n",
       "0   Company Overview LG Energy Solution Vertech, I...         128  plaintext   \n",
       "1   Using our core strengths of expert service to ...         215  plaintext   \n",
       "3   Our AEROS® energy operating system is the engi...         176  plaintext   \n",
       "11  The individual in this position will be respon...         162  plaintext   \n",
       "12  They will have the opportunity to innovate new...         234  plaintext   \n",
       "7   Our diverse and growing team enjoys competitiv...         175  plaintext   \n",
       "8   For more information about LGESVT, please visi...          66  plaintext   \n",
       "20  Work in MLOps infrastructure to automate ML mo...         236  plaintext   \n",
       "\n",
       "       orq_score     opq_score  \n",
       "23  3.818604e-01  1.237190e-06  \n",
       "26  3.729124e-01  1.369416e-03  \n",
       "27  3.484962e-01  1.842955e-04  \n",
       "25  2.616722e-01  1.276113e-08  \n",
       "10  1.635554e-01  1.455531e-07  \n",
       "28  7.631722e-02  1.789053e-06  \n",
       "24  6.289732e-02  4.190706e-04  \n",
       "16  5.318624e-02  3.283486e-10  \n",
       "18  4.171702e-02  9.168556e-09  \n",
       "21  3.348758e-02  7.542002e-11  \n",
       "17  9.729517e-03  4.782181e-09  \n",
       "5   8.384333e-03  4.784805e-06  \n",
       "13  5.564461e-03  3.445191e-06  \n",
       "6   3.759914e-03  8.587309e-06  \n",
       "22  3.147256e-03  1.057429e-09  \n",
       "19  8.100080e-04  6.038575e-09  \n",
       "2   2.543704e-04  5.344878e-06  \n",
       "15  1.702549e-04  3.468670e-07  \n",
       "9   1.041647e-04  4.756000e-07  \n",
       "4   7.431245e-05  1.202627e-04  \n",
       "14  5.024301e-05  2.640119e-10  \n",
       "29  4.284255e-05  5.111316e-03  \n",
       "0   3.892899e-05  1.107686e-04  \n",
       "1   3.555921e-05  3.274243e-04  \n",
       "3   3.170556e-05  1.334708e-06  \n",
       "11  1.693438e-06  2.533433e-10  \n",
       "12  2.267425e-07  2.202967e-07  \n",
       "7   1.544309e-07  1.143961e-08  \n",
       "8   4.586381e-08  4.033160e-07  \n",
       "20  1.397907e-08  1.646237e-11  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "split_orqs_df.sort_values('orq_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f78ce-e9d8-43b6-b138-38641dcedd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take a badly written requirements section and see if you can programmatically parse the qualification string out of it\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# sampling_strategy_limit=6_400 gets 10,635 labeled parts of speech and takes 49 minutes and 30 seconds\n",
    "# sampling_strategy_limit=7_000 gets 10,635 labeled parts of speech and takes 49 minutes and 30 seconds\n",
    "slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=70_000, verbose=True)\n",
    "\n",
    "qual_paragraph = re.sub('</?[^<>]+>', '', child_str.strip(), 0, re.MULTILINE)\n",
    "if len(sent_tokenize(qual_paragraph)) < 2:\n",
    "    child_strs_list = re.split(' *: *', qual_paragraph, 0)\n",
    "    child_tags_list = hau.get_child_tags_list(child_strs_list)\n",
    "    feature_dict_list = cu.get_feature_dict_list(child_tags_list, child_strs_list)\n",
    "    feature_tuple_list = []\n",
    "    for feature_dict in feature_dict_list:\n",
    "        feature_tuple_list.append(hc.get_feature_tuple(feature_dict, pos_lr_predict_single=slrcu.predict_single, pos_crf_predict_single=None, pos_sgd_predict_single=None))\n",
    "    crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "    if crf_list[0] == 'H-RQ':\n",
    "        child_strs_list = re.split(' *; *', ': '.join(child_strs_list[1:]), 0)\n",
    "        child_tags_list = hau.get_child_tags_list(child_strs_list)\n",
    "        feature_dict_list = cu.get_feature_dict_list(child_tags_list, child_strs_list)\n",
    "        feature_tuple_list = []\n",
    "        for feature_dict in feature_dict_list:\n",
    "            feature_tuple_list.append(hc.get_feature_tuple(feature_dict, pos_lr_predict_single=slrcu.predict_single, pos_crf_predict_single=None, pos_sgd_predict_single=None))\n",
    "        crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "        db_pos_list = []\n",
    "        for navigable_parent in child_strs_list:\n",
    "            db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "        pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe3a9a-8b2b-4bfc-b348-ce01a188c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk.tokenize\n",
    "\n",
    "dir(nltk.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f18ee0-88df-42c4-b48d-04a9ed3508c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[f'nltk.tokenize.{fn}' for fn in dir(nltk.tokenize) if 'Tokenize' in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c3df8-2841-4579-a681-9b03518d5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.tokenize.TweetTokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1b67b-0583-4e3e-a2ff-9ffbc8adf7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[f'nltk.tokenize.{fn}' for fn in dir(nltk.tokenize) if 'tokenize' in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d533e-41c9-4ad3-94a5-312f6bc4966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.tokenize.wordpunct_tokenize(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d56c92-2077-4e48-b287-8a8314c12214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.tokenize.word_tokenize(child_str, preserve_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a43f97-3e61-4100-8026-d73f2437eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(nltk.tokenize.string_span_tokenize(child_str, r';\\s*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cf5ab-3264-4833-bc8e-3763ae9284cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.tokenize.sent_tokenize(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87620f95-6be5-46de-bc5b-8548d9316f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(nltk.tokenize.regexp_tokenize(child_str, r'\\w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf922d-1e93-48e0-82f4-f47e64cc42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(nltk.tokenize.regexp_span_tokenize(child_str, r'\\s\\s+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c338cc-6e72-49e8-a7b8-1cc093008d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.tokenize.line_tokenize(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7daf2-70b0-4cc3-868d-1f8e34384722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.tokenize.casual_tokenize(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3287dff-0406-4c4d-89ee-82b6ef750457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.tokenize.blankline_tokenize(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f74215-ceda-4159-a101-90417d72f694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
