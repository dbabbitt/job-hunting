{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7675b025-b593-4d53-9759-6c1e01772c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3ad81-7ac1-4a85-ba90-62ccbde24f49",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1febade-58e7-47f1-8c6d-5447b5737d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4972c0-2fad-4cdf-955a-17a51e4e1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "bin_count = 12\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "height_inches = 3.0\n",
    "width_inches = 18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff7aa81f-314d-4d0d-a238-355d5210f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Neo4j/4.4.7 ========\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "I have 10,635 labeled parts of speech in here\n",
      "Got this <class 'numpy.core._exceptions._ArrayMemoryError'> error in build_pos_logistic_regression_elements trying  to turn the pos_symbol TF-IDF matrix into a normal array: Unable to allocate 31.7 GiB for an array with shape (10635, 400406) and data type float64\n",
      "Utility libraries created in 57 minutes and 34 seconds\n",
      "Last run on 2023-03-07 21:44:15.020697\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(s=s)\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "# Get the neo4j object\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "try:\n",
    "    \n",
    "    version_str = cu.driver.get_server_info().agent\n",
    "    print(f'======== {version_str} ========')\n",
    "    \n",
    "    from hc_utils import HeaderCategories\n",
    "    hc = HeaderCategories(cu=cu, verbose=False)\n",
    "    \n",
    "    # 400 6,094 37 minutes and 50 seconds\n",
    "    # 800 6,094 36 minutes and 42 seconds\n",
    "    # 1,600 8,349 59 minutes and 6 seconds\n",
    "    # 3_200 9,974 1 hour, 4 minutes and 24 seconds\n",
    "    # 6_400 10,635 1 hour, 23 minutes and 11 seconds\n",
    "    from lr_utils import LrUtilities\n",
    "    lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "    lru.build_isheader_logistic_regression_elements(verbose=False)\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=5_000, verbose=False)\n",
    "    lru.build_pos_logistic_regression_elements(sampling_strategy_limit=6_400, verbose=True)\n",
    "    \n",
    "    from crf_utils import CrfUtilities\n",
    "    crf = CrfUtilities(ha=ha, hc=hc, cu=cu, lru=lru, verbose=True)\n",
    "    \n",
    "    from section_utils import SectionUtilities\n",
    "    su = SectionUtilities(s=s, ha=ha, cu=cu, crf=crf, verbose=False)\n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except ServiceUnavailable as e:\n",
    "    print('You need to start Neo4j as a console')\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__}: {str(e).strip()}')\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Utility libraries created in {duration_str}')\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c479f-c162-454d-b4a0-cccb123c567f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57ef681-27d5-4610-8496-ff1d30b09c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "I have 11,746 hand-labeled qualification strings in here\n",
      "Retraining complete\n",
      "Is-qualified classifer retrained in 3 minutes and 4 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary in another notebook\n",
    "t0 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "# sampling_strategy_limit=9_000 gets 11,365 hand-labeled qualification strings and takes 2 minutes and 25 seconds\n",
    "basic_quals_dict = lru.sync_basic_quals_dict(sampling_strategy_limit=8_000, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dab229-b28c-4ddd-812d-6abf153aae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 1427 more mis-estimated minimum-requirements-met percentages to go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit = 0.0 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_verified IS NULL) OR (fn.is_verified = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR\n",
    "        (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name,\n",
    "        fn.posting_url AS url\n",
    "    ORDER BY fn.percent_fit ASC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "print(f'Only {len(files_list)} more mis-estimated minimum-requirements-met percentages to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dfb9e50-c827-4656-9a8a-59258c69edd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 0 more mis-estimated minimum-requirements-met percentages to go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        (toLower(fn.file_name) CONTAINS \"data_scien\")\n",
    "        AND (fn.role_title IS NOT NULL)\n",
    "        AND ((fn.is_closed IS NULL) OR (fn.is_closed = false))\n",
    "        AND ((fn.is_verified IS NULL) OR (fn.is_verified = false))\n",
    "        AND ((fn.is_opportunity_application_emailed IS NULL) OR\n",
    "            (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name\n",
    "    ORDER BY fn.percent_fit ASC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "print(f'Only {len(files_list)} more mis-estimated minimum-requirements-met percentages to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed91ef-2d2e-46c9-be8b-f6458185fad8",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix POS and Quals for this posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "151cdf71-a078-43b6-9a1b-649bb51461e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aafda86facc69d43_Experimentation_Data_Scientist_Remote_Indeed_com.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "file_name = 'aafda86facc69d43_Experimentation_Data_Scientist_Remote_Indeed_com.html'\n",
    "# file_name = files_list.pop()\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if os.path.isfile(file_path):\n",
    "    child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "    is_header_list = []\n",
    "    for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "        if is_header is None:\n",
    "            probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "            idx = probs_list.index(max(probs_list))\n",
    "            is_header = [True, False][idx]\n",
    "        is_header_list.append(is_header)\n",
    "    feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "    feature_tuple_list = []\n",
    "    for feature_dict in feature_dict_list:\n",
    "        feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "    crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8afe8b-e9cc-4dca-866e-88cf37461f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-TS', 'O-O', 'O-O', 'O-O', 'H-JT', 'H-OL', 'H-IP', 'O-JD', 'O-OL', 'H-SP', 'H-SP', 'O-SP', 'O-SP', 'H-TS', 'O-CS', 'O-O', 'O-TS', 'O-TS', 'H-TS', 'O-LN', 'O-LN', 'O-TS', 'O-TS', 'O-CS', 'O-CS', 'O-TS', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-LN', 'H-O', 'H-O', 'O-PD']\n",
      "[27, 28, 29, 30, 31, 32, 33, 34]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-TS) <span style=\"color:#9edae5ff;\"><h2 class=\"css-tmzs7i e1tiznh50\" id=\"jobDetails\" tabindex=\"-1\">Job details (H-TS Task Scope Header)</h2></span><br />1 O-O) <span style=\"color:#8c564b80;\">Matches (O-O Other Non-header)</span><br />2 O-O) <span style=\"color:#8c564b80;\">job preferences (O-O Other Non-header)</span><br />3 O-O) <span style=\"color:#8c564b80;\">you are (O-O Other Non-header)</span><br />4 H-JT) <span style=\"color:#d62728ff;\"><span class=\"css-1j9n3ml eu4oa1w0\">Interested (H-JT Job Title Header)</span></span><br />5 H-OL) <span style=\"color:#c49c94ff;\">in (H-OL Office Location Header)</span><br />6 H-IP) <span style=\"color:#ffbb78ff;\">Job Type (H-IP Interview Procedures Header)</span><br />7 O-JD) <span style=\"color:#98df8a80;\"><div class=\"css-tvvxwd ecydgvn1\">Full-time (O-JD Job Duration Non-header)</div></span><br />8 O-OL) <span style=\"color:#c49c9480;\"><div class=\"css-tvvxwd ecydgvn1\">Remote (O-OL Office Location Non-header)</div></span><br />9 H-SP) <span style=\"color:#17becfff;\"><h2 class=\"jobsearch-JobDescriptionSection-jobDescriptionTitle\">Indeed's salary guide (H-SP Supplemental Pay Header)</h2></span><br />10 H-SP) <span style=\"color:#17becfff;\"><li class=\"css-vktqis eu4oa1w0\">Not provided by employer (H-SP Supplemental Pay Header)</li></span><br />11 O-SP) <span style=\"color:#17becf80;\">$108K - $136K a year is Indeed's estimated salary for this role in Remote. (O-SP Supplemental Pay Non-header)</span><br />12 O-SP) <span style=\"color:#17becf80;\"><span aria-hidden=\"false\" class=\"css-h95u2o e1wnkr790\">Report inaccurate salary (O-SP Supplemental Pay Non-header)</span></span><br />13 H-TS) <span style=\"color:#9edae5ff;\"><h2 class=\"jobsearch-JobDescriptionSection-jobDescriptionTitle icl-u-xs-my--md\" id=\"jobDescriptionTitle\">Full Job Description (H-TS Task Scope Header)</h2></span><br />14 O-CS) <span style=\"color:#1f77b480;\">At Shutterfly, we make life’s experiences unforgettable. We believe there is extraordinary power in the self-expression. That’s why our family of brands helps customers create products and capture moments that reflect who they uniquely are. (O-CS Corporate Scope Non-header)</span><br />15 O-O) <span style=\"color:#8c564b80;\">The (O-O Other Non-header)</span><br />16 O-TS) <span style=\"color:#9edae580;\"><b>Experimentation Data Scientist (O-TS Task Scope Non-header)</b></span><br />17 O-TS) <span style=\"color:#9edae580;\">will partner with the stakeholders (e.g. Performance Marketing, Ecommerce, Product) and other cross-functional stakeholder to evaluating data related to user acquisition, conversions, retention and sales to gauge performance based on business goals, identify key metrics for measuring growth and determine attributes that contribute to profitability. This individual will play a key role in helping the stakeholders become a world-class data and insights-driven team. (O-TS Task Scope Non-header)</span><br />18 H-TS) <span style=\"color:#9edae5ff;\"><b>What you will do: (H-TS Task Scope Header)</b></span><br />19 O-LN) <span style=\"color:#9467bd80;\"><li>Design, recommend and implement A/B tests, with learning ability which can be greatly expanded (O-LN Legal Notifications Non-header)</li></span><br />20 O-LN) <span style=\"color:#9467bd80;\"><li>Working with cross-functional team to recommend experimentation design and align the measurement principles, with learning ability which can be greatly expanded (O-LN Legal Notifications Non-header)</li></span><br />21 O-TS) <span style=\"color:#9edae580;\"><li>Use advanced knowledge (SQL, Python or R is a plus) to pull accurate data from cloud-based systems (O-TS Task Scope Non-header)</li></span><br />22 O-TS) <span style=\"color:#9edae580;\"><li>Apply statistical methods such as statistical significance, casual inference, time-series modeling, mix media modeling, etc. to identify incrementality, benchmarking, sizing, and forecasting. (O-TS Task Scope Non-header)</li></span><br />23 O-CS) <span style=\"color:#1f77b480;\"><li>The ability to collaborate with subject matter experts in defining appropriate features and metrics for a given model (O-CS Corporate Scope Non-header)</li></span><br />24 O-CS) <span style=\"color:#1f77b480;\"><li>Serve as strategic partner with business to size and prioritize tests that could bring high-yield testing results to maximize business impact. (O-CS Corporate Scope Non-header)</li></span><br />25 O-TS) <span style=\"color:#9edae580;\"><li>Provide actionable insights to drive key decisions across the organization using a range of analytical/statistical techniques from descriptive analysis to predictive/explanatory models (O-TS Task Scope Non-header)</li></span><br />26 H-RQ) <span style=\"color:#bcbd22ff;\"><b>The Skills You'll Bring: (H-RQ Required Qualifications Header)</b></span><br /><hr />27 O-RQ) <span style=\"color:#bcbd2280;\"><li>MS or Ph.D. or equivalent experience in a quantitative field or 6+ years of proven ability as a Data Scientist. Preferably in digital media or product fields. (O-RQ Required Qualifications Non-header)</li></span><br />28 O-RQ) <span style=\"color:#bcbd2280;\"><li>4+ years applied experience in building sophisticated datasets and feature engineering (O-RQ Required Qualifications Non-header)</li></span><br />29 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience working with structured and unstructured data stored in distributed files systems. (O-RQ Required Qualifications Non-header)</li></span><br />30 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong proficiency with SQL. Deep experience in Python/Jupyter (O-RQ Required Qualifications Non-header)</li></span><br />31 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong background and knowledge in statistics, probability, and data analysis. (O-RQ Required Qualifications Non-header)</li></span><br />32 O-RQ) <span style=\"color:#bcbd2280;\"><li>Project ownership with an ability to condense &amp; communicate sophisticated concepts and analysis into clear and concise takeaways that drive action. (O-RQ Required Qualifications Non-header)</li></span><br />33 O-RQ) <span style=\"color:#bcbd2280;\"><li>Curious about what drives business trends and. Demonstrated capacity to learn on the fly. (O-RQ Required Qualifications Non-header)</li></span><br />34 O-RQ) <span style=\"color:#bcbd2280;\"><li>Proactive with an interest in improving processes and creating efficiencies. (O-RQ Required Qualifications Non-header)</li></span><br /><hr />35 O-LN) <span style=\"color:#9467bd80;\"><p>Supporting a diverse and inclusive workforce is important to Shutterfly not only because it directly reflects our value of Embracing our Differences, but also because it’s the right thing to do for our business and for our people. Learn more about our commitment to Diversity, Equity and Inclusion at Shutterfly DE&amp;I. (O-LN Legal Notifications Non-header)</p></span><br />36 H-O) <span style=\"color:#8c564bff;\"><h2 class=\"css-14vqcyj e1tiznh50\">Hiring Insights (H-O Other Header)</h2></span><br />37 H-O) <span style=\"color:#8c564bff;\"><h3 class=\"css-1s8hy3a e1tiznh50\">Job activity (H-O Other Header)</h3></span><br />38 O-PD) <span style=\"color:#f7b6d280;\"><span class=\"css-kyg8or eu4oa1w0\">Posted Today (O-PD Post Date Non-header)</span></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33, 34]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070cc54-d512-456d-92fc-bd7bdb3f3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 28, 29, 30, 31, 32, 33, 34]\n",
      "0\n",
      "27 O-RQ) <li>MS or Ph.D. or equivalent experience in a quantitative field or 6+ years of proven ability as a Data Scientist. Preferably in digital media or product fields.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 27\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end=''); print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f1b210b-8651-4291-8c80-046a9c896392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>MS or Ph.D. or equivalent experience in a quantitative field or 6+ years of proven ability as a Data Scientist. Preferably in digital media or product fields.</li>\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb3f749-0a02-4266-876d-08983725feb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<li>Serve as strategic partner with business to size and prioritize tests that could bring high-yield testing results to maximize business impact.</li>', 'is_header': 'False', 'is_task_scope': 'True', 'is_qualification': None, 'is_minimum_qualification': 'False', 'is_preferred_qualification': 'False', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'False', 'is_interview_procedure': 'False', 'is_corporate_scope': 'False', 'is_posting_date': 'False', 'is_other': 'False'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = \"\"\"MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = 'False',\n",
    "            np.is_task_scope = 'True',\n",
    "            np.is_minimum_qualification = 'False',\n",
    "            np.is_preferred_qualification = 'False',\n",
    "            np.is_educational_requirement = 'False',\n",
    "            np.is_legal_notification = 'False',\n",
    "            np.is_other = 'False',\n",
    "            np.is_corporate_scope = 'False',\n",
    "            np.is_job_title = 'False',\n",
    "            np.is_office_location = 'False',\n",
    "            np.is_job_duration = 'False',\n",
    "            np.is_supplemental_pay = 'False',\n",
    "            np.is_interview_procedure = 'False',\n",
    "            np.is_posting_date = 'False'\n",
    "        \"\"\" + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28836b66-b8d4-48cb-92a0-f28efbb39c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<orq>1 - Data Science (P4 - Expert)</orq>', 'is_header': 'False', 'is_task_scope': 'False', 'is_qualification': None, 'is_minimum_qualification': 'True', 'is_preferred_qualification': 'False', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'False', 'is_interview_procedure': 'False', 'is_corporate_scope': 'False', 'is_posting_date': 'False', 'is_other': 'False'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>Understand the needs and challenges of fast-growth organization and participate in its development</li>\" in basic_quals_dict: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary and database\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str, None)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b08e-874a-41db-a163-2232b9c7cc55",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dbe5ce2c-5c8c-4196-96de-ee38953e10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\hunting_df.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node element_id='968277' labels=frozenset({'FileNames'}) properties={'assigned_role': 'Data Science Practitioner', 'career_level_from_to': '9 to 8', 'file_name': '4698820_0_META_PLATFORMS_INC_Data_Scientist.html', 'role_primary_contact_email_id': 'k.balasubramaniam@accenture.com', 'is_role_sold': 'Yes', 'role_title': 'Data Scientist', 'role_client_supply_contact': 'Navarrete Méndez,Maria Patricia', 'is_verified': False, 'role_id': '4698820.0', 'project_metro_city': 'San Francisco', 'role_end_date': '12/1/2023', 'role_primary_contact': 'Krishnamurthy,Balasubramaniam', 'role_start_date': '3/1/2023', 'client_name': 'META PLATFORMS, INC.'}>}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Mark the file name as needing retraining everywhere\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# file_name = '14885afaa7bbd01e_Software_Developer_Engineer_in_Test_SDET_Eagle_ID_83616_Indeed_com.html'\n",
    "mask_series = lru.hunting_df.percent_fit.isin([file_name])\n",
    "lru.hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=lru.hunting_df)\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.percent_fit = NULL, fn.is_verified = false\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    results_list = tx.run(query=cypher_str, parameters={'file_name': file_name})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f00b97db-00ab-4ab9-8a22-323bbb5c6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        MATCH (fn:FileNames {file_name: \"4698820_META_PLATFORMS_INC_Data_Scientist.html\"})\n",
      "        SET fn.is_verified = true\n",
      "        RETURN fn;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node element_id='957809' labels=frozenset({'FileNames'}) properties={'assigned_role': 'Data Science Practitioner', 'career_level_from_to': '9 to 8', 'file_name': '4698820_META_PLATFORMS_INC_Data_Scientist.html', 'role_primary_contact_email_id': 'k.balasubramaniam@accenture.com', 'is_role_sold': 'Yes', 'role_title': 'Data Scientist', 'role_client_supply_contact': 'Navarrete M?ez,Maria Patricia', 'is_verified': True, 'role_id': '4698820', 'project_metro_city': 'San Francisco', 'role_end_date': '12/1/2023', 'percent_fit': 0.16666666666666666, 'role_primary_contact': 'Krishnamurthy,Balasubramaniam', 'role_start_date': '3/1/2023', 'client_name': 'META PLATFORMS, INC.'}>}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# You've made no changes to the qualification dictionary (regardless of parts-of-speech changes)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.is_verified = true\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    parameter_dict = {'file_name': file_name}\n",
    "    results_list = tx.run(query=cypher_str, parameters=parameter_dict)\n",
    "    values_list = []\n",
    "    for record in results_list:\n",
    "        values_list.append(dict(record.items()))\n",
    "\n",
    "    return values_list\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=True)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8adbd-5b7c-43d8-8680-aea4da63a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the file name as closed\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_closed = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9664-96e1-43cb-8de7-99e40d5524f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[13]\n",
    "print(qualification_str)\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4a2c62-661a-4652-b743-efa5e336ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "# file_name = '3c031ea6ad293e92_General_Service_Technician_Westborough_MA_01581_Indeed_com.html'\n",
    "cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646f71a-405a-44d9-aebd-18e70c97f08a",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "232f78ce-e9d8-43b6-b138-38641dcedd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 10,635 labeled parts of speech in here\n",
      "['O-RQ', 'O-PQ', 'O-TS', 'O-TS', 'O-RQ', 'O-TS', 'O-TS', 'O-TS', 'O-LN', 'O-TS']\n",
      "[0, 4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr />0 O-RQ) <span style=\"color:#bcbd2280;\">Requires a Bachelor’s degree, or foreign equivalent degree in Computer Science, Computer Engineering, or Electronic Engineering and four (4) years of experience in the job offered, or four (4) years of experience in a related occupation driving strategy and approach through solution and enterprise testing (O-RQ Required Qualifications Non-header)</span><br />1 O-PQ) <span style=\"color:#c7c7c780;\">executing automation through Ginger, CI/CD, Agile, Python, Java languages, and testing tools such as Selenium (O-PQ Preferred Qualifications Non-header)</span><br />2 O-TS) <span style=\"color:#9edae580;\">collaborating with cross functional teams to analyze, develop, and implement end-to-end solutions (O-TS Task Scope Non-header)</span><br />3 O-TS) <span style=\"color:#9edae580;\">using existing and modernized tooling such as, Jira Align, iTrack, Zephyr, AI/ML, and AQUA (O-TS Task Scope Non-header)</span><br />4 O-RQ) <span style=\"color:#bcbd2280;\">performing the walkthrough and grooming of capabilities and features in cases with ARTs (O-RQ Required Qualifications Non-header)</span><br /><hr />5 O-TS) <span style=\"color:#9edae580;\">creating test plans, scenarios/use cases and test cases associated with capabilities and features (O-TS Task Scope Non-header)</span><br />6 O-TS) <span style=\"color:#9edae580;\">ensuring that all test cases are in alignment with automation frameworks (O-TS Task Scope Non-header)</span><br />7 O-TS) <span style=\"color:#9edae580;\">writing E2E scenario test cases, maximizing test coverage for a feature, and minimizing the impact of disruptive test cases (O-TS Task Scope Non-header)</span><br />8 O-LN) <span style=\"color:#9467bd80;\">designing and implementing automation tests and frameworks to enable continuous deployment and continuous testing for CTP across all phases (O-LN Legal Notifications Non-header)</span><br />9 O-TS) <span style=\"color:#9edae580;\">and ensuring that all automation scripts have gone through standard code quality checks, incorporating Gerrit Code Review and Cloud Review. (O-TS Task Scope Non-header)</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Take a badly written requirements section and see if you can programmatically parse the qualification string out of it\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# sampling_strategy_limit=6_400 gets 10,635 labeled parts of speech and takes 49 minutes and 30 seconds\n",
    "# sampling_strategy_limit=7_000 gets 10,635 labeled parts of speech and takes 49 minutes and 30 seconds\n",
    "lru.build_pos_logistic_regression_elements(sampling_strategy_limit=70_000, verbose=True)\n",
    "\n",
    "child_str = '<p>REQUIREMENTS: Requires a Bachelor’s degree, or foreign equivalent degree in Computer Science, Computer Engineering, or Electronic Engineering and four (4) years of experience in the job offered,'\n",
    "child_str += ' or four (4) years of experience in a related occupation driving strategy and approach through solution and enterprise testing; executing automation through Ginger, CI/CD, Agile, Python, Java languages,'\n",
    "child_str += ' and testing tools such as Selenium; collaborating with cross functional teams to analyze, develop, and implement end-to-end solutions; using existing and modernized tooling such as, Jira Align,'\n",
    "child_str += ' iTrack, Zephyr, AI/ML, and AQUA; performing the walkthrough and grooming of capabilities and features in cases with ARTs; creating test plans,'\n",
    "child_str += ' scenarios/use cases and test cases associated with capabilities and features; ensuring that all test cases are in alignment with automation frameworks; writing E2E scenario test cases,'\n",
    "child_str += ' maximizing test coverage for a feature, and minimizing the impact of disruptive test cases;'\n",
    "child_str += ' designing and implementing automation tests and frameworks to enable continuous deployment and continuous testing for CTP across all phases;'\n",
    "child_str += ' and ensuring that all automation scripts have gone through standard code quality checks, incorporating Gerrit Code Review and Cloud Review.</p>'\n",
    "qual_paragraph = re.sub('</?[^<>]+>', '', child_str.strip(), 0, re.MULTILINE)\n",
    "if len(sent_tokenize(qual_paragraph)) < 2:\n",
    "    child_strs_list = re.split(' *: *', qual_paragraph, 0)\n",
    "    child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "    is_header_list = []\n",
    "    for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "        if is_header is None:\n",
    "            probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "            idx = probs_list.index(max(probs_list))\n",
    "            is_header = [True, False][idx]\n",
    "        is_header_list.append(is_header)\n",
    "    feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "    feature_tuple_list = []\n",
    "    for feature_dict in feature_dict_list:\n",
    "        feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "    crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "    if crf_list[0] == 'H-RQ':\n",
    "        child_strs_list = re.split(' *; *', ': '.join(child_strs_list[1:]), 0)\n",
    "        child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "        is_header_list = []\n",
    "        for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "            if is_header is None:\n",
    "                probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "                idx = probs_list.index(max(probs_list))\n",
    "                is_header = [True, False][idx]\n",
    "            is_header_list.append(is_header)\n",
    "        feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "        feature_tuple_list = []\n",
    "        for feature_dict in feature_dict_list:\n",
    "            feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "        crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "        db_pos_list = []\n",
    "        for navigable_parent in child_strs_list:\n",
    "            db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "        pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe3a9a-8b2b-4bfc-b348-ce01a188c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
