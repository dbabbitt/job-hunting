{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7675b025-b593-4d53-9759-6c1e01772c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e9a76f-08eb-4a9c-9c53-4bf043e26661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee342571-b35a-4688-850c-8aad13befcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(s=s)\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7dd43f-2080-40e0-84a3-f9a7fdd934dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "try:\n",
    "    version_str = cu.driver.verify_connectivity()\n",
    "    \n",
    "    from hc_utils import HeaderCategories\n",
    "    hc = HeaderCategories(cu=cu, verbose=False)\n",
    "    \n",
    "    from section_utils import SectionUtilities\n",
    "    su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "    \n",
    "    from lr_utils import LrUtilities\n",
    "    lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "    \n",
    "    from crf_utils import CrfUtilities\n",
    "    crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except ServiceUnavailable as e:\n",
    "    # print(str(e).strip())\n",
    "    raise ServiceUnavailable('You need to start Neo4j as a console')\n",
    "except Exception as e:\n",
    "    print(e.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2c759f-11f4-4bf8-bc61-35c4b4d1c31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2022-07-16 10:22:44.586236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import humanize\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "from datetime import datetime\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d85a2e-5f1b-4cbe-a2df-944f8bf19523",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf51ee4a-d5bd-4354-9ca6-be20dabf65b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts-of-speech classifier retrained in 9 minutes and 49 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "lru.build_pos_logistic_regression_elements(verbose=False)\n",
    "crf.retrain_pos_classifier(verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Parts-of-speech classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e3644d-7c49-46d0-9af8-e559dff89a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is-header classifier retrained in 4 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "lru.build_isheader_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_isheader_classifier(verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-header classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd80ea2-341e-4672-b810-f4c500ab8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is-qualified classifer retrained in 9 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rebuild the classifer from the quals dictionary\n",
    "t0 = time.time()\n",
    "lru.build_isqualified_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82dab229-b28c-4ddd-812d-6abf153aae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 7 more mis-estimated minimum-requirements-met percentages to go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "navigable_parent_cypher_str = '''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{}'}})\n",
    "    ''' + cu.return_everything_str + ';'\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit < 0.4 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_verified IS NULL) OR (fn.is_verified = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR\n",
    "        (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name,\n",
    "        fn.posting_url AS url\n",
    "    ORDER BY fn.percent_fit ASC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "print(f'Only {len(files_list)} more mis-estimated minimum-requirements-met percentages to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2f3ec-44ee-4be3-b13e-02badca41da4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "151cdf71-a078-43b6-9a1b-649bb51461e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96d6e29e039c9cf4_Data_Scientist_Atlanta_GA_30309_Indeed_com.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# file_name = files_list.pop()\n",
    "file_name = '96d6e29e039c9cf4_Data_Scientist_Atlanta_GA_30309_Indeed_com.html'\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "page_soup = wsu.get_page_soup(file_path)\n",
    "div_soup = page_soup.find_all(name='div', id='jobDescriptionText')[0]\n",
    "child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "cu.ensure_filename(file_name, verbose=False)\n",
    "cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99fcd0c5-e0ac-431d-bacd-b22a7b5ed4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O-TS', 'H-TS', 'H-RQ', 'O-CS', 'O-CS', 'O-TS', 'O-OL', 'O-CS', 'O-CS', 'O-SP', 'O-CS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-ER', 'O-TS', 'O-PQ', 'O-TS', 'O-TS', 'O-CS', 'O-IP', 'O-OL', 'O-CS', 'O-OL', 'O-CS', 'O-CS', 'O-SP', 'O-CS', 'O-CS']\n",
      "[17]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 O-TS) <span style=\"color:#9edae580;\">AECOM is seeking a Data Scientist to be based in Savannah or Atlanta, GA. (O-TS Task Scope Non-header)</span><br />1 H-TS) <span style=\"color:#9edae5ff;\">This position is expected to begin in August 2022. (H-TS Task Scope Header)</span><br />2 H-RQ) <span style=\"color:#bcbd22ff;\">At AECOM, we’re delivering a better world. (H-RQ Required Qualifications Header)</span><br />3 O-CS) <span style=\"color:#1f77b480;\">We believe infrastructure creates opportunity for everyone. Whether it’s improving your commute, keeping the lights on, providing access to clean water or transforming skylines, our work helps people and communities thrive. (O-CS Corporate Scope Non-header)</span><br />4 O-CS) <span style=\"color:#1f77b480;\">Our clients trust us to bring together the best people, ideas, technical expertise and digital solutions to our work in transportation, buildings, water, the environment and new energy. We’re one global team – 47,000 strong – driven by a common purpose to deliver a better world. (O-CS Corporate Scope Non-header)</span><br />5 O-TS) <span style=\"color:#9edae580;\">Here, you will have freedom to grow in a world of opportunity. (O-TS Task Scope Non-header)</span><br />6 O-OL) <span style=\"color:#c49c9480;\">We will give you the flexibility you need to do your best work with hybrid work options. Whether you’re working from an AECOM office, remote location or at a client site, you will be working in a dynamic environment where your integrity, entrepreneurial spirit and pioneering mindset are championed. (O-OL Office Location Non-header)</span><br />7 O-CS) <span style=\"color:#1f77b480;\">You will help us foster a culture of equity, diversity and inclusion – a safe and respectful workplace, where we invite everyone to bring their whole selves to work using their unique talents, backgrounds and expertise to create transformational outcomes for our clients. (O-CS Corporate Scope Non-header)</span><br />8 O-CS) <span style=\"color:#1f77b480;\">We will encourage you to grow and develop your career with us through our technical and professional development programs and diverse career opportunities. We believe in leadership at all levels. No matter where you sit in the organization you can make a lasting impact on the projects you work on, the teams and committees you join and our business. (O-CS Corporate Scope Non-header)</span><br />9 O-SP) <span style=\"color:#17becf80;\">We offer competitive pay and benefits, well-being programs to support you and your family, and the development resources you need to advance your career. (O-SP Supplemental Pay Non-header)</span><br />10 O-CS) <span style=\"color:#1f77b480;\">When you join us, you will connect and collaborate with a global network of experts – planners, designers, engineers, scientists, consultants, program and construction managers – leading the change toward a more sustainable and equitable future. Join us and let’s get started. (O-CS Corporate Scope Non-header)</span><br />11 H-TS) <span style=\"color:#9edae5ff;\">The responsibilities of this position include, but are not limited to: (H-TS Task Scope Header)</span><br />12 O-TS) <span style=\"color:#9edae580;\">+ Combine advanced analytics and visualization skills to enable research, development and consumer-focused deliverables to assist development of databases. (O-TS Task Scope Non-header)</span><br />13 O-TS) <span style=\"color:#9edae580;\">+ These assignments will be formulated from the following focus areas: Machine Learning & Natural Language Processing (Python/R, Autocad, BIM, C#, C++) (O-TS Task Scope Non-header)</span><br />14 O-TS) <span style=\"color:#9edae580;\">+ Encompasses using algorithms & statistics to build and compare advanced models in the subfields of machine learning, deep learning & natural language processing using software development principles. Specifically building models, that will focus on database management and tracking of assets within the database, regardless of data in its raw native language. (O-TS Task Scope Non-header)</span><br />15 O-TS) <span style=\"color:#9edae580;\">+ Application Development via Data Science APIs and SDK. Applications developed will specifically be built upon for consumer and client use in multiple disciplines but will have a strong focus for engineers (Civil, Bridge, and Structural). (O-TS Task Scope Non-header)</span><br />16 O-TS) <span style=\"color:#9edae580;\">Minimum Requirements (O-TS Task Scope Non-header)</span><br /><hr />17 O-ER) <span style=\"color:#aec7e880;\">+ Bachelor’s degree in Civil, Mechanical, Electrical Engineering, Computer Science, or other related field (O-ER Education Requirements Non-header)</span><br /><hr />18 O-TS) <span style=\"color:#9edae580;\">+ Due to the nature of the job, U.S. Citizenship or Permanent Residency is required (O-TS Task Scope Non-header)</span><br />19 O-PQ) <span style=\"color:#c7c7c780;\">Preferred Qualifications (O-PQ Preferred Qualifications Non-header)</span><br />20 O-TS) <span style=\"color:#9edae580;\">+ Self-motivated individual and pride yourself on being an excellent communicator, both verbally and written. (O-TS Task Scope Non-header)</span><br />21 O-TS) <span style=\"color:#9edae580;\">+ Proficiency with and understanding of machine learning frameworks, libraries, programming such as C programming, Python, MATLAB, Jupyter Notebooks, Pytorch, etc. al. (O-TS Task Scope Non-header)</span><br />22 O-CS) <span style=\"color:#1f77b480;\"><b>Additional Information: (O-CS Corporate Scope Non-header)</b></span><br />23 O-IP) <span style=\"color:#ffbb7880;\">+ Relocation assistance is not available for this position (O-IP Interview Procedures Non-header)</span><br />24 O-OL) <span style=\"color:#c49c9480;\">+ U.S. based remote work possible (O-OL Office Location Non-header)</span><br />25 O-CS) <span style=\"color:#1f77b480;\">What We Offer (O-CS Corporate Scope Non-header)</span><br />26 O-OL) <span style=\"color:#c49c9480;\">We will give you the flexibility you need to do your best work with hybrid work options. Whether you’re working from an AECOM office, remote location or at a client site, you will be working in a dynamic environment where your integrity, entrepreneurial spirit and pioneering mindset are championed. (O-OL Office Location Non-header)</span><br />27 O-CS) <span style=\"color:#1f77b480;\">You will help us foster a culture of equity, diversity and inclusion – a safe and respectful workplace, where we invite everyone to bring their whole selves to work using their unique talents, backgrounds and expertise to create transformational outcomes for our clients. (O-CS Corporate Scope Non-header)</span><br />28 O-CS) <span style=\"color:#1f77b480;\">We will encourage you to grow and develop your career with us through our technical and professional development programs and diverse career opportunities. We believe in leadership at all levels. No matter where you sit in the organization you can make a lasting impact on the projects you work on, the teams and committees you join and our business. (O-CS Corporate Scope Non-header)</span><br />29 O-SP) <span style=\"color:#17becf80;\">We offer competitive pay and benefits, well-being programs to support you and your family, and the development resources you need to advance your career. (O-SP Supplemental Pay Non-header)</span><br />30 O-CS) <span style=\"color:#1f77b480;\">When you join us, you will connect and collaborate with a global network of experts – planners, designers, engineers, scientists, consultants, program and construction managers – leading the change toward a more sustainable and equitable future. Join us and let’s get started. (O-CS Corporate Scope Non-header)</span><br />31 O-CS) <span style=\"color:#1f77b480;\">As an Equal Opportunity Employer, we believe in each person’s potential, and we’ll help you reach yours. (O-CS Corporate Scope Non-header)</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32ce35-6670-4523-9d03-015542cb3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\n",
      "22 O-CS) <b>Additional Information:</b>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 22\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = s.load_object('basic_quals_dict'); print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end=''); print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f1b210b-8651-4291-8c80-046a9c896392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"+ Proficiency with and understanding of machine learning frameworks, libraries, programming such as C programming, Python, MATLAB, Jupyter Notebooks, Pytorch, etc. al.\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bb3f749-0a02-4266-876d-08983725feb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '+ Proficiency with and understanding of machine learning frameworks, libraries, programming such as C programming, Python, MATLAB, Jupyter Notebooks, Pytorch, etc. al.', 'is_header': 'False', 'is_task_scope': 'False', 'is_minimum_qualification': 'False', 'is_preferred_qualification': 'True', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'False', 'is_interview_procedure': 'False', 'is_corporate_scope': 'False', 'is_posting_date': 'False', 'is_other': 'False'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = \"\"\"MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = 'False',\n",
    "            np.is_task_scope = 'False',\n",
    "            np.is_minimum_qualification = 'False',\n",
    "            np.is_preferred_qualification = 'True',\n",
    "            np.is_educational_requirement = 'False',\n",
    "            np.is_legal_notification = 'False',\n",
    "            np.is_other = 'False',\n",
    "            np.is_corporate_scope = 'False',\n",
    "            np.is_job_title = 'False',\n",
    "            np.is_office_location = 'False',\n",
    "            np.is_job_duration = 'False',\n",
    "            np.is_supplemental_pay = 'False',\n",
    "            np.is_interview_procedure = 'False',\n",
    "            np.is_posting_date = 'False'\n",
    "        \"\"\" + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28836b66-b8d4-48cb-92a0-f28efbb39c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "# print(navigable_parent_cypher_str.format(child_str))\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, navigable_parent_cypher_str.format(child_str))\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b08e-874a-41db-a163-2232b9c7cc55",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbe5ce2c-5c8c-4196-96de-ee38953e10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\hunting_df.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node id=808121 labels=frozenset({'FileNames'}) properties={'file_name': '96d6e29e039c9cf4_Data_Scientist_Atlanta_GA_30309_Indeed_com.html', 'posting_url': 'https://www.indeed.com/rc/clk/dl?jk=96d6e29e039c9cf4&from=ja&qd=RnZhMybXSk4M3QtTVGXWoZj-R_bxcYib5xeGNtZ7GZagAfycVnMrWOMaEuEQAkxV7PCzwm8v45ZXoUln4TKYsCmMcYAYettfmz0BIuwIhRk&rd=MS1XhwPLX376n54shWSjvnEwqdD0vnOb9P51Phyha6c&tk=1g848if74groq806&alid=6254377b33b425113af40aa2', 'is_verified': False}>}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Mark the file name as needing retraining everywhere\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "mask_series = lru.hunting_df.percent_fit.isin([file_name])\n",
    "lru.hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=lru.hunting_df)\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.percent_fit = NULL, fn.is_verified = false\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    results_list = tx.run(query=cypher_str, parameters={'file_name': file_name})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b97db-00ab-4ab9-8a22-323bbb5c6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You've made no changes to the qualification dictionary because it looks good as is\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def do_cypher_tx(tx, file_name, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.is_verified = true\n",
    "        RETURN fn;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "    parameter_dict = {'file_name': file_name}\n",
    "    results_list = tx.run(query=cypher_str, parameters=parameter_dict)\n",
    "    values_list = []\n",
    "    for record in results_list:\n",
    "        values_list.append(dict(record.items()))\n",
    "\n",
    "    return values_list\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, file_name=file_name, verbose=True)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8adbd-5b7c-43d8-8680-aea4da63a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the file name as closed\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_closed = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142fab4-fb6e-458a-a717-cad92b90f255",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Prepare cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96965b4-3398-434a-96aa-f19479649305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>I only meet 87.5% of the minimum requirements for the Jr Machine Learning engineer Remote ok Preferable locations Buffalo Grove IL and Woonsocket RI Business Integra Remote position, but I can explain:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1) Majored in Computer Science, Computer Engineering, or equivalent major/equivalent work experience with Statistical background."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2) Achieved a minimum cumulative 3.0/4.0 GPA or equivalent."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3) 1-2 years of Project/program work experience with Data Science concepts, AI/ML using Python/R/Jupyter/Anaconda"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4) 1-2 years of Project/program work experience of computer programming languages Python, HTML, CSS, JavaScript, Unix/Linux, PyCharm, Django, R Studio, Pandas & Scikit libraries"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5) Project/program work experience using RDBMS (Oracle, Maria DB), MySQL, MongoDB No SQL"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7) Experience with MS Office products Excel, Word, PowerPoint, Project, SharePoint & Teams."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8) Strong programing skills using Python/JavaScript/Java"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9) Strong research, analytical, written communication, and oral presentation skills."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "10) Strong statistical background and ability to incorporate them based on the business needs"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "11) Outstanding interpersonal skills and ability to develop relationships across diverse teams."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "12) Experienced in collaboration tools like Rally, Microsoft Teams, Confluence, Miro, SharePoint."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "13) 1-2 years of data science experience (project/internship/program experience) in business setting including collaborating with business partners to understand problems, programming/scripting with Python & R, gather business requirements, design data science models and communicate results and insights back to business partners"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "15) Applying machine learning libraries to address real world data science problems   Education:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16) Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# file_name = 'Staff_Software_Engineer_US_Remote_Mandiant.html'\n",
    "lru.build_isqualified_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=False)\n",
    "# child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, crf_list=crf_list, file_name=file_name)\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "lru.basic_quals_dict = basic_quals_dict\n",
    "quals_str, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "job_title = file_name.replace('.html', '').replace('_Indeed_com', '').replace('_', ' ')\n",
    "display(HTML(f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef7b2a4-d443-4cdd-86ad-a7f4938d4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The minimum requirements that I don't meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6) Knowledge of Application Monitoring Tools like Splunk, AppDynamics, mPulse, Google Cloud Platform."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "14) Data management, building SQL queries and productionalize statistical models with best practices"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(HTML(f\"<p>The minimum requirements that I don't meet are:</p>\"))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if (qual_str not in basic_quals_dict) or not basic_quals_dict[qual_str]:\n",
    "        idx = qual_str.find('>')\n",
    "        if idx == -1:\n",
    "            display(HTML(f'{i+1}) {qual_str}'))\n",
    "        else:\n",
    "            display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d705f1-6522-416e-a223-682fdfd6e66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The preferred requirements that I meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(HTML(f\"<p>The preferred requirements that I meet are:</p>\"))\n",
    "indices_list = [i for i, x in enumerate(pos_list) if (x in ['O-PQ'])]\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9664-96e1-43cb-8de7-99e40d5524f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[13]\n",
    "print(qualification_str)\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57806a7-1f0b-498c-bb71-b5713424cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "lru.basic_quals_dict = basic_quals_dict\n",
    "quals_str, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "job_title = file_name.replace('.html', '').replace('_', ' ')\n",
    "display(HTML(f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed07b0-bedf-4d82-a06d-dbab85962b83",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c62a0c-4d54-4d19-bb71-23f41b23cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "for key in basic_quals_dict.keys():\n",
    "    if 'automat' in key.lower():\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "970db600-c50f-49b3-adfc-4f11466fab97",
   "metadata": {},
   "source": [
    "\n",
    "# Mark all bad file names as needing retraining everywhere\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "mask_series = hunting_df.percent_fit.isin([0.0, 1.0])\n",
    "files_list = hunting_df[mask_series].file_name.tolist()\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.file_name IN {files_list} AND\n",
    "        fn.percent_fit IN [0.0, 1.0]\n",
    "    SET fn.percent_fit = NULL\n",
    "    RETURN fn.file_name AS file_name;'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = [list(row_obj.values())[0] for row_obj in row_objs_list]\n",
    "mask_series = hunting_df.file_name.isin(files_list)\n",
    "hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fed2d-c338-4070-837f-901464bf7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "import numpy as np\n",
    "\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = sorted([child_str for child_str in basic_quals_dict.keys()], key=lambda x: len(x), reverse=True)[0]\n",
    "print(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa007ae4-4df4-4f06-88e5-65e6e062a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "basic_quals_dict.pop(child_str)\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = \"\"\"\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})-[r:NEXT]->(:NavigableParents)\n",
    "        RETURN r.file_name AS file_name;\"\"\"\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(cypher_str.replace('$navigable_parent', f'\"{navigable_parent}\"'))\n",
    "    tx.run(cypher_str, navigable_parent=navigable_parent)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=True)\n",
    "for row_obj in row_objs_list:\n",
    "    file_name = row_obj['file_name']\n",
    "    mask_series = hunting_df.file_name.isin([file_name])\n",
    "    hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "    s.store_objects(hunting_df=hunting_df)\n",
    "    def do_cypher_tx(tx, file_name, verbose=False):\n",
    "        cypher_str = \"\"\"\n",
    "        MATCH (fn:FileNames {file_name: $file_name})\n",
    "        SET fn.percent_fit = NULL;\"\"\"\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(cypher_str.replace('$file_name', f'\"{file_name}\"'))\n",
    "        tx.run(cypher_str, file_name=file_name)\n",
    "    with cu.driver.session() as session:\n",
    "        session.write_transaction(do_cypher_tx, file_name=file_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d81bc-c3f5-4023-b38d-88ff000d2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find a qual in the dictionary with this substring\n",
    "sentence_regex = re.compile(r'[\\.;]')\n",
    "quals_set = set()\n",
    "concatonated_quals_list = sentence_regex.split(child_str.replace('<div>', '').replace('</div>', '').strip())\n",
    "for q in concatonated_quals_list:\n",
    "    q = q.strip()\n",
    "    if q:\n",
    "        quals_set.add(q)\n",
    "quals_list = list(quals_set)\n",
    "for q in quals_list:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ac635-33fe-46d5-a1c3-e369b3a86f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513d5c4-7d91-43ea-9e62-0e670e7d7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(quals_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81df4c0-9f22-41ff-9c59-83862cdea0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe3a9a-8b2b-4bfc-b348-ce01a188c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
