{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb055c8-7f3e-4dd6-a2d0-fc7f70f0c5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7675b025-b593-4d53-9759-6c1e01772c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e9a76f-08eb-4a9c-9c53-4bf043e26661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92346a3f-3506-4e2c-b030-4f4fa74f78fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 39s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from pandas import DataFrame\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from hc_utils import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "from lr_utils import LrUtilities\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "lru.build_isheader_logistic_regression_elements()\n",
    "lru.build_pos_logistic_regression_elements()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dab229-b28c-4ddd-812d-6abf153aae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit IN [0.0, 1.0] AND\n",
    "        ((fn.is_verfied IS NULL) OR \n",
    "        (fn.is_verfied = false)) AND\n",
    "        ((fn.is_closed IS NULL) AND ((fn.is_opportunity_application_emailed IS NULL) OR \n",
    "        (fn.is_opportunity_application_emailed = false))) OR (fn.is_closed = false)\n",
    "    RETURN fn.file_name AS file_name\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2f3ec-44ee-4be3-b13e-02badca41da4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151cdf71-a078-43b6-9a1b-649bb51461e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior_Backend_Engineer_(Data_Science_Software_Engineering_Support)_-_Remote_-_Indeed.com_3e34ac4ae73849ba.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%run ../load_magic/dataframes.py\n",
    "\n",
    "# file_name = files_list.pop()\n",
    "file_name = 'Senior_Backend_Engineer_(Data_Science_Software_Engineering_Support)_-_Remote_-_Indeed.com_3e34ac4ae73849ba.html'\n",
    "print(file_name)\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "page_soup = get_page_soup(file_path)\n",
    "div_soup = page_soup.find_all(name='div', id='jobDescriptionText')[0]\n",
    "child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "cu.ensure_filename(file_name, verbose=False)\n",
    "cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9488aa37-8a06-4b91-b051-762be55762dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plaintext', 'p', 'b', 'p', 'p', 'p', 'p', 'b', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'b', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'li', 'p', 'p', 'i']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "print(child_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f209f452-115b-4789-b206-faa1adb25f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4384d89f-5286-4846-9ff4-11ee518b3dc2",
   "metadata": {},
   "source": [
    "\n",
    "# cu.create_h_pickle(verbose=True)\n",
    "NAVIGABLE_PARENT_IS_HEADER_DICT = s.load_object('NAVIGABLE_PARENT_IS_HEADER_DICT')\n",
    "for i, (is_header, child_str) in enumerate(zip(is_header_list, child_strs_list)):\n",
    "    print(i, NAVIGABLE_PARENT_IS_HEADER_DICT.get(child_str), is_header, child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab2b8bb-ddfd-455e-a5a0-06a613cdbd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_tag': 'p', 'is_header': False, 'is_task_scope': None, 'is_minimum_qualification': None, 'is_preferred_qualification': None, 'is_legal_notification': None, 'is_job_title': None, 'is_office_location': None, 'is_job_duration': None, 'is_supplemental_pay': None, 'is_educational_requirement': None, 'is_interview_procedure': None, 'is_corporate_scope': None, 'is_posting_date': None, 'is_other': None, 'child_str': '<p>MEDS Perform/ Edge Study Feasibility: This is an intelligence and analytics product giving our clients better decision making capabilities.</p>'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_dict_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc96eb8-35d0-47c3-b55a-073194a5adf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('p', '<p>MEDS Perform/ Edge Study Feasibility: This is an intelligence and analytics product giving our clients better decision making capabilities.</p>', 'O-CS')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "feature_tuple_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef8aa5a-fd24-4ab1-a31d-a7063770134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O-CS', 'O-TS', 'O-SP', 'O-TS', 'O-CS', 'O-LN', 'H-TS', 'O-SP', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-CS', 'O-TS', 'O-TS', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-TS', 'O-RQ', 'O-RQ', 'O-PQ', 'O-CS', 'O-TS', 'O-LN']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "crf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1918e8db-d426-465d-8b9f-b92e41ebc596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'H', 'O', 'O', 'O', 'O', 'H', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'O-PQ', 'O-CS', 'O', 'O']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "db_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fcd49e8-8e4b-4cda-b056-28c376b0df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O-CS', 'O-TS', 'O-SP', 'O-TS', 'O-CS', 'O-LN', 'H-TS', 'O-SP', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-CS', 'O-TS', 'O-TS', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'O-PQ', 'O-CS', 'O-TS', 'O-LN']\n",
      "[17, 18, 19, 20, 21, 22, 23, 24]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 O-CS) <span style=\"color:#bcbd2280;\">Medidata: Conquering Diseases Together (O-CS Corporate Scope Non-header)</span><br />1 O-TS) <span style=\"color:#1f77b480;\"><p>Medidata is leading the digital transformation of life sciences, creating hope for millions of patients. Medidata helps generate the evidence and insights to help pharmaceutical, biotech, medical device and diagnostics companies, and academic researchers accelerate value, minimize risk, and optimize outcomes. More than one million registered users across 1,400 customers and partners access the world's most-used platform for clinical development, commercial, and real-world data. Medidata, a Dassault Systèmes company, is headquartered in New York City and has offices around the world to meet the needs of its customers. Discover more at www.medidata.com. (O-TS Task Scope Non-header)</p></span><br />2 O-SP) <span style=\"color:#c49c9480;\"><b>Your Mission: (O-SP Supplemental Pay Non-header)</b></span><br />3 O-TS) <span style=\"color:#1f77b480;\"><p>We’re looking for an experienced Software Engineer to be part of our Research &amp; Development (R&amp;D) org. Our R&amp;D department has been making amazing strides towards how new medicines are identified and developed by our clients (BioTechs and Pharmaceuticals for example) via Machine Learning &amp; AI. This Sr. Software Engineer will assist in building new products (from ideation on). In addition, participate in maintaining and devising new features for existing products like for example: (O-TS Task Scope Non-header)</p></span><br />4 O-CS) <span style=\"color:#bcbd2280;\"><p>MEDS Perform/ Edge Study Feasibility: This is an intelligence and analytics product giving our clients better decision making capabilities. (O-CS Corporate Scope Non-header)</p></span><br />5 O-LN) <span style=\"color:#98df8a80;\"><p>Rave Omics: This is a product which helps detect diseases via the analysis of signals derived from Human DNA. (O-LN Legal Notifications Non-header)</p></span><br />6 H-TS) <span style=\"color:#1f77b4ff;\"><p>Synthetic Control Arms: Often times identifying a clinical trial patient population is a challenge and this product is used to ID patient populations which are hard to find. (H-TS Task Scope Header)</p></span><br />7 O-SP) <span style=\"color:#c49c9480;\"><b>Your Competencies: (O-SP Supplemental Pay Non-header)</b></span><br />8 O-TS) <span style=\"color:#1f77b480;\"><li>Be the technical SME for technical products. Design the architecture, build the solution (O-TS Task Scope Non-header)</li></span><br />9 O-TS) <span style=\"color:#1f77b480;\"><li>Interact with internal stakeholders such as product managers and scientists (O-TS Task Scope Non-header)</li></span><br />10 O-TS) <span style=\"color:#1f77b480;\"><li>Work with other engineers and technical members on implementation, integration and other development areas (O-TS Task Scope Non-header)</li></span><br />11 O-TS) <span style=\"color:#1f77b480;\"><li>Have strong product awareness skills and be able to translate business requirements into technical solutions (O-TS Task Scope Non-header)</li></span><br />12 O-TS) <span style=\"color:#1f77b480;\"><li>Development of application, data and deployment routines in a rapidly changing environment (O-TS Task Scope Non-header)</li></span><br />13 O-CS) <span style=\"color:#bcbd2280;\"><li>Create scalable, consumable, performant web applications geared towards an SOA environment (O-CS Corporate Scope Non-header)</li></span><br />14 O-TS) <span style=\"color:#1f77b480;\"><li>Suggests/ Identifies appropriate tools/technologies as needed to use for solution implementation (O-TS Task Scope Non-header)</li></span><br />15 O-TS) <span style=\"color:#1f77b480;\"><li>Take pride in code quality and deliverables (O-TS Task Scope Non-header)</li></span><br />16 H-RQ) <span style=\"color:#aec7e8ff;\"><b>Your Education &amp; Experience: (H-RQ Required Qualifications Header)</b></span><br /><hr />17 O-RQ) <span style=\"color:#aec7e880;\"><li>Requires a Bachelor’s degree and a minimum of 5 years of related experience in software engineering; or an advanced degree with 3 years of experience; or equivalent work experience (O-RQ Required Qualifications Non-header)</li></span><br />18 O-RQ) <span style=\"color:#aec7e880;\"><li>RESTful API design and development experience (O-RQ Required Qualifications Non-header)</li></span><br />19 O-RQ) <span style=\"color:#aec7e880;\"><li>Experience with third-party APIs and Web Services, API Gateways (O-RQ Required Qualifications Non-header)</li></span><br />20 O-RQ) <span style=\"color:#aec7e880;\"><li>Experience working on cloud infrastructure (AWS) (O-RQ Required Qualifications Non-header)</li></span><br />21 O-RQ) <span style=\"color:#aec7e880;\"><li>Experience with batch and/or stream processing (eg. Apache Kafka) (O-RQ Required Qualifications Non-header)</li></span><br />22 O-RQ) <span style=\"color:#aec7e880;\"><li>Knowledge and experience in web frameworks (O-RQ Required Qualifications Non-header)</li></span><br />23 O-RQ) <span style=\"color:#aec7e880;\"><li>A habit of leaving code cleaner than you found it (O-RQ Required Qualifications Non-header)</li></span><br />24 O-RQ) <span style=\"color:#aec7e880;\"><li>Experience working with large amounts of data (hundreds of GB+) is desirable (O-RQ Required Qualifications Non-header)</li></span><br /><hr />25 O-PQ) <span style=\"color:#ffbb7880;\"><li>Advantage if you have experience/proficiency with cloud technologies (IaaS, PaaS, serverless technology, NoSQL databases), micro-service design, CI/CD, scalable fault tolerant platform design, API design, and distributed systems operations in a DevOps model (O-PQ Preferred Qualifications Non-header)</li></span><br />26 O-PQ) <span style=\"color:#ffbb7880;\"><li>Clojure experience is a huge plus (O-PQ Preferred Qualifications Non-header)</li></span><br />27 O-CS) <span style=\"color:#bcbd2280;\"><p>Medidata is making a real difference in the lives of patients everywhere by accelerating critical drug and medical device development, enabling life-saving drugs and medical devices to get to market faster. Our products sit at the convergence of the Technology and Life Sciences industries, one of most exciting areas for global innovation. Nine of the top 10 best-selling drugs in 2017 were developed on the Medidata platform. (O-CS Corporate Scope Non-header)</p></span><br />28 O-TS) <span style=\"color:#1f77b480;\"><p>Medidata Solutions have powered over 17,000+ clinical trials giving us the largest collection of clinical trial data in the world. With this asset, we pioneer innovative, advanced applications and intelligent data analytics, bringing an unmatched level of quality and efficiency to clinical trials enabling treatments to reach waiting patients sooner. (O-TS Task Scope Non-header)</p></span><br />29 O-LN) <span style=\"color:#98df8a80;\"><i>Medidata Solutions, Inc. is an Equal Opportunity Employer. Medidata Solutions provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability status, protected veteran status, or any other characteristic protected by the law. Medidata Solutions complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. (O-LN Legal Notifications Non-header)</i></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 19, 20, 21, 22, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from matplotlib.colors import to_hex\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Make an RGB dictionary of all the parts-of-speech symbols\n",
    "rgba_dict = su.get_pos_color_dictionary()\n",
    "\n",
    "html_str = ''\n",
    "pos_list = []\n",
    "for i, (crf_symbol, db_symbol) in enumerate(zip(crf_list, db_pos_list)):\n",
    "    if db_symbol in [None, 'O', 'H']:\n",
    "        pos_list.append(crf_symbol)\n",
    "    else:\n",
    "        pos_list.append(db_symbol)\n",
    "print(pos_list)\n",
    "indices_list = su.get_section(pos_list)\n",
    "print(indices_list)\n",
    "for i, (child_str, pos_symbol) in enumerate(zip(child_strs_list, pos_list)):\n",
    "    rgba = rgba_dict[pos_symbol]\n",
    "    hex_str = to_hex(rgba, keep_alpha=True)\n",
    "    if len(indices_list) and (i == min(indices_list)):\n",
    "        html_str += '<hr />'\n",
    "    child_str = su.append_pos_symbol(child_str, pos_symbol, use_explanation=True)\n",
    "    html_str += f'{i+0} {pos_symbol}) <span style=\"color:{hex_str};\">{child_str}</span><br />'\n",
    "    if len(indices_list) and (i == max(indices_list)):\n",
    "        html_str += '<hr />'\n",
    "display(HTML(html_str))\n",
    "print(indices_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92043d-227f-423e-9890-bf1aa34b1303",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b32ce35-6670-4523-9d03-015542cb3818",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\n",
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<li>Experience working with large amounts of data (hundreds of GB+) is desirable</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label individual child strings\n",
    "idx = 24\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "if(child_str in basic_quals_dict):\n",
    "    print(basic_quals_dict[child_str])\n",
    "child_str = cu.clean_text(child_str)\n",
    "print(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f1b210b-8651-4291-8c80-046a9c896392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>Requires a Bachelor s degree and a minimum of 5 years of related experience in software engineering; or an advanced degree with 3 years of experience; or equivalent work experience</li>\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "# child_str = 'Spark, Camel, Python, R, Pyspark, Zepplin, Java, Scala'\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c905300c-bb4a-4e3d-b5cf-b474fbcec75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<li>Requires a Bachelor s degree and a minimum of 5 years of related experience in software engineering; or an advanced degree with 3 years of experience; or equivalent work experience</li>', 'is_header': 'False', 'is_task_scope': 'False', 'is_minimum_qualification': 'True', 'is_preferred_qualification': 'False', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'True', 'is_interview_procedure': 'False', 'is_corporate_scope': 'False', 'is_posting_date': 'False', 'is_other': 'False'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{child_str}'}})\n",
    "    SET\n",
    "        np.is_header = 'False',\n",
    "        np.is_task_scope = 'False',\n",
    "        np.is_minimum_qualification = 'True',\n",
    "        np.is_preferred_qualification = 'False',\n",
    "        np.is_legal_notification = 'False',\n",
    "        np.is_job_title = 'False',\n",
    "        np.is_office_location = 'False',\n",
    "        np.is_job_duration = 'False',\n",
    "        np.is_supplemental_pay = 'False',\n",
    "        np.is_educational_requirement = 'True',\n",
    "        np.is_interview_procedure = 'False',\n",
    "        np.is_corporate_scope = 'False',\n",
    "        np.is_posting_date = 'False',\n",
    "        np.is_other = 'False'\n",
    "    RETURN\n",
    "        np.navigable_parent AS navigable_parent,\n",
    "        np.is_header AS is_header,\n",
    "        np.is_task_scope AS is_task_scope,\n",
    "        np.is_minimum_qualification AS is_minimum_qualification,\n",
    "        np.is_preferred_qualification AS is_preferred_qualification,\n",
    "        np.is_legal_notification AS is_legal_notification,\n",
    "        np.is_job_title AS is_job_title,\n",
    "        np.is_office_location AS is_office_location,\n",
    "        np.is_job_duration AS is_job_duration,\n",
    "        np.is_supplemental_pay AS is_supplemental_pay,\n",
    "        np.is_educational_requirement AS is_educational_requirement,\n",
    "        np.is_interview_procedure AS is_interview_procedure,\n",
    "        np.is_corporate_scope AS is_corporate_scope,\n",
    "        np.is_posting_date AS is_posting_date,\n",
    "        np.is_other AS is_other;'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35154bbf-2823-4a19-835b-038d352f2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# See if this particualr chld string is in the database\n",
    "cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{child_str}'}})\n",
    "    RETURN\n",
    "        np.navigable_parent AS navigable_parent,\n",
    "        np.is_header AS is_header,\n",
    "        np.is_task_scope AS is_task_scope,\n",
    "        np.is_minimum_qualification AS is_minimum_qualification,\n",
    "        np.is_preferred_qualification AS is_preferred_qualification,\n",
    "        np.is_legal_notification AS is_legal_notification,\n",
    "        np.is_job_title AS is_job_title,\n",
    "        np.is_office_location AS is_office_location,\n",
    "        np.is_job_duration AS is_job_duration,\n",
    "        np.is_supplemental_pay AS is_supplemental_pay,\n",
    "        np.is_educational_requirement AS is_educational_requirement,\n",
    "        np.is_interview_procedure AS is_interview_procedure,\n",
    "        np.is_corporate_scope AS is_corporate_scope,\n",
    "        np.is_posting_date AS is_posting_date,\n",
    "        np.is_other AS is_other;'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b08e-874a-41db-a163-2232b9c7cc55",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b97db-00ab-4ab9-8a22-323bbb5c6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You've made no changes to the parts-of-speech symbols because it looks good as is\n",
    "file_name = cu.clean_text(file_name)\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_verfied = true;'''\n",
    "with cu.driver.session() as session:\n",
    "    session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5ce2c-5c8c-4196-96de-ee38953e10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the file name as needing retraining everywhere\n",
    "import numpy as np\n",
    "\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "mask_series = hunting_df.percent_fit.isin([file_name])\n",
    "hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "file_name = cu.clean_text(file_name)\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.percent_fit = NULL;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "970db600-c50f-49b3-adfc-4f11466fab97",
   "metadata": {},
   "source": [
    "\n",
    "# Mark all bad file names as needing retraining everywhere\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "mask_series = hunting_df.percent_fit.isin([0.0, 1.0])\n",
    "files_list = [cu.clean_text(fn) for fn in hunting_df[mask_series].file_name]\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.file_name IN {files_list} AND\n",
    "        fn.percent_fit IN [0.0, 1.0]\n",
    "    SET fn.percent_fit = NULL\n",
    "    RETURN fn.file_name AS file_name;'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = [list(row_obj.values())[0] for row_obj in row_objs_list]\n",
    "mask_series = hunting_df.file_name.isin(files_list)\n",
    "hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fed2d-c338-4070-837f-901464bf7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "import numpy as np\n",
    "\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = sorted([child_str for child_str in basic_quals_dict.keys()], key=lambda x: len(x), reverse=True)[0]\n",
    "print(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa007ae4-4df4-4f06-88e5-65e6e062a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "basic_quals_dict.pop(child_str)\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "child_str = cu.clean_text(child_str)\n",
    "cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: \"{child_str}\"}})-[r:NEXT]->(:NavigableParents)\n",
    "    RETURN r.file_name AS file_name;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "for row_obj in row_objs_list:\n",
    "    file_name = row_obj['file_name']\n",
    "    mask_series = hunting_df.file_name.isin([file_name])\n",
    "    hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "    s.store_objects(hunting_df=hunting_df)\n",
    "    file_name = cu.clean_text(file_name)\n",
    "    cypher_str = f'''\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        SET fn.percent_fit = NULL;'''\n",
    "    # print(cypher_str)\n",
    "    with cu.driver.session() as session:\n",
    "        session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d81bc-c3f5-4023-b38d-88ff000d2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find a qual in the dictionary with this substring\n",
    "sentence_regex = re.compile(r'[\\.;]')\n",
    "quals_set = set()\n",
    "concatonated_quals_list = sentence_regex.split(child_str.replace('<div>', '').replace('</div>', '').strip())\n",
    "for q in concatonated_quals_list:\n",
    "    q = q.strip()\n",
    "    if q:\n",
    "        quals_set.add(q)\n",
    "quals_list = list(quals_set)\n",
    "for q in quals_list:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736a1e7-d7ad-4220-8538-561d152ec2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
