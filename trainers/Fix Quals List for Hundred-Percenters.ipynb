{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb055c8-7f3e-4dd6-a2d0-fc7f70f0c5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7675b025-b593-4d53-9759-6c1e01772c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e9a76f-08eb-4a9c-9c53-4bf043e26661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92346a3f-3506-4e2c-b030-4f4fa74f78fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 15s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "%run ../load_magic/dataframes.py\n",
    "from pandas import DataFrame\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from hc_utils import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "from lr_utils import LrUtilities\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e95dd1-414a-44e8-a4b8-434285999d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 3,669 hand-labeled qualification strings in here\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_VOCAB.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_TT.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_LR.pkl\n",
      "Retraining complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lru.build_isheader_logistic_regression_elements()\n",
    "lru.build_pos_logistic_regression_elements()\n",
    "lru.build_isqualified_logistic_regression_elements()\n",
    "lru.retrain_from_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82dab229-b28c-4ddd-812d-6abf153aae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 78 more to go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "navigable_parent_cypher_str = '''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{}'}})\n",
    "    ''' + cu.return_everything_str + ';'\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit < 0.4 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_verfied IS NULL) OR (fn.is_verfied = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR\n",
    "        (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name,\n",
    "        fn.posting_url AS url\n",
    "    ORDER BY fn.percent_fit ASC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "print(f'Only {len(files_list)} more to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2f3ec-44ee-4be3-b13e-02badca41da4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "151cdf71-a078-43b6-9a1b-649bb51461e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6fae4ce593daa4a8_Principal_Product_Manager_Analytics_Seattle_WA_Indeed_com.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name = files_list.pop()\n",
    "# file_name = 'be05ef541335bb9d_Senior_Data_Scientist_Remote_Indeed_com.html'\n",
    "print(file_name)\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "page_soup = get_page_soup(file_path)\n",
    "div_soup = page_soup.find_all(name='div', id='jobDescriptionText')[0]\n",
    "child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "cu.ensure_filename(file_name, verbose=False)\n",
    "cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99fcd0c5-e0ac-431d-bacd-b22a7b5ed4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O-TS', 'O-TS', 'O-OL', 'O-CS', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-RQ', 'O-CS', 'O-TS', 'O-TS', 'O-CS', 'O-PQ', 'O-ER', 'O-RQ', 'O-RQ', 'O-TS', 'O-TS', 'O-TS', 'O-RQ', 'O-RQ', 'O-RQ', 'O-CS', 'O-TS', 'O-TS', 'O-CS', 'O-CS', 'O-CS', 'O-TS', 'O-CS', 'O-SP', 'O-SP', 'O-RQ', 'O-OL', 'O-CS', 'O-CS', 'O-CS']\n",
      "[11, 17, 18, 19, 23, 24, 25, 36]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 O-TS) <span style=\"color:#9edae580;\"><b>Principal Product Manager - Analytics (O-TS Task Scope Non-header)</b></span><br />1 O-TS) <span style=\"color:#9edae580;\"><p>Truveta is the world's first health provider-led data platform with a vision of Saving Lives with Data. Our mission is to enable researchers to find cures faster, empower every clinician to be an expert, and help families make the most informed decisions about their care. Achieving Truveta's ambitious vision requires an incredible team of talented and inspired people with a special combination of health, software and big data experience who share our company values. (O-TS Task Scope Non-header)</p></span><br />2 O-OL) <span style=\"color:#c49c9480;\"><i>Our headquarters are in the greater Seattle area, but we celebrate and embrace a remote culture. (O-OL Office Location Non-header)</i></span><br />3 O-CS) <span style=\"color:#1f77b480;\"><b>Who We Need (O-CS Corporate Scope Non-header)</b></span><br />4 O-TS) <span style=\"color:#9edae580;\"><p>Truveta is rapidly building a talented and diverse team to tackle complex health and technical challenges. Beyond core capabilities, we are seeking problem solvers, passionate and collaborative teammates, and those willing to roll up their sleeves while making a difference. If you are interested in the opportunity to pursue purposeful work, join a mission-driven team, and build a rewarding career while having fun, Truveta may be the perfect fit for you (O-TS Task Scope Non-header)</p></span><br />5 H-TS) <span style=\"color:#9edae5ff;\"><b>This Opportunity (H-TS Task Scope Header)</b></span><br />6 O-TS) <span style=\"color:#9edae580;\"><p>This is a role on our Analytics and Data Science team, which focuses on building the best analytics tools and experiences to analyze Truveta's unprecedented data. Analyzing tens of millions of data points is difficult; analyzing tens of millions of de-identified patient records takes that challenge to a whole new level. We are building a set of capabilities to allow clinical researchers fast and easy access to Truveta's data, create patient cohorts matching their criteria, and perform deep statistical analysis to support their research hypotheses. Ultimately, we want to build AI/ML models on top of one of the most comprehensive set of patients' longitudinal medical history to innovate clinical research in ways no one else can. (O-TS Task Scope Non-header)</p></span><br />7 O-TS) <span style=\"color:#9edae580;\"><p>On our team you will work with a world-class team of engineers, clinical informatics professionals, medical researchers, and product leaders to build the foundations of the Truveta research platform. You will push the envelope for leveraging healthcare data for the mission of improving patient care and the lives of patients. (O-TS Task Scope Non-header)</p></span><br />8 H-TS) <span style=\"color:#9edae5ff;\"><p>Do the following describe you? (H-TS Task Scope Header)</p></span><br />9 O-TS) <span style=\"color:#9edae580;\"><li>You are a product innovator who relentlessly drives innovation to solve customer problems (O-TS Task Scope Non-header)</li></span><br />10 O-TS) <span style=\"color:#9edae580;\"><li>You are a leader who likes to own &amp; define the end-to-end strategy for your area, building a product roadmap, and writing specifications to realize your product vision (O-TS Task Scope Non-header)</li></span><br /><hr />11 O-RQ) <span style=\"color:#bcbd2280;\"><li>You enjoy solving complex problems needed to drive simplicity in the user's experience (O-RQ Required Qualifications Non-header)</li></span><br />12 O-CS) <span style=\"color:#1f77b480;\"><li>You understand Truveta's strategic potential in changing the health care industry and have a strong desire to create industry-wide impact (O-CS Corporate Scope Non-header)</li></span><br />13 O-TS) <span style=\"color:#9edae580;\"><li>You are equally comfortable conversing in business and customer goals as well as having deeply technical discussions around data analysis and API design (O-TS Task Scope Non-header)</li></span><br />14 O-TS) <span style=\"color:#9edae580;\"><li>You are passionate about the rapidly evolving area of data science and using AI/ML models to help human researchers in analyzing large datasets (O-TS Task Scope Non-header)</li></span><br />15 O-CS) <span style=\"color:#1f77b480;\"><b>Key Qualifications (O-CS Corporate Scope Non-header)</b></span><br />16 O-PQ) <span style=\"color:#c7c7c780;\"><li>8+ years of experience in product management or related industry experience (O-PQ Preferred Qualifications Non-header)</li></span><br />17 O-ER) <span style=\"color:#aec7e880;\"><li>Bachelor's degree (or foreign degree equivalent) in Computer Science, Engineering, Analytics, Mathematics, Applied Sciences, or a related field (O-ER Education Requirements Non-header)</li></span><br />18 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience shipping products related to data analytics, data science, or data visualization (O-RQ Required Qualifications Non-header)</li></span><br />19 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong technical background with experience creating programmatic interfaces (APIs/SDK) (O-RQ Required Qualifications Non-header)</li></span><br />20 O-TS) <span style=\"color:#9edae580;\"><li>Proven leadership working with a broad, cross-functional team to drive product vision, define product requirements, coordinate resources from other groups (Design, Marketing, etc.), and guide the team through key milestones (O-TS Task Scope Non-header)</li></span><br />21 O-TS) <span style=\"color:#9edae580;\"><li>Experience gathering requirements across diverse areas and users and converting them into a product solution (O-TS Task Scope Non-header)</li></span><br />22 O-TS) <span style=\"color:#9edae580;\"><li>Comfortable driving complex and ambiguous projects across a diverse set of teams including customer sales &amp; success teams, clinicians, researchers, other product managers, and engineers (O-TS Task Scope Non-header)</li></span><br />23 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience analyzing complex, large-scale datasets and making data-driven decisions (O-RQ Required Qualifications Non-header)</li></span><br />24 O-RQ) <span style=\"color:#bcbd2280;\"><li>Demonstrated experience with real-world data, including EHR (Electronic Health Records) and insurance claims (O-RQ Required Qualifications Non-header)</li></span><br />25 O-RQ) <span style=\"color:#bcbd2280;\"><li>Proven written and verbal communication skills (O-RQ Required Qualifications Non-header)</li></span><br />26 O-CS) <span style=\"color:#1f77b480;\"><li>Experience working as a product manager in the healthcare technology domain is a plus (O-CS Corporate Scope Non-header)</li></span><br />27 O-TS) <span style=\"color:#9edae580;\"><li>Familiarity with clinical research processes including analyzing data to discover, validate, or support a hypothesis is a plus (O-TS Task Scope Non-header)</li></span><br />28 O-TS) <span style=\"color:#9edae580;\"><li>Working knowledge of using Jupyter notebooks, Python and R in data science projects, is nice to have (O-TS Task Scope Non-header)</li></span><br />29 O-CS) <span style=\"color:#1f77b480;\"><b>Why Truveta? (O-CS Corporate Scope Non-header)</b></span><br />30 O-CS) <span style=\"color:#1f77b480;\"><p>Be a part of building something special. Now is the perfect time to join Truveta. We have strong, established leadership with decades of success. We are well-funded. We are building a culture that prioritizes people and their passions across personal, professional and everything in between. Join us as we build an amazing company together. (O-CS Corporate Scope Non-header)</p></span><br />31 O-CS) <span style=\"color:#1f77b480;\"><p>We offer: (O-CS Corporate Scope Non-header)</p></span><br />32 O-TS) <span style=\"color:#9edae580;\"><li>Interesting and meaningful work for every career stage (O-TS Task Scope Non-header)</li></span><br />33 O-CS) <span style=\"color:#1f77b480;\"><li>Competitive compensation (O-CS Corporate Scope Non-header)</li></span><br />34 O-SP) <span style=\"color:#17becf80;\"><li>Comprehensive benefits for grown-ups, with strong medical, dental and vision insurance plans (O-SP Supplemental Pay Non-header)</li></span><br />35 O-SP) <span style=\"color:#17becf80;\"><li>401K plan (O-SP Supplemental Pay Non-header)</li></span><br />36 O-RQ) <span style=\"color:#bcbd2280;\"><li>Professional development for continuous learning (O-RQ Required Qualifications Non-header)</li></span><br /><hr />37 O-OL) <span style=\"color:#c49c9480;\"><li>Work/life autonomy via flexible work hours and flexible paid time off (O-OL Office Location Non-header)</li></span><br />38 O-CS) <span style=\"color:#1f77b480;\"><li>Generous parental leave (O-CS Corporate Scope Non-header)</li></span><br />39 O-CS) <span style=\"color:#1f77b480;\"><li>Regular team activities (virtual and in-person as soon as we are able) (O-CS Corporate Scope Non-header)</li></span><br />40 O-CS) <span style=\"color:#1f77b480;\"><p>Truveta is committed to creating a diverse, inclusive, and empowering workplace. We believe that having employees, interns, and contractors with diverse backgrounds enables Truveta to better meet our mission and serve patients and health communities around the world. We recognize that opportunities in technology historically excluded and continue to disproportionately exclude Black and Indigenous people, people of color, people from working class backgrounds, people with disabilities, and LGBTQIA+ people. We strongly encourage individuals with these identities to apply even if you do not meet all the requirements. (O-CS Corporate Scope Non-header)</p></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 17, 18, 19, 23, 24, 25, 36]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32ce35-6670-4523-9d03-015542cb3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 17, 18, 19, 23, 24, 25, 36]\n",
      "12 O-CS) <li>You understand Truveta's strategic potential in changing the health care industry and have a strong desire to create industry-wide impact</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label individual child strings\n",
    "idx = 12\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f1b210b-8651-4291-8c80-046a9c896392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>You enjoy solving complex problems needed to drive simplicity in the user's experience</li>\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c905300c-bb4a-4e3d-b5cf-b474fbcec75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<li>You are a leader who likes to own &amp; define the end-to-end strategy for your area, building a product roadmap, and writing specifications to realize your product vision</li>', 'is_header': 'False', 'is_task_scope': 'False', 'is_minimum_qualification': 'True', 'is_preferred_qualification': 'False', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'False', 'is_interview_procedure': 'False', 'is_corporate_scope': 'False', 'is_posting_date': 'False', 'is_other': 'False'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "child_str = cu.clean_text(child_str); cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{child_str}'}})\n",
    "    SET\n",
    "        np.is_header = 'False',\n",
    "        np.is_task_scope = 'False',\n",
    "        np.is_minimum_qualification = 'True',\n",
    "        np.is_preferred_qualification = 'False',\n",
    "        np.is_educational_requirement = 'False',\n",
    "        np.is_legal_notification = 'False',\n",
    "        np.is_other = 'False',\n",
    "        np.is_corporate_scope = 'False',\n",
    "        np.is_job_title = 'False',\n",
    "        np.is_office_location = 'False',\n",
    "        np.is_job_duration = 'False',\n",
    "        np.is_supplemental_pay = 'False',\n",
    "        np.is_interview_procedure = 'False',\n",
    "        np.is_posting_date = 'False'\n",
    "    {cu.return_everything_str};'''\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28836b66-b8d4-48cb-92a0-f28efbb39c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "# print(navigable_parent_cypher_str.format(child_str))\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, navigable_parent_cypher_str.format(child_str))\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b08e-874a-41db-a163-2232b9c7cc55",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbe5ce2c-5c8c-4196-96de-ee38953e10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\hunting_df.pkl\n",
      "\n",
      "    MATCH (fn:FileNames {file_name: \"e77c49429023eed4_Senior_Data_Scientist_Analytics_Boston_MA_Indeed_com.html\"})\n",
      "    SET fn.percent_fit = NULL, fn.is_verfied = false\n",
      "    RETURN fn;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node id=766046 labels=frozenset({'FileNames'}) properties={'file_name': 'e77c49429023eed4_Senior_Data_Scientist_Analytics_Boston_MA_Indeed_com.html', 'is_verfied': False}>}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Mark the file name as needing retraining everywhere\n",
    "import numpy as np\n",
    "\n",
    "mask_series = lru.hunting_df.percent_fit.isin([file_name])\n",
    "lru.hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=lru.hunting_df)\n",
    "file_name = cu.clean_text(file_name)\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.percent_fit = NULL, fn.is_verfied = false\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b97db-00ab-4ab9-8a22-323bbb5c6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You've made no changes to the parts-of-speech symbols because it looks good as is\n",
    "file_name = cu.clean_text(file_name)\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_verfied = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8adbd-5b7c-43d8-8680-aea4da63a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the file name as closed\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_closed = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142fab4-fb6e-458a-a717-cad92b90f255",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Prepare cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96965b4-3398-434a-96aa-f19479649305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# file_name = 'Senior_Machine_Learning_Engineer_Remote.html'\n",
    "lru.build_isqualified_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_from_dictionary(verbose=False)\n",
    "# child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, crf_list=crf_list, file_name=file_name)\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "lru.basic_quals_dict = basic_quals_dict\n",
    "quals_str, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "job_title = file_name.replace('.html', '').replace('_Indeed_com', '').replace('_', ' ')\n",
    "display(HTML(f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7b2a4-d443-4cdd-86ad-a7f4938d4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(HTML(f\"<p>The minimum requirements for the {job_title} position that I don't meet are:</p>\"))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if (qual_str not in basic_quals_dict) or not basic_quals_dict[qual_str]:\n",
    "        idx = qual_str.find('>')\n",
    "        if idx == -1:\n",
    "            display(HTML(f'{i+1}) {qual_str}'))\n",
    "        else:\n",
    "            display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d705f1-6522-416e-a223-682fdfd6e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(HTML(f\"<p>The preferred requirements for the {job_title} position that I meet are:</p>\"))\n",
    "indices_list = [i for i, x in enumerate(pos_list) if (x in ['O-PQ'])]\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9664-96e1-43cb-8de7-99e40d5524f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[13]\n",
    "print(qualification_str)\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57806a7-1f0b-498c-bb71-b5713424cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "lru.basic_quals_dict = basic_quals_dict\n",
    "quals_str, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "job_title = file_name.replace('.html', '').replace('_', ' ')\n",
    "display(HTML(f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed07b0-bedf-4d82-a06d-dbab85962b83",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "raw",
   "id": "970db600-c50f-49b3-adfc-4f11466fab97",
   "metadata": {},
   "source": [
    "\n",
    "# Mark all bad file names as needing retraining everywhere\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "mask_series = hunting_df.percent_fit.isin([0.0, 1.0])\n",
    "files_list = [cu.clean_text(fn) for fn in hunting_df[mask_series].file_name]\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.file_name IN {files_list} AND\n",
    "        fn.percent_fit IN [0.0, 1.0]\n",
    "    SET fn.percent_fit = NULL\n",
    "    RETURN fn.file_name AS file_name;'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = [list(row_obj.values())[0] for row_obj in row_objs_list]\n",
    "mask_series = hunting_df.file_name.isin(files_list)\n",
    "hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fed2d-c338-4070-837f-901464bf7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "import numpy as np\n",
    "\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = sorted([child_str for child_str in basic_quals_dict.keys()], key=lambda x: len(x), reverse=True)[0]\n",
    "print(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa007ae4-4df4-4f06-88e5-65e6e062a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "basic_quals_dict.pop(child_str)\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "child_str = cu.clean_text(child_str)\n",
    "cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: \"{child_str}\"}})-[r:NEXT]->(:NavigableParents)\n",
    "    RETURN r.file_name AS file_name;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "for row_obj in row_objs_list:\n",
    "    file_name = row_obj['file_name']\n",
    "    mask_series = hunting_df.file_name.isin([file_name])\n",
    "    hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "    s.store_objects(hunting_df=hunting_df)\n",
    "    file_name = cu.clean_text(file_name)\n",
    "    cypher_str = f'''\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        SET fn.percent_fit = NULL;'''\n",
    "    # print(cypher_str)\n",
    "    with cu.driver.session() as session:\n",
    "        session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d81bc-c3f5-4023-b38d-88ff000d2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find a qual in the dictionary with this substring\n",
    "sentence_regex = re.compile(r'[\\.;]')\n",
    "quals_set = set()\n",
    "concatonated_quals_list = sentence_regex.split(child_str.replace('<div>', '').replace('</div>', '').strip())\n",
    "for q in concatonated_quals_list:\n",
    "    q = q.strip()\n",
    "    if q:\n",
    "        quals_set.add(q)\n",
    "quals_list = list(quals_set)\n",
    "for q in quals_list:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ac635-33fe-46d5-a1c3-e369b3a86f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513d5c4-7d91-43ea-9e62-0e670e7d7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(quals_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81df4c0-9f22-41ff-9c59-83862cdea0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe3a9a-8b2b-4bfc-b348-ce01a188c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
