{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb055c8-7f3e-4dd6-a2d0-fc7f70f0c5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7675b025-b593-4d53-9759-6c1e01772c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e9a76f-08eb-4a9c-9c53-4bf043e26661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92346a3f-3506-4e2c-b030-4f4fa74f78fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3033, 2)\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_VOCAB.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_TT.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_LR.pkl\n",
      "Retraining complete\n",
      "CPU times: total: 2min 45s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from pandas import DataFrame\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from hc_utils import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "from lr_utils import LrUtilities\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "lru.build_isheader_logistic_regression_elements()\n",
    "lru.build_pos_logistic_regression_elements()\n",
    "lru.build_isqualified_logistic_regression_elements()\n",
    "lru.retrain_from_dictionary()\n",
    "\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a01bd1-d9a1-46b7-8012-ebb4258cae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../load_magic/dataframes.py\n",
    "\n",
    "return_everything_str = '''RETURN\n",
    "        np.navigable_parent AS navigable_parent,\n",
    "        np.is_header AS is_header,\n",
    "        np.is_task_scope AS is_task_scope,\n",
    "        np.is_minimum_qualification AS is_minimum_qualification,\n",
    "        np.is_preferred_qualification AS is_preferred_qualification,\n",
    "        np.is_legal_notification AS is_legal_notification,\n",
    "        np.is_job_title AS is_job_title,\n",
    "        np.is_office_location AS is_office_location,\n",
    "        np.is_job_duration AS is_job_duration,\n",
    "        np.is_supplemental_pay AS is_supplemental_pay,\n",
    "        np.is_educational_requirement AS is_educational_requirement,\n",
    "        np.is_interview_procedure AS is_interview_procedure,\n",
    "        np.is_corporate_scope AS is_corporate_scope,\n",
    "        np.is_posting_date AS is_posting_date,\n",
    "        np.is_other AS is_other'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e95dd1-414a-44e8-a4b8-434285999d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "navigable_parent_cypher_str = '''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{}'}})\n",
    "    ''' + return_everything_str + ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dab229-b28c-4ddd-812d-6abf153aae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit IN [0.0, 1.0] AND\n",
    "        ((fn.is_verfied IS NULL) OR (fn.is_verfied = false)) AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN fn.file_name AS file_name\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = []\n",
    "if row_objs_list:\n",
    "    files_list = DataFrame(row_objs_list).file_name.tolist()\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2f3ec-44ee-4be3-b13e-02badca41da4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "151cdf71-a078-43b6-9a1b-649bb51461e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_Science_Marketing_Specialist_-_Madison,_WI_53705_-_Indeed.com_ea76c75716af82e7.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# file_name = files_list.pop()\n",
    "file_name = 'Data_Science_Marketing_Specialist_-_Madison,_WI_53705_-_Indeed.com_ea76c75716af82e7.html'\n",
    "print(file_name)\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "page_soup = get_page_soup(file_path)\n",
    "div_soup = page_soup.find_all(name='div', id='jobDescriptionText')[0]\n",
    "child_strs_list = ha.get_navigable_children(div_soup, [])\n",
    "cu.ensure_filename(file_name, verbose=False)\n",
    "cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "id": "99fcd0c5-e0ac-431d-bacd-b22a7b5ed4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O-TS', 'O-CS', 'O-TS', 'O-TS', 'O-RQ', 'O-TS', 'O-CS', 'O-RQ', 'O-TS', 'O-CS', 'O-CS', 'O-TS', 'H-OL', 'O-TS', 'O-OL', 'H-TS', 'O-CS', 'O-CS', 'O-TS', 'O-SP', 'O-SP', 'O-TS', 'O-TS', 'H-RQ', 'O-ER', 'O-RQ', 'O-RQ', 'O-PQ', 'O-CS', 'O-CS', 'O-SP', 'O-CS', 'O-CS', 'O-O', 'O-IP', 'O-CS', 'O-CS']\n",
      "[4, 7, 24, 25, 26]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 O-TS) <span style=\"color:#9edae580;\"><b>Data Science Marketing Specialist (O-TS Task Scope Non-header)</b></span><br />1 O-CS) <span style=\"color:#1f77b480;\"><b>Description: (O-CS Corporate Scope Non-header)</b></span><br />2 O-TS) <span style=\"color:#9edae580;\"><p>As a Data Science Marketing Specialist at SmartUQ, you will develop, lead, and evolve data science (O-TS Task Scope Non-header)</p></span><br />3 O-TS) <span style=\"color:#9edae580;\"><p>marketing initiatives and activities for SmartUQ. You will also have opportunities to work on data (O-TS Task Scope Non-header)</p></span><br /><hr />4 O-RQ) <span style=\"color:#bcbd2280;\"><p>science projects with clients and partners in a variety of engineering fields, such as aerospace, (O-RQ Required Qualifications Non-header)</p></span><br />5 O-TS) <span style=\"color:#9edae580;\"><p>automotive, heavy equipment, semiconductor, medical device, energy and consumer product. (O-TS Task Scope Non-header)</p></span><br />6 O-CS) <span style=\"color:#1f77b480;\"><b>Who We Are: (O-CS Corporate Scope Non-header)</b></span><br />7 O-RQ) <span style=\"color:#bcbd2280;\"><p>SmartUQ (SmartUQ.com) develops advanced predictive analytics, machine learning, and (O-RQ Required Qualifications Non-header)</p></span><br />8 O-TS) <span style=\"color:#9edae580;\"><p>uncertainty quantification to solve difficult challenges and accelerate innovation in a wide range of (O-TS Task Scope Non-header)</p></span><br />9 O-CS) <span style=\"color:#1f77b480;\"><p>engineering fields. Our software is used by some of the largest engineering companies in the world. (O-CS Corporate Scope Non-header)</p></span><br />10 O-CS) <span style=\"color:#1f77b480;\"><p>We have a fun and focused team who are passionate about helping our customers solve challenging (O-CS Corporate Scope Non-header)</p></span><br />11 O-TS) <span style=\"color:#9edae580;\"><p>problems where no off-the-shelf solutions exist. (O-TS Task Scope Non-header)</p></span><br />12 H-OL) <span style=\"color:#c49c94ff;\"><b>Location: (H-OL Office Location Header)</b></span><br />13 O-TS) <span style=\"color:#9edae580;\"><p>Near the UW-Madison campus on University Avenue close to the Hilldale Shopping Center. (O-TS Task Scope Non-header)</p></span><br />14 O-OL) <span style=\"color:#c49c9480;\"><p>Remote work for 2021 due to the COVID-19. (O-OL Office Location Non-header)</p></span><br />15 H-TS) <span style=\"color:#9edae5ff;\"><b>Responsibilities: (H-TS Task Scope Header)</b></span><br />16 O-CS) <span style=\"color:#1f77b480;\"><li>Develop online marketing efforts across company website including SEO, PPC, email (O-CS Corporate Scope Non-header)</li></span><br />17 O-CS) <span style=\"color:#1f77b480;\">marketing, digital campaigns, etc (O-CS Corporate Scope Non-header)</span><br />18 O-TS) <span style=\"color:#9edae580;\"><li>Draft marketing contents and messages (O-TS Task Scope Non-header)</li></span><br />19 O-SP) <span style=\"color:#17becf80;\"><li>Create company videos (O-SP Supplemental Pay Non-header)</li></span><br />20 O-SP) <span style=\"color:#17becf80;\"><li>Coordinate webinars and other company events (O-SP Supplemental Pay Non-header)</li></span><br />21 O-TS) <span style=\"color:#9edae580;\"><li>Work with engineering, product development, sales and business development teams to (O-TS Task Scope Non-header)</li></span><br />22 O-TS) <span style=\"color:#9edae580;\"><p>provide cross-department solutions (O-TS Task Scope Non-header)</p></span><br />23 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Qualifications: (H-RQ Required Qualifications Header)</b></span><br />24 O-ER) <span style=\"color:#aec7e880;\"><li>Bachelor's degree in statistics or engineering (O-ER Education Requirements Non-header)</li></span><br />25 O-RQ) <span style=\"color:#bcbd2280;\"><li>Excellent communication skills both written and verbally (O-RQ Required Qualifications Non-header)</li></span><br />26 O-RQ) <span style=\"color:#bcbd2280;\"><li>Attention to detail and focus on quality of deliverables (O-RQ Required Qualifications Non-header)</li></span><br /><hr />27 O-PQ) <span style=\"color:#c7c7c780;\"><li>Background in marketing is a plus but not required. (O-PQ Preferred Qualifications Non-header)</li></span><br />28 O-CS) <span style=\"color:#1f77b480;\"><p>At SmartUQ, we have created new technologies to revolutionize the analytics market. We are (O-CS Corporate Scope Non-header)</p></span><br />29 O-CS) <span style=\"color:#1f77b480;\"><p>passionate about using our technology to create products that will make a difference in the world. (O-CS Corporate Scope Non-header)</p></span><br />30 O-SP) <span style=\"color:#17becf80;\"><p>Compensation is commensurate with your expertise. (O-SP Supplemental Pay Non-header)</p></span><br />31 O-CS) <span style=\"color:#1f77b480;\">SmartUQ, 3545 University Ave. Madison WI, 53705. P: (608)255-2440 (O-CS Corporate Scope Non-header)</span><br />32 O-CS) <span style=\"color:#1f77b480;\">www.SmartUQ.com (O-CS Corporate Scope Non-header)</span><br />33 O-O) <span style=\"color:#8c564b80;\"><p>If you feel that you would be a good fit for our team, join us today and submit your cover letter (O-O Other Non-header)</p></span><br />34 O-IP) <span style=\"color:#ffbb7880;\"><p>and resume to hiring@smartuq.com with “Data Science Marketing Specialist” in the subject line. (O-IP Interview Procedures Non-header)</p></span><br />35 O-CS) <span style=\"color:#1f77b480;\">SmartUQ, 3545 University Ave, Madison WI, 53705. P: (608)255-2440 (O-CS Corporate Scope Non-header)</span><br />36 O-CS) <span style=\"color:#1f77b480;\">www.SmartUQ.com (O-CS Corporate Scope Non-header)</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 24, 25, 26]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32ce35-6670-4523-9d03-015542cb3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 O-ER) <li>Bachelor's degree in statistics or engineering</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label individual child strings\n",
    "idx = 24\n",
    "child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "3f1b210b-8651-4291-8c80-046a9c896392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>Ability to function in and lead an agile team with frequent code releases.</li>\" in basic_quals_dict: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "c905300c-bb4a-4e3d-b5cf-b474fbcec75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<p>SmartUQ (SmartUQ.com) develops advanced predictive analytics, machine learning, and</p>', 'is_header': 'False', 'is_task_scope': 'False', 'is_minimum_qualification': 'False', 'is_preferred_qualification': 'False', 'is_legal_notification': 'False', 'is_job_title': 'False', 'is_office_location': 'False', 'is_job_duration': 'False', 'is_supplemental_pay': 'False', 'is_educational_requirement': 'False', 'is_interview_procedure': 'False', 'is_corporate_scope': 'True', 'is_posting_date': 'False', 'is_other': 'False'}]"
      ]
     },
     "execution_count": 1041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "child_str = cu.clean_text(child_str); cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{child_str}'}})\n",
    "    SET\n",
    "        np.is_header = 'False',\n",
    "        np.is_task_scope = 'False',\n",
    "        np.is_minimum_qualification = 'False',\n",
    "        np.is_preferred_qualification = 'False',\n",
    "        np.is_educational_requirement = 'False',\n",
    "        np.is_legal_notification = 'False',\n",
    "        np.is_other = 'False',\n",
    "        np.is_corporate_scope = 'True',\n",
    "        np.is_job_title = 'False',\n",
    "        np.is_office_location = 'False',\n",
    "        np.is_job_duration = 'False',\n",
    "        np.is_supplemental_pay = 'False',\n",
    "        np.is_interview_procedure = 'False',\n",
    "        np.is_posting_date = 'False'\n",
    "    {return_everything_str};'''\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28836b66-b8d4-48cb-92a0-f28efbb39c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "# print(navigable_parent_cypher_str.format(child_str))\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, navigable_parent_cypher_str.format(child_str))\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b08e-874a-41db-a163-2232b9c7cc55",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "dbe5ce2c-5c8c-4196-96de-ee38953e10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\hunting_df.pkl\n",
      "\n",
      "    MATCH (fn:FileNames {file_name: \"e1db3c3e9881536e_Senior_Software_Engineer_IOT_AI_Python_Clojure_Kafka_Remote_Indeed_com.html\"})\n",
      "    SET fn.percent_fit = NULL, fn.is_verfied = false\n",
      "    RETURN fn;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node id=800468 labels=frozenset({'FileNames'}) properties={'file_name': 'e1db3c3e9881536e_Senior_Software_Engineer_IOT_AI_Python_Clojure_Kafka_Remote_Indeed_com.html', 'posting_url': 'https://www.indeed.com/rc/clk/dl?jk=e1db3c3e9881536e&from=ja&qd=RnZhMybXSk4M3QtTVGXWoZj-R_bxcYib5xeGNtZ7GZZCz9IDoAfw9Pn-C-g9mkpdOSc52OjgArjyV5yiFpuqp5qA1NCNQVI9fbkRsSzBsL8&rd=v1-HcdjGhgpDNCskhCHpOQbXCHXgJEVMrHKBS2mW9rM&tk=1g691kiaugv2v800&alid=6254377b33b425113af40aa2', 'is_verfied': False}>}]"
      ]
     },
     "execution_count": 1034,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Mark the file name as needing retraining everywhere\n",
    "import numpy as np\n",
    "\n",
    "mask_series = lru.hunting_df.percent_fit.isin([file_name])\n",
    "lru.hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=lru.hunting_df)\n",
    "file_name = cu.clean_text(file_name)\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.percent_fit = NULL, fn.is_verfied = false\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<b>A strong candidate will also have</b>\" in basic_quals_dict: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "f00b97db-00ab-4ab9-8a22-323bbb5c6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    MATCH (fn:FileNames {file_name: \"1007942473548_REMOTE_Machine_Learning_Engineer_Scala_Spark_HDFS_Kafka_exp_req.html\"})\n",
      "    SET fn.is_verfied = true\n",
      "    RETURN fn;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fn': <Node id=779161 labels=frozenset({'FileNames'}) properties={'file_name': '1007942473548_REMOTE_Machine_Learning_Engineer_Scala_Spark_HDFS_Kafka_exp_req.html', 'percent_fit': 0.2, 'posting_url': 'https://www.glassdoor.com/partner/jobListing.htm?pos=104&ao=1110586&s=257&guid=0000018181accf2cb2519594576e938e&src=GD_JOB_AD&t=JA&vt=e&uido=D4EF7B3C079902263168F19360ADF10F&ea=1&cs=1_999f7610&cb=1655737995467&jobListingId=1007942473548&cpc=83630893E902B957&jrtk=3-0-1g60qpk17k24s801-1g60qpk1tk632800-29dc722459419df1--6NYlbfkN0AIiLXtwtv0BDns9BiY4ItblantFozdL6jLmLxNvS8mvgNhVHnAPNyrRMg00-pQP-PZGxb57-iGy38WEBT2u49x765kGi3EW0bn3QrwMGkj6ihcKML0lRrY3nxDdnujbf9BPF-Pf8JePAx098LMAN2cC0VaDUpGNsKhmtI55_zNTCUuGIYKKANL24aQx87egXenRNK2NoZGYHzb2UgYpwWknaJTSWM_DQAESrgOAPCe0VsnC_MPgqrbRR__QF_Yq9-C3F-BlK4CI9DrbRRWr_2eEDKlafFiacS1pVRh3DMWG4cBaAzA9WyJkziQe1X_oJYqn_XWyEVuE3cwtQUyfZK1JrQfOX1n3bR16A0ts5H2vg6x8V9pDEDE6yxEZf1lhvBvHOjJRAqlBpe3LTOgmvOYXqGTfdSqQObZYnMhC7XWHt28t7f8QlFhXfS81qrqqzaCMoeZvB1De66b8W_WAJ5Meo1twqeo-khPw46dJi5zL36TyDoCT1xKEJYKi0u6vekl73qLNCJAxIP5OM_g-8sH-LSGOvHcHIYArHQynG7LuHoUAA0uDV1ei3VBpRyjlTwdJfvY_2aIOBvQh6_MIhIP&ja=203099456&utm_medium=email&utm_source=jobalert&utm_campaign=jobAlertAlert&utm_content=ja-jobpos9-1007942473548', 'is_verfied': True}>}]"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# You've made no changes to the parts-of-speech symbols because it looks good as is\n",
    "file_name = cu.clean_text(file_name)\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_verfied = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8adbd-5b7c-43d8-8680-aea4da63a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the file name as closed\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "    SET fn.is_closed = true\n",
    "    RETURN fn;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142fab4-fb6e-458a-a717-cad92b90f255",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Prepare cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "c96965b4-3398-434a-96aa-f19479649305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>I only meet 83.3% of the minimum requirements for the 50a73dc4a517a6bd Data Science and Analytics Lead Boston MA Indeed com position, but I can explain:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>2) Comfort with statistical methods including frequentist statistics, regression modeling, and hypothesis testing</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>3) Competency working scalably with Python (or R) and leveraging them to deliver analytical insights</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>4) Comfort with modern data analytics and BI environments such as Jupyter, Dash, Quicksight, etc.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>5) Great communication skills and can work comfortably with technical and non-technical stakeholders to develop requirements</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>6) Advanced degree in statistics, mathematics, applied analytics, or other related field</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# file_name = 'Senior_Machine_Learning_Engineer_Remote.html'\n",
    "lru.build_isqualified_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_from_dictionary(verbose=False)\n",
    "# child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, crf_list=crf_list, file_name=file_name)\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "lru.basic_quals_dict = basic_quals_dict\n",
    "quals_str, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "job_title = file_name.replace('.html', '').replace('_', ' ')\n",
    "display(HTML(f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "0ef7b2a4-d443-4cdd-86ad-a7f4938d4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The minimum requirements for the 50a73dc4a517a6bd Data Science and Analytics Lead Boston MA Indeed com position that I don't meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>1) 4+ years of experience successfully developing and delivering actionable analytical reports, ideally in a space similar to ours (startup, healthcare, regulated data)</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(HTML(f\"<p>The minimum requirements for the {job_title} position that I don't meet are:</p>\"))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if (qual_str not in basic_quals_dict) or not basic_quals_dict[qual_str]:\n",
    "        idx = qual_str.find('>')\n",
    "        if idx == -1:\n",
    "            display(HTML(f'{i+1}) {qual_str}'))\n",
    "        else:\n",
    "            display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9664-96e1-43cb-8de7-99e40d5524f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[2]\n",
    "print(qualification_str)\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57806a7-1f0b-498c-bb71-b5713424cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "lru.basic_quals_dict = basic_quals_dict\n",
    "quals_str, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "job_title = file_name.replace('.html', '').replace('_', ' ')\n",
    "display(HTML(f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed07b0-bedf-4d82-a06d-dbab85962b83",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "raw",
   "id": "970db600-c50f-49b3-adfc-4f11466fab97",
   "metadata": {},
   "source": [
    "\n",
    "# Mark all bad file names as needing retraining everywhere\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "mask_series = hunting_df.percent_fit.isin([0.0, 1.0])\n",
    "files_list = [cu.clean_text(fn) for fn in hunting_df[mask_series].file_name]\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.file_name IN {files_list} AND\n",
    "        fn.percent_fit IN [0.0, 1.0]\n",
    "    SET fn.percent_fit = NULL\n",
    "    RETURN fn.file_name AS file_name;'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "files_list = [list(row_obj.values())[0] for row_obj in row_objs_list]\n",
    "mask_series = hunting_df.file_name.isin(files_list)\n",
    "hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fed2d-c338-4070-837f-901464bf7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "import numpy as np\n",
    "\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = sorted([child_str for child_str in basic_quals_dict.keys()], key=lambda x: len(x), reverse=True)[0]\n",
    "print(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa007ae4-4df4-4f06-88e5-65e6e062a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark the files with the largest qualification (implying it was run together) as needing to be retrained\n",
    "basic_quals_dict.pop(child_str)\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "child_str = cu.clean_text(child_str)\n",
    "cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: \"{child_str}\"}})-[r:NEXT]->(:NavigableParents)\n",
    "    RETURN r.file_name AS file_name;'''\n",
    "print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "for row_obj in row_objs_list:\n",
    "    file_name = row_obj['file_name']\n",
    "    mask_series = hunting_df.file_name.isin([file_name])\n",
    "    hunting_df.loc[mask_series, 'percent_fit'] = np.nan\n",
    "    s.store_objects(hunting_df=hunting_df)\n",
    "    file_name = cu.clean_text(file_name)\n",
    "    cypher_str = f'''\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        SET fn.percent_fit = NULL;'''\n",
    "    # print(cypher_str)\n",
    "    with cu.driver.session() as session:\n",
    "        session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d81bc-c3f5-4023-b38d-88ff000d2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find a qual in the dictionary with this substring\n",
    "sentence_regex = re.compile(r'[\\.;]')\n",
    "quals_set = set()\n",
    "concatonated_quals_list = sentence_regex.split(child_str.replace('<div>', '').replace('</div>', '').strip())\n",
    "for q in concatonated_quals_list:\n",
    "    q = q.strip()\n",
    "    if q:\n",
    "        quals_set.add(q)\n",
    "quals_list = list(quals_set)\n",
    "for q in quals_list:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ac635-33fe-46d5-a1c3-e369b3a86f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513d5c4-7d91-43ea-9e62-0e670e7d7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(quals_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81df4c0-9f22-41ff-9c59-83862cdea0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe3a9a-8b2b-4bfc-b348-ce01a188c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
