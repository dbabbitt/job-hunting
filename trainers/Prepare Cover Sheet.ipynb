{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174c9bb2-7d08-4fa2-aa2b-e3be342e52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2c4fa-fe66-4b71-9899-4b533c04515b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06fd23c4-353b-4800-973d-785e63a9856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "import humanize\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import winsound\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42298f7-a9cc-4d21-871b-bf2abf92b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage(\n",
    "    data_folder_path=os.path.abspath('../data'),\n",
    "    saves_folder_path=os.path.abspath('../saves')\n",
    ")\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(\n",
    "    s=s,\n",
    "    secrets_json_path=os.path.abspath('../data/secrets/jh_secrets.json')\n",
    ")\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "# Get the neo4j object\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(\n",
    "    uri=uri, user=user, password=password, driver=None, s=s, ha=ha\n",
    ")\n",
    "\n",
    "try:\n",
    "    version_str = cu.driver.get_server_info().agent\n",
    "    print(f'======== {version_str} ========')\n",
    "except ServiceUnavailable as e:\n",
    "    print('You need to start Neo4j as a console')\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__}: {str(e).strip()}')\n",
    "\n",
    "from hc_utils import HeaderCategories\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "\n",
    "from lr_utils import LrUtilities\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, lru=lru, verbose=True)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, wsu=wsu, cu=cu, crf=crf, verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Utility libraries created in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551caae7-a91c-44fd-a2a8-fcd00dd454e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 350,840 is-qualified vocabulary keys in here\n",
      "Is-qualified LR elements built in 1 minute and 33 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has built its is-qualified classifier\n",
    "t0 = time.time()\n",
    "if not hasattr(lru, 'ISQUALIFIED_LR'):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=5_000, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified LR elements built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822b9227-0511-48de-8521-d026b71ecf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 81,585 hand-labeled header htmls in here\n",
      "Is-header classifier retrained in 23 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has retrained its is-header classifier\n",
    "t0 = time.time()\n",
    "if not hasattr(lru, 'ISHEADER_PREDICT_PERCENT_FIT'):\n",
    "    if not hasattr(lru, 'ISHEADER_LR'):\n",
    "        lru.build_isheader_logistic_regression_elements(verbose=True)\n",
    "    lru.retrain_isheader_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-header classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d5f01c-6342-4c46-9d52-a3608cc29ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import enchant\n",
    "from IPython.display import HTML\n",
    "\n",
    "file_name = \"fc48b76d6849bb2f_Senior_QA_Analyst_Remote_Indeed_com.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7248bd-9c02-48f1-8bd2-e1028b202405",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ed87db8-7c12-48c4-b2c0-932cf9333f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 12,401 hand-labeled qualification strings in here\n",
      "I have 413,963 is-qualified vocabulary keys in here\n",
      "Is-qualified classifer retrained in 1 minute and 40 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary in another notebook\n",
    "t0 = time.time()\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75c495-79a9-4475-ad97-46ae6d42a294",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Prepare cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "265ddacf-68eb-49fd-8b0b-1b78afceaa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>I only meet 100.0% of the minimum requirements for the Senior QA Analyst Remote position, but I can explain:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>1) Must have strong knowledge of SQL queries and concepts</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>2) Must have strong experience with automated test tool- Selenium Web driver</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>3) Must have experience using the LINUX command line Interface</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>4) Knowledge of scripting languages such as Shell, Python, Perl</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>5) Excellent verbal and communication skills required</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "ask_str = ''\n",
    "child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "\n",
    "feature_tuple_list = []\n",
    "if hasattr(lru, 'POS_PREDICT_PERCENT_FIT_DICT'):\n",
    "    pos_lr_predict_single = lru.pos_lr_predict_single\n",
    "else:\n",
    "    pos_lr_predict_single = None\n",
    "if hasattr(crf, 'pos_crf_predict_single'):\n",
    "    pos_crf_predict_single = crf.pos_crf_predict_single\n",
    "else:\n",
    "    pos_crf_predict_single = None\n",
    "for feature_dict in hc.get_feature_dict_list(ha.get_child_tags_list(child_strs_list), is_header_list, child_strs_list):\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, pos_lr_predict_single=pos_lr_predict_single, pos_crf_predict_single=pos_crf_predict_single))\n",
    "\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, crf_list=crf_list, file_name=file_name)\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "_, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "d = enchant.Dict('en_US')\n",
    "job_title = ' '.join([w for w in file_name.replace('.html', '').replace('_Indeed_com', '').split('_') if d.check(w)])\n",
    "met_str = f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'\n",
    "ask_str += met_str\n",
    "display(HTML(met_str))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in lru.basic_quals_dict:\n",
    "        if lru.basic_quals_dict[qual_str]:\n",
    "            met_str = f'{i+1}) {qual_str}'\n",
    "            ask_str += ' ' + met_str\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(met_str))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef7b2a4-d443-4cdd-86ad-a7f4938d4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The minimum requirements that I don't meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "unmet_str = \"<p>The minimum requirements that I don't meet are:</p>\"\n",
    "display(HTML(unmet_str))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if (qual_str not in lru.basic_quals_dict) or not lru.basic_quals_dict[qual_str]:\n",
    "        met_str = f'{i+1}) {qual_str}'\n",
    "        unmet_str += ' ' + met_str\n",
    "        idx = qual_str.find('>')\n",
    "        if idx == -1:\n",
    "            display(HTML(met_str))\n",
    "        else:\n",
    "            display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2d705f1-6522-416e-a223-682fdfd6e66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The preferred requirements that I meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>2) Bachelor's (Preferred)</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# This doesn't work unless you score all the O-PQs\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list = []\n",
    "for i, (crf_symbol, db_symbol) in enumerate(zip(crf_list, db_pos_list)):\n",
    "    if db_symbol in [None, 'O', 'H']:\n",
    "        pos_list.append(crf_symbol)\n",
    "    else:\n",
    "        pos_list.append(db_symbol)\n",
    "met_str = f\"<p>The preferred requirements that I meet are:</p>\"\n",
    "display(HTML(met_str))\n",
    "min_str = ''\n",
    "pqs_list = [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-PQ'])]\n",
    "for i, qual_str in enumerate(pqs_list):\n",
    "    if qual_str in lru.basic_quals_dict:\n",
    "        if lru.basic_quals_dict[qual_str]:\n",
    "            pref_str = f'{i+1}) {qual_str}'\n",
    "            min_str += ' ' + pref_str\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(pref_str))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))\n",
    "if min_str:\n",
    "    ask_str += met_str + min_str\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271b3e8-1d86-46a8-aa8e-3e9d519a5eeb",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Write cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087a9de1-5276-415b-8ee6-c6d249c26189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply to the recruiter email that you don't meet 12.5% of the requirements (<p>The minimum requirements that I don't meet are:</p> 3) <li>Strong background in data analysis, statistics, security metrics and knowledge of common security frameworks and standards (e.g., NIST, CIS)</li>) , though you do meet these criterion: <p>I only meet 87.5% of the minimum requirements for the Security Data Science Consultant Remote position, but I can explain:</p> 1) <li>Bachelor's or Master's degree in data science/data analytics, Computer Science, Mathematics, or a related field.</li> 2) <li>5+ years of experience in data analysis, modeling, and visualization</li> 4) <li>Proficiency in programming languages such as Python, R, or SQL</li> 5) <li>Experience with big data, AI/machine learning/deep learning, and data visualization tools such as Apache Spark, Amazon SageMaker, TensorFlow, Snowflake, Tableau or Power BI</li> 6) <li>Ability to communicate complex technical concepts to non-technical stakeholders.</li> 7) <li>Strong problem-solving skills and ability to work independently.</li> 8) <li>Excellent verbal and written communication skills.</li> and am interested in applying for the job. (Replace [Your Name] with Dave Babbitt, Replace [Recruiter] with Shankar)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topic = 'recruiter'\n",
    "if topic == 'recruiter':\n",
    "    recruiter_name = 'Shankar'\n",
    "    youchat_str = f\"Reply to the recruiter email that you don't meet {1-job_fitness:.1%} of the requirements (\"\n",
    "    youchat_str += unmet_str + f') , though you do meet these criterion: {ask_str} and am interested in applying for the job.'#and have applied for the job.\n",
    "    youchat_str += f' (Replace [Your Name] with Dave Babbitt, Replace [Recruiter] with {recruiter_name})'\n",
    "elif topic == 'cover':\n",
    "    import pandas as pd\n",
    "    cypher_str = f\"\"\"\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        RETURN\n",
    "            fn.role_primary_contact AS role_primary_contact,\n",
    "            fn.role_primary_contact_email_id AS role_primary_contact_email_id,\n",
    "            fn.role_title AS role_title\n",
    "        ORDER BY fn.percent_fit DESC;\"\"\"\n",
    "    cover_df = pd.DataFrame(cu.get_execution_results(cypher_str, verbose=False))\n",
    "    recruiter_name = cover_df.role_primary_contact.squeeze()\n",
    "    email_address = cover_df.role_primary_contact_email_id.squeeze()\n",
    "    role_title = cover_df.role_title.squeeze()\n",
    "    if (recruiter_name is None) or (email_address is None):\n",
    "        suffix_str = ''\n",
    "    else:\n",
    "        suffix_str = f' to \"{recruiter_name}\" <{email_address}>'\n",
    "    youchat_str = f'Write a cover letter email{suffix_str}, complete with subject, using this information: ' + ask_str + ' Replace [Your Name] with Dave Babbitt'\n",
    "elif topic == 'zoom':\n",
    "    interviewer_name = 'Dan, David, Alex, and Melinda'\n",
    "    company_name = '3GIMBALS'\n",
    "    youchat_str = f\"Write a follow up thank you note for an interview using this information: a) Interviewer Name: {interviewer_name}, b) Position: {job_title},\"\n",
    "    youchat_str += f\" c) Company Name {company_name}, d) relevant skills: {ask_str}, e) Your Name: Dave Babbitt. Ask about going over the programming exercise.\"\n",
    "elif topic == 'phone':\n",
    "    interviewer_name = 'Dan, David, Alex, and Melinda'\n",
    "    company_name = '3GIMBALS'\n",
    "    interviewer_title = 'interview team'\n",
    "    youchat_str = f\"Write an email, complete with subject, to {interviewer_name} about what a pleasure it was to talk to them, the {interviewer_title},\"\n",
    "    youchat_str += f\" on the phone about the {job_title} position with {company_name}. Replace [Your Name] with Dave Babbitt\"\n",
    "elif topic == 'interested':\n",
    "    file_path = '../data/txt/resume.txt'\n",
    "    with open(file_path, 'r') as file:\n",
    "        resume_str = file.read().rstrip()\n",
    "    task_strs_list = []\n",
    "    for task_str in [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-TS'])]:\n",
    "        task_strs_list.append(task_str)\n",
    "    company_name = child_strs_list[1]\n",
    "    youchat_str = f\"Explain in first person singular why I would be interested in this role at {company_name}, given\\n\\n1) this information about the task\"\n",
    "    youchat_str += f\" scope:\\n\\n{' '.join(task_strs_list)}\\n\\nand, 2) my resume:\\n\\n{resume_str}\"\n",
    "elif topic == 'question':\n",
    "    file_path = '../data/txt/resume.txt'\n",
    "    with open(file_path, 'r') as file:\n",
    "        resume_str = file.read().rstrip()\n",
    "    task_strs_list = []\n",
    "    for task_str in [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-TS'])]:\n",
    "        task_strs_list.append(task_str)\n",
    "    company_name = child_strs_list[1]\n",
    "    youchat_str = f\"Pretend you have the competencies and experience listed on the resume. Explain in first person singular\"\n",
    "    youchat_str += f\" how you manage projects, communicate with clients, discover their needs, make recommendations, stay in budget, manage changing requirements,\"\n",
    "    youchat_str += f\" and produce results, given this resume:\\n\\n{resume_str[75:]}\"\n",
    "elif topic == 'rejected':\n",
    "    job_title = 'Senior Data Engineering Analyst, Platform Engineering (Remote, Anywhere in US)'\n",
    "    recruiting_team_name = 'Humana Recruiting Team'\n",
    "    company_name = 'Humana'\n",
    "    youchat_str = f\"Write a reply to the {recruiting_team_name} rejection letter for the {job_title} position at {company_name},\"\n",
    "    youchat_str += ' persuading the recruiting team to explain in more detail why I was rejected for the role. Replace [Name] with Dave Babbitt'\n",
    "print(youchat_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e1ad3-c36f-4a2a-9d49-3b4d59404d98",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "662a0814-82bf-48b9-99b6-a87d1b4780f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply to the recruiter email that you don't meet 12.5% of the requirements (<p>The minimum requirements that I don't meet are:</p> 3) <li>Strong background in data analysis, statistics, security metrics and knowledge of common security frameworks and standards (e.g., NIST, CIS)</li>) , though you do meet these criterion: <p>I only meet 87.5% of the minimum requirements for the Security Data Science Consultant Remote position, but I can explain:</p> 1) <li>Bachelor's or Master's degree in data science/data analytics, Computer Science, Mathematics, or a related field.</li> 2) <li>5+ years of experience in data analysis, modeling, and visualization</li> 4) <li>Proficiency in programming languages such as Python, R, or SQL</li> 5) <li>Experience with big data, AI/machine learning/deep learning, and data visualization tools such as Apache Spark, Amazon SageMaker, TensorFlow, Snowflake, Tableau or Power BI</li> 6) <li>Ability to communicate complex technical concepts to non-technical stakeholders.</li> 7) <li>Strong problem-solving skills and ability to work independently.</li> 8) <li>Excellent verbal and written communication skills.</li> and am interested in applying for the job. (Replace [Your Name] with Dave Babbitt, Replace [Recruiter] with Shankar)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import urllib.parse\n",
    "\n",
    "driver = wsu.get_driver(verbose=False)\n",
    "# youchat_str = 'Rewrite this sentence so it sounds like a minimum requirement: \"Self-sustaining and proactive self-starters who can thrive in a large technological ecosystem with a myriad of tools and documentation.\"'\n",
    "youchat_url = f'https://you.com/search?q={urllib.parse.quote_plus(youchat_str)}&fromSearchBar=true&tbm=youchat'\n",
    "wsu.driver_get_url(driver, youchat_url, verbose=False)\n",
    "print(youchat_str)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bd4fd-ce1f-42aa-9c76-c5db6ff80e00",
   "metadata": {},
   "source": [
    "\n",
    "### Check the back FireFox window to make sure the chat writing has stopped before running this next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e80757-79be-4d5f-806e-d42608a19381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Shankar,\n",
      "Thank you for your email regarding the Security Data Science Consultant Remote position. Although it seems that I don't meet the requirement of having a strong background in data analysis, statistics, security metrics, and knowledge of common security frameworks and standards, I would like to point out that I do meet the following criteria:\n",
      "Bachelor's or Master's degree in data science/data analytics, Computer Science, Mathematics, or a related field.\n",
      "5+ years of experience in data analysis, modeling, and visualization.\n",
      "Proficiency in programming languages such as Python, R, or SQL.\n",
      "Experience with big data, AI/machine learning/deep learning and data visualization tools such as Apache Spark, Amazon SageMaker, TensorFlow, Snowflake, Tableau or Power BI.\n",
      "Ability to communicate complex technical concepts to non-technical stakeholders.\n",
      "Strong problem-solving skills and ability to work independently.\n",
      "Excellent verbal and written communication skills.\n",
      "With the above qualifications, I am keen on applying for this position. Please let me know if you need any further details.\n",
      "Thank you for considering my application.\n",
      "Best regards,\n",
      "Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "css_selector = 'div[data-testid=\"youchat-answer\"]'\n",
    "try:\n",
    "    web_element = driver.find_element(By.CSS_SELECTOR, css_selector)\n",
    "    print(web_element.text)\n",
    "except NoSuchElementException as e:\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__} error: {str(e).strip()}')\n",
    "finally:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886daf59-7a95-4c27-ab2e-f9f8150be523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
