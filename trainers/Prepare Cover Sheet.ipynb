{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174c9bb2-7d08-4fa2-aa2b-e3be342e52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b116b-61d6-4e55-9958-df45b98739f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183303cc-b07c-4099-b236-6362c88636ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bedaf55-77a0-4805-aff2-38efd3229c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "bin_count = 12\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "height_inches = 3.0\n",
    "width_inches = 18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee0d11a-f9d1-4923-b6ba-465eae43386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Neo4j/4.4.7 ========\n",
      "I have 6,094 labeled parts of speech in here\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "Utility libraries created in 49 minutes and 32 seconds\n",
      "Last run on 2023-03-07 21:35:20.145732\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(s=s)\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "# Get the neo4j object\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "try:\n",
    "    \n",
    "    version_str = cu.driver.get_server_info().agent\n",
    "    print(f'======== {version_str} ========')\n",
    "    \n",
    "    from hc_utils import HeaderCategories\n",
    "    hc = HeaderCategories(cu=cu, verbose=False)\n",
    "    \n",
    "    # 400 6,094 37 minutes and 50 seconds\n",
    "    # 800 6,094 44 minutes and 18 seconds\n",
    "    from lr_utils import LrUtilities\n",
    "    lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "    lru.build_isheader_logistic_regression_elements(verbose=False)\n",
    "    lru.build_pos_logistic_regression_elements(sampling_strategy_limit=800, verbose=True)\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=5_000, verbose=False)\n",
    "    \n",
    "    from crf_utils import CrfUtilities\n",
    "    crf = CrfUtilities(ha=ha, hc=hc, cu=cu, lru=lru, verbose=True)\n",
    "    \n",
    "    from section_utils import SectionUtilities\n",
    "    su = SectionUtilities(s=s, ha=ha, cu=cu, crf=crf, verbose=False)\n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except ServiceUnavailable as e:\n",
    "    print('You need to start Neo4j as a console')\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__}: {str(e).strip()}')\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Utility libraries created in {duration_str}')\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d5f01c-6342-4c46-9d52-a3608cc29ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import enchant\n",
    "from IPython.display import HTML\n",
    "\n",
    "file_name = \"aafda86facc69d43_Experimentation_Data_Scientist_Remote_Indeed_com.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7248bd-9c02-48f1-8bd2-e1028b202405",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ed87db8-7c12-48c4-b2c0-932cf9333f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "I have 11,659 hand-labeled qualification strings in here\n",
      "Retraining complete\n",
      "Is-qualified classifer retrained in 2 minutes and 12 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary in another notebook\n",
    "t0 = time.time()\n",
    "basic_quals_dict = lru.sync_basic_quals_dict(sampling_strategy_limit=10_000, verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75c495-79a9-4475-ad97-46ae6d42a294",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Prepare cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265ddacf-68eb-49fd-8b0b-1b78afceaa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>I only meet 100.0% of the minimum requirements for the Experimentation Data Scientist Remote position, but I can explain:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>1) MS or Ph.D. or equivalent experience in a quantitative field or 6+ years of proven ability as a Data Scientist. Preferably in digital media or product fields.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>2) 4+ years applied experience in building sophisticated datasets and feature engineering</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>3) Experience working with structured and unstructured data stored in distributed files systems.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>4) Strong proficiency with SQL. Deep experience in Python/Jupyter</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>5) Strong background and knowledge in statistics, probability, and data analysis.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>6) Project ownership with an ability to condense &amp; communicate sophisticated concepts and analysis into clear and concise takeaways that drive action.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>7) Curious about what drives business trends and. Demonstrated capacity to learn on the fly.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>8) Proactive with an interest in improving processes and creating efficiencies.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "ask_str = ''\n",
    "child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in hc.get_feature_dict_list(ha.get_child_tags_list(child_strs_list), is_header_list, child_strs_list):\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, crf_list=crf_list, file_name=file_name)\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "_, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "d = enchant.Dict('en_US')\n",
    "job_title = ' '.join([w for w in file_name.replace('.html', '').replace('_Indeed_com', '').split('_') if d.check(w)])\n",
    "met_str = f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'\n",
    "ask_str += met_str\n",
    "display(HTML(met_str))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            met_str = f'{i+1}) {qual_str}'\n",
    "            ask_str += ' ' + met_str\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(met_str))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef7b2a4-d443-4cdd-86ad-a7f4938d4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The minimum requirements that I don't meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "unmet_str = \"<p>The minimum requirements that I don't meet are:</p>\"\n",
    "display(HTML(unmet_str))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if (qual_str not in basic_quals_dict) or not basic_quals_dict[qual_str]:\n",
    "        met_str = f'{i+1}) {qual_str}'\n",
    "        unmet_str += ' ' + met_str\n",
    "        idx = qual_str.find('>')\n",
    "        if idx == -1:\n",
    "            display(HTML(met_str))\n",
    "        else:\n",
    "            display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2d705f1-6522-416e-a223-682fdfd6e66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The preferred requirements that I meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# This doesn't work unless you score all the O-PQs\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list = []\n",
    "for i, (crf_symbol, db_symbol) in enumerate(zip(crf_list, db_pos_list)):\n",
    "    if db_symbol in [None, 'O', 'H']:\n",
    "        pos_list.append(crf_symbol)\n",
    "    else:\n",
    "        pos_list.append(db_symbol)\n",
    "met_str = f\"<p>The preferred requirements that I meet are:</p>\"\n",
    "display(HTML(met_str))\n",
    "min_str = ''\n",
    "pqs_list = [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-PQ'])]\n",
    "for i, qual_str in enumerate(pqs_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            pref_str = f'{i+1}) {qual_str}'\n",
    "            min_str += ' ' + pref_str\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(pref_str))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))\n",
    "if min_str:\n",
    "    ask_str += met_str + min_str\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271b3e8-1d86-46a8-aa8e-3e9d519a5eeb",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Write cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "087a9de1-5276-415b-8ee6-c6d249c26189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a cover letter email, complete with subject, using this information: <p>I only meet 100.0% of the minimum requirements for the Experimentation Data Scientist Remote position, but I can explain:</p> 1) <li>MS or Ph.D. or equivalent experience in a quantitative field or 6+ years of proven ability as a Data Scientist. Preferably in digital media or product fields.</li> 2) <li>4+ years applied experience in building sophisticated datasets and feature engineering</li> 3) <li>Experience working with structured and unstructured data stored in distributed files systems.</li> 4) <li>Strong proficiency with SQL. Deep experience in Python/Jupyter</li> 5) <li>Strong background and knowledge in statistics, probability, and data analysis.</li> 6) <li>Project ownership with an ability to condense &amp; communicate sophisticated concepts and analysis into clear and concise takeaways that drive action.</li> 7) <li>Curious about what drives business trends and. Demonstrated capacity to learn on the fly.</li> 8) <li>Proactive with an interest in improving processes and creating efficiencies.</li> Replace [Your Name] with Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topic = 'cover'\n",
    "if topic == 'recruiter':\n",
    "    recruiter_name = 'Vena Burgess'\n",
    "    youchat_str = f\"Reply to the recruiter email that although you don't meet {1-job_fitness:.1%} of the requirements (\" + unmet_str + f'), you do meet these criterion: {ask_str} and have applied for the job.'\n",
    "    youchat_str += f' (Replace [Your Name] with Dave Babbitt, Replace [Recruiter] with {recruiter_name})'\n",
    "elif topic == 'cover':\n",
    "    import pandas as pd\n",
    "    cypher_str = f\"\"\"\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        RETURN\n",
    "            fn.role_primary_contact AS role_primary_contact,\n",
    "            fn.role_primary_contact_email_id AS role_primary_contact_email_id,\n",
    "            fn.role_title AS role_title\n",
    "        ORDER BY fn.percent_fit DESC;\"\"\"\n",
    "    cover_df = pd.DataFrame(cu.get_execution_results(cypher_str, verbose=False))\n",
    "    recruiter_name = cover_df.role_primary_contact.squeeze()\n",
    "    email_address = cover_df.role_primary_contact_email_id.squeeze()\n",
    "    role_title = cover_df.role_title.squeeze()\n",
    "    if (recruiter_name is None) or (email_address is None):\n",
    "        suffix_str = ''\n",
    "    else:\n",
    "        suffix_str = f' to \"{recruiter_name}\" <{email_address}>'\n",
    "    youchat_str = f'Write a cover letter email{suffix_str}, complete with subject, using this information: ' + ask_str + ' Replace [Your Name] with Dave Babbitt'\n",
    "elif topic == 'zoom':\n",
    "    interviewer_name = 'Dan, David, Alex, and Melinda'\n",
    "    company_name = '3GIMBALS'\n",
    "    youchat_str = f\"Write a follow up thank you note for an interview using this information: a) Interviewer Name: {interviewer_name}, b) Position: {job_title}, c) Company Name {company_name}, \"\n",
    "    youchat_str += f\"d) relevant skills: {ask_str}, e) Your Name: Dave Babbitt. Ask about going over the programming exercise.\"\n",
    "elif topic == 'phone':\n",
    "    interviewer_name = 'Dan, David, Alex, and Melinda'\n",
    "    company_name = '3GIMBALS'\n",
    "    interviewer_title = 'interview team'\n",
    "    youchat_str = f\"Write an email, complete with subject, to {interviewer_name} about what a pleasure it was to talk to them, the {interviewer_title},\"\n",
    "    youchat_str += f\" on the phone about the {job_title} position with {company_name}. Replace [Your Name] with Dave Babbitt\"\n",
    "elif topic == 'interested':\n",
    "    file_path = '../data/txt/resume.txt'\n",
    "    with open(file_path, 'r') as file:\n",
    "        resume_str = file.read().rstrip()\n",
    "    task_strs_list = []\n",
    "    for task_str in [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-TS'])]:\n",
    "        task_strs_list.append(task_str)\n",
    "    company_name = child_strs_list[1]\n",
    "    youchat_str = f\"Explain in first person singular why I would be interested in this role at {company_name}, given\\n\\n1) this information about the task scope:\\n\\n{' '.join(task_strs_list)}\"\n",
    "    youchat_str += f\"\\n\\nand, 2) my resume:\\n\\n{resume_str}\"\n",
    "elif topic == 'question':\n",
    "    file_path = '../data/txt/resume.txt'\n",
    "    with open(file_path, 'r') as file:\n",
    "        resume_str = file.read().rstrip()\n",
    "    task_strs_list = []\n",
    "    for task_str in [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-TS'])]:\n",
    "        task_strs_list.append(task_str)\n",
    "    company_name = child_strs_list[1]\n",
    "    youchat_str = f\"Pretend you have the competencies and experience listed on the resume. Explain in first person singular\"\n",
    "    youchat_str += f\" how you manage projects, communicate with clients, discover their needs, make recommendations, stay in budget, manage changing requirements, and produce results,\"\n",
    "    youchat_str += f\" given this resume:\\n\\n{resume_str[75:]}\"\n",
    "elif topic == 'rejected':\n",
    "    job_title = 'Senior Data Engineering Analyst, Platform Engineering (Remote, Anywhere in US)'\n",
    "    recruiting_team_name = 'Humana Recruiting Team'\n",
    "    company_name = 'Humana'\n",
    "    youchat_str = f\"Write a reply to the {recruiting_team_name} rejection letter for the {job_title} position at {company_name},\"\n",
    "    youchat_str += ' persuading the recruiting team to explain in more detail why I was rejected for the role. Replace [Name] with Dave Babbitt'\n",
    "print(youchat_str)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7dda006-4720-4d15-9f57-6df44768a0b9",
   "metadata": {},
   "source": [
    "\n",
    "if recruiter_name and email_address:\n",
    "    print(f'To: \"{recruiter_name}\" <{email_address}>')\n",
    "print(f'Subject: Application for {job_title} position')\n",
    "if recruiter_name:\n",
    "    dear_str = f\"Dear {recruiter_name.split(',')[1]} {recruiter_name.split(',')[0]},\"\n",
    "else:\n",
    "    dear_str = 'Dear Recruiter,'\n",
    "print(f\"\"\"\n",
    "{dear_str}\n",
    "\n",
    "I am writing to apply for the {role_title} position at Accenture, as advertised in the Accenture Technology Open Roles spreadsheet sent to me by Juan.\n",
    "{ask_str}\n",
    "I am sure that I have the skills and experience necessary to be a valuable asset to your team and I would be grateful for the opportunity to discuss my qualifications further.\n",
    "\n",
    "Sincerely,\n",
    "\n",
    "Dave Babbitt\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e1ad3-c36f-4a2a-9d49-3b4d59404d98",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Unless you have written consent from the Generative AI and LLM CoE, you may not use generative AI tools while coding and cannot upload Accenture, ecosystem or client content or data to these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662a0814-82bf-48b9-99b6-a87d1b4780f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a cover letter email, complete with subject, using this information: <p>I only meet 100.0% of the minimum requirements for the Experimentation Data Scientist Remote position, but I can explain:</p> 1) <li>MS or Ph.D. or equivalent experience in a quantitative field or 6+ years of proven ability as a Data Scientist. Preferably in digital media or product fields.</li> 2) <li>4+ years applied experience in building sophisticated datasets and feature engineering</li> 3) <li>Experience working with structured and unstructured data stored in distributed files systems.</li> 4) <li>Strong proficiency with SQL. Deep experience in Python/Jupyter</li> 5) <li>Strong background and knowledge in statistics, probability, and data analysis.</li> 6) <li>Project ownership with an ability to condense &amp; communicate sophisticated concepts and analysis into clear and concise takeaways that drive action.</li> 7) <li>Curious about what drives business trends and. Demonstrated capacity to learn on the fly.</li> 8) <li>Proactive with an interest in improving processes and creating efficiencies.</li> Replace [Your Name] with Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import urllib.parse\n",
    "\n",
    "driver = wsu.get_driver(verbose=False)\n",
    "# youchat_str = 'Rewrite this sentence so it sounds like a minimum requirement: \"Self-sustaining and proactive self-starters who can thrive in a large technological ecosystem with a myriad of tools and documentation.\"'\n",
    "youchat_url = f'https://you.com/search?q={urllib.parse.quote_plus(youchat_str)}&fromSearchBar=true&tbm=youchat'\n",
    "wsu.driver_get_url(driver, youchat_url, verbose=False)\n",
    "print(youchat_str)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bd4fd-ce1f-42aa-9c76-c5db6ff80e00",
   "metadata": {},
   "source": [
    "\n",
    "### Check the back FireFox window to make sure the chat writing has stopped before running this next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5e80757-79be-4d5f-806e-d42608a19381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Experimentation Data Scientist Remote position - Dave Babbitt\n",
      "Dear Hiring Team,\n",
      "I am writing to apply for the Experimentation Data Scientist Remote position. I understand that I only meet 100.0% of the minimum requirements, but I believe my skills and experience make me an excellent candidate.\n",
      "I have an MS or Ph.D. in a quantitative field, as well as 6+ years of proven ability as a Data Scientist, preferably in digital media or product fields. Additionally, I have 4+ years of applied experience in building sophisticated datasets and feature engineering, as well as experience working with structured and unstructured data stored in distributed files systems.\n",
      "I am confident in my abilities with SQL, and have a deep experience in Python/Jupyter. My background and knowledge in statistics, probability, and data analysis is strong. I have project ownership with an ability to condense and communicate sophisticated concepts and analysis into clear and concise takeaways that drive action. I am curious about what drives business trends and have the demonstrated capacity to learn on the fly. I am proactive with an interest in improving processes and creating efficiencies.\n",
      "I am confident that I can be a great asset to your team, and I am excited to learn more about this opportunity. I have included my resume for your review, and I look forward to hearing from you.\n",
      "Sincerely,\n",
      "Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "css_selector = 'div[data-testid=\"youchat-text\"]'\n",
    "try:\n",
    "    web_element = driver.find_element(By.CSS_SELECTOR, css_selector)\n",
    "    print(web_element.text)\n",
    "except NoSuchElementException as e:\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__} error: {str(e).strip()}')\n",
    "finally:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886daf59-7a95-4c27-ab2e-f9f8150be523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
