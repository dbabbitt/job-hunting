{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174c9bb2-7d08-4fa2-aa2b-e3be342e52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b116b-61d6-4e55-9958-df45b98739f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183303cc-b07c-4099-b236-6362c88636ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bedaf55-77a0-4805-aff2-38efd3229c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "bin_count = 12\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "height_inches = 3.0\n",
    "width_inches = 18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee0d11a-f9d1-4923-b6ba-465eae43386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Neo4j/4.4.7 ========\n",
      "I have 6,094 labeled parts of speech in here\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "Utility libraries created in 59 minutes and 7 seconds\n",
      "Last run on 2023-02-25 22:47:36.418154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(s=s)\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "# Get the neo4j object\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "try:\n",
    "    \n",
    "    version_str = cu.driver.get_server_info().agent\n",
    "    print(f'======== {version_str} ========')\n",
    "    \n",
    "    from hc_utils import HeaderCategories\n",
    "    hc = HeaderCategories(cu=cu, verbose=False)\n",
    "    \n",
    "    # 400 6,094 37 minutes and 50 seconds\n",
    "    # 800 6,094 44 minutes and 18 seconds\n",
    "    from lr_utils import LrUtilities\n",
    "    lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "    lru.build_isheader_logistic_regression_elements(verbose=False)\n",
    "    lru.build_pos_logistic_regression_elements(sampling_strategy_limit=800, verbose=True)\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=5_000, verbose=False)\n",
    "    \n",
    "    from crf_utils import CrfUtilities\n",
    "    crf = CrfUtilities(ha=ha, hc=hc, cu=cu, lru=lru, verbose=True)\n",
    "    \n",
    "    from section_utils import SectionUtilities\n",
    "    su = SectionUtilities(s=s, ha=ha, cu=cu, crf=crf, verbose=False)\n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except ServiceUnavailable as e:\n",
    "    print('You need to start Neo4j as a console')\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__}: {str(e).strip()}')\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Utility libraries created in {duration_str}')\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5d5f01c-6342-4c46-9d52-a3608cc29ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import enchant\n",
    "from IPython.display import HTML\n",
    "\n",
    "file_name = \"2a39a089a9362a54_Data_Scientist_Engineer_Remote_Indeed_com.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7248bd-9c02-48f1-8bd2-e1028b202405",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ed87db8-7c12-48c4-b2c0-932cf9333f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "I have 10,856 hand-labeled qualification strings in here\n",
      "Retraining complete\n",
      "Is-qualified classifer retrained in 1 minute and 47 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary in another notebook\n",
    "t0 = time.time()\n",
    "basic_quals_dict = lru.sync_basic_quals_dict(sampling_strategy_limit=10_000, verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75c495-79a9-4475-ad97-46ae6d42a294",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Prepare cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "265ddacf-68eb-49fd-8b0b-1b78afceaa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>I only meet 100.0% of the minimum requirements for the Data Scientist Engineer Remote position, but I can explain:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>1) You must have strong SQL skills, including the ability to write complex queries and stored procedures.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>2) You are proficient with Python (or R) and its libraries (Pandas, NumPy, Scikit-Learn, StatsModels, etc.) for data collecting, cleaning and reporting.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>3) You have experience using and pulling data via REST APIs.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>4) You have experience with SQL and data warehousing concepts (preferred Snowflake).</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>5) You have experience in automating ETL pipelines (preferred Apache Airflow).</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>6) You are proficient with business intelligence and data visualization tools (Tableau, Data Studio or similar).</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>7) You may have experience with training or an understanding of traditional machine learning models, including but not limited to linear/logistic regression, decision trees, KNN, k-means, neural networks, etc.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>8) You may have experience with cloud technologies and services (preferred AWS/GCP).</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>9) Intellectual and analytical curiosity - initiative to dig into the \"why\" of various results and a desire to grow responsibility and become a domain expert and strategic thought leader.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>10) You must be comfortable with uncertainty. Projects and assignments will change rapidly, so the candidate must be flexible enough to accommodate changing priorities and timelines.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>11) You have the ability to work with different departments and teams to gather complete datasets and communicate findings and practices company-wide.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>12) You can work independently and proactively, identifying issues and raising them to management, as well as offering potential solutions.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li>13) You have a solid background in technology, mathematics, statistics, accounting, finance, or other quantitative discipline (strongly preferred).</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "14) Must be authorized to work in the United States permanently without the requirement of sponsorship at any point in the future"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "ask_str = ''\n",
    "child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)\n",
    "feature_tuple_list = []\n",
    "for feature_dict in hc.get_feature_dict_list(ha.get_child_tags_list(child_strs_list), is_header_list, child_strs_list):\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, lru.pos_lr_predict_single))\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, crf_list=crf_list, file_name=file_name)\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "prediction_list = list(lru.predict_job_hunt_percent_fit(quals_list))\n",
    "_, qual_count = lru.get_quals_str(prediction_list, quals_list)\n",
    "job_fitness = qual_count/len(prediction_list)\n",
    "d = enchant.Dict('en_US')\n",
    "job_title = ' '.join([w for w in file_name.replace('.html', '').replace('_Indeed_com', '').split('_') if d.check(w)])\n",
    "met_str = f'<p>I only meet {job_fitness:.1%} of the minimum requirements for the {job_title} position, but I can explain:</p>'\n",
    "ask_str += met_str\n",
    "display(HTML(met_str))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            met_str = f'{i+1}) {qual_str}'\n",
    "            ask_str += ' ' + met_str\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(met_str))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ef7b2a4-d443-4cdd-86ad-a7f4938d4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The minimum requirements that I don't meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "unmet_str = \"<p>The minimum requirements that I don't meet are:</p>\"\n",
    "display(HTML(unmet_str))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if (qual_str not in basic_quals_dict) or not basic_quals_dict[qual_str]:\n",
    "        met_str = f'{i+1}) {qual_str}'\n",
    "        unmet_str += ' ' + met_str\n",
    "        idx = qual_str.find('>')\n",
    "        if idx == -1:\n",
    "            display(HTML(met_str))\n",
    "        else:\n",
    "            display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2d705f1-6522-416e-a223-682fdfd6e66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>The preferred requirements that I meet are:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# This doesn't work unless you score all the O-PQs\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list = []\n",
    "for i, (crf_symbol, db_symbol) in enumerate(zip(crf_list, db_pos_list)):\n",
    "    if db_symbol in [None, 'O', 'H']:\n",
    "        pos_list.append(crf_symbol)\n",
    "    else:\n",
    "        pos_list.append(db_symbol)\n",
    "met_str = f\"<p>The preferred requirements that I meet are:</p>\"\n",
    "display(HTML(met_str))\n",
    "min_str = ''\n",
    "pqs_list = [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-PQ'])]\n",
    "for i, qual_str in enumerate(pqs_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            pref_str = f'{i+1}) {qual_str}'\n",
    "            min_str += ' ' + pref_str\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(pref_str))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))\n",
    "if min_str:\n",
    "    ask_str += met_str + min_str\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271b3e8-1d86-46a8-aa8e-3e9d519a5eeb",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Write cover sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "087a9de1-5276-415b-8ee6-c6d249c26189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a cover letter email, complete with subject, using this information: <p>I only meet 100.0% of the minimum requirements for the Data Scientist Engineer Remote position, but I can explain:</p> 1) <li>You must have strong SQL skills, including the ability to write complex queries and stored procedures.</li> 2) <li>You are proficient with Python (or R) and its libraries (Pandas, NumPy, Scikit-Learn, StatsModels, etc.) for data collecting, cleaning and reporting.</li> 3) <li>You have experience using and pulling data via REST APIs.</li> 4) <li>You have experience with SQL and data warehousing concepts (preferred Snowflake).</li> 5) <li>You have experience in automating ETL pipelines (preferred Apache Airflow).</li> 6) <li>You are proficient with business intelligence and data visualization tools (Tableau, Data Studio or similar).</li> 7) <li>You may have experience with training or an understanding of traditional machine learning models, including but not limited to linear/logistic regression, decision trees, KNN, k-means, neural networks, etc.</li> 8) <li>You may have experience with cloud technologies and services (preferred AWS/GCP).</li> 9) <li>Intellectual and analytical curiosity - initiative to dig into the \"why\" of various results and a desire to grow responsibility and become a domain expert and strategic thought leader.</li> 10) <li>You must be comfortable with uncertainty. Projects and assignments will change rapidly, so the candidate must be flexible enough to accommodate changing priorities and timelines.</li> 11) <li>You have the ability to work with different departments and teams to gather complete datasets and communicate findings and practices company-wide.</li> 12) <li>You can work independently and proactively, identifying issues and raising them to management, as well as offering potential solutions.</li> 13) <li>You have a solid background in technology, mathematics, statistics, accounting, finance, or other quantitative discipline (strongly preferred).</li> 14) Must be authorized to work in the United States permanently without the requirement of sponsorship at any point in the future Replace [Your Name] with Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topic = 'cover'\n",
    "if topic == 'recruiter':\n",
    "    recruiter_name = 'Olivia Hodges'\n",
    "    youchat_str = f\"Reply to the recruiter email that you don't meet {1-job_fitness:.1%} of the requirements using this information: \" + unmet_str + ' (Replace [Your Name] with Dave Babbitt,'\n",
    "    youchat_str += f' Replace [Recruiter] with {recruiter_name})'\n",
    "elif topic == 'cover':\n",
    "    import pandas as pd\n",
    "    cypher_str = f\"\"\"\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        RETURN\n",
    "            fn.role_primary_contact AS role_primary_contact,\n",
    "            fn.role_primary_contact_email_id AS role_primary_contact_email_id,\n",
    "            fn.role_title AS role_title\n",
    "        ORDER BY fn.percent_fit DESC;\"\"\"\n",
    "    cover_df = pd.DataFrame(cu.get_execution_results(cypher_str, verbose=False))\n",
    "    recruiter_name = cover_df.role_primary_contact.squeeze()\n",
    "    email_address = cover_df.role_primary_contact_email_id.squeeze()\n",
    "    role_title = cover_df.role_title.squeeze()\n",
    "    if (recruiter_name is None) or (email_address is None):\n",
    "        suffix_str = ''\n",
    "    else:\n",
    "        suffix_str = f' to \"{recruiter_name}\" <{email_address}>'\n",
    "    youchat_str = f'Write a cover letter email{suffix_str}, complete with subject, using this information: ' + ask_str + ' Replace [Your Name] with Dave Babbitt'\n",
    "elif topic == 'zoom':\n",
    "    interviewer_name = 'Dan, David, Alex, and Melinda'\n",
    "    company_name = '3GIMBALS'\n",
    "    youchat_str = f\"Write a follow up thank you note for an interview using this information: a) Interviewer Name: {interviewer_name}, b) Position: {job_title}, c) Company Name {company_name}, \"\n",
    "    youchat_str += f\"d) relevant skills: {ask_str}, e) Your Name: Dave Babbitt. Ask about going over the programming exercise.\"\n",
    "elif topic == 'phone':\n",
    "    interviewer_name = 'Dan, David, Alex, and Melinda'\n",
    "    company_name = '3GIMBALS'\n",
    "    interviewer_title = 'interview team'\n",
    "    youchat_str = f\"Write an email, complete with subject, to {interviewer_name} about what a pleasure it was to talk to them, the {interviewer_title},\"\n",
    "    youchat_str += f\" on the phone about the {job_title} position with {company_name}. Replace [Your Name] with Dave Babbitt\"\n",
    "elif topic == 'interested':\n",
    "    file_path = '../data/txt/resume.txt'\n",
    "    with open(file_path, 'r') as file:\n",
    "        resume_str = file.read().rstrip()\n",
    "    task_strs_list = []\n",
    "    for task_str in [child_str for pos_str, child_str in zip(pos_list, child_strs_list) if (pos_str in ['O-TS'])]:\n",
    "        task_strs_list.append(task_str)\n",
    "    company_name = child_strs_list[1]\n",
    "    youchat_str = f\"Explain in first person singular why I would be interested in this role at {company_name}, given\\n\\n1) this information about the task scope:\\n\\n{' '.join(task_strs_list)}\"\n",
    "    youchat_str += f\"\\n\\nand, 2) my resume:\\n\\n{resume_str}\"\n",
    "elif topic == 'rejected':\n",
    "    job_title = 'Senior Data Engineering Analyst, Platform Engineering (Remote, Anywhere in US)'\n",
    "    recruiting_team_name = 'Humana Recruiting Team'\n",
    "    company_name = 'Humana'\n",
    "    youchat_str = f\"Write a reply to the {recruiting_team_name} rejection letter for the {job_title} position at {company_name},\"\n",
    "    youchat_str += ' persuading the recruiting team to explain in more detail why I was rejected for the role. Replace [Name] with Dave Babbitt'\n",
    "print(youchat_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "add5df15-3fde-428f-b315-f7711a783eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Data Scientist Engineer Remote position\n",
      "\n",
      "Dear Recruiter,\n",
      "\n",
      "I am writing to apply for the None position at Accenture, as advertised in the Accenture Technology Open Roles spreadsheet sent to me by Juan.\n",
      "I am confident that I meet 100.0% of the minimum requirements for the role, and I am eager to explain why I believe I am a great fit for the job.\n",
      "As a data scientist, I am adept at employing data analysis to enhance AI models and can provide three weeks of full-time support to execute related labeling tasks.\n",
      "In addition, I have achieved the P1 - Beginner level of both the Data Analysis & Interpretation and the Visual Design qualifications, demonstrating my proficiency in data analysis and visual design and understanding of the domain.\n",
      "I am sure that I have the skills and experience necessary to be a valuable asset to your team and I would be grateful for the opportunity to discuss my qualifications further.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if recruiter_name and email_address:\n",
    "    print(f'To: \"{recruiter_name}\" <{email_address}>')\n",
    "print(f'Subject: Application for {job_title} position')\n",
    "if recruiter_name:\n",
    "    dear_str = f\"Dear {recruiter_name.split(',')[1]} {recruiter_name.split(',')[0]},\"\n",
    "else:\n",
    "    dear_str = 'Dear Recruiter,'\n",
    "print(f\"\"\"\n",
    "{dear_str}\n",
    "\n",
    "I am writing to apply for the {role_title} position at Accenture, as advertised in the Accenture Technology Open Roles spreadsheet sent to me by Juan.\n",
    "I am confident that I meet {job_fitness:.1%} of the minimum requirements for the role, and I am eager to explain why I believe I am a great fit for the job.\n",
    "As a data scientist, I am adept at employing data analysis to enhance AI models and can provide three weeks of full-time support to execute related labeling tasks.\n",
    "In addition, I have achieved the P1 - Beginner level of both the Data Analysis & Interpretation and the Visual Design qualifications, demonstrating my proficiency\"\"\", end='')\n",
    "print(f\"\"\" in data analysis and visual design and understanding of the domain.\n",
    "I am sure that I have the skills and experience necessary to be a valuable asset to your team and I would be grateful for the opportunity to discuss my qualifications further.\n",
    "\n",
    "Sincerely,\n",
    "\n",
    "Dave Babbitt\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e1ad3-c36f-4a2a-9d49-3b4d59404d98",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Unless you have written consent from the Generative AI and LLM CoE, you may not use generative AI tools while coding and cannot upload Accenture, ecosystem or client content or data to these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "662a0814-82bf-48b9-99b6-a87d1b4780f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a cover letter email, complete with subject, using this information: <p>I only meet 100.0% of the minimum requirements for the Data Scientist Engineer Remote position, but I can explain:</p> 1) <li>You must have strong SQL skills, including the ability to write complex queries and stored procedures.</li> 2) <li>You are proficient with Python (or R) and its libraries (Pandas, NumPy, Scikit-Learn, StatsModels, etc.) for data collecting, cleaning and reporting.</li> 3) <li>You have experience using and pulling data via REST APIs.</li> 4) <li>You have experience with SQL and data warehousing concepts (preferred Snowflake).</li> 5) <li>You have experience in automating ETL pipelines (preferred Apache Airflow).</li> 6) <li>You are proficient with business intelligence and data visualization tools (Tableau, Data Studio or similar).</li> 7) <li>You may have experience with training or an understanding of traditional machine learning models, including but not limited to linear/logistic regression, decision trees, KNN, k-means, neural networks, etc.</li> 8) <li>You may have experience with cloud technologies and services (preferred AWS/GCP).</li> 9) <li>Intellectual and analytical curiosity - initiative to dig into the \"why\" of various results and a desire to grow responsibility and become a domain expert and strategic thought leader.</li> 10) <li>You must be comfortable with uncertainty. Projects and assignments will change rapidly, so the candidate must be flexible enough to accommodate changing priorities and timelines.</li> 11) <li>You have the ability to work with different departments and teams to gather complete datasets and communicate findings and practices company-wide.</li> 12) <li>You can work independently and proactively, identifying issues and raising them to management, as well as offering potential solutions.</li> 13) <li>You have a solid background in technology, mathematics, statistics, accounting, finance, or other quantitative discipline (strongly preferred).</li> 14) Must be authorized to work in the United States permanently without the requirement of sponsorship at any point in the future Replace [Your Name] with Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import urllib.parse\n",
    "\n",
    "driver = wsu.get_driver(verbose=False)\n",
    "# youchat_str = 'Rewrite this sentence so it sounds like a minimum requirement: \"Self-sustaining and proactive self-starters who can thrive in a large technological ecosystem with a myriad of tools and documentation.\"'\n",
    "youchat_url = f'https://you.com/search?q={urllib.parse.quote_plus(youchat_str)}&fromSearchBar=true&tbm=youchat'\n",
    "wsu.driver_get_url(driver, youchat_url, verbose=False)\n",
    "print(youchat_str)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5e80757-79be-4d5f-806e-d42608a19381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Data Scientist Engineer Remote Position - Dave Babbitt\n",
      "Dear Hiring Team,\n",
      "I am writing to apply for the Data Scientist Engineer Remote position that is currently open. I believe I am an ideal candidate for this position and would be a great addition to your team.\n",
      "I understand that the position requires strong SQL skills, including the ability to write complex queries and stored procedures. I have strong SQL skills, as well as experience using and pulling data via REST APIs. I am also proficient with Python (or R) and its libraries (Pandas, NumPy, Scikit-Learn, StatsModels, etc.) for data collecting, cleaning and reporting. Additionally, I have experience with SQL and data warehousing concepts (preferred Snowflake) as well as experience in automating ETL pipelines (preferred Apache Airflow).\n",
      "I am also proficient with business intelligence and data visualization tools (Tableau, Data Studio or similar). I have experience with training or an understanding of traditional machine learning models, including but not limited to linear/logistic regression, decision trees, KNN, k-means, neural networks, etc. In addition, I have experience with cloud technologies and services (preferred AWS/GCP).\n",
      "Furthermore, I have the intellectual and analytical curiosity needed for this role, as well as the initiative to dig into the \"why\" of various results and a desire to grow responsibility and become a domain expert and strategic thought leader. I am also comfortable with uncertainty and have the ability to work with different departments and teams to gather complete datasets and communicate findings and practices company-wide. Lastly, I have the ability to work independently and proactively, identifying issues and raising them to management, as well as offering potential solutions.\n",
      "I understand that I meet 100.0% of the minimum requirements for the Data Scientist Engineer Remote position, but I believe my experience and qualifications are even more than what is required. I have a solid background in technology, mathematics, statistics, accounting, finance, or other quantitative discipline (strongly preferred). Lastly, I am authorized to work in the United States permanently without the requirement of sponsorship at any point in the future.\n",
      "Thank you for considering my application and I look forward to hearing from you soon.\n",
      "Sincerely,\n",
      "Dave Babbitt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "css_selector = 'div[data-testid=\"youchat-text\"]'\n",
    "try:\n",
    "    web_element = driver.find_element(By.CSS_SELECTOR, css_selector)\n",
    "    print(web_element.text)\n",
    "except NoSuchElementException as e:\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__} error: {str(e).strip()}')\n",
    "finally:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886daf59-7a95-4c27-ab2e-f9f8150be523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
