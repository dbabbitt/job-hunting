{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.execute('DROP TABLE IF EXISTS HeaderTagSequence;')\n",
    "db.execute('''\n",
    "CREATE TABLE HeaderTagSequence(\n",
    "    header_tag_sequence_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    file_name_id INTEGER NOT NULL,\n",
    "    header_tag_id INTEGER NOT NULL,\n",
    "    sequence_order INTEGER NOT NULL\n",
    ");''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file_name in files_list:\n",
    "    file_name_id = db.execute('SELECT file_name_id FROM FileNames WHERE file_name = ?', (file_name,)).fetchone()['file_name_id']\n",
    "    child_strs_list = ha.get_child_strs_from_file(file_name)\n",
    "    child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "    for sequence_order, header_tag in enumerate(child_tags_list):\n",
    "        header_tag_id = db.execute('SELECT header_tag_id FROM HeaderTags WHERE header_tag = ?', (header_tag,)).fetchone()['header_tag_id']\n",
    "        db.execute('INSERT INTO HeaderTagSequence (file_name_id, header_tag_id, sequence_order) VALUES (?, ?, ?)',\n",
    "                   (file_name_id, header_tag_id, sequence_order))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.execute('DROP TABLE IF EXISTS NavigableParentSequence;')\n",
    "db.execute('''\n",
    "CREATE TABLE NavigableParentSequence(\n",
    "    navigable_parent_sequence_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    file_name_id INTEGER NOT NULL,\n",
    "    navigable_parent_id INTEGER NOT NULL,\n",
    "    sequence_order INTEGER NOT NULL\n",
    ");''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file_name in files_list:\n",
    "    file_name_id = db.execute('SELECT file_name_id FROM FileNames WHERE file_name = ?', (file_name,)).fetchone()['file_name_id']\n",
    "    child_strs_list = ha.get_child_strs_from_file(file_name)\n",
    "    for sequence_order, navigable_parent in enumerate(child_strs_list):\n",
    "        navigable_parent_id = db.execute('SELECT navigable_parent_id FROM NavigableParents WHERE navigable_parent = ?',\n",
    "                                         (navigable_parent,)).fetchone()['navigable_parent_id']\n",
    "        db.execute('INSERT INTO NavigableParentSequence (file_name_id, navigable_parent_id, sequence_order) VALUES (?, ?, ?)',\n",
    "                   (file_name_id, navigable_parent_id, sequence_order))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../load_magic/storage.py\n",
    "s = Storage()\n",
    "[f's.{fn}' for fn in dir(s) if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corp_scope_headers_list = s.load_object('corp_scope_headers_list')\n",
    "for navigable_parent in corp_scope_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_corporate_scope = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NAVIGABLE_PARENT_IS_HEADER_DICT = s.load_object('NAVIGABLE_PARENT_IS_HEADER_DICT')\n",
    "for navigable_parent, is_header in NAVIGABLE_PARENT_IS_HEADER_DICT.items():\n",
    "    if is_header:\n",
    "        db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_header = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "    else:\n",
    "        db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_header = 0\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NAVIGABLE_PARENT_IS_QUAL_DICT = s.load_object('NAVIGABLE_PARENT_IS_QUAL_DICT')\n",
    "for navigable_parent, is_qualification in NAVIGABLE_PARENT_IS_QUAL_DICT.items():\n",
    "    if is_qualification:\n",
    "        db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_qualification = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "    else:\n",
    "        db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_qualification = 0\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task_scope_headers_list = s.load_object('task_scope_headers_list')\n",
    "for navigable_parent in task_scope_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_task_scope = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "office_loc_headers_list = s.load_object('office_loc_headers_list')\n",
    "for navigable_parent in office_loc_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_office_location = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_quals_headers_list = s.load_object('req_quals_headers_list')\n",
    "for navigable_parent in req_quals_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_minimum_qualification = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "supp_pay_headers_list = s.load_object('supp_pay_headers_list')\n",
    "for navigable_parent in supp_pay_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_supplemental_pay = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preff_quals_headers_list = s.load_object('preff_quals_headers_list')\n",
    "for navigable_parent in preff_quals_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_preferred_qualification = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "legal_notifs_headers_list = s.load_object('legal_notifs_headers_list')\n",
    "for navigable_parent in legal_notifs_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_legal_notification = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other_headers_list = s.load_object('other_headers_list')\n",
    "for navigable_parent in other_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_other = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "educ_reqs_headers_list = s.load_object('educ_reqs_headers_list')\n",
    "for navigable_parent in educ_reqs_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_educational_requirement = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interv_proc_headers_list = s.load_object('interv_proc_headers_list')\n",
    "for navigable_parent in interv_proc_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_interview_procedure = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "post_date_headers_list = s.load_object('post_date_headers_list')\n",
    "for navigable_parent in post_date_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_posting_date = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_duration_headers_list = s.load_object('job_duration_headers_list')\n",
    "for navigable_parent in job_duration_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_job_duration = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_title_headers_list = s.load_object('job_title_headers_list')\n",
    "for navigable_parent in job_title_headers_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_job_title = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "pos_explanation_dict = s.load_object('pos_explanation_dict')\n",
    "random.choice(list(pos_explanation_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.execute('DROP TABLE IF EXISTS PartsOfSpeech;')\n",
    "db.execute('''\n",
    "CREATE TABLE PartsOfSpeech(\n",
    "    pos_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pos_symbol TEXT NOT NULL,\n",
    "    pos_explanation TEXT NOT NULL\n",
    ");''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_explanation_dict = s.load_object('pos_explanation_dict')\n",
    "for pos_symbol, pos_explanation in pos_explanation_dict.items():\n",
    "    if pos_symbol.startswith('H-'):\n",
    "        db.execute('INSERT INTO PartsOfSpeech (pos_symbol, pos_explanation) VALUES (?, ?)',\n",
    "                   (pos_symbol, pos_explanation))\n",
    "        db.execute('INSERT INTO PartsOfSpeech (pos_symbol, pos_explanation) VALUES (?, ?)',\n",
    "                   (pos_symbol.replace('H-', 'O-'), pos_explanation.replace(' Header', ' Non-header')))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flask import Flask\n",
    "\n",
    "[f'Flask.{fn}' for fn in dir(Flask) if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Flask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = Flask(__name__, instance_relative_config=True)\n",
    "[f'app.{fn}' for fn in dir(app) if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[f'app.{fn}' for fn in dir(app) if 'config' in fn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_obj = app.config\n",
    "[f'config_obj.{fn}' for fn in dir(config_obj) if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_obj = app.config\n",
    "for k, v in config_obj.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[f'app.{fn}' for fn in dir(app) if 'blue' in fn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app.register_blueprint?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.56 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "%run ../py/html_analysis.py\n",
    "ha = HeaderAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\HEADERS_DICTIONARY.pickle\n",
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\LDA.pickle\n",
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\CHILD_STR_CLF.pickle\n",
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\CHILD_STR_CLF.pickle\n",
      "Wall time: 11min 19s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "ea = ElementAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "navigable_parent = '<b>About This Role</b>'\n",
    "X_test = ea.HEADERS_DICTIONARY.doc2bow(ha.html_regex_tokenizer(navigable_parent))\n",
    "result_list = ea.LDA[X_test]\n",
    "result_list = sorted(result_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "db = sqlite3.connect(os.path.join('../', 'instance', 'flaskr.sqlite'), detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "db.row_factory = sqlite3.Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import re\n",
    "import random\n",
    "\n",
    "def match(expr, item):\n",
    "    \n",
    "    return bool(re.search(expr, item))\n",
    "\n",
    "db.create_function('MATCHES', 2, match)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "regex_str = r\"\\bequal opportunity employer\\b\"\n",
    "where_statement = f'''WHERE\n",
    "    MATCHES(\"{regex_str}\", navigable_parent) AND\n",
    "    is_legal_notification IS NULL'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "regex_str = r\"\\bKnowledgeable in \\b\"\n",
    "where_statement = f'''WHERE\n",
    "    MATCHES(\"{regex_str}\", navigable_parent) AND\n",
    "    NOT MATCHES(\"(position is based in)\", navigable_parent) AND\n",
    "    is_qualification IS NULL'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "regex_str = r\"snacks|kitchen|beer|fridge\"\n",
    "where_statement = f'''WHERE\n",
    "    MATCHES(\"{regex_str}\", navigable_parent) AND\n",
    "    NOT MATCHES(\"PHOENIX|more than|billion|raised|insurance|trillion|\\d+[MB]|million|toward|was named\", navigable_parent) AND\n",
    "    is_supplemental_pay IS NULL'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "regex_str = r\"\\bis a leader in\\b\"\n",
    "where_statement = f'''WHERE\n",
    "    MATCHES(\"{regex_str}\", navigable_parent) AND\n",
    "    NOT MATCHES(\"looking for|seeking a|you will|seek employees|hiring\", navigable_parent) AND\n",
    "    is_corporate_scope IS NULL'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regex_str = r\"\\byou'll work on\"\n",
    "where_statement = f'''WHERE\n",
    "    MATCHES(\"{regex_str}\", navigable_parent) AND\n",
    "    is_task_scope IS NULL'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sql_str = f'''\n",
    "SELECT navigable_parent\n",
    "FROM NavigableParents\n",
    "{where_statement};'''\n",
    "cursor_obj = db.cursor()\n",
    "cursor_obj.execute(sql_str)\n",
    "row_objs_list = cursor_obj.fetchall()\n",
    "child_strs_list = [row_obj['navigable_parent'] for row_obj in row_objs_list]\n",
    "cursor_obj.close()\n",
    "len(child_strs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<b>What you'll work on:</b>\""
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.choice(child_strs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<b>What you'll work on:</b>\"]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "child_strs_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "sql_str = f\"\"\"\n",
    "UPDATE NavigableParents\n",
    "SET\n",
    "    is_supplemental_pay = 1\n",
    "{where_statement};\"\"\"\n",
    "cursor_obj = db.execute(sql_str)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "sql_str = f\"\"\"\n",
    "UPDATE NavigableParents\n",
    "SET\n",
    "    is_corporate_scope = 1\n",
    "{where_statement};\"\"\"\n",
    "cursor_obj = db.execute(sql_str)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "sql_str = f\"\"\"\n",
    "UPDATE NavigableParents\n",
    "SET\n",
    "    is_qualification = 1\n",
    "{where_statement};\"\"\"\n",
    "cursor_obj = db.execute(sql_str)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_str = f\"\"\"\n",
    "UPDATE NavigableParents\n",
    "SET\n",
    "    is_task_scope = 1\n",
    "{where_statement};\"\"\"\n",
    "cursor_obj = db.execute(sql_str)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "sql_str = f\"\"\"\n",
    "UPDATE NavigableParents\n",
    "SET\n",
    "    is_legal_notification = 1\n",
    "{where_statement};\"\"\"\n",
    "cursor_obj = db.execute(sql_str)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subtypes_list = ['is_task_scope', 'is_minimum_qualification', 'is_preferred_qualification', 'is_legal_notification', 'is_job_title',\n",
    "                 'is_office_location', 'is_job_duration', 'is_supplemental_pay', 'is_educational_requirement', 'is_interview_procedure',\n",
    "                 'is_corporate_scope', 'is_posting_date', 'is_other']\n",
    "for primary_column in subtypes_list:\n",
    "    for secondary_column in subtypes_list:\n",
    "        sql_str = f'''\n",
    "UPDATE NavigableParents\n",
    "SET {secondary_column} = 0\n",
    "WHERE\n",
    "    {primary_column} = 1 AND\n",
    "    {secondary_column} IS NULL;'''\n",
    "        db.execute(sql_str)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\CORP_SCOPE_NONHEADERS_LIST.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "subtypes_dict = {\n",
    "    'is_task_scope': 'TASK_SCOPE_NONHEADERS_LIST',\n",
    "    'is_minimum_qualification': 'REQ_QUALS_NONHEADERS_LIST',\n",
    "    'is_preferred_qualification': 'PREFF_QUALS_NONHEADERS_LIST',\n",
    "    'is_legal_notification': 'LEGAL_NOTIFS_NONHEADERS_LIST',\n",
    "    'is_job_title': 'JOB_TITLE_NONHEADERS_LIST',\n",
    "    'is_office_location': 'OFFICE_LOC_NONHEADERS_LIST',\n",
    "    'is_job_duration': 'JOB_DURATION_NONHEADERS_LIST',\n",
    "    'is_supplemental_pay': 'SUPP_PAY_NONHEADERS_LIST',\n",
    "    'is_educational_requirement': 'EDUC_REQS_NONHEADERS_LIST',\n",
    "    'is_interview_procedure': 'INTERV_PROC_NONHEADERS_LIST',\n",
    "    'is_corporate_scope': 'CORP_SCOPE_NONHEADERS_LIST',\n",
    "    'is_posting_date': 'POST_DATE_NONHEADERS_LIST',\n",
    "    'is_other': 'OTHER_NONHEADERS_LIST'\n",
    "    }\n",
    "for primary_column, list_name in subtypes_dict.items():\n",
    "    sql_str = f'''\n",
    "SELECT navigable_parent\n",
    "FROM NavigableParents\n",
    "WHERE\n",
    "    is_header = 0 AND\n",
    "    {primary_column} = 1;'''\n",
    "    cursor_obj = db.execute(sql_str)\n",
    "    row_objs_list = cursor_obj.fetchall()\n",
    "    child_strs_list = [row_obj['navigable_parent'] for row_obj in row_objs_list]\n",
    "    for tag_str in child_strs_list:\n",
    "        ha.store_unique_list(list_name, tag_str)\n",
    "        clear_output(wait=True)\n",
    "    cursor_obj.close()\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\OTHER_HEADERS_LIST.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subtypes_dict = {\n",
    "    'is_task_scope': 'TASK_SCOPE_HEADERS_LIST',\n",
    "    'is_minimum_qualification': 'REQ_QUALS_HEADERS_LIST',\n",
    "    'is_preferred_qualification': 'PREFF_QUALS_HEADERS_LIST',\n",
    "    'is_legal_notification': 'LEGAL_NOTIFS_HEADERS_LIST',\n",
    "    'is_job_title': 'JOB_TITLE_HEADERS_LIST',\n",
    "    'is_office_location': 'OFFICE_LOC_HEADERS_LIST',\n",
    "    'is_job_duration': 'JOB_DURATION_HEADERS_LIST',\n",
    "    'is_supplemental_pay': 'SUPP_PAY_HEADERS_LIST',\n",
    "    'is_educational_requirement': 'EDUC_REQS_HEADERS_LIST',\n",
    "    'is_interview_procedure': 'INTERV_PROC_HEADERS_LIST',\n",
    "    'is_corporate_scope': 'CORP_SCOPE_HEADERS_LIST',\n",
    "    'is_posting_date': 'POST_DATE_HEADERS_LIST',\n",
    "    'is_other': 'OTHER_HEADERS_LIST'\n",
    "    }\n",
    "for primary_column, list_name in subtypes_dict.items():\n",
    "    sql_str = f'''\n",
    "SELECT navigable_parent\n",
    "FROM NavigableParents\n",
    "WHERE\n",
    "    is_header = 1 AND\n",
    "    {primary_column} = 1;'''\n",
    "    cursor_obj = db.execute(sql_str)\n",
    "    row_objs_list = cursor_obj.fetchall()\n",
    "    child_strs_list = [row_obj['navigable_parent'] for row_obj in row_objs_list]\n",
    "    for tag_str in child_strs_list:\n",
    "        ha.store_unique_list(list_name, tag_str)\n",
    "        clear_output(wait=True)\n",
    "    cursor_obj.close()\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cursor_obj = db.execute('SELECT pos_symbol, pos_explanation FROM PartsOfSpeech')\n",
    "row_objs_list = cursor_obj.fetchall()\n",
    "pos_symbols_list = [row_obj['pos_symbol'] for row_obj in row_objs_list]\n",
    "pos_explanations_list = [row_obj['pos_explanation'] for row_obj in row_objs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14337"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 14347\n",
    "len(ea.HEADERS_DICTIONARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "hc = HeaderCategories()\n",
    "%run ../py/sql_utlis.py\n",
    "su = SqlUtilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def compute_entropy(labels, base=None):\n",
    "    \"\"\" Computes entropy of label distribution. \"\"\"\n",
    "    value, counts = np.unique(list(labels), return_counts=True)\n",
    "    \n",
    "    return entropy(counts, base=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pos_count(topic):\n",
    "    words_list = [re.sub(r'0\\.\\d+\\*\"', '', word, 1).replace('\"', '') for word in re.split(r'\" \\+ 0\\.\\d+\\*\"', topic, 0)]\n",
    "    \n",
    "    # Search the html strings for these words\n",
    "    regex_str = r\"\\b(\" + '|'.join(words_list) + r\")\\b\"\n",
    "    sql_str = f'SELECT navigable_parent FROM NavigableParents WHERE MATCHES(\"{regex_str}\", navigable_parent) AND is_header IS NOT NULL;'\n",
    "    cursor_obj = db.cursor()\n",
    "    cursor_obj.execute(sql_str)\n",
    "    row_objs_list = cursor_obj.fetchall()\n",
    "    child_strs_list = [row_obj['navigable_parent'] for row_obj in row_objs_list]\n",
    "    cursor_obj.close()\n",
    "    \n",
    "    # Get and count the parts of speech from the feature tuples\n",
    "    child_tags_list = su.get_child_tags_list(db, child_strs_list)\n",
    "    feature_dict_list = su.get_feature_dict_list(db, child_tags_list, child_strs_list)\n",
    "    feature_tuple_list = [hc.get_feature_tuple(feature_dict, pos_lr_predict_single=None, pos_crf_predict_single=None) for feature_dict in feature_dict_list]\n",
    "    counter_obj = Counter([feature_tuple[2] for feature_tuple in feature_tuple_list])\n",
    "    \n",
    "    return counter_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "topic_tuples_list = []\n",
    "for i, topic in ea.LDA.show_topics(formatted=True, num_topics=len(pos_explanations_list), num_words=10):\n",
    "    counter_dict = dict(get_pos_count(topic))\n",
    "    entropy_float = compute_entropy(counter_dict.values())\n",
    "    topic_tuple = (entropy_float, i, counter_dict, topic)\n",
    "    topic_tuples_list.append(topic_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted(topic_tuples_list, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7963116401738131"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "compute_entropy(list(random.choice(topic_tuples_list)[2].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entropy_tuples_list = []\n",
    "for topic_tuple in topic_tuples_list:\n",
    "    i = topic_tuple[1]\n",
    "    counter_dict = topic_tuple[2]\n",
    "    entropy_float = compute_entropy(counter_dict.values())\n",
    "    topic = topic_tuple[3]\n",
    "    entropy_tuple = (entropy_float, i, counter_dict, topic)\n",
    "    entropy_tuples_list.append(entropy_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6931471805599453 {'O': 345, 'H': 21}\n",
      "0: 0.045*\"procedures\" + 0.040*\"Statistical\" + 0.028*\"submit\" + 0.027*\"place\" + 0.027*\"Management\" + 0.025*\"San\" + 0.021*\"Lead\" + 0.019*\"Francisco\" + 0.017*\"Program\" + 0.017*\"Are\"\n",
      "\n",
      "0.6931471805599453 {'O': 5089, 'H': 19}\n",
      "19: 0.041*\"<li\" + 0.041*\"</li\" + 0.037*\"business\" + 0.026*\"performance\" + 0.022*\"results\" + 0.018*\"metrics\" + 0.015*\"Build\" + 0.015*\"com\" + 0.015*\"drive\" + 0.014*\"data\"\n",
      "\n",
      "0.6931471805599453 {'O': 945, 'H': 14}\n",
      "21: 0.053*\"health\" + 0.031*\"research\" + 0.025*\"care\" + 0.020*\"statistics\" + 0.019*\"benefits\" + 0.019*\"paid\" + 0.019*\"healthcare\" + 0.017*\"outcomes\" + 0.014*\"survey\" + 0.014*\"clinical\"\n",
      "\n",
      "0.7963116401738131 {'H': 60, 'O': 5154, 'H-TS': 1, 'H-RQ': 1, 'O-PQ': 1, 'H-IP': 1, 'H-CS': 1}\n",
      "24: 0.112*\"or\" + 0.056*\"experience\" + 0.041*\"s\" + 0.039*\"<li\" + 0.039*\"</li\" + 0.034*\"related\" + 0.029*\"degree\" + 0.026*\"Science\" + 0.024*\"field\" + 0.021*\"Computer\"\n",
      "\n",
      "0.9502705392332347 {'O': 5259, 'H': 34, 'H-CS': 1, 'H-RQ': 1, 'O-PQ': 1}\n",
      "7: 0.108*\"<li\" + 0.108*\"</li\" + 0.029*\"with\" + 0.016*\"stakeholders\" + 0.015*\"implement\" + 0.015*\"time\" + 0.014*\"visualization\" + 0.013*\"BI\" + 0.011*\"Paid\" + 0.011*\"off\"\n",
      "\n",
      "0.9502705392332347 {'O': 1185, 'H': 26, 'H-CS': 1, 'H-LN': 1, 'H-O': 1}\n",
      "12: 0.059*\"<div\" + 0.059*\"</div\" + 0.025*\"S\" + 0.024*\"U\" + 0.024*\"by\" + 0.018*\"from\" + 0.016*\"Remote\" + 0.015*\"Department\" + 0.015*\"United\" + 0.014*\"For\"\n",
      "\n",
      "0.9502705392332347 {'H': 22, 'O': 1166, 'H-TS': 1, 'H-IP': 1, 'H-CS': 1}\n",
      "23: 0.030*\"hours\" + 0.027*\"making\" + 0.025*\"recommendations\" + 0.025*\"approaches\" + 0.025*\"decision\" + 0.019*\"PhD\" + 0.016*\"presentations\" + 0.015*\"principles\" + 0.015*\"Operations\" + 0.015*\"s\"\n",
      "\n",
      "1.0397207708399179 {'H': 38, 'O': 2820, 'H-RQ': 1, 'O-PQ': 1}\n",
      "5: 0.037*\"status\" + 0.037*\"or\" + 0.022*\"employment\" + 0.021*\"an\" + 0.020*\"gender\" + 0.018*\"is\" + 0.018*\"disability\" + 0.015*\"national\" + 0.015*\"race\" + 0.015*\"veteran\"\n",
      "\n",
      "1.15374194270109 {'H': 80, 'O': 2807, 'H-TS': 2, 'H-RQ': 1, 'H-IP': 1, 'H-CS': 1, 'H-SP': 1}\n",
      "2: 0.034*\"is\" + 0.021*\"</p\" + 0.021*\"<p\" + 0.021*\"s\" + 0.019*\"world\" + 0.018*\"that\" + 0.017*\"company\" + 0.016*\"technology\" + 0.014*\"Our\" + 0.013*\"more\"\n",
      "\n",
      "1.242453324894 {'O': 6607, 'H': 103, 'H-CS': 1, 'H-PQ': 2, 'H-RQ': 1, 'O-PQ': 1}\n",
      "13: 0.096*\"<li\" + 0.096*\"</li\" + 0.026*\"with\" + 0.025*\"technical\" + 0.020*\"for\" + 0.019*\"data\" + 0.018*\"management\" + 0.018*\"project\" + 0.017*\"Ability\" + 0.017*\"quality\"\n",
      "\n",
      "1.242453324894 {'O': 6717, 'H': 101, 'H-CS': 1, 'H-PQ': 2, 'H-RQ': 1, 'O-PQ': 1}\n",
      "20: 0.117*\"data\" + 0.029*\"with\" + 0.027*\"business\" + 0.022*\"for\" + 0.020*\"models\" + 0.018*\"</li\" + 0.018*\"<li\" + 0.015*\"solutions\" + 0.015*\"from\" + 0.015*\"learning\"\n",
      "\n",
      "1.329661348854758 {'O': 5754, 'H': 65, 'H-RQ': 2, 'H-PQ': 1, 'H-CS': 2, 'O-PQ': 1}\n",
      "17: 0.074*\"</li\" + 0.074*\"<li\" + 0.044*\"on\" + 0.027*\"developing\" + 0.022*\"ability\" + 0.018*\"multiple\" + 0.018*\"A\" + 0.018*\"clinical\" + 0.016*\"projects\" + 0.014*\"with\"\n",
      "\n",
      "1.3321790402101223 {'O': 5773, 'H': 99, 'H-CS': 1, 'H-RQ': 6, 'O-PQ': 1}\n",
      "11: 0.188*\"<li\" + 0.188*\"</li\" + 0.043*\"experience\" + 0.038*\"years\" + 0.027*\"with\" + 0.021*\"Experience\" + 0.019*\"insurance\" + 0.018*\":\" + 0.013*\"working\" + 0.011*\"Learning\"\n",
      "\n",
      "1.3321790402101223 {'O': 5328, 'H': 50, 'H-CS': 1, 'H-RQ': 3, 'O-PQ': 1}\n",
      "18: 0.099*\"<li\" + 0.099*\"</li\" + 0.081*\"skills\" + 0.038*\"Strong\" + 0.033*\"communication\" + 0.022*\"written\" + 0.021*\"Excellent\" + 0.019*\"with\" + 0.018*\"problem\" + 0.017*\"ability\"\n",
      "\n",
      "1.3862943611198906 {'O': 2602, 'H': 127, 'H-PQ': 3, 'H-RQ': 1}\n",
      "4: 0.067*\"we\" + 0.034*\"<i\" + 0.034*\"</i\" + 0.026*\"that\" + 0.024*\"people\" + 0.023*\"make\" + 0.019*\"culture\" + 0.018*\"re\" + 0.017*\"for\" + 0.014*\"us\"\n",
      "\n",
      "1.3862943611198906 {'O': 1270, 'H': 95, 'H-RQ': 2, 'H-TS': 1}\n",
      "25: 0.046*\"required\" + 0.028*\"Knowledge\" + 0.026*\"must\" + 0.022*\"be\" + 0.020*\"able\" + 0.016*\"perform\" + 0.016*\"include\" + 0.016*\"Advanced\" + 0.015*\"duties\" + 0.015*\"Must\"\n",
      "\n",
      "1.5607104090414063 {'O': 649, 'H': 143, 'H-CS': 4, 'H-TS': 9, 'H-PQ': 2, 'H-RQ': 2}\n",
      "8: 0.045*\"What\" + 0.040*\"About\" + 0.028*\"competitive\" + 0.027*\"vision\" + 0.027*\"sampling\" + 0.019*\"ll\" + 0.019*\":\" + 0.017*\"You\" + 0.017*\"Dental\" + 0.017*\"Be\"\n",
      "\n",
      "1.5607104090414063 {'O': 3791, 'H': 225, 'H-PQ': 5, 'H-TS': 8, 'H-RQ': 1, 'H-CS': 1}\n",
      "16: 0.048*\"will\" + 0.030*\"team\" + 0.023*\"be\" + 0.022*\"for\" + 0.019*\"You\" + 0.016*\"as\" + 0.015*\"product\" + 0.015*\"role\" + 0.013*\"an\" + 0.012*\"that\"\n",
      "\n",
      "1.6094379124341005 {'O': 3644, 'H': 199, 'H-PQ': 5, 'H-TS': 7, 'H-CS': 2}\n",
      "10: 0.082*\"Data\" + 0.041*\"The\" + 0.038*\"will\" + 0.031*\"for\" + 0.029*\"as\" + 0.025*\"is\" + 0.024*\"This\" + 0.022*\"Scientist\" + 0.017*\"Senior\" + 0.017*\"team\"\n",
      "\n",
      "1.6094379124341005 {'O': 6769, 'H': 108, 'H-CS': 2, 'H-RQ': 6, 'O-PQ': 1}\n",
      "15: 0.068*\"<li\" + 0.068*\"</li\" + 0.042*\"statistical\" + 0.035*\"or\" + 0.034*\"with\" + 0.034*\"data\" + 0.030*\"as\" + 0.026*\"Experience\" + 0.022*\"such\" + 0.022*\"learning\"\n",
      "\n",
      "1.6769877743224173 {'O': 1021, 'H': 106, 'H-OL': 4, 'H-TS': 6, 'H-PD': 2, 'H-RQ': 4, 'H-JT': 1, 'H-CS': 2, 'H-PQ': 2}\n",
      "9: 0.080*\"time\" + 0.067*\":\" + 0.060*\"</p\" + 0.060*\"<p\" + 0.035*\"Work\" + 0.031*\"Job\" + 0.030*\"Full\" + 0.025*\"Company\" + 0.024*\"position\" + 0.024*\"Type\"\n",
      "\n",
      "1.7328679513998633 {'O': 116, 'H': 50, 'H-TS': 6, 'H-PD': 2, 'H-RQ': 3, 'H-JT': 1, 'H-PQ': 2, 'H-OL': 1}\n",
      "1: 0.087*\"class\" + 0.063*\"u\" + 0.063*\"icl\" + 0.051*\"Description\" + 0.048*\"Job\" + 0.047*\"jobDescriptionTitle\" + 0.043*\"xs\" + 0.042*\"jobsearch\" + 0.040*\"<h2\" + 0.040*\"</h2\"\n",
      "\n",
      "1.7478680974667573 {'O': 5124, 'H': 256, 'H-PQ': 4, 'H-CS': 2, 'H-TS': 8, 'H-RQ': 2, 'O-PQ': 1}\n",
      "6: 0.036*\"you\" + 0.023*\"work\" + 0.020*\"for\" + 0.020*\"with\" + 0.018*\"have\" + 0.018*\"your\" + 0.017*\"is\" + 0.016*\"that\" + 0.015*\"You\" + 0.015*\"on\"\n",
      "\n",
      "1.7478680974667573 {'O': 1250, 'H': 97, 'H-SP': 3, 'H-ER': 3, 'H-RQ': 5, 'H-JD': 2, 'H-TS': 1}\n",
      "14: 0.274*\"</p\" + 0.274*\"<p\" + 0.146*\":\" + 0.028*\"year\" + 0.019*\"Education\" + 0.015*\"00\" + 0.014*\"Schedule\" + 0.014*\"per\" + 0.014*\"Experience\" + 0.013*\"Benefits\"\n",
      "\n",
      "1.7478680974667573 {'O': 5015, 'H': 207, 'H-CS': 1, 'H-TS': 7, 'H-RQ': 3, 'H-PQ': 2, 'O-PQ': 1}\n",
      "22: 0.047*\"or\" + 0.043*\"be\" + 0.036*\"for\" + 0.032*\"may\" + 0.029*\"not\" + 0.028*\"you\" + 0.024*\"this\" + 0.023*\"your\" + 0.018*\"with\" + 0.017*\"required\"\n",
      "\n",
      "2.242973226438147 {'H': 241, 'O': 309, 'H-PQ': 6, 'H-CS': 9, 'H-TS': 23, 'H-IP': 1, 'H-SP': 2, 'H-OL': 12, 'H-ER': 2, 'H-JD': 5, 'H-LN': 4, 'H-PD': 2, 'H-RQ': 20, 'H-JT': 2}\n",
      "3: 0.303*\"<b\" + 0.303*\"</b\" + 0.105*\":\" + 0.018*\"Qualifications\" + 0.017*\"Responsibilities\" + 0.012*\"Requirements\" + 0.012*\"Location\" + 0.012*\"Required\" + 0.011*\"Job\" + 0.009*\"Skills\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "entropy_tuples_list = sorted(entropy_tuples_list, key=lambda x: x[0])\n",
    "for topic_tuple in entropy_tuples_list:\n",
    "    entropy_float = topic_tuple[0]\n",
    "    i = topic_tuple[1]\n",
    "    counter_dict = topic_tuple[2]\n",
    "    topic = topic_tuple[3]\n",
    "    print('')\n",
    "    print(f'{entropy_float} {counter_dict}')\n",
    "    print(f'{i}: {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H-TS', 'O-TS', 'H-RQ', 'O-RQ', 'H-PQ', 'O-PQ', 'H-LN', 'O-LN', 'H-JT', 'O-JT', 'H-OL', 'O-OL', 'H-JD', 'O-JD', 'H-SP', 'O-SP', 'H-ER', 'O-ER', 'H-IP', 'O-IP', 'H-CS', 'O-CS', 'H-PD', 'O-PD', 'H-O', 'O-O']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pos_symbols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_str = f'SELECT navigable_parent FROM NavigableParents WHERE is_task_scope IS NULL AND is_header <> 1;'\n",
    "cursor_obj = db.cursor()\n",
    "cursor_obj.execute(sql_str)\n",
    "row_objs_list = cursor_obj.fetchall()\n",
    "child_strs_list = [row_obj['navigable_parent'] for row_obj in row_objs_list]\n",
    "cursor_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_tag': 'li', 'is_header': None, 'is_task_scope': None, 'is_minimum_qualification': None, 'is_preferred_qualification': None, 'is_legal_notification': None, 'is_job_title': None, 'is_office_location': None, 'is_job_duration': None, 'is_supplemental_pay': None, 'is_educational_requirement': None, 'is_interview_procedure': None, 'is_corporate_scope': None, 'is_posting_date': None, 'is_other': None, 'child_str': '<li>Must be capable of managing multiple projects with time related constraints in a fast- paced contract manufacturing environment.</li>'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.choice(feature_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ea.build_headers_dictionary()\n",
    "ea.build_lda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4812"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ea.HEADERS_DICTIONARY.filter_extremes(no_below=5, no_above=0.5, keep_n=100000, keep_tokens=None)\n",
    "len(ea.HEADERS_DICTIONARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords_list = ['and', '.', 'to', 'a', 'the', 'of', 'in', 'We', 'are', 'our']\n",
    "#ea.HEADERS_DICTIONARY = {}\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "ha = HeaderAnalysis()\n",
    "\n",
    "# Build model with tokenized words\n",
    "sents_list = [sent_str for sublist in ea.CHILD_STRS_LIST_DICT.values() for sent_str in sublist]\n",
    "tokenized_sents_list = [ha.html_regex_tokenizer(sent_str) for sent_str in sents_list]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "#ea.HEADERS_DICTIONARY = Dictionary(tokenized_sents_list)\n",
    "for i in reversed(range(len(tokenized_sents_list))):\n",
    "    for j in reversed(range(len(tokenized_sents_list[i]))):\n",
    "        if tokenized_sents_list[i][j] in stopwords_list:\n",
    "            del tokenized_sents_list[i][j]\n",
    "tokenized_sents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Build model with tokenized words\n",
    "sents_list = [sent_str for sublist in ea.CHILD_STRS_LIST_DICT.values() for sent_str in sublist]\n",
    "tokenized_sents_list = [ha.html_regex_tokenizer(sent_str) for sent_str in sents_list]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "HEADERS_DICTIONARY = Dictionary(tokenized_sents_list)\n",
    "headers_corpus = [HEADERS_DICTIONARY.doc2bow(tag_str) for tag_str in tokenized_sents_list]\n",
    "\n",
    "# Train the model on the corpus\n",
    "num_topics = db.execute('SELECT COUNT(*) FROM PartsOfSpeech').fetchone()['COUNT(*)']\n",
    "id2word = {v: k for k, v in HEADERS_DICTIONARY.token2id.items()}\n",
    "LDA = LdaModel(corpus=headers_corpus, num_topics=num_topics, id2word=id2word, passes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('H-TS', 1), ('O', 2), ('H-TS', 1), ('O', 12), ('H-CS', 1), ('O', 15)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from itertools import groupby\n",
    "\n",
    "pos_list = ['H-TS', 'O', 'O', 'H-TS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'H-CS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    "            'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "consecutives_list = []\n",
    "for k, v in groupby(pos_list):\n",
    "    consecutives_list.append((k, len(list(v))))\n",
    "consecutives_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HEADERS_DICTIONARY.add_documents', 'HEADERS_DICTIONARY.cfs', 'HEADERS_DICTIONARY.compactify', 'HEADERS_DICTIONARY.dfs', 'HEADERS_DICTIONARY.doc2bow', 'HEADERS_DICTIONARY.doc2idx', 'HEADERS_DICTIONARY.filter_extremes', 'HEADERS_DICTIONARY.filter_n_most_frequent', 'HEADERS_DICTIONARY.filter_tokens', 'HEADERS_DICTIONARY.from_corpus', 'HEADERS_DICTIONARY.from_documents', 'HEADERS_DICTIONARY.get', 'HEADERS_DICTIONARY.id2token', 'HEADERS_DICTIONARY.items', 'HEADERS_DICTIONARY.iteritems', 'HEADERS_DICTIONARY.iterkeys', 'HEADERS_DICTIONARY.itervalues', 'HEADERS_DICTIONARY.keys', 'HEADERS_DICTIONARY.load', 'HEADERS_DICTIONARY.load_from_text', 'HEADERS_DICTIONARY.merge_with', 'HEADERS_DICTIONARY.num_docs', 'HEADERS_DICTIONARY.num_nnz', 'HEADERS_DICTIONARY.num_pos', 'HEADERS_DICTIONARY.patch_with_special_tokens', 'HEADERS_DICTIONARY.save', 'HEADERS_DICTIONARY.save_as_text', 'HEADERS_DICTIONARY.token2id', 'HEADERS_DICTIONARY.values']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[f'HEADERS_DICTIONARY.{fn}' for fn in dir(HEADERS_DICTIONARY) if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_topics = db.execute('SELECT COUNT(*) FROM PartsOfSpeech').fetchone()['COUNT(*)']\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\CHILD_STRS_LIST_DICT.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ea.CHILD_STRS_LIST_DICT = {file_name: su.get_child_strs_from_file(db, file_name) for file_name in os.listdir(ha.SAVES_HTML_FOLDER)}\n",
    "s.store_objects(CHILD_STRS_LIST_DICT=ea.CHILD_STRS_LIST_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\dev\\Documents\\Repositories\\job-hunting\\saves\\pickle\\NAVIGABLE_PARENT_IS_HEADER_DICT.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sql_str = '''\n",
    "SELECT\n",
    "    navigable_parent,\n",
    "    is_header\n",
    "FROM NavigableParents\n",
    "WHERE is_header IS NOT NULL'''\n",
    "cursor_obj = db.execute(sql_str)\n",
    "row_obj_list = cursor_obj.fetchall()\n",
    "ha.NAVIGABLE_PARENT_IS_HEADER_DICT = {row_obj['navigable_parent']: row_obj['is_header'] for row_obj in row_obj_list}\n",
    "s.store_objects(NAVIGABLE_PARENT_IS_HEADER_DICT=ha.NAVIGABLE_PARENT_IS_HEADER_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match(':.{15,}$', '<li>software development: 1 year (Preferred)</li>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../py/html_analysis.py\n",
    "ha = HeaderAnalysis()\n",
    "ha.store_unique_list('supp_pay_nonheaders_list', '<li>401(k)</li>')\n",
    "supp_pay_nonheaders_list = s.load_object('supp_pay_nonheaders_list')\n",
    "for navigable_parent in supp_pay_nonheaders_list:\n",
    "    db.execute('''\n",
    "UPDATE NavigableParents\n",
    "SET is_header = 0, is_supplemental_pay = 1\n",
    "WHERE (navigable_parent = ?)''', (navigable_parent,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_str = '''\n",
    "SELECT navigable_parent\n",
    "FROM NavigableParents\n",
    "WHERE\n",
    "    navigable_parent_id IN (\n",
    "        SELECT navigable_parent_id\n",
    "        FROM NavigableParentSequence\n",
    "        WHERE file_name_id IN (\n",
    "            SELECT file_name_id\n",
    "            FROM NavigableParentSequence\n",
    "            WHERE navigable_parent_id = (\n",
    "                SELECT navigable_parent_id\n",
    "                FROM NavigableParents\n",
    "                WHERE navigable_parent = '<li>401(k)</li>'\n",
    "                )\n",
    "            )\n",
    "        ) AND\n",
    "    is_header IS NULL'''\n",
    "cursor_obj = db.execute(sql_str)\n",
    "row_objs_list = cursor_obj.fetchall()\n",
    "child_strs_list = [row_obj['navigable_parent'] for row_obj in row_objs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set(child_strs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.execute('DROP TABLE IF EXISTS FileNames;')\n",
    "db.execute('''\n",
    "CREATE TABLE FileNames(\n",
    "    file_name_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    file_name TEXT NOT NULL\n",
    ");''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../py/html_analysis.py\n",
    "ha = HeaderAnalysis()\n",
    "files_list = os.listdir(ha.SAVES_HTML_FOLDER)\n",
    "for file_name in files_list:\n",
    "    if file_name.endswith('html'):\n",
    "        db.execute('INSERT INTO FileNames (file_name) VALUES (?)', (file_name,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.execute('DROP TABLE IF EXISTS HeaderTags;')\n",
    "db.execute('''\n",
    "CREATE TABLE HeaderTags(\n",
    "    header_tag_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    header_tag TEXT NOT NULL\n",
    ");''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tag_set = set()\n",
    "for file_name in files_list:\n",
    "    child_strs_list = ha.get_child_strs_from_file(file_name)\n",
    "    child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "    for child_tag in child_tags_list:\n",
    "        tag_set.add(child_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for child_tag in sorted(tag_set):\n",
    "    db.execute('INSERT INTO HeaderTags (header_tag) VALUES (?)', (child_tag,))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db.execute('DROP TABLE IF EXISTS NavigableParents;')\n",
    "db.execute('''\n",
    "CREATE TABLE NavigableParents (\n",
    "    navigable_parent_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    navigable_parent TEXT NOT NULL,\n",
    "    is_header BIT NULL,\n",
    "    is_task_scope BIT NULL,\n",
    "    is_minimum_qualification BIT NULL,\n",
    "    is_preferred_qualification BIT NULL,\n",
    "    is_legal_notification BIT NULL,\n",
    "    is_job_title BIT NULL,\n",
    "    is_office_location BIT NULL,\n",
    "    is_job_duration BIT NULL,\n",
    "    is_supplemental_pay BIT NULL,\n",
    "    is_educational_requirement BIT NULL,\n",
    "    is_interview_procedure BIT NULL,\n",
    "    is_corporate_scope BIT NULL,\n",
    "    is_posting_date BIT NULL,\n",
    "    is_other BIT NULL,\n",
    "    is_qualification BIT NULL\n",
    ");''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "navigable_parent_set = set()\n",
    "for file_name in files_list:\n",
    "    child_strs_list = ha.get_child_strs_from_file(file_name)\n",
    "    for child_str in child_strs_list:\n",
    "        navigable_parent_set.add(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for child_str in sorted(navigable_parent_set):\n",
    "    db.execute('INSERT INTO NavigableParents (navigable_parent) VALUES (?)', (child_str,))\n",
    "db.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.7.9)",
   "language": "python",
   "name": "jh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
