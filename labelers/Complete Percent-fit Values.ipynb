{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f597bc2-b333-44f4-b3c8-7c6fdeafad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/5.24.2 ========\n",
      "Utility libraries created in 3 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "executable_path = sys.executable; scripts_folder = osp.join(osp.dirname(executable_path), 'Scripts')\n",
    "py_folder = osp.abspath(osp.join('..', 'py')); ffmpeg_folder = r'C:\\ffmpeg\\bin'\n",
    "if (scripts_folder not in sys.path): sys.path.insert(1, scripts_folder)\n",
    "if (py_folder not in sys.path): sys.path.insert(1, py_folder)\n",
    "if (ffmpeg_folder not in sys.path): sys.path.insert(1, ffmpeg_folder)\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import pyperclip\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d259dffb-c212-4493-a879-1ae5d503f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 532,546 is-qualified vocabulary tokens in here\n",
      "Is-qualified LR model built in 11 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the Logistic Regression utilities class has built its is-qualified classifier\n",
    "t1 = time.time()\n",
    "if not (hasattr(lru, 'ISQUALIFIED_LR') and hasattr(lru, 'ISQUALIFIED_CV')):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified LR model built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3f331b-c66a-4c65-906b-22bc6fc034c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I have 47,849 labeled parts of speech in here\n",
      "Train the POS Classifiers: 100%|███████████████| 25/25 [00:00<00:00, 349.57it/s]\n",
      "predict_single is available\n",
      "Parts-of-speech logistic regression model built in 8 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression model\n",
    "# Parts-of-speech logistic regression model is normally built in 1 hour, 18 minutes, and 19 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'): print('predict_single is available', file=sys.stderr)\n",
    "else: print('predict_single is not available', file=sys.stderr)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech logistic regression model built in {duration_str}'; print(speech_str, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d67a34-e133-45dc-9bf3-a830af359d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 54,088 hand-labeled header htmls prepared\n",
      "7 iterations seen during training fit for a total of 54,088 records trained\n",
      "Is-header classifier trained in 7 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the isheader classifier\n",
    "t1 = time.time()\n",
    "ihu.build_pos_stochastic_gradient_descent_elements(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-header classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f438163-0f14-4a74-978c-769c9dba95c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02bfeac-67b7-4df6-a4a0-32ec3dec0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 24,606 hand-labeled qualification strings in here\n",
      "I have 675,765 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 24 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary below or in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified classifer retrained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad3579-ebc3-4d21-a7c3-f9bd168ac6ca",
   "metadata": {},
   "source": [
    "\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d334d815-e43b-474e-9dbb-db509176f6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Qualifications for 1786632 Senior Data Scientist:\n",
      "*quals_list[0] = \"Stay updated with emerging trends in blockchain analytics and data science methodologies.\" (1.0)\n",
      "*quals_list[1] = \"5-7 years of strong background in building machine learning models and performing statistical analysis.\" (1.0)\n",
      "*quals_list[2] = \"Experience with big data platforms and query languages (eg, SQL, Spark).\" (1.0)\n",
      "*quals_list[3] = \"Expertise in Python and data science libraries such as Pandas, NumPy, and Scikit-learn.\" (1.0)\n",
      "100.00%\n",
      "\n",
      "hunting_df.loc[6181, 'percent_fit'] = (000+000+000+000)/4\n",
      "15 left to go: 6180/6195 = 99.76% completed (taking about 4.3 minutes per post)\n",
      "Inference completed in 14 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "quals_list, file_name = lru.infer_from_hunting_dataframe(fitness_threshold=3/4, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Inference completed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0201434-c7e8-43c8-8004-e09fc12f7c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = time.time() - t0; duration_str = humanize.precisedelta(d, minimum_unit='minutes', format='%0.0f'); mpp = (d//60)/lru.max_togo if lru.max_togo else \"N/A\"\n",
    "raise Exception(f'Postings from the previous email ingestion processed in {duration_str} taking about {mpp} minutes per post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47bd03b8-c0a3-404c-a16d-eb4ce95c6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hands-on 3-5 years of relevant work experience as a Machine Learning Engineer\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qualification string\n",
    "qualification_str = quals_list[10]\n",
    "print(qualification_str); basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[qualification_str]) + '\\n' if (qualification_str in basic_quals_dict) else '', end='')\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4212b-9280-46d1-8e46-104aada7c0df",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix Parts-of-Speech and Quals for this posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ac6efb8-6b56-43dd-9079-d6a87491ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1776627_Data_Scientist_tbi_bank.html\n",
      "Child strings list recreated in 1 minute and 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "file_path = osp.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if osp.isfile(file_path):\n",
    "    child_strs_list = hau.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    print(file_name)\n",
    "    assert hasattr(slrcu, 'pos_predict_percent_fit_dict'), 'slrcu.predict_single needs to be available'\n",
    "    pos_symbol_predictions_list = [slrcu.predict_single(sent_str) for sent_str in child_strs_list]\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Child strings list recreated in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "affcb06a-3165-4349-a936-037af549d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-CS', 'H-CS', 'H-JT', 'O-CS', 'H-CS', 'O-CS', 'O-CS', 'O-RQ', 'O-CS', 'H-JT', 'O-CS', 'O-IP', 'O-IP', 'O-JT', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'H-RQ', 'H-RQ', 'O-PQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'O-PQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'H-SP', 'H-SP', 'O-TS', 'O-RQ', 'O-SP', 'O-SP', 'O-SP', 'O-TS', 'O-RQ', 'O-RQ', 'H-CS', 'O-IP', 'O-IP', 'O-IP', 'O-CS', 'H-OL', 'O-PD', 'O-IP', 'H-JT', 'O-LN', 'O-O', 'O-LN', 'H-JT', 'H-SP', 'O-SP']\n",
      "[7, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 48, 53, 58, 59]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-CS) <span style=\"color:#1f77b4ff;\"><p>Who we are: Do you want to join a well-established bank with a start-up culture? No, we’re not joking! (H-CS Corporate Scope Header)</p></span><br />1 H-CS) <span style=\"color:#1f77b4ff;\">We, at (H-CS Corporate Scope Header)</span><br />2 H-JT) <span style=\"color:#d62728ff;\"><strong>tbi (H-JT Job Title Header)</strong></span><br />3 O-CS) <span style=\"color:#1f77b480;\">, have been one the most profitable banks for years and we are growing at a fast pace. We’re a bank with a long history of success that operates as a start-up and we’re always on the lookout for new opportunities to grow our business. How do we do that? (O-CS Corporate Scope Non-header)</span><br />4 H-CS) <span style=\"color:#1f77b4ff;\">It's all about our (H-CS Corporate Scope Header)</span><br />5 O-CS) <span style=\"color:#1f77b480;\"><strong>people (O-CS Corporate Scope Non-header)</strong></span><br />6 O-CS) <span style=\"color:#1f77b480;\">. Our team is made up of (O-CS Corporate Scope Non-header)</span><br /><hr />7 O-RQ) <span style=\"color:#bcbd2280;\"><strong>brave, passionate and caring (O-RQ Required Qualifications Non-header)</strong></span><br />8 O-CS) <span style=\"color:#1f77b480;\">people who don’t just want to follow the same path – we want to transform into mobile-first, state-of-the-art lifestyle ecosystem. Our colleagues love working here – 80% of them would recommend (O-CS Corporate Scope Non-header)</span><br />9 H-JT) <span style=\"color:#d62728ff;\"><strong>tbi (H-JT Job Title Header)</strong></span><br />10 O-CS) <span style=\"color:#1f77b480;\">as an employer to their friends and family. Our people are engaged in challenging and meaningful work, inspired to grow their potential and career, encouraged to learn and empowered to take decisions. That’s not corporate babble, it’s what our people say. (O-CS Corporate Scope Non-header)</span><br />11 O-IP) <span style=\"color:#ffbb7880;\"><p>Do you want to play a key role in our unique success story? (O-IP Interview Procedures Non-header)</p></span><br />12 O-IP) <span style=\"color:#ffbb7880;\">If so, we're looking for a (O-IP Interview Procedures Non-header)</span><br />13 O-JT) <span style=\"color:#d6272880;\"><strong>Data Scientist (O-JT Job Title Non-header)</strong></span><br />14 O-TS) <span style=\"color:#9edae580;\">to join our team on our journey to success! (O-TS Task Scope Non-header)</span><br />15 H-TS) <span style=\"color:#9edae5ff;\"><strong>What You’ll do: (H-TS Task Scope Header)</strong></span><br />16 O-TS) <span style=\"color:#9edae580;\"><p>Analyze complex datasets to identify trends, patterns, and opportunities (O-TS Task Scope Non-header)</p></span><br />17 O-TS) <span style=\"color:#9edae580;\"><p>Develop predictive models using machine learning and statistical techniques to address business challenges (O-TS Task Scope Non-header)</p></span><br />18 O-TS) <span style=\"color:#9edae580;\"><p>Perform hypothesis testing and design A/B experiments to validate business strategies (O-TS Task Scope Non-header)</p></span><br />19 O-TS) <span style=\"color:#9edae580;\"><p>Perform data cleaning, feature selection, and feature engineering to enhance model accuracy and interpretability (O-TS Task Scope Non-header)</p></span><br />20 O-TS) <span style=\"color:#9edae580;\"><p>Create and validate custom metrics and KPIs to measure model and business performance (O-TS Task Scope Non-header)</p></span><br />21 O-TS) <span style=\"color:#9edae580;\"><p>Implement and evaluate machine learning algorithms (e.g., RandomForest, XGBoost, Neural Networks) (O-TS Task Scope Non-header)</p></span><br />22 O-TS) <span style=\"color:#9edae580;\"><p>Experiment with advanced techniques such as deep learning, natural language processing (NLP), and time series forecasting to derive insights from structured and unstructured data (O-TS Task Scope Non-header)</p></span><br />23 H-TS) <span style=\"color:#9edae5ff;\"><p>Work closely with data engineers to ensure seamless data integration and pipeline development (H-TS Task Scope Header)</p></span><br />24 O-TS) <span style=\"color:#9edae580;\"><p>Collaborate with business stakeholders to translate complex findings into actionable business strategies (O-TS Task Scope Non-header)</p></span><br />25 O-TS) <span style=\"color:#9edae580;\"><p>Partner with business intelligence and analytics teams to create dashboards and visualizations that support business objectives (O-TS Task Scope Non-header)</p></span><br />26 O-TS) <span style=\"color:#9edae580;\"><p>Monitor the performance of deployed models and implement retraining strategies to improve model accuracy over time (O-TS Task Scope Non-header)</p></span><br />27 O-TS) <span style=\"color:#9edae580;\"><p>Optimize algorithms for scalability, efficiency, and robustness (O-TS Task Scope Non-header)</p></span><br />28 O-TS) <span style=\"color:#9edae580;\"><p>Design and build dashboards using visualization tools (e.g., Power BI, Tableau, or custom-built solutions) (O-TS Task Scope Non-header)</p></span><br />29 O-TS) <span style=\"color:#9edae580;\"><p>Create clear and impactful data stories and visualizations to present findings and recommendations to senior management and non-technical audiences (O-TS Task Scope Non-header)</p></span><br />30 O-TS) <span style=\"color:#9edae580;\"><p>Stay current with the latest advancements in machine learning and data science (O-TS Task Scope Non-header)</p></span><br />31 O-TS) <span style=\"color:#9edae580;\"><p>Experiment with new methodologies and tools to continuously enhance the data science capabilities of the organization (O-TS Task Scope Non-header)</p></span><br />32 H-RQ) <span style=\"color:#bcbd22ff;\"><h3 class=\"text-white font-semibold text-lg mb-2\">Requirements (H-RQ Required Qualifications Header)</h3></span><br />33 H-RQ) <span style=\"color:#bcbd22ff;\"><strong>What you’ll need to succeed: (H-RQ Required Qualifications Header)</strong></span><br />34 O-PQ) <span style=\"color:#c7c7c780;\"><li>Master’s degree in Data Science, Statistics, Mathematics, Computer Science, or a related field (O-PQ Preferred Qualifications Non-header)</li></span><br />35 O-RQ) <span style=\"color:#bcbd2280;\"><li>3+ years of Data Scientist-related work experience (O-RQ Required Qualifications Non-header)</li></span><br />36 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong proficiency in Python for data analysis, modeling, and machine learning, alongside SQL for data manipulation and querying (O-RQ Required Qualifications Non-header)</li></span><br />37 O-RQ) <span style=\"color:#bcbd2280;\"><li>Hands-on experience with machine learning libraries like Scikit-Learn, TensorFlow, Keras, PyTorch, and XGBoost (O-RQ Required Qualifications Non-header)</li></span><br />38 O-RQ) <span style=\"color:#bcbd2280;\"><li>Expertise in statistical techniques such as regression, hypothesis testing, and time series analysis to address business challenges (O-RQ Required Qualifications Non-header)</li></span><br />39 O-RQ) <span style=\"color:#bcbd2280;\"><li>In-depth knowledge of data cleaning, wrangling, and transformation using Pandas, Numpy, and SciPy (O-RQ Required Qualifications Non-header)</li></span><br />40 O-PQ) <span style=\"color:#c7c7c780;\"><li>Familiarity with ETL pipelines, data lakes, warehouses, and big data tools (e.g., Hadoop, Spark) (O-PQ Preferred Qualifications Non-header)</li></span><br />41 O-PQ) <span style=\"color:#c7c7c780;\"><li>Experience with cloud-based data ecosystems such as Snowflake, AWS Glue, Google Cloud Dataflow, or Azure Databricks (O-PQ Preferred Qualifications Non-header)</li></span><br />42 O-RQ) <span style=\"color:#bcbd2280;\"><li>Proficiency in data visualization tools like Power BI, Tableau, Matplotlib, Seaborn, and Plotly (O-RQ Required Qualifications Non-header)</li></span><br />43 O-RQ) <span style=\"color:#bcbd2280;\"><li>Knowledge of deep learning frameworks like TensorFlow and Keras, particularly in NLP, image processing, and advanced AI solutions (O-RQ Required Qualifications Non-header)</li></span><br />44 O-RQ) <span style=\"color:#bcbd2280;\"><li>Familiarity with version control systems like Git and collaborative platforms (e.g., GitHub, GitLab) (O-RQ Required Qualifications Non-header)</li></span><br />45 O-PQ) <span style=\"color:#c7c7c780;\"><li>Experience with cloud machine learning platforms (e.g., AWS SageMaker, Google AI) and deploying models via REST APIs or Docker containerization (O-PQ Preferred Qualifications Non-header)</li></span><br />46 O-RQ) <span style=\"color:#bcbd2280;\"><li>Fluent English skills (both written and spoken) (O-RQ Required Qualifications Non-header)</li></span><br />47 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong problem-solving, analytical, and critical thinking skills, with the ability to work both independently and as part of a team (O-RQ Required Qualifications Non-header)</li></span><br />48 O-RQ) <span style=\"color:#bcbd2280;\"><li>A proven track record of delivering high-quality projects on time (O-RQ Required Qualifications Non-header)</li></span><br />49 O-PQ) <span style=\"color:#c7c7c780;\"><li>Preferred certifications in areas like AWS Certified Machine Learning – Specialty or Google Professional Data Engineer (O-PQ Preferred Qualifications Non-header)</li></span><br />50 H-SP) <span style=\"color:#17becfff;\"><strong>What we offer: (H-SP Supplemental Pay Header)</strong></span><br />51 H-SP) <span style=\"color:#17becfff;\"><p>Seize the opportunity to grow your career (H-SP Supplemental Pay Header)</p></span><br />52 O-TS) <span style=\"color:#9edae580;\"><p>Engage in exciting and meaningful work (O-TS Task Scope Non-header)</p></span><br />53 O-RQ) <span style=\"color:#bcbd2280;\"><p>Get recognition for your work and attitude (O-RQ Required Qualifications Non-header)</p></span><br />54 O-SP) <span style=\"color:#17becf80;\"><p>Learn new skills and get management training (O-SP Supplemental Pay Non-header)</p></span><br />55 O-SP) <span style=\"color:#17becf80;\"><p>Become part of a large, friendly and supportive team (O-SP Supplemental Pay Non-header)</p></span><br />56 O-SP) <span style=\"color:#17becf80;\"><p>Get additional private health insurance (O-SP Supplemental Pay Non-header)</p></span><br />57 O-TS) <span style=\"color:#9edae580;\"><p>Receive special prices for multisport card and multiple retailers (O-TS Task Scope Non-header)</p></span><br />58 O-RQ) <span style=\"color:#bcbd2280;\"><p>Obtain preferential prices for our banking products (O-RQ Required Qualifications Non-header)</p></span><br />59 O-RQ) <span style=\"color:#bcbd2280;\"><p>Enjoy a great location in Sofia’s city centre near NDK and South Park (O-RQ Required Qualifications Non-header)</p></span><br /><hr />60 H-CS) <span style=\"color:#1f77b4ff;\"><p>Visit our Career Page to learn more about what makes us different. (H-CS Corporate Scope Header)</p></span><br />61 O-IP) <span style=\"color:#ffbb7880;\">If this sounds like something you’d be interested in, (O-IP Interview Procedures Non-header)</span><br />62 O-IP) <span style=\"color:#ffbb7880;\"><strong>we'd love to hear from you! (O-IP Interview Procedures Non-header)</strong></span><br />63 O-IP) <span style=\"color:#ffbb7880;\"><p>To apply for this position, please send us your CV in English. (O-IP Interview Procedures Non-header)</p></span><br />64 O-CS) <span style=\"color:#1f77b480;\"><p>We'd love to get back to everyone, but due to the number of applications we receive, we can only contact the shortlisted candidates. (O-CS Corporate Scope Non-header)</p></span><br />65 H-OL) <span style=\"color:#c49c94ff;\">_ (H-OL Office Location Header)</span><br />66 O-PD) <span style=\"color:#f7b6d280;\">All applications are treated with utmost confidential ity. (O-PD Post Date Non-header)</span><br />67 O-IP) <span style=\"color:#ffbb7880;\">By submitting your job application to (O-IP Interview Procedures Non-header)</span><br />68 H-JT) <span style=\"color:#d62728ff;\"><strong>tbi bank (H-JT Job Title Header)</strong></span><br />69 O-LN) <span style=\"color:#9467bd80;\">, you confirm that you have read (O-LN Legal Notifications Non-header)</span><br />70 O-O) <span style=\"color:#8c564b80;\">the (O-O Other Non-header)</span><br />71 O-LN) <span style=\"color:#9467bd80;\">document named “Information related to personal data processing for job applicants” publicly available on (O-LN Legal Notifications Non-header)</span><br />72 H-JT) <span style=\"color:#d62728ff;\"><strong>tbi (H-JT Job Title Header)</strong></span><br />73 H-SP) <span style=\"color:#17becfff;\">Career (H-SP Supplemental Pay Header)</span><br />74 O-SP) <span style=\"color:#17becf80;\">page. (O-SP Supplemental Pay Non-header)</span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 48, 53, 58, 59]\n",
      "Parts-of-speech displayed in 1 minute and 17 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(pos_symbol_predictions_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech displayed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91379a3d-1a77-4d8b-9ef6-a76f12204ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26c4dd4e-1418-4420-aff5-ea7b65273194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 H-SP) <strong>What we offer:</strong>\n",
      "51 H-SP) <p>Seize the opportunity to grow your career</p>\n",
      "52 O-TS) <p>Engage in exciting and meaningful work</p>\n",
      "53 O-RQ) <p>Get recognition for your work and attitude</p>\n",
      "54 O-SP) <p>Learn new skills and get management training</p>\n",
      "55 O-SP) <p>Become part of a large, friendly and supportive team</p>\n",
      "56 O-SP) <p>Get additional private health insurance</p>\n",
      "57 O-TS) <p>Receive special prices for multisport card and multiple retailers</p>\n",
      "58 O-RQ) <p>Obtain preferential prices for our banking products</p>\n",
      "59 O-RQ) <p>Enjoy a great location in Sofia’s city centre near NDK and South Park</p>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict'); column_name = 'is_supplemental_pay'; range_obj = range(50, 60)\n",
    "for idx in range_obj:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\\n            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\\n            ''' + cu.return_every_np_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "            ''' + cu.return_every_np_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 14\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f46926-880b-4aed-bc99-4a6bd9ed7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4807386e-93e6-4799-a885-8a1ace2b424b",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16db439a-41cc-4b64-8a7e-d38743e4d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 H-SP) <strong>What we offer:</strong>\n",
      "51 H-SP) <p>Seize the opportunity to grow your career</p>\n",
      "52 O-TS) <p>Engage in exciting and meaningful work</p>\n",
      "53 O-RQ) <p>Get recognition for your work and attitude</p>\n",
      "54 O-SP) <p>Learn new skills and get management training</p>\n",
      "55 O-SP) <p>Become part of a large, friendly and supportive team</p>\n",
      "56 O-SP) <p>Get additional private health insurance</p>\n",
      "57 O-TS) <p>Receive special prices for multisport card and multiple retailers</p>\n",
      "58 O-RQ) <p>Obtain preferential prices for our banking products</p>\n",
      "59 O-RQ) <p>Enjoy a great location in Sofia’s city centre near NDK and South Park</p>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix headers and Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in range_obj:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    is_header = str(child_str.startswith('<strong')).lower()\n",
    "    # is_header = str(':</' in child_str).lower()\n",
    "    def do_cypher_tx(tx, navigable_parent):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET np.is_header = {is_header}\n",
    "            ''' + cu.return_every_np_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session:\n",
    "        row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "        ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7695d-caf6-416f-a761-ec17b839ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in range(63, 69):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET np.is_header = false\n",
    "            ''' + cu.return_every_np_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session:\n",
    "        row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "        ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ab607-cc5c-4476-b692-395b96d293ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix Headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [0]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET np.is_header = true\n",
    "            ''' + cu.return_every_np_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session:\n",
    "        row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str)\n",
    "        ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfa2e-4e09-4da7-b046-98f5c170ec67",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07255146-70be-4d52-942c-1505d6e02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display cypher necessary to apply for all the jobs you qualify for that you haven't applied for\n",
    "pyperclip.copy(cu.get_job_application_links)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cu.get_job_application_links)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    display(df)\n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_closed = true\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET\n",
    "    fn.is_opportunity_application_emailed = true,\n",
    "    fn.opportunity_application_email_date = date(),\n",
    "    fn.application_url = \"xxxxxx\"\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "speech_str = 'Job application cypher code copied to clipboard'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22c3685b-69f1-40fd-aa98-c473365ff866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Ensure you have already run the \"Fix Parts-of-Speech and Quals for \n",
    "# this posting\" cells above or displayed the context of an \n",
    "# individual child string above. Don't close the Notepad++ window \n",
    "# until you have replaced the child string\n",
    "# file_name = 'Data_Science_Consulting_Engagement_Manager_-_Remote_-_Indeed.com_9993304a3df214bf.html'\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "wsu.clean_job_posting(file_path)\n",
    "try: pyperclip.copy(re.sub(\"((?:<li>([^><]+)</li>\\n)+)\", \"<ul>\\n\\\\1</ul>\\n\", '\\n'.join(child_strs_list), 0, re.MULTILINE))\n",
    "except: pass\n",
    "!\"{text_editor_path}\" \"{file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b5f300f-c5ed-45d3-8c62-cd5a37fde7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "wsu.convert_p_b_to_h3(file_path, basic_text_set={'h3'}, phrase_elements_set={'b'}, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b06ebf9b-c4d6-42c8-9ea7-9eb4a062411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "wsu.replace_phrase_elements_in_block_elements(file_path, block_elements_set={'li'}, phrase_elements_set={'b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc1622-878d-4830-8df2-ff54b0ee1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "wsu.replace_single_child_tags_in_li(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af64e55d-eb9b-413d-8b71-bef7188d48a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                MATCH (fn:FileNames {file_name: \"83ff1d9973fe7277_Systems_Engineer_Remote_Indeed_com.html\"})\n",
      "                SET fn.percent_fit = NULL;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cu.rebuild_filename_node(file_name, navigable_parent=None, verbose=True)\n",
    "speech_str = f'{su.get_job_title_from_file_name(file_name)} node rebuild completed'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fae8b-14ec-4c20-96b0-70c622ac7c73",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d17dac-be9e-4bc3-aa01-58eed1baa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_every_np_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc697c17-7f13-4abd-8f80-3d5bf4a73d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular qualification string from the quals dictionary\n",
    "qualification_str = quals_list[2]\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict.pop(qualification_str, None)\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{qualification_str}\" in basic_quals_dict: {qualification_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e765305-d9a3-4955-a905-8389c35ad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular qualification string from the database\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=qualification_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005f4a8-f07c-4538-8d1b-210d32dd3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually set each feature\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = true,\n",
    "            np.is_task_scope = false,\n",
    "            np.is_minimum_qualification = false,\n",
    "            np.is_preferred_qualification = false,\n",
    "            np.is_educational_requirement = true,\n",
    "            np.is_legal_notification = false,\n",
    "            np.is_other = false,\n",
    "            np.is_corporate_scope = false,\n",
    "            np.is_job_title = false,\n",
    "            np.is_office_location = false,\n",
    "            np.is_job_duration = false,\n",
    "            np.is_supplemental_pay = false,\n",
    "            np.is_interview_procedure = false,\n",
    "            np.is_posting_date = false\n",
    "        ''' + cu.return_every_np_str + ';'\n",
    "    return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False); row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a9fa5-9f15-4bcc-a3df-b75dbb52ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "for file_name in ['']:\n",
    "    \n",
    "    # Lose the node features and folder storage\n",
    "    cu.delete_filename_node(\n",
    "        file_name, remove_node=True, remove_file=True, verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e40b2e-5214-49ef-8795-fa9534b9bfd7",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe80356-c69a-4579-b298-31e40e871b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the scrfcu has built its parts-of-speech conditional random field model\n",
    "# Parts-of-speech CRF model normally built in 29 minutes and 57 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech conditional random field model built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453a69d-7080-4ebf-96a8-528e9541ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the ssgdcu has built its parts-of-speech stochastic gradient decent model\n",
    "t1 = time.time()\n",
    "if not hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech stochastic gradient descent model built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7d031-531c-4024-b9f4-03485a91a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the crf has built its parts-of-speech classifier\n",
    "# POS classifier normally trained in 15 hours, 42 minutes and 41 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(crf, 'CRF'): crf.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(crf, 'CRF'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'POS classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef1d94-4466-4100-86cd-0d66f23d0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "speech_str = f'Last run on {datetime.now()}'; print(speech_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
