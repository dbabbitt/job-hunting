{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb7318f-5285-4f7b-bc3e-2859fe05f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 13 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(1, '../py')\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "\n",
    "freq = 990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f331b-c66a-4c65-906b-22bc6fc034c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,102 labeled parts of speech in here\n",
      "predict_single is available\n",
      "Parts-of-speech logistic regression elements built in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression elements\n",
    "# Parts-of-speech logistic regression elements is normally built in 1 hour, 27 minutes and 21 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'): print('predict_single is available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech logistic regression elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe80356-c69a-4579-b298-31e40e871b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "Parts-of-speech conditional random field elements built in 1 second\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the scrfcu has built its parts-of-speech conditional random field elements\n",
    "# Parts-of-speech CRF elements normally built in 29 minutes and 57 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech conditional random field elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3453a69d-7080-4ebf-96a8-528e9541ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,102 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech stochastic gradient descent elements built in 9 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the ssgdcu has built its parts-of-speech stochastic gradient decent elements\n",
    "t1 = time.time()\n",
    "if not hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech stochastic gradient descent elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e7d031-531c-4024-b9f4-03485a91a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "POS classifier trained in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the crf has built its parts-of-speech classifier\n",
    "# POS classifier normally trained in 15 hours, 42 minutes and 41 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(crf, 'CRF'): crf.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(crf, 'CRF'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'POS classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d259dffb-c212-4493-a879-1ae5d503f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 424,879 is-qualified vocabulary tokens in here\n",
      "Is-qualified LR elements built in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has built its is-qualified classifier\n",
    "t1 = time.time()\n",
    "if not (hasattr(lru, 'ISQUALIFIED_LR') and hasattr(lru, 'ISQUALIFIED_CV')):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified LR elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d67a34-e133-45dc-9bf3-a830af359d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,902 hand-labeled header htmls prepared\n",
      "7 iterations seen during training fit for a total of 49,902 records trained\n",
      "Is-header classifier trained in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the isheader classifier\n",
    "t1 = time.time()\n",
    "ihu.build_pos_stochastic_gradient_descent_elements(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-header classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcef1d94-4466-4100-86cd-0d66f23d0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2024-06-04 09:07:42.287931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "speech_str = f'Last run on {datetime.now()}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f438163-0f14-4a74-978c-769c9dba95c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02bfeac-67b7-4df6-a4a0-32ec3dec0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 16,974 hand-labeled qualification strings in here\n",
      "I have 544,428 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 1 minute and 28 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the\n",
    "# qualification dictionary below or in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified classifer retrained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad3579-ebc3-4d21-a7c3-f9bd168ac6ca",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d334d815-e43b-474e-9dbb-db509176f6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Qualifications for Electrochemical Modeling Engineer Remote:\n",
      "quals_list[0] = \"<li>Prolonged periods of time in front of a computer.</li>\" (1.0)\n",
      "*quals_list[1] = \"<li>Proficiency with Python and common data science libraries such as Pandas, NumPy, and SciPy.</li>\" (1.0)\n",
      "*quals_list[2] = \"Employment in this position is conditioned on the continued availability of government authorization to authorize release of such items, to the extent required, including without limitation an export license, or other documentation required to establish authorization to receive access to such items\" (1.0)\n",
      "quals_list[3] = \"<li>Rapid learner and a self-motivated individual who thrives in a collaborative start-up environment.</li>\" (1.0)\n",
      "*quals_list[4] = \"<p>This position requires access to technology, software and other information that is subject to governmental access control restrictions, due to export controls\" (1.0)\n",
      "quals_list[5] = \"<li>Master's or PhD in Computational Chemistry, Materials Engineering, or a related Electrochemical discipline.</li>\" (0.0)\n",
      "*quals_list[6] = \"<li>Some physical data retrieval (ie from non-networked computers located within the Solid Power buildings).</li>\" (0.99)\n",
      "quals_list[7] = \"<li>2+ years of professional experience using commercial software to develop Multiphysics models of lithium-ion batteries.</li>\" (0.0)\n",
      "*quals_list[8] = \"<li>Excellent communication, negotiation, and organizational skills with strong attention to detail.</li>\" (1.0)\n",
      "*quals_list[9] = \"<li>A strong understanding of electrochemistry, preferably with at least some experience in battery systems.</li>\" (0.9259)\n",
      "quals_list[10] = \"<li>Strong analytical and statistical problem-solving skills, with specific experience in regression tasks.</li>\" (0.0)\n",
      "*quals_list[11] = \"<p>All offers of employment at Solid Power are contingent upon clear results of a thorough background check.</p>\" (1.0)\n",
      "75.00%\n",
      "\n",
      "hunting_df.loc[3926, 'percent_fit'] = (1+000+000+1+000+0+000+0+000+000+0+000)/12\n",
      "3926/3950 = 99.4% completed\n",
      "Inference completed in 34 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "quals_list, file_name = lru.infer_from_hunting_dataframe(fitness_threshold=3/4, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Inference completed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264da9-f96a-491a-83d9-25d15fcdfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47bd03b8-c0a3-404c-a16d-eb4ce95c6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li>Prolonged periods of time in front of a computer.</li>\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qualification string\n",
    "qualification_str = quals_list[0]\n",
    "print(qualification_str); basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[qualification_str]) + '\\n' if(qualification_str in basic_quals_dict) else '', end='')\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4212b-9280-46d1-8e46-104aada7c0df",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix Parts-of-Speech and Quals for this posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac6efb8-6b56-43dd-9079-d6a87491ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08d145a370f9d61d_Multiphysics_Electrochemical_Modeling_Engineer_Remote_Indeed_com.html\n",
      "CRF and child strings list recreated in 1 minute and 3 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "file_path = os.path.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if os.path.isfile(file_path):\n",
    "    child_strs_list = hau.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    print(file_name)\n",
    "    child_tags_list = hau.get_child_tags_list(child_strs_list)\n",
    "    feature_dict_list = cu.get_feature_dict_list(child_tags_list, child_strs_list)\n",
    "    feature_tuple_list = []\n",
    "    for feature_dict in feature_dict_list:\n",
    "        feature_tuple_list.append(hc.get_feature_tuple(\n",
    "            feature_dict, pos_lr_predict_single=slrcu.predict_single, pos_crf_predict_single=scrfcu.predict_single,\n",
    "            pos_sgd_predict_single=ssgdcu.predict_single\n",
    "        ))\n",
    "    crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'CRF and child strings list recreated in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "affcb06a-3165-4349-a936-037af549d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-TS', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'H-RQ', 'O-ER', 'O-RQ', 'O-RQ', 'O-RQ', 'O-PQ', 'O-RQ', 'O-RQ', 'O-RQ', 'H-RQ', 'O-RQ', 'O-RQ', 'H-SP', 'O-SP', 'H-RQ', 'O-O', 'H-SP', 'O-SP', 'H-RQ', 'O-RQ', 'O-LN', 'O-RQ']\n",
      "[9, 10, 11, 12, 14, 15, 16, 18, 19, 27, 29]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-TS) <span style=\"color:#9edae5ff;\"><b>Position Overview: (H-TS Task Scope Header)</b></span><br />1 O-TS) <span style=\"color:#9edae580;\"><p>Solid Power is seeking a Multiphysics Electrochemical Modeling Engineer to join our talented team of scientists working to revolutionize the battery industry through the development of next‐generation, all solid‐state rechargeable batteries. Solid Power is a dynamic, fast‐paced, collaborative, and innovative team environment. The preferred candidate will have significant experience working with and using Multiphysics simulations to model electrochemical device behavior. The candidate will improve upon existing P2D/P4D DFN models, using the models to guide experimental planning especially as it relates to battery formulation improvements. (O-TS Task Scope Non-header)</p></span><br />2 H-TS) <span style=\"color:#9edae5ff;\"><b>Job Duties: (H-TS Task Scope Header)</b></span><br />3 O-TS) <span style=\"color:#9edae580;\"><li>Develop and validate mathematical models (both fundamental physics-based and data driven) to predict thermal, mechanical, and electrochemical behavior of ASSB materials, sub-assemblies, and finished cells. (O-TS Task Scope Non-header)</li></span><br />4 O-TS) <span style=\"color:#9edae580;\"><li>Work with subject matter experts to develop experimental plans to isolate and quantify key model parameters. (O-TS Task Scope Non-header)</li></span><br />5 O-TS) <span style=\"color:#9edae580;\"><li>Collaborate with subject matter experts to refine and continually validate modeling approaches. (O-TS Task Scope Non-header)</li></span><br />6 O-TS) <span style=\"color:#9edae580;\"><li>Clearly explain to internal stakeholders why/how modeling predictions are meaningful and thoroughly document model upgrades for future use. (O-TS Task Scope Non-header)</li></span><br />7 O-TS) <span style=\"color:#9edae580;\"><li>Collaborate with data scientists on strategies to accelerate Multiphysics modeling solvers and strategies to guide virtual experiment prioritization (e.g. Bayesian approaches). (O-TS Task Scope Non-header)</li></span><br />8 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Qualifications/Requirements: (H-RQ Required Qualifications Header)</b></span><br /><hr />9 O-ER) <span style=\"color:#aec7e880;\"><li>Master's or Ph.D. in Computational Chemistry, Materials Engineering, or a related Electrochemical discipline. (O-ER Education Requirements Non-header)</li></span><br />10 O-RQ) <span style=\"color:#bcbd2280;\"><li>2+ years of professional experience using commercial software to develop Multiphysics models of lithium-ion batteries. (O-RQ Required Qualifications Non-header)</li></span><br />11 O-RQ) <span style=\"color:#bcbd2280;\"><li>A strong understanding of electrochemistry, preferably with at least some experience in battery systems. (O-RQ Required Qualifications Non-header)</li></span><br />12 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong analytical and statistical problem-solving skills, with specific experience in regression tasks. (O-RQ Required Qualifications Non-header)</li></span><br />13 O-PQ) <span style=\"color:#c7c7c780;\"><li>Experience working with common Multiphysics modeling software. COMSOL experience is preferred and PyBaMM experience is a plus. (O-PQ Preferred Qualifications Non-header)</li></span><br />14 O-RQ) <span style=\"color:#bcbd2280;\"><li>Proficiency with Python and common data science libraries such as Pandas, NumPy, and SciPy. (O-RQ Required Qualifications Non-header)</li></span><br />15 O-RQ) <span style=\"color:#bcbd2280;\"><li>Rapid learner and a self-motivated individual who thrives in a collaborative start-up environment. (O-RQ Required Qualifications Non-header)</li></span><br />16 O-RQ) <span style=\"color:#bcbd2280;\"><li>Excellent communication, negotiation, and organizational skills with strong attention to detail. (O-RQ Required Qualifications Non-header)</li></span><br />17 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Physical Requirements: (H-RQ Required Qualifications Header)</b></span><br />18 O-RQ) <span style=\"color:#bcbd2280;\"><li>Prolonged periods of time in front of a computer. (O-RQ Required Qualifications Non-header)</li></span><br />19 O-RQ) <span style=\"color:#bcbd2280;\"><li>Some physical data retrieval (i.e. from non-networked computers located within the Solid Power buildings). (O-RQ Required Qualifications Non-header)</li></span><br />20 H-SP) <span style=\"color:#17becfff;\"><b>Salary Range: (H-SP Supplemental Pay Header)</b></span><br />21 O-SP) <span style=\"color:#17becf80;\">$100,000 - $132,000/Annually (O-SP Supplemental Pay Non-header)</span><br />22 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Application Deadline: (H-RQ Required Qualifications Header)</b></span><br />23 O-O) <span style=\"color:#8c564b80;\">06/13/2024 (O-O Other Non-header)</span><br />24 H-SP) <span style=\"color:#17becfff;\"><b>Benefits: (H-SP Supplemental Pay Header)</b></span><br />25 O-SP) <span style=\"color:#17becf80;\">Solid Power offers a comprehensive benefit package that includes medical/dental/vision insurance, employer paid Life/AD&D/STD/LTD insurance, 401k with company match, paid holidays, unlimited PTO, cell phone reimbursement and eligibility in our bonus and equity plans. (O-SP Supplemental Pay Non-header)</span><br />26 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Export Control Requirements: (H-RQ Required Qualifications Header)</b></span><br />27 O-RQ) <span style=\"color:#bcbd2280;\"><p>This position requires access to technology, software and other information that is subject to governmental access control restrictions, due to export controls. Employment in this position is conditioned on the continued availability of government authorization to authorize release of such items, to the extent required, including without limitation an export license, or other documentation required to establish authorization to receive access to such items. (O-RQ Required Qualifications Non-header)</p></span><br />28 O-LN) <span style=\"color:#9467bd80;\"><p>Company may delay commencement of employment, rescind an offer of employment, terminate employment, and/or may modify job responsibilities, compensation, benefits, and/or access to Company facilities and information systems, as Company deems appropriate, in order to ensure compliance with applicable government access control restrictions. (O-LN Legal Notifications Non-header)</p></span><br />29 O-RQ) <span style=\"color:#bcbd2280;\"><p>All offers of employment at Solid Power are contingent upon clear results of a thorough background check. (O-RQ Required Qualifications Non-header)</p></span><br /><hr />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 10, 11, 12, 14, 15, 16, 18, 19, 27, 29]\n",
      "Parts-of-speech displayed in 1 minute and 8 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech displayed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91379a3d-1a77-4d8b-9ef6-a76f12204ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26c4dd4e-1418-4420-aff5-ea7b65273194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 H-LN) <b>Legal Notifications:</b>\n",
      "42 O-TS) <li>Export Control Requirements: This position requires access to technology, software and other information that is subject to governmental access control restrictions, due to export controls.</li>\n",
      "43 O-RQ) <li>Export Control Requirements: Employment in this position is conditioned on the continued availability of government authorization to authorize release of such items, to the extent required, including without limitation an export license, or other documentation required to establish authorization to receive access to such items.</li>\n",
      "44 O-RQ) <li>Export Control Requirements: Company may delay commencement of employment, rescind an offer of employment, terminate employment, and/or may modify job responsibilities, compensation, benefits, and/or access to Company facilities and information systems, as Company deems appropriate, in order to ensure compliance with applicable government access control restrictions.</li>\n",
      "45 O-RQ) <li>Export Control Requirements: All offers of employment at Solid Power are contingent upon clear results of a thorough background check.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict'); column_name = 'is_legal_notification'\n",
    "for idx in list(range(41, 46)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\\n            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\\n            ''' + cu.return_everything_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                np.is_educational_requirement = {str(column_name == 'is_educational_requirement').lower()},\n",
    "                np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 26, 31, 43, 44, 45]\n",
      "33 O-RQ) <li>Position Overview: An ideal candidate will have familiarity with ML-based forcefields and ML techniques for accelerating ab initio calculations.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 33\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2f46926-880b-4aed-bc99-4a6bd9ed7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>Position Overview: An ideal candidate will have familiarity with ML-based forcefields and ML techniques for accelerating ab initio calculations.</li>\" in basic_quals_dict: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "326ab607-cc5c-4476-b692-395b96d293ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 O-RQ) Competencies:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [14]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = true\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24e7695d-caf6-416f-a761-ec17b839ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 H-RQ) <li>Qualifications: You have: Experience in a high-growth tech environment</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [39]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = false\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4005f4a8-f07c-4538-8d1b-210d32dd3199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'navigable_parent': '<b>Educational Requirements:</b>', 'is_header': True, 'is_task_scope': False, 'is_minimum_qualification': False, 'is_preferred_qualification': False, 'is_legal_notification': False, 'is_job_title': False, 'is_office_location': False, 'is_job_duration': False, 'is_supplemental_pay': False, 'is_educational_requirement': True, 'is_interview_procedure': False, 'is_corporate_scope': False, 'is_posting_date': False, 'is_other': False}]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Manually set each feature\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = true,\n",
    "            np.is_task_scope = false,\n",
    "            np.is_minimum_qualification = false,\n",
    "            np.is_preferred_qualification = false,\n",
    "            np.is_educational_requirement = true,\n",
    "            np.is_legal_notification = false,\n",
    "            np.is_other = false,\n",
    "            np.is_corporate_scope = false,\n",
    "            np.is_job_title = false,\n",
    "            np.is_office_location = false,\n",
    "            np.is_job_duration = false,\n",
    "            np.is_supplemental_pay = false,\n",
    "            np.is_interview_procedure = false,\n",
    "            np.is_posting_date = false\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False); row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c062a-8ec0-4daf-9727-6b8676c26fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set all the questions to interview procedures\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "column_name = 'is_interview_procedure'\n",
    "for idx in range(len(child_strs_list)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    if '?' in child_str:\n",
    "        def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "            cypher_str = '''\n",
    "                MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "                ''' + cu.return_everything_str + ';'\n",
    "            results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "            return [dict(record.items()) for record in results_list]\n",
    "        with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "        if (row_objs_list[0][column_name] != True):\n",
    "            print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "            print(f'{idx} {pos_symbol}) {child_str}')\n",
    "            def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "                cypher_str = f'''\n",
    "                    MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "                    SET\n",
    "                        np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                        np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                        np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                        np.is_educational_requirement = {str(column_name == 'is_educational_requirement').lower()},\n",
    "                        np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                        np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                        np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                        np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                        np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                        np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                        np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                        np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                        np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "                    ''' + cu.return_everything_str + ';'\n",
    "                return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "            with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d17dac-be9e-4bc3-aa01-58eed1baa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfa2e-4e09-4da7-b046-98f5c170ec67",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07255146-70be-4d52-942c-1505d6e02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display cypher necessary to apply for all the jobs you qualify for that you haven't yet\n",
    "import pyperclip\n",
    "\n",
    "# lru.display_hunting_dataframe_as_histogram()\n",
    "cypher_str = f'''\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        (fn.percent_fit >= 0.8) AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS file_name,\n",
    "        fn.posting_url AS posting_url\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "pyperclip.copy(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    display(df)\n",
    "    \n",
    "    for file_name in df.file_name:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{file_name}\"]\n",
    "SET fn.is_closed = true\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "    \n",
    "    for file_name in df.file_name:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{file_name}\"]\n",
    "SET fn.is_opportunity_application_emailed = true, fn.opportunity_application_email_date = date()\n",
    "RETURN fn;\"\"\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8626518c-6d69-45b9-9f9a-ebe909644d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                MATCH\n",
      "                    (np:NavigableParents {navigable_parent: \"<li>Export Control Requirements: All offers of employment at Solid Power are contingent upon clear results of a thorough background check.</li>\"}),\n",
      "                    (ht:HeaderTags {header_tag: \"li\"})\n",
      "                MERGE (ht)-[r:SUMMARIZES]->(np);\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Ensure you have already displayed the context of an individual child string above\n",
    "# Don't close the Notepad++ window until you have replaced the child string\n",
    "def display_file_in_text_editor(file_name):\n",
    "    text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "    file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "    !\"{text_editor_path}\" \"{file_path}\"\n",
    "display_file_in_text_editor(file_name)\n",
    "cu.rebuild_filename_node(file_name, navigable_parent=None, verbose=True)\n",
    "speech_str = 'File name node rebuild completed'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>Professional development assistance</li>\" in basic_quals_dict: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary and database\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str, None)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a9fa5-9f15-4bcc-a3df-b75dbb52ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "for file_name in ['']:\n",
    "    cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3aad62-d78e-4243-b46f-dec293d4552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def separate_qualifications(quals_list):\n",
    "  \"\"\"\n",
    "  This function takes a list of qualifications and separates them into individual sentences.\n",
    "\n",
    "  Args:\n",
    "      quals_list: A list of strings, where each string represents a qualification.\n",
    "\n",
    "  Returns:\n",
    "      A list of lists, where each inner list contains the individual qualifications extracted from the corresponding element in the original quals_list.\n",
    "  \"\"\"\n",
    "  separated_quals = []\n",
    "  for qual in quals_list:\n",
    "    # Split qualifications based on commas, semicolons, and colons followed by whitespace\n",
    "    split_quals = re.split(r\", |; |:\", qual)\n",
    "    # Further split based on \"and\" if it's not the first word and there's punctuation before it\n",
    "    for i, sentence in enumerate(split_quals):\n",
    "      if i > 0 and re.search(r\"\\b(and)\\b\", sentence, flags=re.IGNORECASE) and re.search(r\"[,\\.;]\", split_quals[i-1]):\n",
    "        split_quals[i-1] += f\" {sentence.strip()}\"\n",
    "        split_quals.pop(i)\n",
    "    # Remove empty strings and leading/trailing whitespace\n",
    "    separated_quals.append([q.strip() for q in split_quals if q.strip()])\n",
    "  return separated_quals\n",
    "\n",
    "separated_qualifications = separate_qualifications(quals_list)\n",
    "\n",
    "# Print the separated qualifications\n",
    "for qual_set in separated_qualifications:\n",
    "  for qual in qual_set:\n",
    "    print(qual)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2828f-ab7b-4550-b5cc-92078c40f331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
