{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb7318f-5285-4f7b-bc3e-2859fe05f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f331b-c66a-4c65-906b-22bc6fc034c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,093 labeled parts of speech in here\n",
      "predict_single is available\n",
      "Parts-of-speech logistic regression elements built in 7 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression elements\n",
    "# Parts-of-speech logistic regression elements is normally built in 1 hour, 27 minutes and 21 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'): print('predict_single is available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech logistic regression elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe80356-c69a-4579-b298-31e40e871b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "Parts-of-speech conditional random field elements built in 1 second\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the scrfcu has built its parts-of-speech conditional random field elements\n",
    "# Parts-of-speech CRF elements normally built in 29 minutes and 57 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech conditional random field elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3453a69d-7080-4ebf-96a8-528e9541ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,093 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech stochastic gradient descent elements built in 10 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the ssgdcu has built its parts-of-speech stochastic gradient decent elements\n",
    "t1 = time.time()\n",
    "if not hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech stochastic gradient descent elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e7d031-531c-4024-b9f4-03485a91a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "POS classifier trained in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the crf has built its parts-of-speech classifier\n",
    "# POS classifier normally trained in 15 hours, 42 minutes and 41 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(crf, 'CRF'): crf.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(crf, 'CRF'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'POS classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d259dffb-c212-4493-a879-1ae5d503f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 424,879 is-qualified vocabulary tokens in here\n",
      "Is-qualified LR elements built in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has built its is-qualified classifier\n",
    "t1 = time.time()\n",
    "if not (hasattr(lru, 'ISQUALIFIED_LR') and hasattr(lru, 'ISQUALIFIED_CV')):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified LR elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d67a34-e133-45dc-9bf3-a830af359d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 50,531 hand-labeled header htmls prepared\n",
      "7 iterations seen during training fit for a total of 50,531 records trained\n",
      "Is-header classifier trained in 7 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the isheader classifier\n",
    "t1 = time.time()\n",
    "ihu.build_pos_stochastic_gradient_descent_elements(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-header classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcef1d94-4466-4100-86cd-0d66f23d0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2024-08-16 07:19:11.215302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "speech_str = f'Last run on {datetime.now()}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f438163-0f14-4a74-978c-769c9dba95c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f02bfeac-67b7-4df6-a4a0-32ec3dec0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 18,301 hand-labeled qualification strings in here\n",
      "I have 514,511 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 1 minute and 46 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary below or in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified classifer retrained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad3579-ebc3-4d21-a7c3-f9bd168ac6ca",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d334d815-e43b-474e-9dbb-db509176f6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4438/4438 = 100.0% completed\n",
      "Inference completed in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "quals_list, file_name = lru.infer_from_hunting_dataframe(fitness_threshold=3/4, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Inference completed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264da9-f96a-491a-83d9-25d15fcdfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47bd03b8-c0a3-404c-a16d-eb4ce95c6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience must include Computational/deep learning frameworks such as Scikit Learn or TensorFlow\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qualification string\n",
    "qualification_str = quals_list[7]\n",
    "print(qualification_str); basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[qualification_str]) + '\\n' if(qualification_str in basic_quals_dict) else '', end='')\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4212b-9280-46d1-8e46-104aada7c0df",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix Parts-of-Speech and Quals for this posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ac6efb8-6b56-43dd-9079-d6a87491ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926e87043c51a5ba_Lead_Data_Scientist_San_Jose_CA_95113_Indeed_com.html\n",
      "CRF and child strings list recreated in 1 minute and 43 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "file_path = osp.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if osp.isfile(file_path):\n",
    "    child_strs_list = hau.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    print(file_name)\n",
    "    child_tags_list = hau.get_child_tags_list(child_strs_list)\n",
    "    feature_dict_list = cu.get_feature_dict_list(child_tags_list, child_strs_list)\n",
    "    feature_tuple_list = []\n",
    "    for feature_dict in feature_dict_list:\n",
    "        feature_tuple_list.append(hc.get_feature_tuple(\n",
    "            feature_dict, pos_lr_predict_single=slrcu.predict_single, pos_crf_predict_single=scrfcu.predict_single,\n",
    "            pos_sgd_predict_single=ssgdcu.predict_single\n",
    "        ))\n",
    "    crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'CRF and child strings list recreated in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "affcb06a-3165-4349-a936-037af549d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-JT', 'O-JT', 'O-JT', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-CS', 'O-IP', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'H-ER', 'O-ER', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'H-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'H-OL', 'O-OL', 'O-OL', 'O-OL', 'H-JD', 'O-JD', 'H-IP', 'O-IP', 'O-IP', 'O-IP']\n",
      "[39, 40, 41, 42, 43, 44, 45, 46, 47]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-JT) <span style=\"color:#d62728ff;\"><h3 class=\"jobSectionHeader\">Job Title: (H-JT Job Title Header)</h3></span><br />1 O-JT) <span style=\"color:#d6272880;\"><li>TITLE: Lead Data Scientist (O-JT Job Title Non-header)</li></span><br />2 O-JT) <span style=\"color:#d6272880;\"><li>Job ID: 2024-301466 (O-JT Job Title Non-header)</li></span><br />3 O-CS) <span style=\"color:#1f77b480;\"><h3 class=\"jobSectionHeader\">Overview: (O-CS Corporate Scope Non-header)</h3></span><br />4 O-CS) <span style=\"color:#1f77b480;\"><li>Live the experience. (O-CS Corporate Scope Non-header)</li></span><br />5 O-CS) <span style=\"color:#1f77b480;\"><li>From professional empowerment to continual learning opportunities. (O-CS Corporate Scope Non-header)</li></span><br />6 O-CS) <span style=\"color:#1f77b480;\"><li>From ongoing investment in our strategic initiatives to a career of self-determination. (O-CS Corporate Scope Non-header)</li></span><br />7 O-CS) <span style=\"color:#1f77b480;\"><li>At Ulta Beauty, our team is critical to our scalability-and is recognized that way. (O-CS Corporate Scope Non-header)</li></span><br />8 O-CS) <span style=\"color:#1f77b480;\"><li>We've been defined as a \"mature start-up.\" A place where interdepartmental exposure, open doors, and genuine collaboration is ubiquitous. (O-CS Corporate Scope Non-header)</li></span><br />9 O-CS) <span style=\"color:#1f77b480;\"><li>Where challenges come fast and furious, requiring agility, mental dexterity, and creativity. (O-CS Corporate Scope Non-header)</li></span><br />10 O-CS) <span style=\"color:#1f77b480;\"><li>Where our passion for better solutions drives us and is core to who we are. (O-CS Corporate Scope Non-header)</li></span><br />11 O-CS) <span style=\"color:#1f77b480;\"><li>We're engineering for the future of retail, and it's no-holds-barred. (O-CS Corporate Scope Non-header)</li></span><br />12 O-CS) <span style=\"color:#1f77b480;\"><li>But for those motivated by continual change and ambiguity, by superior leadership, by whip smart colleagues who will press you daily for your very best, you'll find that virtually nothing's impossible at Ulta Beauty. (O-CS Corporate Scope Non-header)</li></span><br />13 O-CS) <span style=\"color:#1f77b480;\"><li>COMPANY: Ulta, Inc. (O-CS Corporate Scope Non-header)</li></span><br />14 O-CS) <span style=\"color:#1f77b480;\"><h3 class=\"jobSectionHeader\">About: (O-CS Corporate Scope Non-header)</h3></span><br />15 O-CS) <span style=\"color:#1f77b480;\"><li>At Ulta Beauty (NASDAQ: ULTA), the possibilities are beautiful. (O-CS Corporate Scope Non-header)</li></span><br />16 O-CS) <span style=\"color:#1f77b480;\"><li>Ulta Beauty is the largest North American beauty retailer and the premier beauty destination for cosmetics, fragrance, skin care products, hair care products and salon services. (O-CS Corporate Scope Non-header)</li></span><br />17 O-CS) <span style=\"color:#1f77b480;\"><li>We bring possibilities to life through the power of beauty each and every day in our stores and online with more than 25,000 products from approximately 500 well-established and emerging beauty brands across all categories and price points, including Ulta Beauty's own private label. (O-CS Corporate Scope Non-header)</li></span><br />18 O-CS) <span style=\"color:#1f77b480;\"><li>Ulta Beauty also offers a full-service salon in every store featuring-hair, skin, brow, and make-up services. (O-CS Corporate Scope Non-header)</li></span><br />19 O-IP) <span style=\"color:#ffbb7880;\"><li>We will consider for employment all qualified applicants, including those with arrest records, conviction records, or other criminal histories, in a manner consistent with the requirements of any applicable state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, and the New York City Fair Chance Act. (O-IP Interview Procedures Non-header)</li></span><br />20 O-TS) <span style=\"color:#9edae580;\"><h3 class=\"jobSectionHeader\">DUTIES: (O-TS Task Scope Non-header)</h3></span><br />21 O-TS) <span style=\"color:#9edae580;\"><li>Algorithmic Development: Understanding, implementation and application of state-of-the-art algorithms that will power retail-oriented AI applications. (O-TS Task Scope Non-header)</li></span><br />22 O-TS) <span style=\"color:#9edae580;\"><li>Areas to tackle include Supervised Machine Learning, Unsupervised Machine Learning, Data Mining, Deep Learning, Natural Language Processing (NLP), and Big Data. (O-TS Task Scope Non-header)</li></span><br />23 O-TS) <span style=\"color:#9edae580;\"><li>Analyze large and complex data sets to extract meaningful insights and identify patterns and trends. (O-TS Task Scope Non-header)</li></span><br />24 O-TS) <span style=\"color:#9edae580;\"><li>Software Engineering: Contribute and integrate all efforts into a team-wide platform using best-of-class and scalable software engineering practices. (O-TS Task Scope Non-header)</li></span><br />25 O-TS) <span style=\"color:#9edae580;\"><li>Big Data analysis: Application of statistical techniques to gather insights from enterprise and experimental data to support strategic decisions of his/her core team. (O-TS Task Scope Non-header)</li></span><br />26 O-TS) <span style=\"color:#9edae580;\"><li>Application of data analysis on \"Big Data\" across various structured and un-structured platforms. (O-TS Task Scope Non-header)</li></span><br />27 O-TS) <span style=\"color:#9edae580;\"><li>Design, build and maintain scalable data pipelines and data warehouses to support data analysis and reporting. (O-TS Task Scope Non-header)</li></span><br />28 O-TS) <span style=\"color:#9edae580;\"><li>Research: Understand the state of the art in Machine Learning and Data Mining, to analytically compare different solutions and collaborate in the selection of appropriate techniques to solve a domain specific problem. (O-TS Task Scope Non-header)</li></span><br />29 O-TS) <span style=\"color:#9edae580;\"><li>Develop novel algorithms in the field when / if necessary. (O-TS Task Scope Non-header)</li></span><br />30 O-TS) <span style=\"color:#9edae580;\"><li>Mentor: Mentor and lead a team of data scientists, providing guidance and coaching to promote professional development and growth. (O-TS Task Scope Non-header)</li></span><br />31 O-TS) <span style=\"color:#9edae580;\"><li>Product Innovation: Active participation on product R&amp;D activities. (O-TS Task Scope Non-header)</li></span><br />32 O-TS) <span style=\"color:#9edae580;\"><li>Identify and suggest features for new prototypes that showcase relevant technical solutions to achieve business goals. (O-TS Task Scope Non-header)</li></span><br />33 O-TS) <span style=\"color:#9edae580;\"><li>Stay up to date with the latest advances in machine learning and data science and evaluate and adopt new technologies and methodologies as appropriate. (O-TS Task Scope Non-header)</li></span><br />34 O-TS) <span style=\"color:#9edae580;\"><li>Communication: Present technical results to their core team and other technical and non-technical stakeholders. (O-TS Task Scope Non-header)</li></span><br />35 O-TS) <span style=\"color:#9edae580;\"><li>Collaborate with cross-functional teams to identify opportunities for data-driven decision-making and drive business value. (O-TS Task Scope Non-header)</li></span><br />36 O-TS) <span style=\"color:#9edae580;\"><li>Project management: Planning of the projects at hand, identifying and ordering tasks, while providing accurate time estimations for them. (O-TS Task Scope Non-header)</li></span><br />37 O-TS) <span style=\"color:#9edae580;\"><li>Implement and document tasks according to pre-defined requirements. (O-TS Task Scope Non-header)</li></span><br />38 H-ER) <span style=\"color:#aec7e8ff;\"><h3 class=\"jobSectionHeader\">Educational Requirements: (H-ER Education Requirements Header)</h3></span><br /><hr />39 O-ER) <span style=\"color:#aec7e880;\"><li>Master's degree in Computer Science, Mathematics, Physics, Statistics, or related field. (O-ER Education Requirements Non-header)</li></span><br />40 O-RQ) <span style=\"color:#bcbd2280;\"><h3 class=\"jobSectionHeader\">REQUIREMENTS: (O-RQ Required Qualifications Non-header)</h3></span><br />41 O-RQ) <span style=\"color:#bcbd2280;\"><li>Four (4) years in any occupation with experience working in data science, machine learning or AI. (O-RQ Required Qualifications Non-header)</li></span><br />42 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience must include Work cross-functionally and communicate solutions that meet the business objectives (O-RQ Required Qualifications Non-header)</li></span><br />43 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience must include Programming language Python (O-RQ Required Qualifications Non-header)</li></span><br />44 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience must include Experience with data analysis and visualization libraries such as Pandas, NumPy, Matplotlib or Seaborn (O-RQ Required Qualifications Non-header)</li></span><br />45 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience must include Computational/deep learning frameworks such as Scikit Learn or TensorFlow (O-RQ Required Qualifications Non-header)</li></span><br />46 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience must include Experience with cloud computing platforms such as Google Cloud, Azure, and AWS (O-RQ Required Qualifications Non-header)</li></span><br />47 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience must include and Experience building ML solutions from inception to launch (O-RQ Required Qualifications Non-header)</li></span><br /><hr />48 H-SP) <span style=\"color:#17becfff;\"><h3 class=\"jobSectionHeader\">Supplemental Pay: (H-SP Supplemental Pay Header)</h3></span><br />49 O-SP) <span style=\"color:#17becf80;\"><li>SALARY: $183,352 - $184,352 per year (O-SP Supplemental Pay Non-header)</li></span><br />50 O-SP) <span style=\"color:#17becf80;\"><li>The pay range for this position is $183,352.00 - $184,352.00 / Year with the opportunity for eligible associates to earn additional compensation pursuant to the Company's bonus plan. (O-SP Supplemental Pay Non-header)</li></span><br />51 O-SP) <span style=\"color:#17becf80;\"><li>Full-time positions are eligible for paid time off, health, dental, vision, life and disability benefits. (O-SP Supplemental Pay Non-header)</li></span><br />52 O-SP) <span style=\"color:#17becf80;\"><li>Part-time positions are eligible for dental, vision, life, and disability benefits. (O-SP Supplemental Pay Non-header)</li></span><br />53 H-OL) <span style=\"color:#c49c94ff;\"><h3 class=\"jobSectionHeader\">Office Location: (H-OL Office Location Header)</h3></span><br />54 O-OL) <span style=\"color:#c49c9480;\"><li>LOCATION: 1000 Remington Blvd., Suite 120, Bolingbrook, IL 60440 (O-OL Office Location Non-header)</li></span><br />55 O-OL) <span style=\"color:#c49c9480;\"><li>TELECOMMUTING EMPLOYEE: Reports to company headquarters in Bolingbrook, IL. (O-OL Office Location Non-header)</li></span><br />56 O-OL) <span style=\"color:#c49c9480;\"><li>Can work remotely or telecommute up to 100%. (O-OL Office Location Non-header)</li></span><br />57 H-JD) <span style=\"color:#98df8aff;\"><h3 class=\"jobSectionHeader\">Job Duration: (H-JD Job Duration Header)</h3></span><br />58 O-JD) <span style=\"color:#98df8a80;\"><li>HOURS: Monday to Friday, 8:00 am to 5:00 pm (O-JD Job Duration Non-header)</li></span><br />59 H-IP) <span style=\"color:#ffbb78ff;\"><h3 class=\"jobSectionHeader\">Interview Procedures: (H-IP Interview Procedures Header)</h3></span><br />60 O-IP) <span style=\"color:#ffbb7880;\"><li>TO APPLY: https://careers.ulta.com/careers/ (O-IP Interview Procedures Non-header)</li></span><br />61 O-IP) <span style=\"color:#ffbb7880;\"><li>Exact pay will be based on factors including, but not limited to relevant education, qualifications, certifications, experience, level, shift, geographic location, and business and organizational needs. (O-IP Interview Procedures Non-header)</li></span><br />62 O-IP) <span style=\"color:#ffbb7880;\"><li>For additional information concerning our benefits, visit our Benefits and Career Development page: https://careers.ulta.com/careers/about-us/benefits-and-career-development (O-IP Interview Procedures Non-header)</li></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "Parts-of-speech displayed in 1 minute and 51 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech displayed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91379a3d-1a77-4d8b-9ef6-a76f12204ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26c4dd4e-1418-4420-aff5-ea7b65273194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 H-IP) <h3 class=\"jobSectionHeader\">Interview Procedures:</h3>\n",
      "50 O-IP) <li>TO APPLY: https://careers.ulta.com/careers/</li>\n",
      "51 O-IP) <li>Exact pay will be based on factors including, but not limited to relevant education, qualifications, certifications, experience, level, shift, geographic location, and business and organizational needs.</li>\n",
      "52 O-SP) <li>For additional information concerning our benefits, visit our Benefits and Career Development page: https://careers.ulta.com/careers/about-us/benefits-and-career-development</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict'); column_name = 'is_interview_procedure'\n",
    "for idx in list(range(49, 53)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\\n            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\\n            ''' + cu.return_everything_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                np.is_educational_requirement = {str(column_name == 'is_educational_requirement').lower()},\n",
    "                np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 18, 21, 23, 27, 38, 41, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 60, 62, 65, 66, 67, 68]\n",
      "34 O-RQ) <li>2 ounces High West Bourbon (optional)</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 34\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2f46926-880b-4aed-bc99-4a6bd9ed7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>2 ounces High West Bourbon (optional)</li>\" in basic_quals_dict: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24e7695d-caf6-416f-a761-ec17b839ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 O-RQ) <li>Live the experience.</li>\n",
      "2 O-SP) <li>From professional empowerment to continual learning opportunities.</li>\n",
      "3 O-TS) <li>From ongoing investment in our strategic initiatives to a career of self-determination.</li>\n",
      "4 O-RQ) <li>At Ulta Beauty, our team is critical to our scalability-and is recognized that way.</li>\n",
      "5 O-RQ) <li>We've been defined as a \"mature start-up.\" A place where interdepartmental exposure, open doors, and genuine collaboration is ubiquitous.</li>\n",
      "6 O-RQ) <li>Where challenges come fast and furious, requiring agility, mental dexterity, and creativity.</li>\n",
      "7 H-CS) <li>Where our passion for better solutions drives us and is core to who we are.</li>\n",
      "8 O-CS) <li>We're engineering for the future of retail, and it's no-holds-barred.</li>\n",
      "9 O-SP) <li>But for those motivated by continual change and ambiguity, by superior leadership, by whip smart colleagues who will press you daily for your very best, you'll find that virtually nothing's impossible at Ulta Beauty.</li>\n",
      "10 O-RQ) <li>COMPANY: Ulta, Inc.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in range(1, 11):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = false\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "326ab607-cc5c-4476-b692-395b96d293ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 O-RQ) <h3 class=\"jobSectionHeader\">REQUIREMENTS:</h3>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [40]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = true\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfa2e-4e09-4da7-b046-98f5c170ec67",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07255146-70be-4d52-942c-1505d6e02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display cypher necessary to apply for all the jobs you qualify for that you haven't applied for\n",
    "import pyperclip\n",
    "\n",
    "cypher_str = f'''\n",
    "    // Get job application links for jobs you should apply to\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit >= 0.8 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS filename,\n",
    "        fn.posting_url AS posting_url\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "pyperclip.copy(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    display(df)\n",
    "    \n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_closed = true\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "    \n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_opportunity_application_emailed = true, fn.opportunity_application_email_date = date()\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "speech_str = 'Job application cypher code copied to clipboard'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22c3685b-69f1-40fd-aa98-c473365ff866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Ensure you have already run the \"Fix Parts-of-Speech and Quals for \n",
    "# this posting\" cells above or displayed the context of an \n",
    "# individual child string above. Don't close the Notepad++ window \n",
    "# until you have replaced the child string\n",
    "def display_file_in_text_editor(file_name):\n",
    "    text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "    file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "    !\"{text_editor_path}\" \"{file_path}\"\n",
    "display_file_in_text_editor(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af64e55d-eb9b-413d-8b71-bef7188d48a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                MATCH\n",
      "                    (np:NavigableParents {navigable_parent: \"<li>For additional information concerning our benefits, visit our Benefits and Career Development page: https://careers.ulta.com/careers/about-us/benefits-and-career-development</li>\"}),\n",
      "                    (ht:HeaderTags {header_tag: \"li\"})\n",
      "                MERGE (ht)-[r:SUMMARIZES]->(np);\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cu.rebuild_filename_node(file_name, navigable_parent=None, verbose=True)\n",
    "speech_str = 'File name node rebuild completed'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fae8b-14ec-4c20-96b0-70c622ac7c73",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d17dac-be9e-4bc3-aa01-58eed1baa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d1a8b-85e6-4fb8-aba3-43874e6dabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str, None)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e765305-d9a3-4955-a905-8389c35ad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the database\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005f4a8-f07c-4538-8d1b-210d32dd3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually set each feature\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = true,\n",
    "            np.is_task_scope = false,\n",
    "            np.is_minimum_qualification = false,\n",
    "            np.is_preferred_qualification = false,\n",
    "            np.is_educational_requirement = true,\n",
    "            np.is_legal_notification = false,\n",
    "            np.is_other = false,\n",
    "            np.is_corporate_scope = false,\n",
    "            np.is_job_title = false,\n",
    "            np.is_office_location = false,\n",
    "            np.is_job_duration = false,\n",
    "            np.is_supplemental_pay = false,\n",
    "            np.is_interview_procedure = false,\n",
    "            np.is_posting_date = false\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False); row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a9fa5-9f15-4bcc-a3df-b75dbb52ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "for file_name in ['']:\n",
    "    cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3aad62-d78e-4243-b46f-dec293d4552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def separate_qualifications(quals_list):\n",
    "  \"\"\"\n",
    "  This function takes a list of qualifications and separates them into individual sentences.\n",
    "\n",
    "  Args:\n",
    "      quals_list: A list of strings, where each string represents a qualification.\n",
    "\n",
    "  Returns:\n",
    "      A list of lists, where each inner list contains the individual qualifications extracted from the corresponding element in the original quals_list.\n",
    "  \"\"\"\n",
    "  separated_quals = []\n",
    "  for qual in quals_list:\n",
    "    # Split qualifications based on commas, semicolons, and colons followed by whitespace\n",
    "    split_quals = re.split(r\", |; |:\", qual)\n",
    "    # Further split based on \"and\" if it's not the first word and there's punctuation before it\n",
    "    for i, sentence in enumerate(split_quals):\n",
    "      if i > 0 and re.search(r\"\\b(and)\\b\", sentence, flags=re.IGNORECASE) and re.search(r\"[,\\.;]\", split_quals[i-1]):\n",
    "        split_quals[i-1] += f\" {sentence.strip()}\"\n",
    "        split_quals.pop(i)\n",
    "    # Remove empty strings and leading/trailing whitespace\n",
    "    separated_quals.append([q.strip() for q in split_quals if q.strip()])\n",
    "  return separated_quals\n",
    "\n",
    "separated_qualifications = separate_qualifications(quals_list)\n",
    "\n",
    "# Print the separated qualifications\n",
    "for qual_set in separated_qualifications:\n",
    "  for qual in qual_set:\n",
    "    print(qual)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2828f-ab7b-4550-b5cc-92078c40f331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
