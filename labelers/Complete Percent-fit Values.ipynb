{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb7318f-5285-4f7b-bc3e-2859fe05f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 10 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "executable_path = sys.executable; scripts_folder = osp.join(osp.dirname(executable_path), 'Scripts')\n",
    "py_folder = osp.abspath('../py'); ffmpeg_folder = r'C:\\ffmpeg\\bin'\n",
    "if (scripts_folder not in sys.path): sys.path.insert(1, scripts_folder)\n",
    "if (py_folder not in sys.path): sys.path.insert(1, py_folder)\n",
    "if (ffmpeg_folder not in sys.path): sys.path.insert(1, ffmpeg_folder)\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import pyperclip\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f331b-c66a-4c65-906b-22bc6fc034c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 48,129 labeled parts of speech in here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train the POS Classifiers: 100%|██████████████████████████████████████████████████████| 25/25 [00:00<00:00, 408.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is available\n",
      "Parts-of-speech logistic regression elements built in 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression elements\n",
    "# Parts-of-speech logistic regression elements is normally built in 1 hour, 55 minutes and 45 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'): print('predict_single is available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech logistic regression elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe80356-c69a-4579-b298-31e40e871b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "Parts-of-speech conditional random field elements built in 1 second\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the scrfcu has built its parts-of-speech conditional random field elements\n",
    "# Parts-of-speech CRF elements normally built in 29 minutes and 57 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech conditional random field elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3453a69d-7080-4ebf-96a8-528e9541ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 48,129 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech stochastic gradient descent elements built in 9 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the ssgdcu has built its parts-of-speech stochastic gradient decent elements\n",
    "t1 = time.time()\n",
    "if not hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech stochastic gradient descent elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e7d031-531c-4024-b9f4-03485a91a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "POS classifier trained in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the crf has built its parts-of-speech classifier\n",
    "# POS classifier normally trained in 15 hours, 42 minutes and 41 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(crf, 'CRF'): crf.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(crf, 'CRF'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'POS classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d259dffb-c212-4493-a879-1ae5d503f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 532,546 is-qualified vocabulary tokens in here\n",
      "Is-qualified LR elements built in 7 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has built its is-qualified classifier\n",
    "t1 = time.time()\n",
    "if not (hasattr(lru, 'ISQUALIFIED_LR') and hasattr(lru, 'ISQUALIFIED_CV')):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified LR elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d67a34-e133-45dc-9bf3-a830af359d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 51,612 hand-labeled header htmls prepared\n",
      "7 iterations seen during training fit for a total of 51,612 records trained\n",
      "Is-header classifier trained in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the isheader classifier\n",
    "t1 = time.time()\n",
    "ihu.build_pos_stochastic_gradient_descent_elements(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-header classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcef1d94-4466-4100-86cd-0d66f23d0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2024-10-20 15:23:53.725733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "speech_str = f'Last run on {datetime.now()}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f438163-0f14-4a74-978c-769c9dba95c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f02bfeac-67b7-4df6-a4a0-32ec3dec0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 21,212 hand-labeled qualification strings in here\n",
      "I have 589,616 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 15 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary below or in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified classifer retrained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad3579-ebc3-4d21-a7c3-f9bd168ac6ca",
   "metadata": {},
   "source": [
    "\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d334d815-e43b-474e-9dbb-db509176f6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Qualifications for 1351404 Data Engineer France S A S:\n",
      "*quals_list[0] = \"Expertise in data mining, data storage and Extract-Transform-Load (\" (1.0)\n",
      "quals_list[1] = \"SQL\" (1.0)\n",
      "*quals_list[2] = \"Communication skills.\" (1.0)\n",
      "*quals_list[3] = \"Opportunities for professional development and continuous training.\" (1.0)\n",
      "100.00%\n",
      "\n",
      "hunting_df.loc[5113, 'percent_fit'] = (000+1+000+000)/4\n",
      "5112/5139 = 99.5% completed\n",
      "Inference completed in 35 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "quals_list, file_name = lru.infer_from_hunting_dataframe(fitness_threshold=3/4, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Inference completed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264da9-f96a-491a-83d9-25d15fcdfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47bd03b8-c0a3-404c-a16d-eb4ce95c6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience working in agile teams using collaboration software like Jira or similar\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qualification string\n",
    "qualification_str = quals_list[9]\n",
    "print(qualification_str); basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[qualification_str]) + '\\n' if(qualification_str in basic_quals_dict) else '', end='')\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4212b-9280-46d1-8e46-104aada7c0df",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix Parts-of-Speech and Quals for this posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ac6efb8-6b56-43dd-9079-d6a87491ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342245_Senior_Product_Data_Scientist_Celonis.html\n",
      "CRF and child strings list recreated in 41 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "file_path = osp.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if osp.isfile(file_path):\n",
    "    child_strs_list = hau.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    print(file_name)\n",
    "    assert hasattr(slrcu, 'pos_predict_percent_fit_dict'), 'slrcu.predict_single needs to be available'\n",
    "    pos_symbol_predictions_list = [slrcu.predict_single(sent_str) for sent_str in child_strs_list]\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'CRF and child strings list recreated in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "affcb06a-3165-4349-a936-037af549d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O-CS', 'H-CS', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'H-PQ', 'O-PQ', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'H-CS', 'O-CS', 'H-CS', 'H-LN', 'O-LN', 'H-TS', 'O-IP', 'O-IP']\n",
      "[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 O-CS) <span style=\"color:#1f77b480;\"><p>We're Celonis, the global leader in Process Mining technology and one of the world's fastest-growing SaaS firms. We believe there is a massive opportunity to unlock productivity by placing data and intelligence at the core of business processes - and for that, we need you to join us. (O-CS Corporate Scope Non-header)</p></span><br />1 H-CS) <span style=\"color:#1f77b4ff;\"><strong>The Team: (H-CS Corporate Scope Header)</strong></span><br />2 O-TS) <span style=\"color:#9edae580;\"><p>As a member of the Engineering organization, the Product Analytics &amp; Data Sciences team provides analytic support and a strategic perspective to the product and engineering teams to enable them to make evidence-based conclusions. We deliver actionable insights by collecting, organizing, and interpreting data about user journeys, product telemetry, incidents, infrastructure utilization, sales motions, and much more. We transform data into analytic assets by conducting exploratory analysis, identifying outliers, validating hypotheses, building statistical models, quantifying risk; communicating findings through well-crafted stories and critical recommendations. (O-TS Task Scope Non-header)</p></span><br />3 H-TS) <span style=\"color:#9edae5ff;\"><strong>The Role: (H-TS Task Scope Header)</strong></span><br />4 O-TS) <span style=\"color:#9edae580;\"><p>As a Product Data Scientist in the Product Analytics &amp; Data Sciences team, you will play a key role in developing and communicating data-informed insights that will help with strategic and tactical decision-making in a hyper-growth environment. You will partner with engineers and product team members to understand business problems and help define data solutions. You will build data pipelines for new data sources, develop machine learning models, and create visualizations to communicate findings and recommendations to engineers, managers, and executives. In this exciting role, in addition to crunching data, you will also need to facilitate data-informed discussions between stakeholders across the organization, through effective storytelling with meaningful insight. (O-TS Task Scope Non-header)</p></span><br />5 O-TS) <span style=\"color:#9edae580;\"><strong>The work you’ll do: (O-TS Task Scope Non-header)</strong></span><br />6 O-TS) <span style=\"color:#9edae580;\"><li>Build visualizations as well as written narratives to communicate quantitative insights and facilitate discussions with data-informed insights. (O-TS Task Scope Non-header)</li></span><br />7 O-TS) <span style=\"color:#9edae580;\"><li>Collaborate with partners across the product and engineering teams to understand business motivations (O-TS Task Scope Non-header)</li></span><br />8 O-TS) <span style=\"color:#9edae580;\"><li>Continuously engage in refining data engineering processes to ensure data accuracy, consistency, and integrity through continuous audit and review. (O-TS Task Scope Non-header)</li></span><br />9 O-TS) <span style=\"color:#9edae580;\"><li>Effectively present and communicate analytical findings to stakeholders across the organization. (O-TS Task Scope Non-header)</li></span><br />10 O-TS) <span style=\"color:#9edae580;\"><li>Employ statistical analysis and/or modeling techniques on a variety of data - product telemetry, incidents, user journeys, sales motions, infrastructure utilization, and others, to drive resource optimization, feature improvement, or product adoption-related initiatives (O-TS Task Scope Non-header)</li></span><br />11 O-TS) <span style=\"color:#9edae580;\"><li>Formulate and deliver data analysis by engaging across all the steps of the process, including data gathering, building data pipelines, performing analyses, and delivering insights at scale (O-TS Task Scope Non-header)</li></span><br />12 O-TS) <span style=\"color:#9edae580;\"><li>Serve as the data science specialist on the team, building data-informed insights to deliver findings and recommendations to product and engineering teams (O-TS Task Scope Non-header)</li></span><br /><hr />13 O-RQ) <span style=\"color:#bcbd2280;\"><strong>The qualifications you need: (O-RQ Required Qualifications Non-header)</strong></span><br />14 O-RQ) <span style=\"color:#bcbd2280;\"><li>6+ years relevant experience as a Product Analytics Engineer / Data Scientist or similar, partnering with product, engineering, or growth teams (O-RQ Required Qualifications Non-header)</li></span><br />15 O-RQ) <span style=\"color:#bcbd2280;\"><li>Bachelor’s degree or equivalent with a strong focus on Mathematics, Computer Science, or Data Science (O-RQ Required Qualifications Non-header)</li></span><br />16 O-RQ) <span style=\"color:#bcbd2280;\"><li>Eager to work in a fast-growing organization with diverse and international teams spread across multiple locations (O-RQ Required Qualifications Non-header)</li></span><br />17 O-RQ) <span style=\"color:#bcbd2280;\"><li>Exceptional attention to detail (O-RQ Required Qualifications Non-header)</li></span><br />18 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience working in agile teams using collaboration software like Jira or similar (O-RQ Required Qualifications Non-header)</li></span><br />19 O-RQ) <span style=\"color:#bcbd2280;\"><li>Experience working with large datasets and predictive modeling (O-RQ Required Qualifications Non-header)</li></span><br />20 O-RQ) <span style=\"color:#bcbd2280;\"><li>Have excellent written and verbal communication skills (O-RQ Required Qualifications Non-header)</li></span><br />21 O-RQ) <span style=\"color:#bcbd2280;\"><li>Outcome-oriented with strong decision-making skills and the ability to prioritize multiple goals while meeting deadlines (O-RQ Required Qualifications Non-header)</li></span><br />22 O-RQ) <span style=\"color:#bcbd2280;\"><li>Strong understanding of statistical techniques and machine learning (O-RQ Required Qualifications Non-header)</li></span><br />23 O-RQ) <span style=\"color:#bcbd2280;\"><li>Technical proficiency with analytical tools for data extraction, visualization, and analysis (SQL, Python, Pandas) (O-RQ Required Qualifications Non-header)</li></span><br /><hr />24 H-PQ) <span style=\"color:#c7c7c7ff;\"><strong>Preferred Qualifications: (H-PQ Preferred Qualifications Header)</strong></span><br />25 O-PQ) <span style=\"color:#c7c7c780;\"><li>Master’s preferred. (O-PQ Preferred Qualifications Non-header)</li></span><br />26 O-SP) <span style=\"color:#17becf80;\"><strong>What Celonis Can Offer You: (O-SP Supplemental Pay Non-header)</strong></span><br />27 O-SP) <span style=\"color:#17becf80;\"><li>The unique opportunity to work with industry-leading process mining technology (O-SP Supplemental Pay Non-header)</li></span><br />28 O-SP) <span style=\"color:#17becf80;\"><li>Investment in your personal growth and skill development (clear career paths, internal mobility opportunities, L&amp;D platform, mentorships, and more) (O-SP Supplemental Pay Non-header)</li></span><br />29 O-SP) <span style=\"color:#17becf80;\"><li>Great compensation and benefits packages (equity (restricted stock units), life insurance, time off, generous leave for new parents from day one, and more). For intern and working student benefits, click here . (O-SP Supplemental Pay Non-header)</li></span><br />30 O-SP) <span style=\"color:#17becf80;\"><li>Physical and mental well-being support (subsidized gym membership, access to counseling, virtual events on well-being topics, and more) (O-SP Supplemental Pay Non-header)</li></span><br />31 O-SP) <span style=\"color:#17becf80;\"><li>A global and growing team of Celonauts from diverse backgrounds to learn from and work with (O-SP Supplemental Pay Non-header)</li></span><br />32 O-SP) <span style=\"color:#17becf80;\"><li>An open-minded culture with innovative, autonomous teams (O-SP Supplemental Pay Non-header)</li></span><br />33 O-SP) <span style=\"color:#17becf80;\"><li>Business Resource Groups to help you feel connected, valued and seen (Black@Celonis, Women@Celonis, Parents@Celonis, Pride@Celonis, Resilience@Celonis, and more) (O-SP Supplemental Pay Non-header)</li></span><br />34 O-SP) <span style=\"color:#17becf80;\"><li>A clear set of company values that guide everything we do: Live for Customer Value, The Best Team Wins, We Own It, and Earth Is Our Future (O-SP Supplemental Pay Non-header)</li></span><br />35 H-CS) <span style=\"color:#1f77b4ff;\"><strong>About Us: (H-CS Corporate Scope Header)</strong></span><br />36 O-CS) <span style=\"color:#1f77b480;\"><p>Celonis helps some of the world’s largest and most esteemed brands make processes work for people, companies and the planet. With over 5,000 enterprise customer deployments across nearly every industry, the Celonis Process Intelligence Platform uses process mining and AI to give you a living digital twin of your business operation. It’s system-agnostic and without bias, and empowers companies to reduce waste, create value and benefit people across the top, bottom, and green lines. Since 2011, the Celonis platform has enabled its customers to identify more than $18 billion in value. Celonis is headquartered in Munich, Germany, and New York City, USA, with more than 20 offices worldwide. (O-CS Corporate Scope Non-header)</p></span><br />37 H-CS) <span style=\"color:#1f77b4ff;\"><p>Get familiar with the Celonis Process Intelligence Platform by watching this video . (H-CS Corporate Scope Header)</p></span><br />38 H-LN) <span style=\"color:#9467bdff;\"><strong>Equal Opportunity at Celonis: (H-LN Legal Notifications Header)</strong></span><br />39 O-LN) <span style=\"color:#9467bd80;\"><p>Celonis is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment and equal opportunity in all aspects of employment. We will not tolerate any unlawful discrimination or harassment of any kind. We make all employment decisions without regard to race/ethnicity, color, sex, pregnancy, age, sexual orientation, gender identity or expression, transgender status, national origin, citizenship status, religion, physical or mental disability, veteran status, or any other factor protected by applicable anti-discrimination laws. As a US federal contractor, we are committed to the principles of affirmative action in accordance with applicable laws and regulations. Different makes us better . (O-LN Legal Notifications Non-header)</p></span><br />40 H-TS) <span style=\"color:#9edae5ff;\"><strong>Your Privacy: (H-TS Task Scope Header)</strong></span><br />41 O-IP) <span style=\"color:#ffbb7880;\"><p>Any information you submit to Celonis as part of your application will be processed in accordance with Celonis’ Accessibility and Candidate Notices (O-IP Interview Procedures Non-header)</p></span><br />42 O-IP) <span style=\"color:#ffbb7880;\"><p>Please be aware of common job offer scams, impersonators and frauds. Learn more here . (O-IP Interview Procedures Non-header)</p></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Parts-of-speech displayed in 46 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(pos_symbol_predictions_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech displayed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91379a3d-1a77-4d8b-9ef6-a76f12204ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26c4dd4e-1418-4420-aff5-ea7b65273194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 H-SP) <strong>What Celonis Can Offer You:</strong>\n",
      "27 O-SP) <li>The unique opportunity to work with industry-leading process mining technology</li>\n",
      "28 O-TS) <li>Investment in your personal growth and skill development (clear career paths, internal mobility opportunities, L&amp;D platform, mentorships, and more)</li>\n",
      "29 O-SP) <li>Great compensation and benefits packages (equity (restricted stock units), life insurance, time off, generous leave for new parents from day one, and more). For intern and working student benefits, click here .</li>\n",
      "30 O-SP) <li>Physical and mental well-being support (subsidized gym membership, access to counseling, virtual events on well-being topics, and more)</li>\n",
      "31 O-SP) <li>A global and growing team of Celonauts from diverse backgrounds to learn from and work with</li>\n",
      "32 O-PQ) <li>An open-minded culture with innovative, autonomous teams</li>\n",
      "33 O-SP) <li>Business Resource Groups to help you feel connected, valued and seen (Black@Celonis, Women@Celonis, Parents@Celonis, Pride@Celonis, Resilience@Celonis, and more)</li>\n",
      "34 O-CS) <li>A clear set of company values that guide everything we do: Live for Customer Value, The Best Team Wins, We Own It, and Earth Is Our Future</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict'); column_name = 'is_supplemental_pay'\n",
    "for idx in list(range(26, 35)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\\n            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\\n            ''' + cu.return_every_np_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "            ''' + cu.return_every_np_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 14, 15, 16, 17, 20, 21, 22, 23]\n",
      "25 O-PQ) <li>Master’s preferred.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 25\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2f46926-880b-4aed-bc99-4a6bd9ed7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>Master’s preferred.</li>\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24e7695d-caf6-416f-a761-ec17b839ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 H-O) B2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in range(26, 27):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = false\n",
    "            ''' + cu.return_every_np_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "326ab607-cc5c-4476-b692-395b96d293ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 H-CS) <strong>The Team:</strong>\n",
      "3 H-TS) <strong>The Role:</strong>\n",
      "5 O-TS) <strong>The work you’ll do:</strong>\n",
      "13 O-RQ) <strong>The qualifications you need:</strong>\n",
      "24 H-PQ) <strong>Preferred Qualifications:</strong>\n",
      "26 O-SP) <strong>What Celonis Can Offer You:</strong>\n",
      "35 H-CS) <strong>About Us:</strong>\n",
      "38 H-LN) <strong>Equal Opportunity at Celonis:</strong>\n",
      "40 H-TS) <strong>Your Privacy:</strong>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [1, 3, 5, 13, 24, 26, 35, 38, 40]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = true\n",
    "            ''' + cu.return_every_np_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfa2e-4e09-4da7-b046-98f5c170ec67",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07255146-70be-4d52-942c-1505d6e02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display cypher necessary to apply for all the jobs you qualify for that you haven't applied for\n",
    "cypher_str = f'''\n",
    "    // Get job application links for jobs you should apply to\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit >= 0.8 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS filename,\n",
    "        fn.posting_url AS posting_url\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "pyperclip.copy(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    display(df)\n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_closed = true\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_opportunity_application_emailed = true, fn.opportunity_application_email_date = date()\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "speech_str = 'Job application cypher code copied to clipboard'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22c3685b-69f1-40fd-aa98-c473365ff866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Ensure you have already run the \"Fix Parts-of-Speech and Quals for \n",
    "# this posting\" cells above or displayed the context of an \n",
    "# individual child string above. Don't close the Notepad++ window \n",
    "# until you have replaced the child string\n",
    "# file_name = '476d6e5bd50da5a6_Data_Scientist_Remote_Indeed_com.html'\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "wsu.clean_job_posting(file_path)\n",
    "try: pyperclip.copy(re.sub(\"((?:<li>([^><]+)</li>\\n)+)\", \"<ul>\\n\\\\1</ul>\\n\", '\\n'.join(child_strs_list), 0, re.MULTILINE))\n",
    "except: pass\n",
    "!\"{text_editor_path}\" \"{file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "af64e55d-eb9b-413d-8b71-bef7188d48a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                MATCH\n",
      "                    (np:NavigableParents {navigable_parent: \"<p>Please be aware of common job offer scams, impersonators and frauds. Learn more here .</p>\"}),\n",
      "                    (ht:HeaderTags {header_tag: \"p\"})\n",
      "                MERGE (ht)-[r:SUMMARIZES]->(np);\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cu.rebuild_filename_node(file_name, navigable_parent=None, verbose=True)\n",
    "speech_str = f'{su.get_job_title_from_file_name(file_name)} node rebuild completed'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fae8b-14ec-4c20-96b0-70c622ac7c73",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d17dac-be9e-4bc3-aa01-58eed1baa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_every_np_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d1a8b-85e6-4fb8-aba3-43874e6dabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular qualification string from the quals dictionary\n",
    "qualification_str = quals_list[25]\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict.pop(qualification_str, None)\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{qualification_str}\" in basic_quals_dict: {qualification_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e765305-d9a3-4955-a905-8389c35ad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular qualification string from the database\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=qualification_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005f4a8-f07c-4538-8d1b-210d32dd3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually set each feature\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = true,\n",
    "            np.is_task_scope = false,\n",
    "            np.is_minimum_qualification = false,\n",
    "            np.is_preferred_qualification = false,\n",
    "            np.is_educational_requirement = true,\n",
    "            np.is_legal_notification = false,\n",
    "            np.is_other = false,\n",
    "            np.is_corporate_scope = false,\n",
    "            np.is_job_title = false,\n",
    "            np.is_office_location = false,\n",
    "            np.is_job_duration = false,\n",
    "            np.is_supplemental_pay = false,\n",
    "            np.is_interview_procedure = false,\n",
    "            np.is_posting_date = false\n",
    "        ''' + cu.return_every_np_str + ';'\n",
    "    return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False); row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a9fa5-9f15-4bcc-a3df-b75dbb52ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "for file_name in ['']:\n",
    "    cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2828f-ab7b-4550-b5cc-92078c40f331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
