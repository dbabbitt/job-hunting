{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb7318f-5285-4f7b-bc3e-2859fe05f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 14 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os.path as osp\n",
    "if (osp.abspath('../py') not in sys.path): sys.path.insert(1, osp.abspath('../py'))\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f331b-c66a-4c65-906b-22bc6fc034c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 48,494 labeled parts of speech in here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train the POS Classifiers: 100%|██████████████████████████████████████████████████████| 25/25 [00:00<00:00, 417.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is available\n",
      "Parts-of-speech logistic regression elements built in 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression elements\n",
    "# Parts-of-speech logistic regression elements is normally built in 1 hour, 55 minutes and 45 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'): print('predict_single is available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech logistic regression elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe80356-c69a-4579-b298-31e40e871b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "Parts-of-speech conditional random field elements built in 1 second\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the scrfcu has built its parts-of-speech conditional random field elements\n",
    "# Parts-of-speech CRF elements normally built in 29 minutes and 57 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech conditional random field elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3453a69d-7080-4ebf-96a8-528e9541ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 48,494 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech stochastic gradient descent elements built in 10 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the ssgdcu has built its parts-of-speech stochastic gradient decent elements\n",
    "t1 = time.time()\n",
    "if not hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech stochastic gradient descent elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e7d031-531c-4024-b9f4-03485a91a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "POS classifier trained in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the crf has built its parts-of-speech classifier\n",
    "# POS classifier normally trained in 15 hours, 42 minutes and 41 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(crf, 'CRF'): crf.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(crf, 'CRF'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'POS classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d259dffb-c212-4493-a879-1ae5d503f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 532,546 is-qualified vocabulary tokens in here\n",
      "Is-qualified LR elements built in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has built its is-qualified classifier\n",
    "t1 = time.time()\n",
    "if not (hasattr(lru, 'ISQUALIFIED_LR') and hasattr(lru, 'ISQUALIFIED_CV')):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified LR elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d67a34-e133-45dc-9bf3-a830af359d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 51,070 hand-labeled header htmls prepared\n",
      "7 iterations seen during training fit for a total of 51,070 records trained\n",
      "Is-header classifier trained in 12 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the isheader classifier\n",
    "t1 = time.time()\n",
    "ihu.build_pos_stochastic_gradient_descent_elements(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-header classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcef1d94-4466-4100-86cd-0d66f23d0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2024-10-01 05:14:54.771153\n"
     ]
    }
   ],
   "source": [
    "\n",
    "speech_str = f'Last run on {datetime.now()}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f438163-0f14-4a74-978c-769c9dba95c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f02bfeac-67b7-4df6-a4a0-32ec3dec0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 19,883 hand-labeled qualification strings in here\n",
      "I have 554,720 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 18 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary below or in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified classifer retrained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad3579-ebc3-4d21-a7c3-f9bd168ac6ca",
   "metadata": {},
   "source": [
    "\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d334d815-e43b-474e-9dbb-db509176f6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4766/4766 = 100.0% completed\n",
      "Inference completed in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "quals_list, file_name = lru.infer_from_hunting_dataframe(fitness_threshold=3/4, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Inference completed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264da9-f96a-491a-83d9-25d15fcdfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47bd03b8-c0a3-404c-a16d-eb4ce95c6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isn’t afraid to voice opinions and contribute to the design process\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qualification string\n",
    "qualification_str = quals_list[6]\n",
    "print(qualification_str); basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[qualification_str]) + '\\n' if(qualification_str in basic_quals_dict) else '', end='')\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4212b-9280-46d1-8e46-104aada7c0df",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix Parts-of-Speech and Quals for this posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ac6efb8-6b56-43dd-9079-d6a87491ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1b59346bf8eb1d3a_AI_ML_Engineer_Remote_Indeed_com.html\n",
      "CRF and child strings list recreated in 48 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "file_path = osp.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if osp.isfile(file_path):\n",
    "    child_strs_list = hau.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    print(file_name)\n",
    "    assert hasattr(slrcu, 'pos_predict_percent_fit_dict'), 'slrcu.predict_single needs to be available'\n",
    "    pos_symbol_predictions_list = [slrcu.predict_single(sent_str) for sent_str in child_strs_list]\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'CRF and child strings list recreated in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affcb06a-3165-4349-a936-037af549d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O-SP', 'O-CS', 'H-TS', 'O-SP', 'H-JT', 'O-TS', 'H-TS', 'O-TS', 'H-CS', 'H-PQ', 'O-SP', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'H-RQ', 'H-ER', 'O-RQ', 'O-PQ', 'O-PQ', 'H-RQ', 'H-RQ', 'O-RQ', 'H-RQ', 'O-PQ', 'H-RQ', 'O-RQ', 'H-PQ', 'O-RQ', 'H-RQ', 'O-PQ', 'H-RQ', 'O-RQ', 'H-PQ', 'O-PQ', 'H-PQ', 'O-PQ', 'O-RQ', 'O-PQ', 'O-PQ', 'H-RQ', 'O-LN', 'H-RQ', 'O-IP', 'H-OL', 'O-OL', 'H-CS', 'O-SP', 'O-SP', 'O-SP', 'O-SP', 'O-LN', 'O-IP', 'O-IP']\n",
      "[11, 12, 13, 14, 17, 22, 26, 28, 32]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 O-SP) <span style=\"color:#17becf80;\">About DMI: (O-SP Supplemental Pay Non-header)</span><br />1 O-CS) <span style=\"color:#1f77b480;\"><div>DMI is a leading global provider of digital services working at the intersection of public and private sectors. With broad capabilities across IT managed services, cybersecurity, cloud migration and application development, DMI provides on-site and remote support to clients within governments, healthcare, financial services, transportation, manufacturing, and other critical infrastructure sectors. DMI has grown to over 2,100+ employees globally and has been continually recognized as a Top Workplace in both regional and national categories. (O-CS Corporate Scope Non-header)</div></span><br />2 H-TS) <span style=\"color:#9edae5ff;\">About the Opportunity: (H-TS Task Scope Header)</span><br />3 O-SP) <span style=\"color:#17becf80;\">DMI, LLC is seeking an (O-SP Supplemental Pay Non-header)</span><br />4 H-JT) <span style=\"color:#d62728ff;\"><b>AI/ML Engineer (H-JT Job Title Header)</b></span><br />5 O-TS) <span style=\"color:#9edae580;\">. This role is remote supporting EST work hours, collaborating with a major automotive client out of Detroit. (O-TS Task Scope Non-header)</span><br />6 H-TS) <span style=\"color:#9edae5ff;\"><b>Duties and Responsibilities: (H-TS Task Scope Header)</b></span><br />7 O-TS) <span style=\"color:#9edae580;\"><div>The AI/MLOps Engineer (AMOE) is an applied solutions expert blending software engineering, machine learning, and DevOps practices. As part of a small, dedicated AI team, the AMOE builds CI/CD pipelines, deploys applications, ensures security by design, and automates workflows. (O-TS Task Scope Non-header)</div></span><br />8 H-CS) <span style=\"color:#1f77b4ff;\"><div>Our team develops production ML/AI applications across various domains, including logistics, operations, and business optimization. Effective communication and the ability to create clear documentation and diagrams are crucial, as collaboration with vendors and stakeholders is common. We value maintainable, testable code. Integration tests, CI/CD, observability, and twelve-factor app design are key to our approach. (H-CS Corporate Scope Header)</div></span><br />9 H-PQ) <span style=\"color:#c7c7c7ff;\"><b>The ideal candidate: (H-PQ Preferred Qualifications Header)</b></span><br />10 O-SP) <span style=\"color:#17becf80;\"><li>Enjoys learning across the tech stack, from DevSecOps to AI/ML (O-SP Supplemental Pay Non-header)</li></span><br /><hr />11 O-RQ) <span style=\"color:#bcbd2280;\"><li>Takes pride in building reliable, maintainable infrastructure (O-RQ Education Requirements Non-header)</li></span><br />12 O-RQ) <span style=\"color:#bcbd2280;\"><li>Isn’t afraid to voice opinions and contribute to the design process (O-RQ Education Requirements Non-header)</li></span><br />13 O-RQ) <span style=\"color:#bcbd2280;\"><li>Values code reviews and pair programming (O-RQ Education Requirements Non-header)</li></span><br />14 O-RQ) <span style=\"color:#bcbd2280;\"><li>Thrives in a remote-first environment, effectively using collaboration tools (O-RQ Education Requirements Non-header)</li></span><br />15 H-RQ) <span style=\"color:#bcbd22ff;\">Qualifications: (H-RQ Required Qualifications Header)</span><br />16 H-ER) <span style=\"color:#aec7e8ff;\"><b>Education and Years of Experience: (H-ER Education Requirements Header)</b></span><br />17 O-RQ) <span style=\"color:#bcbd2280;\"><li>8+ years of AI/ML Engineer experience (O-RQ Education Requirements Non-header)</li></span><br />18 O-PQ) <span style=\"color:#c7c7c780;\"><li>Proven engineering background with a degree in Computer Science, Data Analytics, or equivalent work experience (O-PQ Preferred Qualifications Non-header)</li></span><br />19 O-PQ) <span style=\"color:#c7c7c780;\"><li>Relevant technical certifications (e.g., DevOps certifications like CKA, CKS, RHCSA) (O-PQ Preferred Qualifications Non-header)</li></span><br />20 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Desired Skills/Certifications: (H-RQ Required Qualifications Header)</b></span><br />21 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Python Proficiency: (H-RQ Required Qualifications Header)</b></span><br />22 O-RQ) <span style=\"color:#bcbd2280;\">Able to read, write, document code, and manage dependencies (O-RQ Education Requirements Non-header)</span><br />23 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Git Expertise: (H-RQ Required Qualifications Header)</b></span><br />24 O-PQ) <span style=\"color:#c7c7c780;\">Comfortable using GitHub for development, including PRs and GitOps (O-PQ Preferred Qualifications Non-header)</span><br />25 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Command Line Skills: (H-RQ Required Qualifications Header)</b></span><br />26 O-RQ) <span style=\"color:#bcbd2280;\">Strong in *nix environments, familiar with Unix-based systems (O-RQ Education Requirements Non-header)</span><br />27 H-PQ) <span style=\"color:#c7c7c7ff;\"><b>Networking &amp; Security Knowledge: (H-PQ Preferred Qualifications Header)</b></span><br />28 O-RQ) <span style=\"color:#bcbd2280;\">Solid understanding of multi-network environments and data security (O-RQ Education Requirements Non-header)</span><br />29 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Containers &amp; Orchestration Experience: (H-RQ Required Qualifications Header)</b></span><br />30 O-PQ) <span style=\"color:#c7c7c780;\">Experience with containerization (Docker) and Kubernetes (O-PQ Preferred Qualifications Non-header)</span><br />31 H-RQ) <span style=\"color:#bcbd22ff;\"><b>IaC &amp; Cloud Deployment Familiarity: (H-RQ Required Qualifications Header)</b></span><br />32 O-RQ) <span style=\"color:#bcbd2280;\">Familiar with cloud-native tools and infrastructure-as-code (Terraform, Argo CD, etc.) (O-RQ Education Requirements Non-header)</span><br /><hr />33 H-PQ) <span style=\"color:#c7c7c7ff;\"><b>ML/AI Knowledge: (H-PQ Preferred Qualifications Header)</b></span><br />34 O-PQ) <span style=\"color:#c7c7c780;\">Understanding of model development, training, and monitoring (O-PQ Preferred Qualifications Non-header)</span><br />35 H-PQ) <span style=\"color:#c7c7c7ff;\"><b>Bonus Qualifications: (H-PQ Preferred Qualifications Header)</b></span><br />36 O-PQ) <span style=\"color:#c7c7c780;\"><li>Familiarity with ML/AI libraries (Pandas, scikit-learn, TensorFlow, etc) is a bonus (O-PQ Preferred Qualifications Non-header)</li></span><br />37 O-RQ) <span style=\"color:#bcbd2280;\"><li>Proficiency in other languages (Go, JavaScript) is a bonus (O-RQ Education Requirements Non-header)</li></span><br />38 O-PQ) <span style=\"color:#c7c7c780;\"><li>Experience with software architecture and designing scalable systems is a bonus (O-PQ Preferred Qualifications Non-header)</li></span><br />39 O-PQ) <span style=\"color:#c7c7c780;\"><li>SQL proficiency for data tasks is a bonus (O-PQ Preferred Qualifications Non-header)</li></span><br />40 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Min Citizenship Status Required: (H-RQ Required Qualifications Header)</b></span><br />41 O-LN) <span style=\"color:#9467bd80;\">No restrictions (O-LN Legal Notifications Non-header)</span><br />42 H-RQ) <span style=\"color:#bcbd22ff;\"><b>Physical Requirements: (H-RQ Required Qualifications Header)</b></span><br />43 O-IP) <span style=\"color:#ffbb7880;\">No Physical requirement needed for this position. (O-IP Interview Procedures Non-header)</span><br />44 H-OL) <span style=\"color:#c49c94ff;\"><b>Location: (H-OL Office Location Header)</b></span><br />45 O-OL) <span style=\"color:#c49c9480;\">Remote, US (O-OL Office Location Non-header)</span><br />46 H-CS) <span style=\"color:#1f77b4ff;\"><b>Working at DMI (H-CS Corporate Scope Header)</b></span><br />47 O-SP) <span style=\"color:#17becf80;\"><p>DMI is a diverse, prosperous, and rewarding place to work. Being part of the DMI family means we care about your wellbeing. We offer a variety of perks and benefits that help meet various interests and needs, while still having the opportunity to work directly with several of our award-winning, Fortune 1000 clients. The following categories make up your DMI wellbeing: (O-SP Supplemental Pay Non-header)</p></span><br />48 O-SP) <span style=\"color:#17becf80;\"><li>Convenience/Concierge - Virtual visits through health insurance, pet insurance, commuter benefits, discount tickets for movies, travel, and many other items to provide convenience. (O-SP Supplemental Pay Non-header)</li></span><br />49 O-SP) <span style=\"color:#17becf80;\"><li>Financial – Generous 401k matches both pre-tax and post-tax (ROTH) contributions along with financial wellness education, EAP, Life Insurance and Disability help provide financial stability for each DMI employee. (O-SP Supplemental Pay Non-header)</li></span><br />50 O-SP) <span style=\"color:#17becf80;\"><li>Wellness – Healthcare benefits, Wellness programs, Flu Shots, Biometric screenings, and several other wellness options. (O-SP Supplemental Pay Non-header)</li></span><br />51 O-LN) <span style=\"color:#9467bd80;\"><div>Employees are valued for their talents and contributions. We all take pride in helping our customers achieve their goals, which in turn contributes to the overall success of the company. The company does and will take affirmative action to employ and advance in employment individuals with disabilities and protected veterans, and to treat qualified individuals without discrimination based on their physical or mental disability or veteran status. DMI is an Equal Opportunity Employer Minority/Female/Veterans/Disability. DMI maintains a drug-free workplace. (O-LN Legal Notifications Non-header)</div></span><br />52 O-IP) <span style=\"color:#ffbb7880;\"><div>***************** No Agencies Please ***************** (O-IP Interview Procedures Non-header)</div></span><br />53 O-IP) <span style=\"color:#ffbb7880;\"><div>Applicants selected may be subject to a government security investigation and must meet eligibility requirements for access to classified information. US citizenship may be required for some positions. (O-IP Interview Procedures Non-header)</div></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 17, 22, 26, 28, 32]\n",
      "Parts-of-speech displayed in 54 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(pos_symbol_predictions_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech displayed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91379a3d-1a77-4d8b-9ef6-a76f12204ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26c4dd4e-1418-4420-aff5-ea7b65273194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 H-RQ) <b>Physical Requirements:</b>\n",
      "43 O-IP) No Physical requirement needed for this position.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict'); column_name = 'is_interview_procedure'\n",
    "for idx in list(range(42, 44)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\\n            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\\n            ''' + cu.return_everything_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 17, 22, 26, 28, 32]\n",
      "39 O-PQ) <li>SQL proficiency for data tasks is a bonus</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 39\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2f46926-880b-4aed-bc99-4a6bd9ed7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>SQL proficiency for data tasks is a bonus</li>\" in basic_quals_dict: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24e7695d-caf6-416f-a761-ec17b839ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 O-TS) <li pos=\"O-RQ\">Ability to lead an Agile team of data scientists, engineers, architects and testers</li>\n",
      "45 O-RQ) <li>Demonstrated ability to work independently</li>\n",
      "46 O-RQ) <li>Strong problem-solving skills and ability to think creatively to overcome technical challenges</li>\n",
      "47 O-PQ) <li>Ability to participate in the full machine learning lifecycle, from business understanding, data collection and preprocessing to model selection, evaluation, deployment and monitoring</li>\n",
      "48 O-RQ) <li>Ability to adapt to rapidly changing technologies and methodologies in the AI/ML field</li>\n",
      "49 O-RQ) <li>Excellent communication, analytical, and interpersonal skills</li>\n",
      "50 O-RQ) <li>Ability to gather requirements and work effectively as part of an Agile team</li>\n",
      "51 O-TS) <li>Capacity to explain complex technical concepts to non-technical stakeholders</li>\n",
      "52 O-RQ) <li>Excellent technical writing skills</li>\n",
      "53 O-RQ) <li>Ability to collaborate with business stakeholders to identify opportunities for AI/ML applications</li>\n",
      "54 O-RQ) <li>Ability to develop and maintain documentation for ML models, including methodology, assumptions, and limitations</li>\n",
      "55 O-RQ) <li>Ability to mentor junior team members and contribute to the growth of the AI/ML practice</li>\n",
      "56 O-RQ) <li>Ability to thrive in a mainly remote work environment</li>\n",
      "57 O-PQ) <li>Commitment to continuous learning in the fast-evolving AI/ML landscape and look for ways to apply new techniques when appropriate.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in range(44, 58):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = false\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "326ab607-cc5c-4476-b692-395b96d293ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 H-RQ) <b>Qualifications:</b>\n",
      "28 H-RQ) <b>Skills:</b>\n",
      "36 O-RQ) <b>Additional Skills:</b>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [26, 28, 36]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = true\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfa2e-4e09-4da7-b046-98f5c170ec67",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07255146-70be-4d52-942c-1505d6e02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display cypher necessary to apply for all the jobs you qualify for that you haven't applied for\n",
    "import pyperclip\n",
    "\n",
    "cypher_str = f'''\n",
    "    // Get job application links for jobs you should apply to\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit >= 0.8 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS filename,\n",
    "        fn.posting_url AS posting_url\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "pyperclip.copy(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    display(df)\n",
    "    \n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_closed = true\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "    \n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_opportunity_application_emailed = true, fn.opportunity_application_email_date = date()\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "speech_str = 'Job application cypher code copied to clipboard'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22c3685b-69f1-40fd-aa98-c473365ff866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Ensure you have already run the \"Fix Parts-of-Speech and Quals for \n",
    "# this posting\" cells above or displayed the context of an \n",
    "# individual child string above. Don't close the Notepad++ window \n",
    "# until you have replaced the child string\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "wsu.clean_job_posting(file_path)\n",
    "# pyperclip.copy('\\n'.join(child_strs_list))\n",
    "!\"{text_editor_path}\" \"{file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "79696e3b-0257-4794-bdb0-71b04481237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyperclip.copy(re.sub(\"((?:<li>([^><]+)</li>\\n)+)\", \"<ul>\\n\\\\1</ul>\\n\", '\\n'.join(child_strs_list), 0, re.MULTILINE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af64e55d-eb9b-413d-8b71-bef7188d48a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                MATCH\n",
      "                    (np:NavigableParents {navigable_parent: \"<div>Applicants selected may be subject to a government security investigation and must meet eligibility requirements for access to classified information. US citizenship may be required for some positions.</div>\"}),\n",
      "                    (ht:HeaderTags {header_tag: \"div\"})\n",
      "                MERGE (ht)-[r:SUMMARIZES]->(np);\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cu.rebuild_filename_node(file_name, navigable_parent=None, verbose=True)\n",
    "speech_str = f'{su.get_job_title_from_file_name(file_name)} node rebuild completed'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fae8b-14ec-4c20-96b0-70c622ac7c73",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d17dac-be9e-4bc3-aa01-58eed1baa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fe1d1a8b-85e6-4fb8-aba3-43874e6dabdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"Other requirements may apply.\" in basic_quals_dict: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove this particular qualification string from the quals dictionary\n",
    "qualification_str = quals_list[25]\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict.pop(qualification_str, None)\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{qualification_str}\" in basic_quals_dict: {qualification_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2e765305-d9a3-4955-a905-8389c35ad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular qualification string from the database\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=qualification_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005f4a8-f07c-4538-8d1b-210d32dd3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually set each feature\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = true,\n",
    "            np.is_task_scope = false,\n",
    "            np.is_minimum_qualification = false,\n",
    "            np.is_preferred_qualification = false,\n",
    "            np.is_educational_requirement = true,\n",
    "            np.is_legal_notification = false,\n",
    "            np.is_other = false,\n",
    "            np.is_corporate_scope = false,\n",
    "            np.is_job_title = false,\n",
    "            np.is_office_location = false,\n",
    "            np.is_job_duration = false,\n",
    "            np.is_supplemental_pay = false,\n",
    "            np.is_interview_procedure = false,\n",
    "            np.is_posting_date = false\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False); row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a9fa5-9f15-4bcc-a3df-b75dbb52ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "for file_name in ['']:\n",
    "    cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2828f-ab7b-4550-b5cc-92078c40f331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
