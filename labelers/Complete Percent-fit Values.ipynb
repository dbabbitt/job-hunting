{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb7318f-5285-4f7b-bc3e-2859fe05f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "======== Neo4j/4.4.7 ========\n",
      "Utility libraries created in 3 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%matplotlib inline\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')\n",
    "from jobpostlib import (crf, cu, datetime, duration, hau, hc, humanize, ihu, lru, nu, osp, scrfcu, slrcu, ssgdcu, su, t0, time, wsu, speech_engine)\n",
    "from pandas import DataFrame\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f331b-c66a-4c65-906b-22bc6fc034c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,102 labeled parts of speech in here\n",
      "predict_single is available\n",
      "Parts-of-speech logistic regression elements built in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression elements\n",
    "# Parts-of-speech logistic regression elements is normally built in 1 hour, 27 minutes and 21 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'): print('predict_single is available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech logistic regression elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe80356-c69a-4579-b298-31e40e871b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "Parts-of-speech conditional random field elements built in 1 second\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the scrfcu has built its parts-of-speech conditional random field elements\n",
    "# Parts-of-speech CRF elements normally built in 29 minutes and 57 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech conditional random field elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3453a69d-7080-4ebf-96a8-528e9541ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,102 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech stochastic gradient descent elements built in 10 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the ssgdcu has built its parts-of-speech stochastic gradient decent elements\n",
    "t1 = time.time()\n",
    "if not hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech stochastic gradient descent elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e7d031-531c-4024-b9f4-03485a91a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "POS classifier trained in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the crf has built its parts-of-speech classifier\n",
    "# POS classifier normally trained in 15 hours, 42 minutes and 41 seconds\n",
    "t1 = time.time()\n",
    "if not hasattr(crf, 'CRF'): crf.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(crf, 'CRF'): print('predict_single is now available')\n",
    "else: print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'POS classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d259dffb-c212-4493-a879-1ae5d503f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 424,879 is-qualified vocabulary tokens in here\n",
      "Is-qualified LR elements built in 5 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the lru has built its is-qualified classifier\n",
    "t1 = time.time()\n",
    "if not (hasattr(lru, 'ISQUALIFIED_LR') and hasattr(lru, 'ISQUALIFIED_CV')):\n",
    "    lru.build_isqualified_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified LR elements built in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d67a34-e133-45dc-9bf3-a830af359d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 50,451 hand-labeled header htmls prepared\n",
      "7 iterations seen during training fit for a total of 50,451 records trained\n",
      "Is-header classifier trained in 6 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the isheader classifier\n",
    "t1 = time.time()\n",
    "ihu.build_pos_stochastic_gradient_descent_elements(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-header classifier trained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcef1d94-4466-4100-86cd-0d66f23d0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2024-07-26 10:06:39.689953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "speech_str = f'Last run on {datetime.now()}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f438163-0f14-4a74-978c-769c9dba95c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f02bfeac-67b7-4df6-a4a0-32ec3dec0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 18,866 hand-labeled qualification strings in here\n",
      "I have 598,884 is-qualified vocabulary tokens in here\n",
      "Is-qualified classifer retrained in 26 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the\n",
    "# qualification dictionary below or in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Is-qualified classifer retrained in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad3579-ebc3-4d21-a7c3-f9bd168ac6ca",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d334d815-e43b-474e-9dbb-db509176f6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4283/4283 = 100.0% completed\n",
      "Inference completed in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "quals_list, file_name = lru.infer_from_hunting_dataframe(fitness_threshold=3/4, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Inference completed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264da9-f96a-491a-83d9-25d15fcdfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47bd03b8-c0a3-404c-a16d-eb4ce95c6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li>Ability/experience to research and develop algorithms to analyze structured cyber-security data, including supervised machine learning, entity resolution, classification, and the implementation of analytical algorithms on a distributed cloud-based infrastructure.</li>\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qualification string\n",
    "qualification_str = quals_list[20]\n",
    "print(qualification_str); basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[qualification_str]) + '\\n' if(qualification_str in basic_quals_dict) else '', end='')\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4212b-9280-46d1-8e46-104aada7c0df",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Fix Parts-of-Speech and Quals for this posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8ac6efb8-6b56-43dd-9079-d6a87491ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2555bd9ebea9e7bb_Sr_Machine_Learning_Engineer_WFHMD_1530_Reston_VA_20191_Indeed_com.html\n",
      "CRF and child strings list recreated in 1 minute and 24 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "file_path = osp.join(cu.SAVES_HTML_FOLDER, file_name)\n",
    "if osp.isfile(file_path):\n",
    "    child_strs_list = hau.get_child_strs_from_file(file_name=file_name)\n",
    "    cu.ensure_filename(file_name, verbose=False)\n",
    "    cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)\n",
    "    print(file_name)\n",
    "    child_tags_list = hau.get_child_tags_list(child_strs_list)\n",
    "    feature_dict_list = cu.get_feature_dict_list(child_tags_list, child_strs_list)\n",
    "    feature_tuple_list = []\n",
    "    for feature_dict in feature_dict_list:\n",
    "        feature_tuple_list.append(hc.get_feature_tuple(\n",
    "            feature_dict, pos_lr_predict_single=slrcu.predict_single, pos_crf_predict_single=scrfcu.predict_single,\n",
    "            pos_sgd_predict_single=ssgdcu.predict_single\n",
    "        ))\n",
    "    crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'CRF and child strings list recreated in {duration_str}'; print(speech_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "affcb06a-3165-4349-a936-037af549d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H-RQ', 'O-RQ', 'O-RQ', 'H-JD', 'O-JD', 'H-OL', 'O-OL', 'H-RQ', 'O-RQ', 'H-ER', 'O-ER', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'H-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'O-TS', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'H-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'O-RQ', 'H-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'O-PQ', 'H-LN', 'O-CS', 'O-SP', 'H-CS', 'O-CS', 'O-CS']\n",
      "[1, 2, 8, 10, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0 H-RQ) <span style=\"color:#bcbd22ff;\"><h3 class=\"jobSectionHeader\">Minimum Qualifications: (H-RQ Required Qualifications Header)</h3></span><br /><hr />1 O-RQ) <span style=\"color:#bcbd2280;\"><li>Clearance Level: Top Secret (TS/SCI Eligible) (O-RQ Required Qualifications Non-header)</li></span><br />2 O-RQ) <span style=\"color:#bcbd2280;\"><li>US Citizenship: Required (O-RQ Required Qualifications Non-header)</li></span><br />3 H-JD) <span style=\"color:#98df8aff;\"><h3 class=\"jobSectionHeader\">Job Duration: (H-JD Job Duration Header)</h3></span><br />4 O-JD) <span style=\"color:#98df8a80;\"><li>Job Classification: Full Time (O-JD Job Duration Non-header)</li></span><br />5 H-OL) <span style=\"color:#c49c94ff;\"><h3 class=\"jobSectionHeader\">Office Location: (H-OL Office Location Header)</h3></span><br />6 O-OL) <span style=\"color:#c49c9480;\"><li>Location: Remote (O-OL Office Location Non-header)</li></span><br />7 H-RQ) <span style=\"color:#bcbd22ff;\"><h3 class=\"jobSectionHeader\">Minimum Qualifications: (H-RQ Required Qualifications Header)</h3></span><br />8 O-RQ) <span style=\"color:#bcbd2280;\"><li>Years of Machine Learning Engineer Experience: 7-10 years (O-RQ Required Qualifications Non-header)</li></span><br />9 H-ER) <span style=\"color:#aec7e8ff;\"><h3 class=\"jobSectionHeader\">Educational Requirements: (H-ER Education Requirements Header)</h3></span><br />10 O-ER) <span style=\"color:#aec7e880;\"><li>Education Level: Bachelor's Degree or equivalent Machine Learning Engineer experience (O-ER Education Requirements Non-header)</li></span><br />11 H-TS) <span style=\"color:#9edae5ff;\"><h3 class=\"jobSectionHeader\">Task Scope: (H-TS Task Scope Header)</h3></span><br />12 O-TS) <span style=\"color:#9edae580;\"><li>What Makes this a Great Opportunity: An exciting remote telework opportunity, to work as a Senior Machine Learning (ML) Engineer who will be responsible for research, development, implementing, and deploying machine learning models and algorithms to solve a wide range of cyber analytical challenges. (O-TS Task Scope Non-header)</li></span><br />13 O-TS) <span style=\"color:#9edae580;\"><li>You will collaborate with cross-functional teams to identify opportunities for applying machine learning techniques, collect and preprocess data, design, and train models, and deploy solutions into production environments. (O-TS Task Scope Non-header)</li></span><br />14 O-TS) <span style=\"color:#9edae580;\"><li>What Makes this a Great Opportunity: This role offers an exciting opportunity to work with state-of-the-art technologies and make a significant impact in the field of machine learning. (O-TS Task Scope Non-header)</li></span><br />15 O-TS) <span style=\"color:#9edae580;\"><li>What Makes this a Great Opportunity: The selected candidate will join a small, talented, highly effective performing team providing and enhancing crucial cyber capabilities. (O-TS Task Scope Non-header)</li></span><br />16 O-TS) <span style=\"color:#9edae580;\"><li>Position Description: GITI is looking for a Machine Learning (ML) Engineer with documented expertise to be responsible for researching, developing, architecting, and integrating ML models, algorithms, tools, and techniques into existing or new environments. (O-TS Task Scope Non-header)</li></span><br />17 H-TS) <span style=\"color:#9edae5ff;\"><li>Position Description: A candidate who will architect and implement machine learning and extract-transform-load (ETL) algorithms and conduct data integrity and validation actions. (H-TS Task Scope Header)</li></span><br />18 O-TS) <span style=\"color:#9edae580;\"><li>Position Description: A candidate who will work with our data scientists to design, develop, and integrate ML models and algorithms to address specific problems, (eg, classification, regression, clustering, recommendation systems, etc), and introduce ML and pattern recognition to discover hidden insights. (O-TS Task Scope Non-header)</li></span><br />19 O-TS) <span style=\"color:#9edae580;\"><li>Position Description: The candidate may work independently but participate in project-wide reviews of requirements, system architecture, and detailed design documents. (O-TS Task Scope Non-header)</li></span><br />20 O-TS) <span style=\"color:#9edae580;\"><li>Assist and introduce ML and pattern recognition to discover hidden insights; architect and implement data processing, cleansing, and conducting data integrity and validation actions. (O-TS Task Scope Non-header)</li></span><br />21 O-TS) <span style=\"color:#9edae580;\"><li>Exercise creativity in applying non-traditional approaches to the analysis of unstructured data in support of high-value use cases using multi-dimensional visualization. (O-TS Task Scope Non-header)</li></span><br />22 O-TS) <span style=\"color:#9edae580;\"><li>Implement processing on high-volume, high-velocity data streams. (O-TS Task Scope Non-header)</li></span><br />23 O-TS) <span style=\"color:#9edae580;\"><li>Recommend and implement interactive reports, visual analytics, and dashboards focused primarily on understanding and using deep packet inspection of structured and unstructured collected digital data. (O-TS Task Scope Non-header)</li></span><br />24 O-TS) <span style=\"color:#9edae580;\"><li>Work closely with data scientists, software developers, and project managers to understand requirements and identify opportunities for applying data analysis techniques. (O-TS Task Scope Non-header)</li></span><br />25 O-TS) <span style=\"color:#9edae580;\"><li>Collect, preprocess, and analyze large datasets to extract meaningful insights and features for model training. (O-TS Task Scope Non-header)</li></span><br />26 O-TS) <span style=\"color:#9edae580;\"><li>Collaborate with software developers to integrate data analytical solutions into production systems and applications. (O-TS Task Scope Non-header)</li></span><br />27 O-TS) <span style=\"color:#9edae580;\"><li>Stay updated on the latest advancements in large data analytics and machine learning research and technologies and identify opportunities for innovation and improvement. (O-TS Task Scope Non-header)</li></span><br />28 O-TS) <span style=\"color:#9edae580;\"><li>Continually learn and improve your skills through sharing with others and taking advantage of available training sources. (O-TS Task Scope Non-header)</li></span><br />29 H-RQ) <span style=\"color:#bcbd22ff;\"><h3 class=\"jobSectionHeader\">Minimum Qualifications: (H-RQ Required Qualifications Header)</h3></span><br />30 O-RQ) <span style=\"color:#bcbd2280;\"><li>What Makes this a Great Opportunity: Global InfoTek Inc., (GITI) is looking for a motivated, talented, and creative ML Engineer to join our team! (O-RQ Required Qualifications Non-header)</li></span><br />31 O-RQ) <span style=\"color:#bcbd2280;\"><li>Position Description: Successful candidates for this role must have critical thinking skills, be creative, curious, resourceful, and have a passion for conveying a wide range of information through research leading to deeper insights. (O-RQ Required Qualifications Non-header)</li></span><br />32 O-RQ) <span style=\"color:#bcbd2280;\"><li>Position Description: Our ML Engineer must collaborate well with a strong lean-forward attitude to shift knowledge left, deliver well, and produce quality results. (O-RQ Required Qualifications Non-header)</li></span><br />33 O-RQ) <span style=\"color:#bcbd2280;\"><li>Ability/experience to research and develop algorithms to analyze structured cyber-security data, including supervised machine learning, entity resolution, classification, and the implementation of analytical algorithms on a distributed cloud-based infrastructure. (O-RQ Required Qualifications Non-header)</li></span><br />34 O-RQ) <span style=\"color:#bcbd2280;\"><li>Requires strong technical and computational skills â€“ engineering, physics, and mathematics, coupled with the ability to code design, develop, and deploy sophisticated applications using advanced structured data analysis techniques and utilizing high-performance computing environments. (O-RQ Required Qualifications Non-header)</li></span><br />35 O-RQ) <span style=\"color:#bcbd2280;\"><li>Can utilize advanced tools and computational skills to interpret, connect, predict, and make discoveries in complex cyber-security data and deliver recommendations for business and analytic decisions. (O-RQ Required Qualifications Non-header)</li></span><br />36 O-RQ) <span style=\"color:#bcbd2280;\"><li>Demonstrate ability to research and apply new tools, techniques, and solution approaches. (O-RQ Required Qualifications Non-header)</li></span><br />37 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Experience working with machine learning, data science, or related fields. (O-RQ Required Qualifications Non-header)</li></span><br />38 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Experience working with cyber-security data. (O-RQ Required Qualifications Non-header)</li></span><br />39 H-RQ) <span style=\"color:#bcbd22ff;\"><li>Required Skills: Experience in statistical analysis and visualization of complex data. (H-RQ Required Qualifications Header)</li></span><br />40 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: An understanding and ability to implement data hygiene methods via ETL. (O-RQ Required Qualifications Non-header)</li></span><br />41 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Ability to build upon previous analytics capabilities to enable more complex analysis of large datasets, including graphs to generate actionable intelligence. (O-RQ Required Qualifications Non-header)</li></span><br />42 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Solid understanding of machine learning algorithms and techniques, including supervised and unsupervised learning, deep learning, reinforcement learning, etc. (O-RQ Required Qualifications Non-header)</li></span><br />43 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Hands-on experience with popular machine learning libraries and frameworks, (eg, TensorFlow, PyTorch, Scikit-learn, Keras, SciPy, etc). (O-RQ Required Qualifications Non-header)</li></span><br />44 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Experience with data processing and analysis tools, (eg, Python, Sci-Kit, NumPy, SQL, Spark, etc). (O-RQ Required Qualifications Non-header)</li></span><br />45 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Excellent problem-solving and analytical skills, with a keen attention to detail. (O-RQ Required Qualifications Non-header)</li></span><br />46 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Strong communication and collaboration skills, with the ability to independently or to work effectively in a team environment; the ability to quickly adapt to changing priorities/requirements. (O-RQ Required Qualifications Non-header)</li></span><br />47 O-RQ) <span style=\"color:#bcbd2280;\"><li>Required Skills: Experience with network traffic inspection tools (eg, Suricata, Arkime, Zeek, etc). (O-RQ Required Qualifications Non-header)</li></span><br /><hr />48 H-PQ) <span style=\"color:#c7c7c7ff;\"><h3 class=\"jobSectionHeader\">Preferred Qualifications: (H-PQ Preferred Qualifications Header)</h3></span><br />49 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Experience with Apache Spark, Apache Streaming, and Jupyter Hub+ Event Reporter to introduce ML and pattern recognition to discover hidden insights. (O-PQ Preferred Qualifications Non-header)</li></span><br />50 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Working knowledge of networks, network traffic data, and virtual environments. (O-PQ Preferred Qualifications Non-header)</li></span><br />51 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Experience with containerization (eg, Docker, Kubernetes, Rancher, etc). (O-PQ Preferred Qualifications Non-header)</li></span><br />52 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Experience with ML methods (eg, decision trees, neural networks, reinforcement learning, etc). (O-PQ Preferred Qualifications Non-header)</li></span><br />53 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: An understanding and working knowledge to analyze and gain visibility to network metadata, and content, identify malicious code, anomaly detection, and potentially predictive analysis. (O-PQ Preferred Qualifications Non-header)</li></span><br />54 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Working knowledge in programming languages, (eg, Python, Rust, Go, Java, etc). (O-PQ Preferred Qualifications Non-header)</li></span><br />55 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Working knowledge with cloud computing platforms, (eg, AWS, Azure, or Google Cloud, etc). (O-PQ Preferred Qualifications Non-header)</li></span><br />56 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Familiarity with big data technologies, (eg, Elastic Search, Apache Hadoop, Spark, Kafka, etc). (O-PQ Preferred Qualifications Non-header)</li></span><br />57 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Experience deploying ML models in production environments using containerization technologies, (eg, Docker, Kubernetes). (O-PQ Preferred Qualifications Non-header)</li></span><br />58 O-PQ) <span style=\"color:#c7c7c780;\"><li>Desired Skills: Publications or contributions to ML-related research projects or open-source initiatives. (O-PQ Preferred Qualifications Non-header)</li></span><br />59 H-LN) <span style=\"color:#9467bdff;\"><h3 class=\"jobSectionHeader\">Legal Notifications: (H-LN Legal Notifications Header)</h3></span><br />60 O-CS) <span style=\"color:#1f77b480;\"><li>Global InfoTek, Inc is an equal opportunity employer. (O-CS Corporate Scope Non-header)</li></span><br />61 O-SP) <span style=\"color:#17becf80;\"><li>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or based on disability. (O-SP Supplemental Pay Non-header)</li></span><br />62 H-CS) <span style=\"color:#1f77b4ff;\"><h3 class=\"jobSectionHeader\">Corporate Scope: (H-CS Corporate Scope Header)</h3></span><br />63 O-CS) <span style=\"color:#1f77b480;\"><li>About Global InfoTek, Inc: Global InfoTek Inc has an award-winning track record of designing, developing, and deploying best-of-breed technologies that address the nation's pressing cyber and advanced technology needs. (O-CS Corporate Scope Non-header)</li></span><br />64 O-CS) <span style=\"color:#1f77b480;\"><li>About Global InfoTek, Inc: GITI has rapidly merged pioneering technologies, operational effectiveness, and best business practices for over two decades. (O-CS Corporate Scope Non-header)</li></span><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 8, 10, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "Parts-of-speech displayed in 1 minute and 30 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "pos_list, indices_list = su.visualize_basic_quals_section(crf_list, child_strs_list, db_pos_list=db_pos_list, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "speech_str = f'Parts-of-speech displayed in {duration_str}'; print(speech_str); speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91379a3d-1a77-4d8b-9ef6-a76f12204ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "26c4dd4e-1418-4420-aff5-ea7b65273194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 H-TS) <h3 class=\"jobSectionHeader\">Task Scope:</h3>\n",
      "12 O-TS) <li>What Makes this a Great Opportunity: An exciting remote telework opportunity, to work as a Senior Machine Learning (ML) Engineer who will be responsible for research, development, implementing, and deploying machine learning models and algorithms to solve a wide range of cyber analytical challenges.</li>\n",
      "13 O-TS) <li>You will collaborate with cross-functional teams to identify opportunities for applying machine learning techniques, collect and preprocess data, design, and train models, and deploy solutions into production environments.</li>\n",
      "14 O-TS) <li>What Makes this a Great Opportunity: This role offers an exciting opportunity to work with state-of-the-art technologies and make a significant impact in the field of machine learning.</li>\n",
      "15 O-TS) <li>What Makes this a Great Opportunity: The selected candidate will join a small, talented, highly effective performing team providing and enhancing crucial cyber capabilities.</li>\n",
      "16 O-TS) <li>Position Description: GITI is looking for a Machine Learning (ML) Engineer with documented expertise to be responsible for researching, developing, architecting, and integrating ML models, algorithms, tools, and techniques into existing or new environments.</li>\n",
      "17 H-TS) <li>Position Description: A candidate who will architect and implement machine learning and extract-transform-load (ETL) algorithms and conduct data integrity and validation actions.</li>\n",
      "18 O-TS) <li>Position Description: A candidate who will work with our data scientists to design, develop, and integrate ML models and algorithms to address specific problems, (eg, classification, regression, clustering, recommendation systems, etc), and introduce ML and pattern recognition to discover hidden insights.</li>\n",
      "19 O-TS) <li>Position Description: The candidate may work independently but participate in project-wide reviews of requirements, system architecture, and detailed design documents.</li>\n",
      "20 O-TS) <li>Assist and introduce ML and pattern recognition to discover hidden insights; architect and implement data processing, cleansing, and conducting data integrity and validation actions.</li>\n",
      "21 O-TS) <li>Exercise creativity in applying non-traditional approaches to the analysis of unstructured data in support of high-value use cases using multi-dimensional visualization.</li>\n",
      "22 O-TS) <li>Implement processing on high-volume, high-velocity data streams.</li>\n",
      "23 O-TS) <li>Recommend and implement interactive reports, visual analytics, and dashboards focused primarily on understanding and using deep packet inspection of structured and unstructured collected digital data.</li>\n",
      "24 O-TS) <li>Work closely with data scientists, software developers, and project managers to understand requirements and identify opportunities for applying data analysis techniques.</li>\n",
      "25 O-TS) <li>Collect, preprocess, and analyze large datasets to extract meaningful insights and features for model training.</li>\n",
      "26 O-TS) <li>Collaborate with software developers to integrate data analytical solutions into production systems and applications.</li>\n",
      "27 O-TS) <li>Stay updated on the latest advancements in large data analytics and machine learning research and technologies and identify opportunities for innovation and improvement.</li>\n",
      "28 O-TS) <li>Continually learn and improve your skills through sharing with others and taking advantage of available training sources.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict'); column_name = 'is_task_scope'\n",
    "for idx in list(range(11, 29)):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = '''\\n            MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\\n            ''' + cu.return_everything_str + ';'\n",
    "        results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "        return [dict(record.items()) for record in results_list]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_job_title = {str(column_name == 'is_job_title').lower()},\n",
    "                np.is_corporate_scope = {str(column_name == 'is_corporate_scope').lower()},\n",
    "                np.is_task_scope = {str(column_name == 'is_task_scope').lower()},\n",
    "                np.is_educational_requirement = {str(column_name == 'is_educational_requirement').lower()},\n",
    "                np.is_minimum_qualification = {str(column_name == 'is_minimum_qualification').lower()},\n",
    "                np.is_preferred_qualification = {str(column_name == 'is_preferred_qualification').lower()},\n",
    "                np.is_supplemental_pay = {str(column_name == 'is_supplemental_pay').lower()},\n",
    "                np.is_office_location = {str(column_name == 'is_office_location').lower()},\n",
    "                np.is_job_duration = {str(column_name == 'is_job_duration').lower()},\n",
    "                np.is_interview_procedure = {str(column_name == 'is_interview_procedure').lower()},\n",
    "                np.is_legal_notification = {str(column_name == 'is_legal_notification').lower()},\n",
    "                np.is_other = {str(column_name == 'is_other').lower()},\n",
    "                np.is_posting_date = {str(column_name == 'is_posting_date').lower()}\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1d97acb2-2b60-4a56-9b3b-ecfc2b6582e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 8, 10, 16, 20, 22, 23, 27, 28, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 63]\n",
      "58 O-PQ) <li>Desired Skills: Publications or contributions to ML-related research projects or open-source initiatives.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the context of an individual child string\n",
    "idx = 58\n",
    "print(indices_list); child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]; basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "print(f'{idx} {pos_symbol}) {child_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b2f46926-880b-4aed-bc99-4a6bd9ed7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "\"<li>Desired Skills: Publications or contributions to ML-related research projects or open-source initiatives.</li>\" in basic_quals_dict: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict); print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "24e7695d-caf6-416f-a761-ec17b839ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 O-TS) <li>What Makes this a Great Opportunity: An exciting remote telework opportunity, to work as a Senior Machine Learning (ML) Engineer who will be responsible for research, development, implementing, and deploying machine learning models and algorithms to solve a wide range of cyber analytical challenges.</li>\n",
      "13 O-TS) <li>You will collaborate with cross-functional teams to identify opportunities for applying machine learning techniques, collect and preprocess data, design, and train models, and deploy solutions into production environments.</li>\n",
      "14 O-TS) <li>What Makes this a Great Opportunity: This role offers an exciting opportunity to work with state-of-the-art technologies and make a significant impact in the field of machine learning.</li>\n",
      "15 O-TS) <li>What Makes this a Great Opportunity: The selected candidate will join a small, talented, highly effective performing team providing and enhancing crucial cyber capabilities.</li>\n",
      "16 O-TS) <li>Position Description: GITI is looking for a Machine Learning (ML) Engineer with documented expertise to be responsible for researching, developing, architecting, and integrating ML models, algorithms, tools, and techniques into existing or new environments.</li>\n",
      "17 H-TS) <li>Position Description: A candidate who will architect and implement machine learning and extract-transform-load (ETL) algorithms and conduct data integrity and validation actions.</li>\n",
      "18 O-TS) <li>Position Description: A candidate who will work with our data scientists to design, develop, and integrate ML models and algorithms to address specific problems, (eg, classification, regression, clustering, recommendation systems, etc), and introduce ML and pattern recognition to discover hidden insights.</li>\n",
      "19 O-TS) <li>Position Description: The candidate may work independently but participate in project-wide reviews of requirements, system architecture, and detailed design documents.</li>\n",
      "20 O-TS) <li>Assist and introduce ML and pattern recognition to discover hidden insights; architect and implement data processing, cleansing, and conducting data integrity and validation actions.</li>\n",
      "21 O-TS) <li>Exercise creativity in applying non-traditional approaches to the analysis of unstructured data in support of high-value use cases using multi-dimensional visualization.</li>\n",
      "22 O-TS) <li>Implement processing on high-volume, high-velocity data streams.</li>\n",
      "23 O-TS) <li>Recommend and implement interactive reports, visual analytics, and dashboards focused primarily on understanding and using deep packet inspection of structured and unstructured collected digital data.</li>\n",
      "24 O-TS) <li>Work closely with data scientists, software developers, and project managers to understand requirements and identify opportunities for applying data analysis techniques.</li>\n",
      "25 O-TS) <li>Collect, preprocess, and analyze large datasets to extract meaningful insights and features for model training.</li>\n",
      "26 O-TS) <li>Collaborate with software developers to integrate data analytical solutions into production systems and applications.</li>\n",
      "27 O-TS) <li>Stay updated on the latest advancements in large data analytics and machine learning research and technologies and identify opportunities for innovation and improvement.</li>\n",
      "28 O-TS) <li>Continually learn and improve your skills through sharing with others and taking advantage of available training sources.</li>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Non-headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in range(12, 29):\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = false\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "326ab607-cc5c-4476-b692-395b96d293ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 O-ER) <b>Education and Requirements:</b>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix Headers\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "for idx in [27]:\n",
    "    child_str = child_strs_list[idx]; pos_symbol = pos_list[idx]\n",
    "    print(str(basic_quals_dict[child_str]) + '\\n' if(child_str in basic_quals_dict) else '', end='')\n",
    "    print(f'{idx} {pos_symbol}) {child_str}')\n",
    "    def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "        cypher_str = f'''\n",
    "            MATCH (np:NavigableParents {{navigable_parent: $navigable_parent}})\n",
    "            SET\n",
    "                np.is_header = true\n",
    "            ''' + cu.return_everything_str + ';'\n",
    "        return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "    with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfa2e-4e09-4da7-b046-98f5c170ec67",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07255146-70be-4d52-942c-1505d6e02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display cypher necessary to apply for all the jobs you qualify for that you haven't yet\n",
    "import pyperclip\n",
    "\n",
    "cypher_str = f'''\n",
    "    // Get job application links\n",
    "    MATCH (fn:FileNames)\n",
    "    WHERE\n",
    "        fn.percent_fit >= 0.8 AND\n",
    "        ((fn.is_closed IS NULL) OR (fn.is_closed = false)) AND\n",
    "        ((fn.is_opportunity_application_emailed IS NULL) OR (fn.is_opportunity_application_emailed = false))\n",
    "    RETURN\n",
    "        fn.percent_fit AS percent_fit,\n",
    "        fn.file_name AS filename,\n",
    "        fn.posting_url AS posting_url\n",
    "    ORDER BY fn.percent_fit DESC;'''\n",
    "pyperclip.copy(cypher_str)\n",
    "row_objs_list = []\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "if row_objs_list:\n",
    "    df = DataFrame(row_objs_list)\n",
    "    display(df)\n",
    "    \n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_closed = true\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "    \n",
    "    for filename in df.filename:\n",
    "        print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_opportunity_application_emailed = true, fn.opportunity_application_email_date = date()\n",
    "RETURN fn;\"\"\")\n",
    "        break\n",
    "speech_str = 'Job application cypher code copied to clipboard'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03210789-6fa6-4238-a4fc-1866fde581fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MATCH (fn:FileNames)\n",
      "WHERE fn.file_name IN [\"hMAt6M1ae9pW73omZm4dhw_Senior_Machine_Learning_Engineer_Bedford_MA.html\"]\n",
      "SET fn.is_phone_screen_completed = true, fn.phone_screen_completion_date = date()\n",
      "RETURN fn;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'hMAt6M1ae9pW73omZm4dhw_Senior_Machine_Learning_Engineer_Bedford_MA.html'\n",
    "print(f\"\"\"\n",
    "MATCH (fn:FileNames)\n",
    "WHERE fn.file_name IN [\"{filename}\"]\n",
    "SET fn.is_phone_screen_completed = true, fn.phone_screen_completion_date = date()\n",
    "RETURN fn;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626518c-6d69-45b9-9f9a-ebe909644d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Ensure you have already run the \"Fix Parts-of-Speech and Quals for \n",
    "# this posting\" cells above or displayed the context of an \n",
    "# individual child string above. Don't close the Notepad++ window \n",
    "# until you have replaced the child string\n",
    "def display_file_in_text_editor(file_name):\n",
    "    text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "    file_path = osp.abspath(osp.join(hau.SAVES_HTML_FOLDER, file_name))\n",
    "    !\"{text_editor_path}\" \"{file_path}\"\n",
    "display_file_in_text_editor(file_name)\n",
    "cu.rebuild_filename_node(file_name, navigable_parent=None, verbose=True)\n",
    "speech_str = 'File name node rebuild completed'; speech_engine.say(speech_str); speech_engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fae8b-14ec-4c20-96b0-70c622ac7c73",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d17dac-be9e-4bc3-aa01-58eed1baa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    results_list = tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d1a8b-85e6-4fb8-aba3-43874e6dabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = nu.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str, None)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "nu.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e765305-d9a3-4955-a905-8389c35ad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the database\n",
    "def do_cypher_tx(tx, qualification_str, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (qs:QualificationStrings {qualification_str: $qualification_str})\n",
    "        DETACH DELETE qs;\n",
    "        '''\n",
    "    results_list = tx.run(query=cypher_str, parameters={'qualification_str': qualification_str})\n",
    "\n",
    "    return [dict(record.items()) for record in results_list]\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(do_cypher_tx, qualification_str=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005f4a8-f07c-4538-8d1b-210d32dd3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually set each feature\n",
    "def do_cypher_tx(tx, navigable_parent, verbose=False):\n",
    "    cypher_str = '''\n",
    "        MATCH (np:NavigableParents {navigable_parent: $navigable_parent})\n",
    "        SET\n",
    "            np.is_header = true,\n",
    "            np.is_task_scope = false,\n",
    "            np.is_minimum_qualification = false,\n",
    "            np.is_preferred_qualification = false,\n",
    "            np.is_educational_requirement = true,\n",
    "            np.is_legal_notification = false,\n",
    "            np.is_other = false,\n",
    "            np.is_corporate_scope = false,\n",
    "            np.is_job_title = false,\n",
    "            np.is_office_location = false,\n",
    "            np.is_job_duration = false,\n",
    "            np.is_supplemental_pay = false,\n",
    "            np.is_interview_procedure = false,\n",
    "            np.is_posting_date = false\n",
    "        ''' + cu.return_everything_str + ';'\n",
    "    return [dict(record.items()) for record in tx.run(query=cypher_str, parameters={'navigable_parent': navigable_parent})]\n",
    "with cu.driver.session() as session: row_objs_list = session.write_transaction(do_cypher_tx, navigable_parent=child_str, verbose=False)\n",
    "ihu.retrain_classifier(row_objs_list[0]['navigable_parent'], row_objs_list[0]['is_header'], verbose=False); row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a9fa5-9f15-4bcc-a3df-b75dbb52ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove file name from database\n",
    "for file_name in ['']:\n",
    "    cu.delete_filename_node(file_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3aad62-d78e-4243-b46f-dec293d4552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def separate_qualifications(quals_list):\n",
    "  \"\"\"\n",
    "  This function takes a list of qualifications and separates them into individual sentences.\n",
    "\n",
    "  Args:\n",
    "      quals_list: A list of strings, where each string represents a qualification.\n",
    "\n",
    "  Returns:\n",
    "      A list of lists, where each inner list contains the individual qualifications extracted from the corresponding element in the original quals_list.\n",
    "  \"\"\"\n",
    "  separated_quals = []\n",
    "  for qual in quals_list:\n",
    "    # Split qualifications based on commas, semicolons, and colons followed by whitespace\n",
    "    split_quals = re.split(r\", |; |:\", qual)\n",
    "    # Further split based on \"and\" if it's not the first word and there's punctuation before it\n",
    "    for i, sentence in enumerate(split_quals):\n",
    "      if i > 0 and re.search(r\"\\b(and)\\b\", sentence, flags=re.IGNORECASE) and re.search(r\"[,\\.;]\", split_quals[i-1]):\n",
    "        split_quals[i-1] += f\" {sentence.strip()}\"\n",
    "        split_quals.pop(i)\n",
    "    # Remove empty strings and leading/trailing whitespace\n",
    "    separated_quals.append([q.strip() for q in split_quals if q.strip()])\n",
    "  return separated_quals\n",
    "\n",
    "separated_qualifications = separate_qualifications(quals_list)\n",
    "\n",
    "# Print the separated qualifications\n",
    "for qual_set in separated_qualifications:\n",
    "  for qual in qual_set:\n",
    "    print(qual)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2828f-ab7b-4550-b5cc-92078c40f331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
