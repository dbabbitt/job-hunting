{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e9fbf-e1ac-4809-a823-d279cb6b1c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174c9bb2-7d08-4fa2-aa2b-e3be342e52ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11703807-055d-4ab2-8cf3-854e9e355651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec298430-518c-4177-9206-abf9417c24c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 15s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities()\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from section_utils import SectionUtilities\n",
    "su = SectionUtilities(s=s, ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "from lr_utils import LrUtilities\n",
    "from hc_utils import HeaderCategories\n",
    "\n",
    "hc = HeaderCategories(cu=cu, verbose=False)\n",
    "lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "lru.build_isheader_logistic_regression_elements()\n",
    "lru.build_pos_logistic_regression_elements()\n",
    "\n",
    "from crf_utils import CrfUtilities\n",
    "crf = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead9dbe6-e7f6-4c75-86bd-62f6ca1b9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "navigable_parent_cypher_str = '''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{}'}})\n",
    "    RETURN\n",
    "        np.navigable_parent AS navigable_parent,\n",
    "        np.is_header AS is_header,\n",
    "        np.is_task_scope AS is_task_scope,\n",
    "        np.is_minimum_qualification AS is_minimum_qualification,\n",
    "        np.is_preferred_qualification AS is_preferred_qualification,\n",
    "        np.is_legal_notification AS is_legal_notification,\n",
    "        np.is_job_title AS is_job_title,\n",
    "        np.is_office_location AS is_office_location,\n",
    "        np.is_job_duration AS is_job_duration,\n",
    "        np.is_supplemental_pay AS is_supplemental_pay,\n",
    "        np.is_educational_requirement AS is_educational_requirement,\n",
    "        np.is_interview_procedure AS is_interview_procedure,\n",
    "        np.is_corporate_scope AS is_corporate_scope,\n",
    "        np.is_posting_date AS is_posting_date,\n",
    "        np.is_other AS is_other;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6a5d6c-eed6-4682-a67b-7c351207d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quals_str(prediction_list, quals_list, basic_quals_dict):\n",
    "    qual_count = 0\n",
    "    quals_str = ''\n",
    "    for pred_array, (i, qual_str) in zip(prediction_list, enumerate(quals_list)):\n",
    "        if qual_str in basic_quals_dict:\n",
    "            formatted_str = '\\nquals_list[{}] = \"{}\" ({})'\n",
    "        else:\n",
    "            formatted_str = '\\n*quals_list[{}] = \"{}\" ({})'\n",
    "        prediction = pred_array[1]\n",
    "        quals_str += formatted_str.format(i, qual_str, prediction)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return quals_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e6db89-4dd2-4ecb-b5ad-9536705a766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qual_sum(qual_str):\n",
    "    results = '\"{}\"'.format(qual_str)\n",
    "    if qual_str in basic_quals_dict:\n",
    "        results = basic_quals_dict[qual_str]\n",
    "    else:\n",
    "        results = predict_job_hunt_percent_fit([qual_str])[0][1]\n",
    "        if results > 0.5:\n",
    "            results = 1.0\n",
    "        else:\n",
    "            results = 0.0\n",
    "    \n",
    "    return str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e62eab-b035-46b1-937e-bf467682f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_loc_computation(row_index, quals_list, basic_quals_dict):\n",
    "    print()\n",
    "    numerator_str_list = []\n",
    "    for qual_str in quals_list:\n",
    "        if qual_str in basic_quals_dict:\n",
    "            numerator_str_list.append(str(basic_quals_dict[qual_str]))\n",
    "        else:\n",
    "            numerator_str_list.append('000')\n",
    "    numerator_str = '+'.join(numerator_str_list)\n",
    "    print(\"hunting_df.loc[{}, 'percent_fit'] = ({})/{}\".format(row_index, numerator_str, len(quals_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a3c553-9d8c-4937-8a35-e49bfc312912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def print_fit_job(row_index, row_series, basic_quals_dict):\n",
    "    job_fitness = 0.0\n",
    "    file_name = row_series.file_name\n",
    "    child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "    indices_list = su.find_basic_quals_section_indexes(child_strs_list=child_strs_list, file_name=file_name)\n",
    "    assert indices_list, f'Something is wrong with {file_name}'\n",
    "    prequals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "    sentence_regex = re.compile(r'[\\.;]')\n",
    "    quals_set = set()\n",
    "    for qual in prequals_list:\n",
    "        concatonated_quals_list = sentence_regex.split(qual)\n",
    "        if len(concatonated_quals_list) > 2:\n",
    "            for q in concatonated_quals_list:\n",
    "                quals_set.add(q)\n",
    "        else:\n",
    "            quals_set.add(qual)\n",
    "    quals_list = list(quals_set)\n",
    "    prediction_list = list(predict_job_hunt_percent_fit(quals_list))\n",
    "    quals_str, qual_count = get_quals_str(prediction_list, quals_list, basic_quals_dict)\n",
    "    if len(prediction_list):\n",
    "        job_fitness = qual_count/len(prediction_list)\n",
    "        if job_fitness > 0.8:\n",
    "            job_title = re.sub(r'(_-_Indeed.com)?(_[a-z0-9]{16})?\\.html$', '', file_name).replace('_', ' ')\n",
    "            print(f'Basic Qualifications for {job_title}:{quals_str}')\n",
    "            print(job_fitness)\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list, job_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c84d7ead-87f7-4cfc-bd25-efd1307d70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_hunting(hunting_df, row_index, row_series, qual_sum, quals_list):\n",
    "    percent_fit = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "    hunting_df.loc[row_index, 'percent_fit'] = percent_fit\n",
    "    s.store_objects(hunting_df=hunting_df, verbose=False)\n",
    "    file_name = cu.clean_text(row_series.file_name)\n",
    "    cypher_str = f'''\n",
    "        MATCH (fn:FileNames {{file_name: \"{file_name}\"}})\n",
    "        SET fn.percent_fit = {percent_fit};'''\n",
    "    print(cypher_str.strip())\n",
    "    with cu.driver.session() as session:\n",
    "        session.write_transaction(cu.do_cypher_tx, cypher_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad3579-ebc3-4d21-a7c3-f9bd168ac6ca",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "408e8c61-7925-44ab-bcd3-e5544c5d0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cypher_str = '''\n",
    "    MATCH (fn:FileNames)\n",
    "    RETURN fn;'''\n",
    "row_objs_list = cu.get_execution_results(cypher_str, verbose=False)\n",
    "hunting_df = pd.DataFrame([{k: v for k, v in row_obj['fn'].items()} for row_obj in row_objs_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "862258eb-509a-4ee6-85d7-486f0d6754e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2195, 2)\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\bq_cv_vocab.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\bq_tt.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_clf.pkl\n",
      "Retraining complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Rebuild the dataframe from the dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "rows_list = [{'qualification_str': qualification_str, 'is_fit': is_fit} for qualification_str, is_fit in basic_quals_dict.items()]\n",
    "basic_quals_df = pd.DataFrame(rows_list)\n",
    "print(basic_quals_df.shape)\n",
    "mask_series = (basic_quals_df.is_fit == True)\n",
    "basic_quals_df.loc[mask_series, 'is_fit'] = 1\n",
    "mask_series = (basic_quals_df.is_fit == False)\n",
    "basic_quals_df.loc[mask_series, 'is_fit'] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_df.set_index('qualification_str').is_fit.to_dict())\n",
    "s.store_objects(basic_quals_df=basic_quals_df)\n",
    "\n",
    "# Re-transform the bag-of-words and tf-idf from the new manual scores\n",
    "sents_list = basic_quals_df.qualification_str.tolist()\n",
    "\n",
    "# Bag-of-words\n",
    "cv = CountVectorizer(lowercase=True, tokenizer=ha.html_regex_tokenizer, ngram_range=(1, 3))\n",
    "\n",
    "# Learn the vocabulary dictionary and return the document-term matrix\n",
    "bow_matrix = cv.fit_transform(sents_list)\n",
    "\n",
    "s.store_objects(bq_cv_vocab=cv.vocabulary_)\n",
    "\n",
    "# Tf-idf, must get from BOW first\n",
    "tt = TfidfTransformer()\n",
    "tfidf_matrix = tt.fit_transform(bow_matrix)\n",
    "s.store_objects(bq_tt=tt)\n",
    "\n",
    "# Re-train the classifier\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy().astype(int)\n",
    "fit_estimators_dict = s.load_object('fit_estimators_dict')\n",
    "basic_quals_clf = fit_estimators_dict['LogisticRegression']\n",
    "basic_quals_clf.fit(X, y)\n",
    "s.store_objects(basic_quals_clf=basic_quals_clf)\n",
    "\n",
    "# Re-calibrate the inference engine\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "def predict_job_hunt_percent_fit(quals_list):\n",
    "    y_predict_proba = np.array([])\n",
    "    if len(quals_list):\n",
    "        X_test = bq_tt.transform(bq_cv.transform(quals_list)).toarray()\n",
    "        y_predict_proba = basic_quals_clf.predict_proba(X_test)\n",
    "    \n",
    "    return y_predict_proba\n",
    "print('Retraining complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97158119-ced4-4cde-9ead-9e7babe6631a",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9f988dab-4677-4227-a8ed-6ab72335f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (fn:FileNames {file_name: \"Senior_Data_Scientist_-_Santa_Clara,_CA_-_Indeed.com_c267f29f0f85e8b8.html\"})\n",
      "        SET fn.percent_fit = 0.4;\n",
      "755/756 = 99% completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "mask_series = (hunting_df.percent_fit >= 0.0)\n",
    "for row_index, row_series in hunting_df[~mask_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)\n",
    "    if job_fitness > 0.8:\n",
    "        if all(qual_str in basic_quals_dict for qual_str in quals_list):\n",
    "            update_hunting(hunting_df, row_index, row_series, qual_sum, quals_list)\n",
    "        else:\n",
    "            break\n",
    "    elif len(quals_list):\n",
    "        update_hunting(hunting_df, row_index, row_series, qual_sum, quals_list)\n",
    "print('{}/{} = {}% completed'.format(hunting_df[mask_series].shape[0], hunting_df.shape[0],\n",
    "                                     int(100 * hunting_df[mask_series].shape[0] / hunting_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2696d4e4-fba6-42ca-92ab-e4308b51ec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hunting_df.percent_fit.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adde7906-399d-4a84-a2cb-ed327f307ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 754/756 = 99% completed\n",
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd03b8-c0a3-404c-a16d-eb4ce95c6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[1]\n",
    "print(qualification_str)\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50146b21-cb1d-4475-9465-2a383f002533",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6efb8-6b56-43dd-9079-d6a87491ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = row_series.file_name\n",
    "# file_name = 'Senior_Data_Scientist Statistics_and_Machine_Learning_b7c10bcd03f70654.html'\n",
    "print(file_name)\n",
    "child_strs_list = ha.get_child_strs_from_file(file_name=file_name)\n",
    "cu.ensure_filename(file_name, verbose=False)\n",
    "cu.populate_from_child_strings(child_strs_list, file_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9131d92-4c07-4cf0-9718-a8da37bf794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "child_tags_list = ha.get_child_tags_list(child_strs_list)\n",
    "print(child_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fefebb4-fb42-40bd-8d1d-16efecbe38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_header_list = []\n",
    "for is_header, child_str in zip(ha.get_is_header_list(child_strs_list), child_strs_list):\n",
    "    if is_header is None:\n",
    "        probs_list = lru.ISHEADER_PREDICT_PERCENT_FIT(child_str)\n",
    "        idx = probs_list.index(max(probs_list))\n",
    "        is_header = [True, False][idx]\n",
    "    is_header_list.append(is_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ac0b6-abd5-4f4c-b562-f4af2c1f6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cu.create_h_pickle(verbose=False)\n",
    "NAVIGABLE_PARENT_IS_HEADER_DICT = s.load_object('NAVIGABLE_PARENT_IS_HEADER_DICT')\n",
    "for i, (is_header, child_str) in enumerate(zip(is_header_list, child_strs_list)):\n",
    "    print(i, NAVIGABLE_PARENT_IS_HEADER_DICT.get(child_str), is_header, child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0657df-23b0-430d-b31e-556a12a8bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_dict_list = hc.get_feature_dict_list(child_tags_list, is_header_list, child_strs_list)\n",
    "feature_dict_list[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb362a-f9e8-44b4-a105-40497b3f292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_tuple_list = []\n",
    "for feature_dict in feature_dict_list:\n",
    "    feature_tuple_list.append(hc.get_feature_tuple(feature_dict, pos_lr_predict_single=lru.pos_lr_predict_single, pos_crf_predict_single=None))\n",
    "feature_tuple_list[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4229ec-11a8-417a-8281-4bd489b49bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crf_list = crf.CRF.predict_single(crf.sent2features(feature_tuple_list))\n",
    "crf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c7d91-10f6-457f-b4fc-184ccc91e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_pos_list = []\n",
    "for navigable_parent in child_strs_list:\n",
    "    db_pos_list = cu.append_parts_of_speech_list(navigable_parent, pos_list=db_pos_list)\n",
    "db_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e521577-acb9-4305-97d8-fa9d031fae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.colors import to_hex\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Make an RGB dictionary of all the parts-of-speech symbols\n",
    "rgba_dict = su.get_pos_color_dictionary()\n",
    "\n",
    "html_str = ''\n",
    "pos_list = []\n",
    "for i, (crf_symbol, db_symbol) in enumerate(zip(crf_list, db_pos_list)):\n",
    "    if db_symbol in [None, 'O', 'H']:\n",
    "        pos_list.append(crf_symbol)\n",
    "    else:\n",
    "        pos_list.append(db_symbol)\n",
    "indices_list = [i for i, x in enumerate(pos_list) if (x in ['O-RQ', 'O-ER'])]\n",
    "print(indices_list)\n",
    "for i, (child_str, pos_symbol) in enumerate(zip(child_strs_list, pos_list)):\n",
    "    rgba = rgba_dict[pos_symbol]\n",
    "    hex_str = to_hex(rgba, keep_alpha=True)\n",
    "    if len(indices_list) and (i == min(indices_list)):\n",
    "        html_str += '<hr />'\n",
    "    child_str = su.append_pos_symbol(child_str, pos_symbol, use_explanation=True)\n",
    "    html_str += f'{i+0} {pos_symbol}) <span style=\"color:{hex_str};\">{child_str}</span><br />'\n",
    "    if len(indices_list) and (i == max(indices_list)):\n",
    "        html_str += '<hr />'\n",
    "display(HTML(html_str))\n",
    "print(indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc02fb-b54e-4db6-9268-7a5f7baf81ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dfa2e-4e09-4da7-b046-98f5c170ec67",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4937f42-336d-4a5e-9ae9-b0942d639161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hand-label individual child strings\n",
    "idx = 32\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "if(child_str in basic_quals_dict):\n",
    "    print(basic_quals_dict[child_str])\n",
    "child_str = cu.clean_text(child_str)\n",
    "print(child_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8cbe7e-1006-438d-99d7-dcf19112f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hand-label this particular child string in the quals dictionary\n",
    "# child_str = '<li>BS degree in CS, EE, math, or similar field, or equivalent experience</li>'\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_dict[child_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {basic_quals_dict[child_str]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76d1e0-bb9e-41a2-bd1e-61667bea8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cypher_str = f'''\n",
    "    MATCH (np:NavigableParents {{navigable_parent: '{child_str}'}})\n",
    "    SET\n",
    "        np.is_header = 'False',\n",
    "        np.is_task_scope = 'False',\n",
    "        np.is_minimum_qualification = 'False',\n",
    "        np.is_preferred_qualification = 'False',\n",
    "        np.is_legal_notification = 'True',\n",
    "        np.is_job_title = 'False',\n",
    "        np.is_office_location = 'False',\n",
    "        np.is_job_duration = 'False',\n",
    "        np.is_supplemental_pay = 'False',\n",
    "        np.is_educational_requirement = 'False',\n",
    "        np.is_interview_procedure = 'False',\n",
    "        np.is_corporate_scope = 'False',\n",
    "        np.is_posting_date = 'False',\n",
    "        np.is_other = 'False'\n",
    "    RETURN\n",
    "        np.navigable_parent AS navigable_parent,\n",
    "        np.is_header AS is_header,\n",
    "        np.is_task_scope AS is_task_scope,\n",
    "        np.is_minimum_qualification AS is_minimum_qualification,\n",
    "        np.is_preferred_qualification AS is_preferred_qualification,\n",
    "        np.is_legal_notification AS is_legal_notification,\n",
    "        np.is_job_title AS is_job_title,\n",
    "        np.is_office_location AS is_office_location,\n",
    "        np.is_job_duration AS is_job_duration,\n",
    "        np.is_supplemental_pay AS is_supplemental_pay,\n",
    "        np.is_educational_requirement AS is_educational_requirement,\n",
    "        np.is_interview_procedure AS is_interview_procedure,\n",
    "        np.is_corporate_scope AS is_corporate_scope,\n",
    "        np.is_posting_date AS is_posting_date,\n",
    "        np.is_other AS is_other;'''\n",
    "# print(cypher_str)\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, cypher_str)\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e430da-5ec7-4885-9db1-06bcef8c33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what's in the database already for this html string\n",
    "# print(navigable_parent_cypher_str.format(child_str))\n",
    "with cu.driver.session() as session:\n",
    "    row_objs_list = session.write_transaction(cu.do_cypher_tx, navigable_parent_cypher_str.format(child_str))\n",
    "row_objs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9799d12-801a-4c0b-99bc-4b66a011066d",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767d2cb-2c13-421a-b29e-546d2b1b401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove this particular child string from the quals dictionary\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "child_str = child_strs_list[idx]\n",
    "basic_quals_dict.pop(child_str)\n",
    "# basic_quals_dict[child_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)\n",
    "print(f'\"{child_str}\" in basic_quals_dict: {child_str in basic_quals_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c9dd8-86df-445c-ae7b-401f1979370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show what qualifications you have for this posting\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "file_name = 'Sr_Data_Analyst_with_Customer_Data_Services_-_New_York,_NY_-_Indeed.com_0540b5b387d37378.html'\n",
    "mask_series = (hunting_df.file_name == file_name)\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "for row_index, row_series in hunting_df[mask_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)\n",
    "display(HTML(f'I only meet {job_fitness:.1%} of the minimum requirements:'))\n",
    "for i, qual_str in enumerate(quals_list):\n",
    "    if qual_str in basic_quals_dict:\n",
    "        if basic_quals_dict[qual_str]:\n",
    "            idx = qual_str.find('>')\n",
    "            if idx == -1:\n",
    "                display(HTML(f'{i+1}) {qual_str}'))\n",
    "            else:\n",
    "                display(HTML(f'{qual_str[:idx+1]}{i+1}) {qual_str[idx+1:]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa8961-cbbd-4bc9-b35e-bc3625249c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cu.create_h_pickle(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42dfcf-8776-43b2-b00c-d3f5af1751b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quals_list = [child_str for i, child_str in enumerate(child_strs_list) if i in indices_list]\n",
    "quals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1729f-9df6-409b-9e13-c11c3e3e1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_list = list(predict_job_hunt_percent_fit(quals_list))\n",
    "prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed19f97-eb6f-4868-90b5-4803d0186e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
