{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output, display\n",
    "from cohere.error import CohereAPIError\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Cohere, OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from openai.error import RateLimitError\n",
    "from pandas import DataFrame\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from tqdm.notebook import tqdm\n",
    "import humanize\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import winsound\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the Storage object\n",
    "from storage import Storage\n",
    "s = Storage(\n",
    "    data_folder_path=os.path.abspath('../data'),\n",
    "    saves_folder_path=os.path.abspath('../saves')\n",
    ")\n",
    "\n",
    "# Get the WebScrapingUtilities object\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(\n",
    "    s=s,\n",
    "    secrets_json_path=os.path.abspath('../data/secrets/jh_secrets.json')\n",
    ")\n",
    "\n",
    "# To get your API key, visit https://serpapi.com/dashboard\n",
    "os.environ['SERPAPI_API_KEY'] = wsu.secrets_json['SERPAPI_API_KEY']\n",
    "\n",
    "# To get your API key, visit https://dashboard.cohere.ai/api-keys\n",
    "os.environ['COHERE_API_KEY'] = wsu.secrets_json['Cohere_API_Key']\n",
    "\n",
    "# To get your API key, visit https://beta.dreamstudio.ai/membership\n",
    "os.environ['STABILITY_KEY'] = wsu.secrets_json['Dream_Studio_API_Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,116 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech logistic regression elements built in 8 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the HeaderAnalysis object\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "# Get the CypherUtilities object and Neo4j driver\n",
    "from cypher_utils import CypherUtilities\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "cu = CypherUtilities(\n",
    "    uri=uri, user=user, password=password, driver=None, s=s, ha=ha\n",
    ")\n",
    "\n",
    "# Get the SectionLRClassifierUtilities object\n",
    "from section_classifier_utils import SectionLRClassifierUtilities\n",
    "slrcu = SectionLRClassifierUtilities(ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "# Check if the slrcu has built its parts-of-speech logistic regression elements\n",
    "t1 = time.time()\n",
    "if not hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    slrcu.build_pos_logistic_regression_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(slrcu, 'pos_predict_percent_fit_dict'):\n",
    "    print('predict_single is now available')\n",
    "else:\n",
    "    print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Parts-of-speech logistic regression elements built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_single is now available\n",
      "Parts-of-speech conditional random field elements built in 1 second\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the SectionCRFClassifierUtilities object\n",
    "from section_classifier_utils import SectionCRFClassifierUtilities\n",
    "scrfcu = SectionCRFClassifierUtilities(cu=cu, ha=ha, verbose=False)\n",
    "\n",
    "# Check if the scrfcu has built its parts-of-speech conditional random field elements\n",
    "t1 = time.time()\n",
    "if not hasattr(scrfcu, 'pos_symbol_crf'):\n",
    "    scrfcu.build_pos_conditional_random_field_elements(verbose=True)\n",
    "if hasattr(scrfcu, 'pos_predict_percent_fit_dict'):\n",
    "    print('predict_single is now available')\n",
    "else:\n",
    "    print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Parts-of-speech conditional random field elements built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 49,116 labeled parts of speech in here\n",
      "predict_single is now available\n",
      "Parts-of-speech stochastic gradient descent elements built in 9 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the SectionSGDClassifierUtilities object\n",
    "from section_classifier_utils import SectionSGDClassifierUtilities\n",
    "ssgdcu = SectionSGDClassifierUtilities(ha=ha, cu=cu, verbose=False)\n",
    "\n",
    "# Check if the ssgdcu has built its parts-of-speech stochastic gradient decent elements\n",
    "t1 = time.time()\n",
    "if not hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    ssgdcu.build_pos_stochastic_gradient_descent_elements(sampling_strategy_limit=None, verbose=True)\n",
    "if hasattr(ssgdcu, 'pos_predict_percent_fit_dict'):\n",
    "    print('predict_single is now available')\n",
    "else:\n",
    "    print('predict_single is not available')\n",
    "duration_str = humanize.precisedelta(time.time() - t1, minimum_unit='seconds', format='%0.0f')\n",
    "print(f'Parts-of-speech stochastic gradient descent elements built in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Trial key rate limit - 5 API calls / minute\n",
    "@sleep_and_retry\n",
    "@limits(calls=5, period=60)\n",
    "def get_suggestion(chain, navigable_parent):\n",
    "    llm_suggestion = chain.run(navigable_parent).strip()\n",
    "    \n",
    "    return llm_suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_file_in_text_editor(file_name):\n",
    "    text_editor_path = r\"C:\\Program Files\\Notepad++\\notepad++.exe\"\n",
    "    file_path = os.path.join(ha.SAVES_HTML_FOLDER, file_name)\n",
    "    !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Get GPT's help to break up overly-long O-RQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navigable_parent</th>\n",
       "      <th>file_name</th>\n",
       "      <th>char_count</th>\n",
       "      <th>llm_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experience in all phases of SDLC like Requirem...</td>\n",
       "      <td>1c57f00badeec1a2_Principal_Full_Stack_Engineer...</td>\n",
       "      <td>381</td>\n",
       "      <td>&lt;p&gt;We are seeking a candidate with the followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: No one is perfect. You’ve made some mistakes...</td>\n",
       "      <td>c5998e2b1c9b877e_Senior_Software_Engineer_Remo...</td>\n",
       "      <td>381</td>\n",
       "      <td>&lt;p&gt;No one is perfect. You’ve made some mistake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We’re looking for a QA Engineer to be a key me...</td>\n",
       "      <td>e35bac775dc584b1_QA_Engineer_Remote_Indeed_com...</td>\n",
       "      <td>380</td>\n",
       "      <td>&lt;p&gt;We are seeking a candidate with the followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;li&gt;Familiarity with statistical methods and r...</td>\n",
       "      <td>40f70f73663d2525_Data_Scientist_II_Remote_Inde...</td>\n",
       "      <td>379</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;li&gt;A minimum of 8 years beyond a bachelor’s d...</td>\n",
       "      <td>b18474e2fa35c2f2_Senior_Research_Officer_Washi...</td>\n",
       "      <td>378</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;li&gt;Advanced user of Microsoft Office (includi...</td>\n",
       "      <td>b18474e2fa35c2f2_Senior_Research_Officer_Washi...</td>\n",
       "      <td>378</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;li&gt;Analytical Skills: A candidate for this po...</td>\n",
       "      <td>Senior_Data_Analyst_-_Washington_State_-_Indee...</td>\n",
       "      <td>377</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our ideal teammate is someone who is a continu...</td>\n",
       "      <td>Junior_Data_Scientist_Data_Science_Development...</td>\n",
       "      <td>375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;li&gt;Ability to run standard model algorithms i...</td>\n",
       "      <td>Lead_Data_Scientist_World_Wide_Technology_Remo...</td>\n",
       "      <td>374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;li&gt;Ability to run standard model algorithms i...</td>\n",
       "      <td>Data_Scientist_World_Wide_Technology_Remote_or...</td>\n",
       "      <td>374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;div&gt;Eight years of advanced analytics experie...</td>\n",
       "      <td>3c12fd2ee4ca9386_Lead_Data_Scientist_Lehi_UT_8...</td>\n",
       "      <td>372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This position requires a recent Ph.D. in compu...</td>\n",
       "      <td>eb556b650e073d84_Research_Biologist_Computatio...</td>\n",
       "      <td>372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;li&gt;Bachelor’s degree in computer science, dat...</td>\n",
       "      <td>9ee5ff7ef058e633_Data_Engineer_Senior_Blooming...</td>\n",
       "      <td>369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;div&gt;5 years of advanced analytics experience ...</td>\n",
       "      <td>c733cdcfb1373458_Sr_Data_Scientist_Lehi_UT_840...</td>\n",
       "      <td>369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;p&gt;· Masters or PhD Degree with a minimum of 2...</td>\n",
       "      <td>Data_Scientist_(Fraud_Prevention)_-_Sam's_Club...</td>\n",
       "      <td>368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;li&gt;You are an excellent communicator / listen...</td>\n",
       "      <td>d8e3b247edeb5a3f_Data_Engineer_Remote_Indeed_c...</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;li&gt;You recognize and can apply engineering be...</td>\n",
       "      <td>Machine_Learning_Engineer_-_Remote_-_Indeed.co...</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>with at least five years experience in some so...</td>\n",
       "      <td>Lead_Data_Scientist_-_Remote_-_Indeed.com_327b...</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;li&gt;Possesses and applies expertise on multipl...</td>\n",
       "      <td>83ff1d9973fe7277_Systems_Engineer_Remote_Indee...</td>\n",
       "      <td>360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;p&gt;OB Media is seeking a quantitative-minded p...</td>\n",
       "      <td>e205913c0690efb7_Data_Analyst_Remote_Indeed_co...</td>\n",
       "      <td>358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     navigable_parent  \\\n",
       "0   Experience in all phases of SDLC like Requirem...   \n",
       "1   : No one is perfect. You’ve made some mistakes...   \n",
       "2   We’re looking for a QA Engineer to be a key me...   \n",
       "3   <li>Familiarity with statistical methods and r...   \n",
       "4   <li>A minimum of 8 years beyond a bachelor’s d...   \n",
       "5   <li>Advanced user of Microsoft Office (includi...   \n",
       "6   <li>Analytical Skills: A candidate for this po...   \n",
       "7   Our ideal teammate is someone who is a continu...   \n",
       "8   <li>Ability to run standard model algorithms i...   \n",
       "9   <li>Ability to run standard model algorithms i...   \n",
       "10  <div>Eight years of advanced analytics experie...   \n",
       "11  This position requires a recent Ph.D. in compu...   \n",
       "12  <li>Bachelor’s degree in computer science, dat...   \n",
       "13  <div>5 years of advanced analytics experience ...   \n",
       "14  <p>· Masters or PhD Degree with a minimum of 2...   \n",
       "15  <li>You are an excellent communicator / listen...   \n",
       "16  <li>You recognize and can apply engineering be...   \n",
       "17  with at least five years experience in some so...   \n",
       "18  <li>Possesses and applies expertise on multipl...   \n",
       "19  <p>OB Media is seeking a quantitative-minded p...   \n",
       "\n",
       "                                            file_name  char_count  \\\n",
       "0   1c57f00badeec1a2_Principal_Full_Stack_Engineer...         381   \n",
       "1   c5998e2b1c9b877e_Senior_Software_Engineer_Remo...         381   \n",
       "2   e35bac775dc584b1_QA_Engineer_Remote_Indeed_com...         380   \n",
       "3   40f70f73663d2525_Data_Scientist_II_Remote_Inde...         379   \n",
       "4   b18474e2fa35c2f2_Senior_Research_Officer_Washi...         378   \n",
       "5   b18474e2fa35c2f2_Senior_Research_Officer_Washi...         378   \n",
       "6   Senior_Data_Analyst_-_Washington_State_-_Indee...         377   \n",
       "7   Junior_Data_Scientist_Data_Science_Development...         375   \n",
       "8   Lead_Data_Scientist_World_Wide_Technology_Remo...         374   \n",
       "9   Data_Scientist_World_Wide_Technology_Remote_or...         374   \n",
       "10  3c12fd2ee4ca9386_Lead_Data_Scientist_Lehi_UT_8...         372   \n",
       "11  eb556b650e073d84_Research_Biologist_Computatio...         372   \n",
       "12  9ee5ff7ef058e633_Data_Engineer_Senior_Blooming...         369   \n",
       "13  c733cdcfb1373458_Sr_Data_Scientist_Lehi_UT_840...         369   \n",
       "14  Data_Scientist_(Fraud_Prevention)_-_Sam's_Club...         368   \n",
       "15  d8e3b247edeb5a3f_Data_Engineer_Remote_Indeed_c...         367   \n",
       "16  Machine_Learning_Engineer_-_Remote_-_Indeed.co...         366   \n",
       "17  Lead_Data_Scientist_-_Remote_-_Indeed.com_327b...         366   \n",
       "18  83ff1d9973fe7277_Systems_Engineer_Remote_Indee...         360   \n",
       "19  e205913c0690efb7_Data_Analyst_Remote_Indeed_co...         358   \n",
       "\n",
       "                                       llm_suggestion  \n",
       "0   <p>We are seeking a candidate with the followi...  \n",
       "1   <p>No one is perfect. You’ve made some mistake...  \n",
       "2   <p>We are seeking a candidate with the followi...  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if not s.pickle_exists('tldr_df'):\n",
    "    tldr_cypher_str = \"\"\"\n",
    "        // Filter for NavigableParents nodes with an ambiguous SUMMARIZES relationship\n",
    "        MATCH (np:NavigableParents)\n",
    "        WHERE size((np)<-[:SUMMARIZES]-(:PartsOfSpeech)) >= 1\n",
    "        WITH np\n",
    "\n",
    "        // Find all NavigableParents nodes in the graph with\n",
    "        // an incoming SUMMARIZES relationship to a PartsOfSpeech node\n",
    "        MATCH (np)<-[r:SUMMARIZES]-(pos:PartsOfSpeech)\n",
    "        WHERE\n",
    "            pos.pos_symbol = \"O-RQ\"\n",
    "            AND NOT (np.navigable_parent STARTS WITH \"<orq>\")\n",
    "        WITH np\n",
    "\n",
    "        // Find all the relationship types in the graph with a file_name property\n",
    "        MATCH (np)-[r:NEXT]-(:NavigableParents)\n",
    "        WHERE exists(r.file_name)\n",
    "        WITH np, r\n",
    "\n",
    "        // Return the navigable parent\n",
    "        RETURN DISTINCT\n",
    "            np.navigable_parent AS navigable_parent,\n",
    "            r.file_name AS file_name\n",
    "        ORDER BY size(navigable_parent) DESC;\"\"\"\n",
    "    with cu.driver.session() as session: tldr_df = DataFrame(session.write_transaction(cu.do_cypher_tx, tldr_cypher_str))\n",
    "    tldr_df['char_count'] = tldr_df.navigable_parent.map(lambda x: len(x))\n",
    "    if not 'llm_suggestion' in tldr_df.columns:\n",
    "        tldr_df['llm_suggestion'] = np.nan\n",
    "    s.store_objects(tldr_df=tldr_df, verbose=False)\n",
    "else: tldr_df = s.load_object('tldr_df')\n",
    "display(tldr_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = 'Break up the following HTML STRING into paragraphs and bullet points so that it is easier to read.'\n",
    "template += ' Ensure that the only thing added in the REFORMATTED HTML is tags, and nothing is rephrased.'\n",
    "\n",
    "# Hand-labeled examples\n",
    "template += '\\n\\nHTML STRING: \"with bachelor’s degree in Computer Science, Engineering Any, Technology or'\n",
    "template += ' related and 5 yrs. of exp to design & Implement test Automation Frameworks and suites using'\n",
    "template += ' the automation tools and technologies like HP UFT, Selenium Web Driver, Java, Python, Junit,'\n",
    "template += ' Macros, TestNG & Cucumber. Develop, integrate, and maintain Automation scripts. Work on'\n",
    "template += ' Continuous Integration tools (CI/CD) like Jenkins for continuous integration and deployment of'\n",
    "template += ' Automation builds. Have knowledge on understanding of API integration. Automate Database and'\n",
    "template += ' have SQL knowledge. Should be well versed in using various highly specialized tools and'\n",
    "template += ' technologies like Jira, ALM, Appium, Protractor, Jasmine, Maven, ANT, Jenkins, AWS, DevOps,'\n",
    "template += ' CVCD Toolset, TOSCA, Gherkin, Groovy, Rest Assured, Postman, HTML and SoapUI. Should have good'\n",
    "template += ' communication skills and experience in agile/scrum, implementing overall testing strategy,'\n",
    "template += ' estimates and able to manage a team.\"\\n=========\\n'\n",
    "template += 'REFORMATTED HTML:\\n'\n",
    "template += \"\"\"\n",
    "<p>We are seeking a candidate with the following qualifications:</p>\n",
    "<ul>\n",
    "    <li>Bachelor’s degree in Computer Science, Engineering Any, Technology or related field</li>\n",
    "    <li>5 years of experience in designing and implementing test automation frameworks and suites</li>\n",
    "</ul>\n",
    "<p>The ideal candidate should have expertise in the following areas:</p>\n",
    "<ul>\n",
    "    <li>\n",
    "        Automation tools and technologies, such as:\n",
    "        <ul>\n",
    "            <li>HP UFT</li>\n",
    "            <li>Selenium Web Driver</li>\n",
    "            <li>Java</li>\n",
    "            <li>Python</li>\n",
    "            <li>Junit</li>\n",
    "            <li>Macros</li>\n",
    "            <li>TestNG</li>\n",
    "            <li>Cucumber</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Developing, integrating, and maintaining automation scripts</li>\n",
    "    <li>\n",
    "        Working with Continuous Integration tools (CI/CD), such as:\n",
    "        <ul>\n",
    "            <li>Jenkins, for continuous integration and deployment of automation builds</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Understanding of API integration</li>\n",
    "    <li>Automating databases and having SQL knowledge</li>\n",
    "    <li>\n",
    "        Using various highly specialized tools and technologies, such as:\n",
    "        <ul>\n",
    "            <li>Jira</li>\n",
    "            <li>ALM</li>\n",
    "            <li>Appium</li>\n",
    "            <li>Protractor</li>\n",
    "            <li>Jasmine</li>\n",
    "            <li>Maven</li>\n",
    "            <li>ANT</li>\n",
    "            <li>Jenkins</li>\n",
    "            <li>AWS</li>\n",
    "            <li>DevOps</li>\n",
    "            <li>CVCD Toolset</li>\n",
    "            <li>TOSCA</li>\n",
    "            <li>Gherkin</li>\n",
    "            <li>Groovy</li>\n",
    "            <li>Rest Assured</li>\n",
    "            <li>Postman</li>\n",
    "            <li>HTML</li>\n",
    "            <li>SoapUI</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<p>In addition, the candidate should:</p>\n",
    "<ul>\n",
    "    <li>Have good communication skills</li>\n",
    "    <li>Have experience in agile/scrum methodologies</li>\n",
    "    <li>Be able to implement an overall testing strategy and provide estimates</li>\n",
    "    <li>Be able to manage a team.</li>\n",
    "</ul>\"\"\"\n",
    "\n",
    "template += '\\n\\nHTML STRING: \"{html_str}\"\\n=========\\nREFORMATTED HTML:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['html_str'],\n",
    "    template=template,\n",
    ")\n",
    "# llm = OpenAI(model_name='text-davinci-003', temperature=1.0, max_retries=1)\n",
    "llm = Cohere(model='command-xlarge-nightly', temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(prompt.format(html_str=tldr_df.loc[0, 'navigable_parent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\tldr_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tldr_df = s.load_object('tldr_df')\n",
    "mask_series = tldr_df.llm_suggestion.isnull()\n",
    "for row_index, row_series in tldr_df[mask_series].iterrows():\n",
    "    navigable_parent = row_series.navigable_parent\n",
    "    try:\n",
    "        llm_suggestion = get_suggestion(chain, navigable_parent)\n",
    "        time.sleep(1) # Sleep for 1 second between each call\n",
    "    except RateLimitError:\n",
    "        print(\"You've already spent 10 bucks on this; your wife will be pissed\")\n",
    "        break\n",
    "    except CohereAPIError as e:\n",
    "        message_str = str(e).strip()\n",
    "        if 'too many tokens' in message_str:\n",
    "            print(message_str)\n",
    "            break\n",
    "        time.sleep(60)\n",
    "        llm_suggestion = get_suggestion(chain, navigable_parent)\n",
    "        time.sleep(1) # Sleep for 1 second between each call\n",
    "    except Exception as e:\n",
    "        print(f'{e.__class__} error: {str(e).strip()}')\n",
    "        print()\n",
    "        print(f\"\"\"template += '\\\\n\\\\nHTML STRING: \"{navigable_parent}\"\\\\n=========\\\\n'\"\"\")\n",
    "        print(\"\"\"template += 'REFORMATTED HTML:\\\\n'\"\"\")\n",
    "        print(f\"mask_series = (tldr_df.navigable_parent == '{navigable_parent}')\")\n",
    "        break\n",
    "    tldr_df.loc[row_index, 'llm_suggestion'] = llm_suggestion\n",
    "    s.store_objects(tldr_df=tldr_df, verbose=True)\n",
    "    break\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<p>· Masters or PhD Degree with a minimum of 2 years experience in at least one of the following: Machine Learning (Supervised, Unsupervised), Bayesian Statistics, Statistical Modeling (e.g. Survival Analysis, Generalized Linear models), Advanced Machine Learning (e.g. Reinforcement Learning, Deep Learning) , NLP, Dynamic Programming &amp; Optimal Control Theory</p>\n",
      "\n",
      "<p>We are seeking a candidate with the following qualifications:</p>\n",
      "<ul>\n",
      "    <li>Masters or PhD degree with a minimum of 2 years experience in at least one of the following: Machine Learning (Supervised, Unsupervised), Bayesian Statistics, Statistical Modeling (e.g. Survival Analysis, Generalized Linear models), Advanced Machine Learning (e.g. Reinforcement Learning, Deep Learning) , NLP, Dynamic Programming &amp; Optimal Control Theory</li>\n",
      "</ul>\n",
      "<p>The ideal candidate should have expertise in the following areas:</p>\n",
      "<ul>\n",
      "    <li>\n",
      "        Machine Learning (Supervised, Unsupervised), Bayesian Statistics, Statistical Modeling (e.g. Survival Analysis, Generalized Linear models), Advanced Machine Learning (e.g. Reinforcement Learning, Deep Learning) , NLP, Dynamic Programming &amp; Optimal Control Theory</li>\n",
      "    <li>\n",
      "        Python</li>\n",
      "        <ul>\n",
      "            <li\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Break up overly-long O-RQs:\n",
    "# Don't close the Notepad++ window until you have replaced the child string\n",
    "file_name = tldr_df.loc[row_index, 'file_name']\n",
    "child_str = tldr_df.loc[row_index, 'navigable_parent']\n",
    "print()\n",
    "print(child_str)\n",
    "print()\n",
    "print(tldr_df.loc[row_index, 'llm_suggestion'])\n",
    "winsound.Beep(freq, duration)\n",
    "display_file_in_text_editor(tldr_df.loc[row_index, 'file_name'])\n",
    "cu.rebuild_filename_node(file_name, wsu, navigable_parent=child_str, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Go ahead and update what you can in the database\n",
    "tldr_df = s.load_object('tldr_df')\n",
    "mask_series = ~tldr_df.llm_suggestion.isnull()\n",
    "for (row_index, row_series) in tqdm(tldr_df[mask_series].iterrows(), total=tldr_df[mask_series].shape[0]):\n",
    "\n",
    "    # Open the file in read mode\n",
    "    file_name = row_series.file_name\n",
    "    file_path = os.path.join(ha.SAVES_HTML_FOLDER, file_name)\n",
    "    with open(file_path, 'r', encoding=s.encoding_type) as file:\n",
    "        \n",
    "        # Read the file content\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Replace some text\n",
    "    old_child_str = row_series.navigable_parent\n",
    "    new_child_str = row_series.llm_suggestion\n",
    "    file_content = file_content.replace(old_child_str, new_child_str)\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(file_path, 'w', encoding=s.encoding_type) as file:\n",
    "        \n",
    "        # Write the modified content to the file\n",
    "        file.write(file_content)\n",
    "    \n",
    "    # Rebuild the node in the database\n",
    "    cu.rebuild_filename_node(file_name, wsu, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Job Hunting (Python 3.10.9)",
   "language": "python",
   "name": "jh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
