{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7259adf2-2eb9-49cf-973a-9312f45183aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c90ada4-c985-45b0-aee6-2acd3c4be606",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc60d4aa-3cfe-4675-85f7-8abe9cc0b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cac595b-abe4-4471-928d-c77de0bda920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the Neo4j driver\n",
    "from storage import Storage\n",
    "s = Storage()\n",
    "\n",
    "from ha_utils import HeaderAnalysis\n",
    "ha = HeaderAnalysis(s=s, verbose=False)\n",
    "\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(s=s)\n",
    "uri = wsu.secrets_json['neo4j']['connect_url']\n",
    "user =  wsu.secrets_json['neo4j']['username']\n",
    "password = wsu.secrets_json['neo4j']['password']\n",
    "\n",
    "from cypher_utils import CypherUtilities\n",
    "cu = CypherUtilities(uri=uri, user=user, password=password, driver=None, s=s, ha=ha)\n",
    "\n",
    "from is_header_sgd_classifier import IsHeaderSgdClassifier\n",
    "ihu = IsHeaderSgdClassifier(ha=ha, cu=cu, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d69104-f878-4368-b707-0c0b343ee9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Neo4j/4.4.7 ========\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "try:\n",
    "    version_str = cu.driver.verify_connectivity()\n",
    "    print(f'======== {version_str} ========')\n",
    "    \n",
    "    from hc_utils import HeaderCategories\n",
    "    hc = HeaderCategories(cu=cu, verbose=False)\n",
    "    \n",
    "    from section_utils import SectionUtilities\n",
    "    su = SectionUtilities(verbose=False)\n",
    "    \n",
    "    from lr_utils import LrUtilities\n",
    "    lru = LrUtilities(ha=ha, cu=cu, hc=hc, verbose=False)\n",
    "    \n",
    "    from crf_utils import CrfUtilities\n",
    "    crfu = CrfUtilities(ha=ha, hc=hc, cu=cu, verbose=False)\n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except ServiceUnavailable as e:\n",
    "    # print(str(e).strip())\n",
    "    raise ServiceUnavailable('You need to start Neo4j as a console')\n",
    "except Exception as e:\n",
    "    print(f'{e.__class__}: {str(e).strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12509eaf-5457-43b9-8ef8-3328c335dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on 2023-01-06 15:10:06.137222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import time\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import winsound\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 880  # Hz\n",
    "width_inches = 18.0\n",
    "height_inches = 3.0\n",
    "bin_count = 12\n",
    "print(f'Last run on {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e52e65-5588-48b8-9edc-a321e3fcda94",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029e4453-6ce7-4c5a-9bba-1f65f35debff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is-header classifier retrained in 16 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You need to run this again if you changed the qualification dictionary in another notebook\n",
    "t1 = time.time()\n",
    "\n",
    "# Keep the total retraining time to less than two minutes by adjusting the sampling strategy limit\n",
    "lru.sync_basic_quals_dict(sampling_strategy_limit=None, verbose=False)\n",
    "\n",
    "ihu.retrain_classifier(new_data_list, new_labels_list, verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Is-header classifier retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b9d4954-951c-4f49-8964-934109b82316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts-of-speech classifier retrained in 10 minutes and 3 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "slrcu.build_pos_logistic_regression_elements(verbose=False)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Parts-of-speech classifier rebuilt in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af630a1e-5713-4e9b-8958-d750c3878c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 7,124 hand-labeled qualification strings in here\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_dict.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\basic_quals_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_VOCAB.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_TT.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\ISQUALIFIED_LR.pkl\n",
      "Retraining complete\n",
      "Is-qualified classifer retrained in 17 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rebuild the classifer from the quals dictionary\n",
    "t0 = time.time()\n",
    "lru.build_isqualified_logistic_regression_elements(verbose=False)\n",
    "lru.retrain_isqualified_classifier(verbose=True)\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Is-qualified classifer retrained in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67b087-6906-4998-b92d-78c1ac8231b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the training data\n",
    "t0 = time.time()\n",
    "HEADER_PATTERN_DICT = s.load_object('HEADER_PATTERN_DICT')\n",
    "X_train = []\n",
    "y_train = []\n",
    "for file_name, feature_dict_list in HEADER_PATTERN_DICT.items():\n",
    "    feature_tuple_list = [hc.get_feature_tuple(feature_dict, pos_lr_predict_single=slrcu.predict_single, pos_crf_predict_single=None, pos_sgd_predict_single=None) for feature_dict in feature_dict_list]\n",
    "    pos_list = [feature_tuple[2] for feature_tuple in feature_tuple_list]\n",
    "    y_train.append(pos_list)\n",
    "    X_train.append(crfu.sent2features(feature_tuple_list))\n",
    "duration_str = humanize.precisedelta(time.time() - t0, minimum_unit='seconds', format='%0.0f')\n",
    "winsound.Beep(freq, duration)\n",
    "print(f'Training data created in {duration_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb27b1f6-2176-4e1d-9816-5df2f58f4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn_crfsuite\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define fixed parameters and parameters to search\n",
    "CRF = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fa8e64f-672f-4261-9275-9ea8ace27542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O-O', 'H-O', 'O-JT', 'O-OL', 'H-JD', 'H-TS', 'O-TS', 'H-RQ', 'H-PQ', 'H-CS', 'O-CS', 'O-RQ', 'O-LN', 'O-PQ', 'H-SP', 'O-SP', 'H-PD', 'H-OL', 'H-LN', 'O-JD', 'H-ER', 'H-IP', 'O-ER', 'H-JT', 'O-IP']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CRF.fit(X_train, y_train)\n",
    "labels = list(CRF.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00ef153c-4fd8-4290-a6d4-71a7b1075fd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CRF' object has no attribute 'keep_tempfiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Search\u001b[39;00m\n\u001b[0;32m     11\u001b[0m rs \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     12\u001b[0m     CRF, params_space, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mf1_scorer\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:789\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    786\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[0;32m    787\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[1;32m--> 789\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    791\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch)\n\u001b[0;32m    793\u001b[0m fit_and_score_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    794\u001b[0m     scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    795\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    801\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    802\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:85\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[0;32m     82\u001b[0m             )\n\u001b[0;32m     84\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m---> 85\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     87\u001b[0m     new_object_params[name] \u001b[38;5;241m=\u001b[39m clone(param, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:211\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    209\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m--> 211\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    213\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
     ]
    }
   ],
   "source": [
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# Use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# Search\n",
    "rs = RandomizedSearchCV(\n",
    "    CRF, params_space, cv=3, verbose=1, n_jobs=-1, n_iter=50, scoring=f1_scorer\n",
    ")\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be202e7d-0ba0-421c-a4d9-5c286dd2c8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
